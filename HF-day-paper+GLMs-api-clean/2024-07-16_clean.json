[
    "1. \"Qwen2 Technical Report\" - ID: 2407.10671\n2. \"Learning to Refuse: Towards Mitigating Privacy Risks in LLMs\" - ID: 2407.10058\n3. \"The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism\" - ID: 2407.10457\n4. \"Q-Sparse: All Large Language Models can be Fully Sparsely-Activated\" - ID: 2407.10969\n5. \"GRUtopia: Dream General Robots in a City at Scale\" - ID: 2407.10943\n6. \"Make-An-Agent: A Generalizable Policy Network Generator with Behavior-Prompted Diffusion\" - ID: 2407.10973\n7. \"Masked Generative Video-to-Audio Transformers with Enhanced Synchronicity\" - ID: 2407.10387\n8. \"SHERL: Synthesizing High Accuracy and Efficient Memory for Resource-Limited Transfer Learning\" - ID: 2407.07523\n9. \"Video Occupancy Models\" - ID: 2407.09533\n10. \"Noise Calibration: Plug-and-play Content-Preserving Video Enhancement using Pre-trained Video Diffusion Models\" - ID: 2407.10285\n11. \"LLM Circuit Analyses Are Consistent Across Training and Scale\" - ID: 2407.10827\n12. \"DataDream: Few-shot Guided Dataset Generation\" - ID: 2407.10910\n13. \"MMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models\" - ID: 2407.10953\n14. \"LAB-Bench: Measuring Capabilities of Language Models for Biology Research\" - ID: 2407.10362"
]