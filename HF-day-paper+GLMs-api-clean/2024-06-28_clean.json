[
    "1. \"OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding\" - ID: 2406.19389\n2. \"Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs\" - ID: 2406.18629\n3. \"Simulating Classroom Education with LLM-Empowered Agents\" - ID: 2406.19226\n4. \"SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation\" - ID: 2406.19215\n5. \"Aligning Teacher with Student Preferences for Tailored Training Data Generation\" - ID: 2406.19227\n6. \"MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression\" - ID: 2406.14909\n7. \"Can LLMs Learn by Teaching? A Preliminary Study\" - ID: 2406.14629\n8. \"MUMU: Bootstrapping Multimodal Image Generation from Text-to-Image Data\" - ID: 2406.18790\n9. \"Is Programming by Example solved by LLMs?\" - ID: 2406.08316\n10. \"Dataset Size Recovery from LoRA Weights\" - ID: 2406.19395\n11. \"LiveBench: A Challenging, Contamination-Free LLM Benchmark\" - ID: 2406.19314\n12. \"Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding\" - ID: 2406.19263\n13. \"ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech Recognition Using LLMs\" - ID: 2406.18120\n14. \"Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation\" - ID: 2406.18676\n15. \"Benchmarking Mental State Representations in Language Models\" - ID: 2406.17513\n16. \"ResumeAtlas: Revisiting Resume Classification with Large-Scale Datasets and Large Language Models\" - ID: 2406.18125\n17. \"T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings\" - ID: 2406.19223"
]