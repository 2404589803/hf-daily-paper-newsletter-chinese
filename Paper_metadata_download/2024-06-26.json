[
    {
        "paper": {
            "id": "2406.17557",
            "authors": [
                {
                    "_id": "667baf1709faa9d48c05b503",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62596f9e1c0a084224b93e00/X2aLkJ0ofhkXwAg7lXvxD.jpeg",
                        "isPro": false,
                        "fullname": "Guilherme Penedo",
                        "user": "guipenedo",
                        "type": "user"
                    },
                    "name": "Guilherme Penedo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:02.663Z",
                    "hidden": false
                },
                {
                    "_id": "667baf1709faa9d48c05b504",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626ede24d2fa9e7d598c8709/JKS8-Y2Jw87EgNQZBRswq.jpeg",
                        "isPro": false,
                        "fullname": "Hynek Kydlicek",
                        "user": "hynky",
                        "type": "user"
                    },
                    "name": "Hynek Kydlíček",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:53:11.720Z",
                    "hidden": false
                },
                {
                    "_id": "667baf1709faa9d48c05b505",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg",
                        "isPro": false,
                        "fullname": "Loubna Ben Allal",
                        "user": "loubnabnl",
                        "type": "user"
                    },
                    "name": "Loubna Ben allal",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:36:05.109Z",
                    "hidden": false
                },
                {
                    "_id": "667baf1709faa9d48c05b506",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1613655355830-noauth.png",
                        "isPro": false,
                        "fullname": "Anton Lozhkov",
                        "user": "anton-l",
                        "type": "user"
                    },
                    "name": "Anton Lozhkov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:53:20.691Z",
                    "hidden": false
                },
                {
                    "_id": "667baf1709faa9d48c05b507",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1626214544196-60c757ea5f9a76ab3f844f12.png",
                        "isPro": false,
                        "fullname": "Margaret Mitchell",
                        "user": "meg",
                        "type": "user"
                    },
                    "name": "Margaret Mitchell",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:53:30.450Z",
                    "hidden": false
                },
                {
                    "_id": "667baf1709faa9d48c05b508",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1618592397610-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Colin Raffel",
                        "user": "craffel",
                        "type": "user"
                    },
                    "name": "Colin Raffel",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:53:36.838Z",
                    "hidden": false
                },
                {
                    "_id": "667baf1709faa9d48c05b509",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5e48005437cb5b49818287a5/4uCXGGui-9QifAT4qelxU.png",
                        "isPro": false,
                        "fullname": "Leandro von Werra",
                        "user": "lvwerra",
                        "type": "user"
                    },
                    "name": "Leandro Von Werra",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:53:42.769Z",
                    "hidden": false
                },
                {
                    "_id": "667baf1709faa9d48c05b50a",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1583857746553-5df7e9e5da6d0311fd3d53f9.jpeg",
                        "isPro": true,
                        "fullname": "Thomas Wolf",
                        "user": "thomwolf",
                        "type": "user"
                    },
                    "name": "Thomas Wolf",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:53:49.151Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T13:50:56.000Z",
            "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at\n  Scale",
            "summary": "The performance of a large language model (LLM) depends heavily on the\nquality and size of its pretraining dataset. However, the pretraining datasets\nfor state-of-the-art open LLMs like Llama 3 and Mixtral are not publicly\navailable and very little is known about how they were created. In this work,\nwe introduce FineWeb, a 15-trillion token dataset derived from 96 Common Crawl\nsnapshots that produces better-performing LLMs than other open pretraining\ndatasets. To advance the understanding of how best to curate high-quality\npretraining datasets, we carefully document and ablate all of the design\nchoices used in FineWeb, including in-depth investigations of deduplication and\nfiltering strategies. In addition, we introduce FineWeb-Edu, a 1.3-trillion\ntoken collection of educational text filtered from FineWeb. LLMs pretrained on\nFineWeb-Edu exhibit dramatically better performance on knowledge- and\nreasoning-intensive benchmarks like MMLU and ARC. Along with our datasets, we\npublicly release our data curation codebase and all of the models trained\nduring our ablation experiments.",
            "upvotes": 42
        },
        "publishedAt": "2024-06-26T04:44:38.772Z",
        "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17557.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png",
            "fullname": "Philipp Schmid",
            "name": "philschmid",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17636",
            "authors": [
                {
                    "_id": "667bb9fcb9e88cc05404e766",
                    "user": {
                        "avatarUrl": "/avatars/35f6f6eb2e8f6b283034632a141c2670.svg",
                        "isPro": false,
                        "fullname": "Alexander Gambashidze",
                        "user": "alexgambashidze",
                        "type": "user"
                    },
                    "name": "Alexander Gambashidze",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-26T06:49:36.679Z",
                    "hidden": false
                },
                {
                    "_id": "667bb9fcb9e88cc05404e767",
                    "user": {
                        "avatarUrl": "/avatars/6f241c967b045c6d18fba8efd0fee3c6.svg",
                        "isPro": false,
                        "fullname": "Anton Kulikov",
                        "user": "neolizee",
                        "type": "user"
                    },
                    "name": "Anton Kulikov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T10:00:33.181Z",
                    "hidden": false
                },
                {
                    "_id": "667bb9fcb9e88cc05404e768",
                    "name": "Yuriy Sosnin",
                    "hidden": false
                },
                {
                    "_id": "667bb9fcb9e88cc05404e769",
                    "name": "Ilya Makarov",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T15:21:50.000Z",
            "title": "Aligning Diffusion Models with Noise-Conditioned Perception",
            "summary": "Recent advancements in human preference optimization, initially developed for\nLanguage Models (LMs), have shown promise for text-to-image Diffusion Models,\nenhancing prompt alignment, visual appeal, and user preference. Unlike LMs,\nDiffusion Models typically optimize in pixel or VAE space, which does not align\nwell with human perception, leading to slower and less efficient training\nduring the preference alignment stage. We propose using a perceptual objective\nin the U-Net embedding space of the diffusion model to address these issues.\nOur approach involves fine-tuning Stable Diffusion 1.5 and XL using Direct\nPreference Optimization (DPO), Contrastive Preference Optimization (CPO), and\nsupervised fine-tuning (SFT) within this embedding space. This method\nsignificantly outperforms standard latent-space implementations across various\nmetrics, including quality and computational cost. For SDXL, our approach\nprovides 60.8\\% general preference, 62.2\\% visual appeal, and 52.1\\% prompt\nfollowing against original open-sourced SDXL-DPO on the PartiPrompts dataset,\nwhile significantly reducing compute. Our approach not only improves the\nefficiency and quality of human preference alignment for diffusion models but\nis also easily integrable with other optimization techniques. The training code\nand LoRA weights will be available here:\nhttps://huggingface.co/alexgambashidze/SDXL\\_NCP-DPO\\_v0.1",
            "upvotes": 17
        },
        "publishedAt": "2024-06-26T05:25:43.436Z",
        "title": "Aligning Diffusion Models with Noise-Conditioned Perception",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6192657ba9638054a9818f04/MYS--MiCKBPyBXqhNKLj8.jpeg",
            "https://cdn-uploads.huggingface.co/production/uploads/6192657ba9638054a9818f04/PuDvAgEUHDbJWy8Z2GKy3.jpeg",
            "https://cdn-uploads.huggingface.co/production/uploads/6192657ba9638054a9818f04/DoZPZ5pCR9kX9Zz3EsIQo.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17636.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/35f6f6eb2e8f6b283034632a141c2670.svg",
            "fullname": "Alexander Gambashidze",
            "name": "alexgambashidze",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17763",
            "authors": [
                {
                    "_id": "667b82ced0f52ca58a1c71eb",
                    "user": {
                        "avatarUrl": "/avatars/59ada2512d6daac39b1dea122900ef9b.svg",
                        "isPro": false,
                        "fullname": "Jiahe Huang",
                        "user": "jhhuangchloe",
                        "type": "user"
                    },
                    "name": "Jiahe Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:48.529Z",
                    "hidden": false
                },
                {
                    "_id": "667b82ced0f52ca58a1c71ec",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64547ca006728ff79a38e7a5/xfTVQXMSfRv-IbljFpswQ.jpeg",
                        "isPro": false,
                        "fullname": "Guandao Yang",
                        "user": "guandao",
                        "type": "user"
                    },
                    "name": "Guandao Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:46.756Z",
                    "hidden": false
                },
                {
                    "_id": "667b82ced0f52ca58a1c71ed",
                    "user": {
                        "avatarUrl": "/avatars/e6938c81a5b2b3dc19454d43ab1a6abc.svg",
                        "isPro": false,
                        "fullname": "zichen wang",
                        "user": "chn02",
                        "type": "user"
                    },
                    "name": "Zichen Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:59:09.389Z",
                    "hidden": false
                },
                {
                    "_id": "667b82ced0f52ca58a1c71ee",
                    "name": "Jeong Joon Park",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T17:48:24.000Z",
            "title": "DiffusionPDE: Generative PDE-Solving Under Partial Observation",
            "summary": "We introduce a general framework for solving partial differential equations\n(PDEs) using generative diffusion models. In particular, we focus on the\nscenarios where we do not have the full knowledge of the scene necessary to\napply classical solvers. Most existing forward or inverse PDE approaches\nperform poorly when the observations on the data or the underlying coefficients\nare incomplete, which is a common assumption for real-world measurements. In\nthis work, we propose DiffusionPDE that can simultaneously fill in the missing\ninformation and solve a PDE by modeling the joint distribution of the solution\nand coefficient spaces. We show that the learned generative priors lead to a\nversatile framework for accurately solving a wide range of PDEs under partial\nobservation, significantly outperforming the state-of-the-art methods for both\nforward and inverse directions.",
            "upvotes": 16
        },
        "publishedAt": "2024-06-26T02:32:25.253Z",
        "title": "DiffusionPDE: Generative PDE-Solving Under Partial Observation",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64547ca006728ff79a38e7a5/D5YP4z_dBW_-nrNS37l7T.jpeg",
            "https://cdn-uploads.huggingface.co/production/uploads/64547ca006728ff79a38e7a5/uItgLsUPMvlWsg4vssnW8.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17763.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64547ca006728ff79a38e7a5/xfTVQXMSfRv-IbljFpswQ.jpeg",
            "fullname": "Guandao Yang",
            "name": "guandao",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17588",
            "authors": [
                {
                    "_id": "667b958491bd7b3e1e04bdc5",
                    "name": "Shawn Gavin",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdc6",
                    "name": "Tuney Zheng",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdc7",
                    "user": {
                        "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
                        "isPro": false,
                        "fullname": "Jiaheng Liu",
                        "user": "CheeryLJH",
                        "type": "user"
                    },
                    "name": "Jiaheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:55:28.515Z",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdc8",
                    "user": {
                        "avatarUrl": "/avatars/1c948a7e8053073ae05631da0747bac7.svg",
                        "isPro": false,
                        "fullname": "quehry",
                        "user": "quehry",
                        "type": "user"
                    },
                    "name": "Quehry Que",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:56:11.687Z",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdc9",
                    "name": "Noah Wang",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdca",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdcb",
                    "name": "Chenchen Zhang",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdcc",
                    "user": {
                        "avatarUrl": "/avatars/c15a54c51998c0e6367685e8e1737ec9.svg",
                        "isPro": false,
                        "fullname": "Wenhao Huang",
                        "user": "EZ-hwh",
                        "type": "user"
                    },
                    "name": "Wenhao Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:57:06.805Z",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdcd",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
                        "isPro": false,
                        "fullname": "Wenhu Chen",
                        "user": "wenhu",
                        "type": "user"
                    },
                    "name": "Wenhu Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T09:57:00.522Z",
                    "hidden": false
                },
                {
                    "_id": "667b958491bd7b3e1e04bdce",
                    "user": {
                        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                        "isPro": false,
                        "fullname": "Ge Zhang",
                        "user": "zhangysk",
                        "type": "user"
                    },
                    "name": "Ge Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:11.978Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T14:31:26.000Z",
            "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
            "summary": "The long-context capabilities of large language models (LLMs) have been a hot\ntopic in recent years. To evaluate the performance of LLMs in different\nscenarios, various assessment benchmarks have emerged. However, as most of\nthese benchmarks focus on identifying key information to answer questions,\nwhich mainly requires the retrieval ability of LLMs, these benchmarks can\npartially represent the reasoning performance of LLMs from large amounts of\ninformation. Meanwhile, although LLMs often claim to have context windows of\n32k, 128k, 200k, or even longer, these benchmarks fail to reveal the actual\nsupported length of these LLMs. To address these issues, we propose the LongIns\nbenchmark dataset, a challenging long-context instruction-based exam for LLMs,\nwhich is built based on the existing instruction datasets. Specifically, in our\nLongIns, we introduce three evaluation settings: Global Instruction & Single\nTask (GIST), Local Instruction & Single Task (LIST), and Local Instruction &\nMultiple Tasks (LIMT). Based on LongIns, we perform comprehensive evaluations\non existing LLMs and have the following important findings: (1). The\ntop-performing GPT-4 with 128k context length performs poorly on the evaluation\ncontext window of 16k in our LongIns. (2). For the multi-hop reasoning ability\nof many existing LLMs, significant efforts are still needed under short context\nwindows (less than 4k).",
            "upvotes": 14
        },
        "publishedAt": "2024-06-26T02:44:05.739Z",
        "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17588.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
            "fullname": "Ge Zhang",
            "name": "zhangysk",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17770",
            "authors": [
                {
                    "_id": "667b8c509ccdbeba7c5fb537",
                    "user": {
                        "avatarUrl": "/avatars/efc93bc767e561c6c6d429f65c23382d.svg",
                        "isPro": false,
                        "fullname": "Xiangyu Z",
                        "user": "PhoenixZ",
                        "type": "user"
                    },
                    "name": "Xiangyu Zhao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:44.481Z",
                    "hidden": false
                },
                {
                    "_id": "667b8c509ccdbeba7c5fb538",
                    "user": {
                        "avatarUrl": "/avatars/1f5e9b9dfcc16df8e88e3dcecfcb4e10.svg",
                        "isPro": false,
                        "fullname": "Xiangtai Li",
                        "user": "LXT",
                        "type": "user"
                    },
                    "name": "Xiangtai Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:47:13.545Z",
                    "hidden": false
                },
                {
                    "_id": "667b8c509ccdbeba7c5fb539",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
                        "isPro": false,
                        "fullname": "HAODONG DUAN",
                        "user": "KennyUTC",
                        "type": "user"
                    },
                    "name": "Haodong Duan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:47:25.009Z",
                    "hidden": false
                },
                {
                    "_id": "667b8c509ccdbeba7c5fb53a",
                    "name": "Haian Huang",
                    "hidden": false
                },
                {
                    "_id": "667b8c509ccdbeba7c5fb53b",
                    "name": "Yining Li",
                    "hidden": false
                },
                {
                    "_id": "667b8c509ccdbeba7c5fb53c",
                    "name": "Kai Chen",
                    "hidden": false
                },
                {
                    "_id": "667b8c509ccdbeba7c5fb53d",
                    "name": "Hua Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T17:55:11.000Z",
            "title": "MG-LLaVA: Towards Multi-Granularity Visual Instruction Tuning",
            "summary": "Multi-modal large language models (MLLMs) have made significant strides in\nvarious visual understanding tasks. However, the majority of these models are\nconstrained to process low-resolution images, which limits their effectiveness\nin perception tasks that necessitate detailed visual information. In our study,\nwe present MG-LLaVA, an innovative MLLM that enhances the model's visual\nprocessing capabilities by incorporating a multi-granularity vision flow, which\nincludes low-resolution, high-resolution, and object-centric features. We\npropose the integration of an additional high-resolution visual encoder to\ncapture fine-grained details, which are then fused with base visual features\nthrough a Conv-Gate fusion network. To further refine the model's object\nrecognition abilities, we incorporate object-level features derived from\nbounding boxes identified by offline detectors. Being trained solely on\npublicly available multimodal data through instruction tuning, MG-LLaVA\ndemonstrates exceptional perception skills. We instantiate MG-LLaVA with a wide\nvariety of language encoders, ranging from 3.8B to 34B, to evaluate the model's\nperformance comprehensively. Extensive evaluations across multiple benchmarks\ndemonstrate that MG-LLaVA outperforms existing MLLMs of comparable parameter\nsizes, showcasing its remarkable efficacy. The code will be available at\nhttps://github.com/PhoenixZ810/MG-LLaVA.",
            "upvotes": 11
        },
        "publishedAt": "2024-06-26T02:06:32.665Z",
        "title": "MG-LLaVA: Towards Multi-Granularity Visual Instruction Tuning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17770.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/efc93bc767e561c6c6d429f65c23382d.svg",
            "fullname": "Xiangyu Z",
            "name": "PhoenixZ",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17758",
            "authors": [
                {
                    "_id": "667bacafeeef441d207e8007",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/RIQIF-JJdNI0SwJEq_9z7.jpeg",
                        "isPro": false,
                        "fullname": "Jianzong Wu",
                        "user": "jianzongwu",
                        "type": "user"
                    },
                    "name": "Jianzong Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:12:19.381Z",
                    "hidden": false
                },
                {
                    "_id": "667bacafeeef441d207e8008",
                    "user": {
                        "avatarUrl": "/avatars/1f5e9b9dfcc16df8e88e3dcecfcb4e10.svg",
                        "isPro": false,
                        "fullname": "Xiangtai Li",
                        "user": "LXT",
                        "type": "user"
                    },
                    "name": "Xiangtai Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:12:37.354Z",
                    "hidden": false
                },
                {
                    "_id": "667bacafeeef441d207e8009",
                    "name": "Yanhong Zeng",
                    "hidden": false
                },
                {
                    "_id": "667bacafeeef441d207e800a",
                    "name": "Jiangning Zhang",
                    "hidden": false
                },
                {
                    "_id": "667bacafeeef441d207e800b",
                    "name": "Qianyu Zhou",
                    "hidden": false
                },
                {
                    "_id": "667bacafeeef441d207e800c",
                    "user": {
                        "avatarUrl": "/avatars/cf3e7f7c5bf790f93fc6b4cb5d72c915.svg",
                        "isPro": false,
                        "fullname": "Yining Li",
                        "user": "ANTiSOC1AL",
                        "type": "user"
                    },
                    "name": "Yining Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:13:50.314Z",
                    "hidden": false
                },
                {
                    "_id": "667bacafeeef441d207e800d",
                    "name": "Yunhai Tong",
                    "hidden": false
                },
                {
                    "_id": "667bacafeeef441d207e800e",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T17:42:25.000Z",
            "title": "MotionBooth: Motion-Aware Customized Text-to-Video Generation",
            "summary": "In this work, we present MotionBooth, an innovative framework designed for\nanimating customized subjects with precise control over both object and camera\nmovements. By leveraging a few images of a specific object, we efficiently\nfine-tune a text-to-video model to capture the object's shape and attributes\naccurately. Our approach presents subject region loss and video preservation\nloss to enhance the subject's learning performance, along with a subject token\ncross-attention loss to integrate the customized subject with motion control\nsignals. Additionally, we propose training-free techniques for managing subject\nand camera motions during inference. In particular, we utilize cross-attention\nmap manipulation to govern subject motion and introduce a novel latent shift\nmodule for camera movement control as well. MotionBooth excels in preserving\nthe appearance of subjects while simultaneously controlling the motions in\ngenerated videos. Extensive quantitative and qualitative evaluations\ndemonstrate the superiority and effectiveness of our method. Our project page\nis at https://jianzongwu.github.io/projects/motionbooth",
            "upvotes": 10
        },
        "publishedAt": "2024-06-26T04:23:14.242Z",
        "title": "MotionBooth: Motion-Aware Customized Text-to-Video Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17758.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17245",
            "authors": [
                {
                    "_id": "667b8e9481adc76dc729773d",
                    "user": {
                        "avatarUrl": "/avatars/7a64b81c29f4f6700fa18effc5616865.svg",
                        "isPro": false,
                        "fullname": "Wenyu Du",
                        "user": "wydu",
                        "type": "user"
                    },
                    "name": "Wenyu Du",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:22.268Z",
                    "hidden": false
                },
                {
                    "_id": "667b8e9481adc76dc729773e",
                    "name": "Shuang Cheng",
                    "hidden": false
                },
                {
                    "_id": "667b8e9481adc76dc729773f",
                    "user": {
                        "avatarUrl": "/avatars/314b55c2428426c846d9449f98db4355.svg",
                        "isPro": false,
                        "fullname": "Tongxu Luo",
                        "user": "Kuroxiro",
                        "type": "user"
                    },
                    "name": "Tongxu Luo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T10:18:26.315Z",
                    "hidden": false
                },
                {
                    "_id": "667b8e9481adc76dc7297740",
                    "user": {
                        "avatarUrl": "/avatars/e8915abaff04f6762247e196b7cf84df.svg",
                        "isPro": false,
                        "fullname": "Zihan Qiu",
                        "user": "QwQZh",
                        "type": "user"
                    },
                    "name": "Zihan Qiu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:29:42.663Z",
                    "hidden": false
                },
                {
                    "_id": "667b8e9481adc76dc7297741",
                    "name": "Zeyu Huang",
                    "hidden": false
                },
                {
                    "_id": "667b8e9481adc76dc7297742",
                    "name": "Ka Chun Cheung",
                    "hidden": false
                },
                {
                    "_id": "667b8e9481adc76dc7297743",
                    "name": "Reynold Cheng",
                    "hidden": false
                },
                {
                    "_id": "667b8e9481adc76dc7297744",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/641a6895fb5ffff5ac79d593/dFR_ofjbqCrcqGa9R3MMq.jpeg",
                        "isPro": false,
                        "fullname": "Jie Fu",
                        "user": "bigaidream",
                        "type": "user"
                    },
                    "name": "Jie Fu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:19.335Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T03:24:06.000Z",
            "title": "Unlocking Continual Learning Abilities in Language Models",
            "summary": "Language models (LMs) exhibit impressive performance and generalization\ncapabilities. However, LMs struggle with the persistent challenge of\ncatastrophic forgetting, which undermines their long-term sustainability in\ncontinual learning (CL). Existing approaches usually address the issue by\nincorporating old task data or task-wise inductive bias into LMs. However, old\ndata and accurate task information are often unavailable or costly to collect,\nhindering the availability of current CL approaches for LMs. To address this\nlimitation, we introduce MIGU (MagnItude-based\nGradient Updating for continual learning), a\nrehearsal-free and task-label-free method that only updates the model\nparameters with large magnitudes of output in LMs' linear layers. MIGU is based\non our observation that the L1-normalized magnitude distribution of the output\nin LMs' linear layers is different when the LM models deal with different task\ndata. By imposing this simple constraint on the gradient update process, we can\nleverage the inherent behaviors of LMs, thereby unlocking their innate CL\nabilities. Our experiments demonstrate that MIGU is universally applicable to\nall three LM architectures (T5, RoBERTa, and Llama2), delivering\nstate-of-the-art or on-par performance across continual finetuning and\ncontinual pre-training settings on four CL benchmarks. For example, MIGU brings\na 15.2% average accuracy improvement over conventional parameter-efficient\nfinetuning baselines in a 15-task CL benchmark. MIGU can also seamlessly\nintegrate with all three existing CL types to further enhance performance. Code\nis available at https://github.com/wenyudu/MIGU{this https URL}.",
            "upvotes": 9
        },
        "publishedAt": "2024-06-26T02:17:15.546Z",
        "title": "Unlocking Continual Learning Abilities in Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17245.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/7a64b81c29f4f6700fa18effc5616865.svg",
            "fullname": "Wenyu Du",
            "name": "wydu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16273",
            "authors": [
                {
                    "_id": "667b8d11bfe251ebedad28aa",
                    "user": {
                        "avatarUrl": "/avatars/644dfa9eb489229c5e809d574099d759.svg",
                        "isPro": false,
                        "fullname": "Sandeep Mishra",
                        "user": "battleMaster",
                        "type": "user"
                    },
                    "name": "Sandeep Mishra",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-06-26T04:05:41.987Z",
                    "hidden": false
                },
                {
                    "_id": "667b8d11bfe251ebedad28ab",
                    "user": {
                        "avatarUrl": "/avatars/5a1790b5e1e54b18363f14ef699a8b21.svg",
                        "isPro": false,
                        "fullname": "Oindrila Saha",
                        "user": "oindrila13saha",
                        "type": "user"
                    },
                    "name": "Oindrila Saha",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-26T03:37:58.089Z",
                    "hidden": false
                },
                {
                    "_id": "667b8d11bfe251ebedad28ac",
                    "name": "Alan C. Bovik",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T02:40:26.000Z",
            "title": "YouDream: Generating Anatomically Controllable Consistent Text-to-3D\n  Animals",
            "summary": "3D generation guided by text-to-image diffusion models enables the creation\nof visually compelling assets. However previous methods explore generation\nbased on image or text. The boundaries of creativity are limited by what can be\nexpressed through words or the images that can be sourced. We present YouDream,\na method to generate high-quality anatomically controllable animals. YouDream\nis guided using a text-to-image diffusion model controlled by 2D views of a 3D\npose prior. Our method generates 3D animals that are not possible to create\nusing previous text-to-3D generative methods. Additionally, our method is\ncapable of preserving anatomic consistency in the generated animals, an area\nwhere prior text-to-3D approaches often struggle. Moreover, we design a fully\nautomated pipeline for generating commonly found animals. To circumvent the\nneed for human intervention to create a 3D pose, we propose a multi-agent LLM\nthat adapts poses from a limited library of animal 3D poses to represent the\ndesired animal. A user study conducted on the outcomes of YouDream demonstrates\nthe preference of the animal models generated by our method over others.\nTurntable results and code are released at https://youdream3d.github.io/",
            "upvotes": 8
        },
        "publishedAt": "2024-06-26T02:17:58.652Z",
        "title": "YouDream: Generating Anatomically Controllable Consistent Text-to-3D Animals",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6635368639a7401f16fdec55/M3JXdH5OzW1xs_z0za0O5.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/6635368639a7401f16fdec55/BNaPl3wL3EHEj--ujtKTA.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/6635368639a7401f16fdec55/1YEfzgZ0dSNJV8avhiwNZ.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16273.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/5a1790b5e1e54b18363f14ef699a8b21.svg",
            "fullname": "Oindrila Saha",
            "name": "oindrila13saha",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16678",
            "authors": [
                {
                    "_id": "667a937567be4d7b18f989c2",
                    "user": {
                        "avatarUrl": "/avatars/28ba4fbb780ad4192f6fae980bba2c0d.svg",
                        "isPro": false,
                        "fullname": "Markus Frohmann",
                        "user": "markus583",
                        "type": "user"
                    },
                    "name": "Markus Frohmann",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:36:06.767Z",
                    "hidden": false
                },
                {
                    "_id": "667a937567be4d7b18f989c3",
                    "user": {
                        "avatarUrl": "/avatars/1bee779c1be67cdbcbddcfe42f6d60e6.svg",
                        "isPro": false,
                        "fullname": "Igor Sterner",
                        "user": "igorsterner",
                        "type": "user"
                    },
                    "name": "Igor Sterner",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:52:39.150Z",
                    "hidden": false
                },
                {
                    "_id": "667a937567be4d7b18f989c4",
                    "user": {
                        "avatarUrl": "/avatars/d9d81b31824668896b0718d113e9a3b5.svg",
                        "isPro": false,
                        "fullname": "Ivan Vulić",
                        "user": "ivulic",
                        "type": "user"
                    },
                    "name": "Ivan Vulić",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:52:45.019Z",
                    "hidden": false
                },
                {
                    "_id": "667a937567be4d7b18f989c5",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1648291574509-5fbe9404dd6e953c5a521e13.jpeg",
                        "isPro": false,
                        "fullname": "Benjamin Minixhofer",
                        "user": "benjamin",
                        "type": "user"
                    },
                    "name": "Benjamin Minixhofer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:52:50.766Z",
                    "hidden": false
                },
                {
                    "_id": "667a937567be4d7b18f989c6",
                    "name": "Markus Schedl",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T14:36:11.000Z",
            "title": "Segment Any Text: A Universal Approach for Robust, Efficient and\n  Adaptable Sentence Segmentation",
            "summary": "Segmenting text into sentences plays an early and crucial role in many NLP\nsystems. This is commonly achieved by using rule-based or statistical methods\nrelying on lexical features such as punctuation. Although some recent works no\nlonger exclusively rely on punctuation, we find that no prior method achieves\nall of (i) robustness to missing punctuation, (ii) effective adaptability to\nnew domains, and (iii) high efficiency. We introduce a new model - Segment any\nText (SaT) - to solve this problem. To enhance robustness, we propose a new\npretraining scheme that ensures less reliance on punctuation. To address\nadaptability, we introduce an extra stage of parameter-efficient fine-tuning,\nestablishing state-of-the-art performance in distinct domains such as verses\nfrom lyrics and legal documents. Along the way, we introduce architectural\nmodifications that result in a threefold gain in speed over the previous state\nof the art and solve spurious reliance on context far in the future. Finally,\nwe introduce a variant of our model with fine-tuning on a diverse, multilingual\nmixture of sentence-segmented data, acting as a drop-in replacement and\nenhancement for existing segmentation tools. Overall, our contributions provide\na universal approach for segmenting any text. Our method outperforms all\nbaselines - including strong LLMs - across 8 corpora spanning diverse domains\nand languages, especially in practically relevant situations where text is\npoorly formatted. Our models and code, including documentation, are available\nat https://huggingface.co/segment-any-text under the MIT license.",
            "upvotes": 6
        },
        "publishedAt": "2024-06-26T06:51:35.518Z",
        "title": "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/61a0b6254e926abc0de81839/xfZRI8EYpOo28LIUv0WI4.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16678.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/28ba4fbb780ad4192f6fae980bba2c0d.svg",
            "fullname": "Markus Frohmann",
            "name": "markus583",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.15339",
            "authors": [
                {
                    "_id": "667abc244ede40ecf16d00a9",
                    "user": {
                        "avatarUrl": "/avatars/041ad5abf9be42e336938f51ebb8746c.svg",
                        "isPro": false,
                        "fullname": "Yaowei Li",
                        "user": "Yw22",
                        "type": "user"
                    },
                    "name": "Yaowei Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:16:27.685Z",
                    "hidden": false
                },
                {
                    "_id": "667abc244ede40ecf16d00aa",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg",
                        "isPro": false,
                        "fullname": "Xintao Wang",
                        "user": "Xintao",
                        "type": "user"
                    },
                    "name": "Xintao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:16:34.274Z",
                    "hidden": false
                },
                {
                    "_id": "667abc244ede40ecf16d00ab",
                    "user": {
                        "avatarUrl": "/avatars/3ac1dbd25e52435185babdeb3da28875.svg",
                        "isPro": false,
                        "fullname": "Zhaoyang Zhang",
                        "user": "ZyZcuhk",
                        "type": "user"
                    },
                    "name": "Zhaoyang Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:17:48.987Z",
                    "hidden": false
                },
                {
                    "_id": "667abc244ede40ecf16d00ac",
                    "user": {
                        "avatarUrl": "/avatars/e834d8f1d4781e3bb0b5d6d25b3b3505.svg",
                        "isPro": false,
                        "fullname": "Zhouxia Wang",
                        "user": "wzhouxiff",
                        "type": "user"
                    },
                    "name": "Zhouxia Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:18:00.332Z",
                    "hidden": false
                },
                {
                    "_id": "667abc244ede40ecf16d00ad",
                    "name": "Ziyang Yuan",
                    "hidden": false
                },
                {
                    "_id": "667abc244ede40ecf16d00ae",
                    "user": {
                        "avatarUrl": "/avatars/c58d228dbdf4f1edb5aa4e635dacb51d.svg",
                        "isPro": false,
                        "fullname": "Liangbin Xie",
                        "user": "Liangbin",
                        "type": "user"
                    },
                    "name": "Liangbin Xie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:18:14.101Z",
                    "hidden": false
                },
                {
                    "_id": "667abc244ede40ecf16d00af",
                    "name": "Yuexian Zou",
                    "hidden": false
                },
                {
                    "_id": "667abc244ede40ecf16d00b0",
                    "name": "Ying Shan",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-21T17:55:05.000Z",
            "title": "Image Conductor: Precision Control for Interactive Video Synthesis",
            "summary": "Filmmaking and animation production often require sophisticated techniques\nfor coordinating camera transitions and object movements, typically involving\nlabor-intensive real-world capturing. Despite advancements in generative AI for\nvideo creation, achieving precise control over motion for interactive video\nasset generation remains challenging. To this end, we propose Image Conductor,\na method for precise control of camera transitions and object movements to\ngenerate video assets from a single image. An well-cultivated training strategy\nis proposed to separate distinct camera and object motion by camera LoRA\nweights and object LoRA weights. To further address cinematographic variations\nfrom ill-posed trajectories, we introduce a camera-free guidance technique\nduring inference, enhancing object movements while eliminating camera\ntransitions. Additionally, we develop a trajectory-oriented video motion data\ncuration pipeline for training. Quantitative and qualitative experiments\ndemonstrate our method's precision and fine-grained control in generating\nmotion-controllable videos from images, advancing the practical application of\ninteractive video synthesis. Project webpage available at\nhttps://liyaowei-stu.github.io/project/ImageConductor/",
            "upvotes": 6
        },
        "publishedAt": "2024-06-26T05:40:05.250Z",
        "title": "Image Conductor: Precision Control for Interactive Video Synthesis",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15339.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "/avatars/c58d228dbdf4f1edb5aa4e635dacb51d.svg",
            "fullname": "Liangbin Xie",
            "name": "Liangbin",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16377",
            "authors": [
                {
                    "_id": "667bbd1f20887e69a0767249",
                    "user": {
                        "avatarUrl": "/avatars/23392fda23fa6288fcb309f7eaa73472.svg",
                        "isPro": false,
                        "fullname": "Deng Cai",
                        "user": "jcyk",
                        "type": "user"
                    },
                    "name": "Deng Cai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:57:48.845Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a076724a",
                    "user": {
                        "avatarUrl": "/avatars/a26908ebcbb74feaf44fe83a44fef8ac.svg",
                        "isPro": false,
                        "fullname": "Huayang",
                        "user": "huayangli",
                        "type": "user"
                    },
                    "name": "Huayang Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:57:57.304Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a076724b",
                    "user": {
                        "avatarUrl": "/avatars/3c8589b68a942b4afd54df2ae4b96336.svg",
                        "isPro": false,
                        "fullname": "Tingchen Fu",
                        "user": "TingchenFu",
                        "type": "user"
                    },
                    "name": "Tingchen Fu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:58:06.805Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a076724c",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f71b23d3bdacb7eec43b1f/6RNVG9zug9tutjo5i8T4C.jpeg",
                        "isPro": false,
                        "fullname": "SihengLi",
                        "user": "SihengLi",
                        "type": "user"
                    },
                    "name": "Siheng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:58:12.922Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a076724d",
                    "user": {
                        "avatarUrl": "/avatars/cdb3da22593facf545a0bafbf548b07e.svg",
                        "isPro": false,
                        "fullname": "Xu Weiwen",
                        "user": "xww033",
                        "type": "user"
                    },
                    "name": "Weiwen Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:58:23.686Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a076724e",
                    "user": {
                        "avatarUrl": "/avatars/3c5389a5ffecbc05583004c627b21b6c.svg",
                        "isPro": false,
                        "fullname": "Li Shuaiyi",
                        "user": "HappSyon",
                        "type": "user"
                    },
                    "name": "Shuaiyi Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:58:34.454Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a076724f",
                    "name": "Bowen Cao",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a0767250",
                    "name": "Zhisong Zhang",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a0767251",
                    "user": {
                        "avatarUrl": "/avatars/584e56b5168bee4191673795549795fa.svg",
                        "isPro": false,
                        "fullname": "Xinting Huang",
                        "user": "huangxt39",
                        "type": "user"
                    },
                    "name": "Xinting Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:59:11.540Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a0767252",
                    "user": {
                        "avatarUrl": "/avatars/17d77f59885db13d4f9c10a9b1245131.svg",
                        "isPro": false,
                        "fullname": "Leyang Cui",
                        "user": "nealcly",
                        "type": "user"
                    },
                    "name": "Leyang Cui",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:59:17.570Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a0767253",
                    "name": "Yan Wang",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a0767254",
                    "user": {
                        "avatarUrl": "/avatars/f9757030d82c69aef933309e0c83ccd0.svg",
                        "isPro": false,
                        "fullname": "Lemao Liu",
                        "user": "lemaoliu",
                        "type": "user"
                    },
                    "name": "Lemao Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:59:27.508Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a0767255",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a74e2aae68caef0b82c27e/tnPaCv2PeDfSX1G7v3QrQ.jpeg",
                        "isPro": false,
                        "fullname": "Taro Watanabe",
                        "user": "tarowatanabe",
                        "type": "user"
                    },
                    "name": "Taro Watanabe",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:59:32.954Z",
                    "hidden": false
                },
                {
                    "_id": "667bbd1f20887e69a0767256",
                    "user": {
                        "avatarUrl": "/avatars/971763f3b724d63bc64b7d3599cfc753.svg",
                        "isPro": false,
                        "fullname": "Shuming Shi",
                        "user": "Shuming",
                        "type": "user"
                    },
                    "name": "Shuming Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:59:50.079Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T07:42:32.000Z",
            "title": "On the Transformations across Reward Model, Parameter Update, and\n  In-Context Prompt",
            "summary": "Despite the general capabilities of pre-trained large language models (LLMs),\nthey still need further adaptation to better serve practical applications. In\nthis paper, we demonstrate the interchangeability of three popular and distinct\nadaptation tools: parameter updating, reward modeling, and in-context\nprompting. This interchangeability establishes a triangular framework with six\ntransformation directions, each of which facilitates a variety of applications.\nOur work offers a holistic view that unifies numerous existing studies and\nsuggests potential research directions. We envision our work as a useful\nroadmap for future research on LLMs.",
            "upvotes": 6
        },
        "publishedAt": "2024-06-26T05:37:24.303Z",
        "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/646735a1946476c5d214e5b2/fcZ3mIOqDnCLkanDHuJ4a.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16377.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/23392fda23fa6288fcb309f7eaa73472.svg",
            "fullname": "Deng Cai",
            "name": "jcyk",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16863",
            "authors": [
                {
                    "_id": "667b9209835224aefa4346bc",
                    "user": {
                        "avatarUrl": "/avatars/cae8ba0a8d61fb4e576934431f43991b.svg",
                        "isPro": false,
                        "fullname": "Haonan Qiu",
                        "user": "MoonQiu",
                        "type": "user"
                    },
                    "name": "Haonan Qiu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:17.268Z",
                    "hidden": false
                },
                {
                    "_id": "667b9209835224aefa4346bd",
                    "user": {
                        "avatarUrl": "/avatars/6c5dda9e58747054a989f077a078f3dc.svg",
                        "isPro": false,
                        "fullname": "Zhaoxi Chen",
                        "user": "FrozenBurning",
                        "type": "user"
                    },
                    "name": "Zhaoxi Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:49:17.574Z",
                    "hidden": false
                },
                {
                    "_id": "667b9209835224aefa4346be",
                    "user": {
                        "avatarUrl": "/avatars/e834d8f1d4781e3bb0b5d6d25b3b3505.svg",
                        "isPro": false,
                        "fullname": "Zhouxia Wang",
                        "user": "wzhouxiff",
                        "type": "user"
                    },
                    "name": "Zhouxia Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:49:24.235Z",
                    "hidden": false
                },
                {
                    "_id": "667b9209835224aefa4346bf",
                    "user": {
                        "avatarUrl": "/avatars/dad52f8955110f0a2caeb613d6aa3ea2.svg",
                        "isPro": false,
                        "fullname": "He",
                        "user": "Yingqing",
                        "type": "user"
                    },
                    "name": "Yingqing He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:49:32.974Z",
                    "hidden": false
                },
                {
                    "_id": "667b9209835224aefa4346c0",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1665146415483-63401c89f81b9d101361f712.png",
                        "isPro": false,
                        "fullname": "Richard",
                        "user": "menghanxia",
                        "type": "user"
                    },
                    "name": "Menghan Xia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:49:39.656Z",
                    "hidden": false
                },
                {
                    "_id": "667b9209835224aefa4346c1",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
                        "isPro": false,
                        "fullname": "Ziwei Liu",
                        "user": "liuziwei7",
                        "type": "user"
                    },
                    "name": "Ziwei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T12:49:45.579Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T17:59:56.000Z",
            "title": "FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models",
            "summary": "Diffusion model has demonstrated remarkable capability in video generation,\nwhich further sparks interest in introducing trajectory control into the\ngeneration process. While existing works mainly focus on training-based methods\n(e.g., conditional adapter), we argue that diffusion model itself allows decent\ncontrol over the generated content without requiring any training. In this\nstudy, we introduce a tuning-free framework to achieve trajectory-controllable\nvideo generation, by imposing guidance on both noise construction and attention\ncomputation. Specifically, 1) we first show several instructive phenomenons and\nanalyze how initial noises influence the motion trajectory of generated\ncontent. 2) Subsequently, we propose FreeTraj, a tuning-free approach that\nenables trajectory control by modifying noise sampling and attention\nmechanisms. 3) Furthermore, we extend FreeTraj to facilitate longer and larger\nvideo generation with controllable trajectories. Equipped with these designs,\nusers have the flexibility to provide trajectories manually or opt for\ntrajectories automatically generated by the LLM trajectory planner. Extensive\nexperiments validate the efficacy of our approach in enhancing the trajectory\ncontrollability of video diffusion models.",
            "upvotes": 6
        },
        "publishedAt": "2024-06-26T02:31:10.132Z",
        "title": "FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16863.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/cae8ba0a8d61fb4e576934431f43991b.svg",
            "fullname": "Haonan Qiu",
            "name": "MoonQiu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.13144",
            "authors": [
                {
                    "_id": "667ba21253401797def65940",
                    "user": {
                        "avatarUrl": "/avatars/d22517d4833f4255fd62fda5280bd8ca.svg",
                        "isPro": false,
                        "fullname": "Jiho Kim",
                        "user": "jiho283",
                        "type": "user"
                    },
                    "name": "Jiho Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:03:09.335Z",
                    "hidden": false
                },
                {
                    "_id": "667ba21253401797def65941",
                    "name": "Woosog Chay",
                    "hidden": false
                },
                {
                    "_id": "667ba21253401797def65942",
                    "user": {
                        "avatarUrl": "/avatars/c2b5386a4c5c74c5dc365447141551ba.svg",
                        "isPro": false,
                        "fullname": "hyeonji hwang",
                        "user": "hyeonz",
                        "type": "user"
                    },
                    "name": "Hyeonji Hwang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:21:02.798Z",
                    "hidden": false
                },
                {
                    "_id": "667ba21253401797def65943",
                    "user": {
                        "avatarUrl": "/avatars/be8375ed32ac234919e26a2450bf9d38.svg",
                        "isPro": false,
                        "fullname": "Daeun Kyung",
                        "user": "dek924",
                        "type": "user"
                    },
                    "name": "Daeun Kyung",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:21:08.357Z",
                    "hidden": false
                },
                {
                    "_id": "667ba21253401797def65944",
                    "name": "Hyunseung Chung",
                    "hidden": false
                },
                {
                    "_id": "667ba21253401797def65945",
                    "name": "Eunbyeol Cho",
                    "hidden": false
                },
                {
                    "_id": "667ba21253401797def65946",
                    "name": "Yohan Jo",
                    "hidden": false
                },
                {
                    "_id": "667ba21253401797def65947",
                    "user": {
                        "avatarUrl": "/avatars/358504b57f2a600753e9bc459091061b.svg",
                        "isPro": false,
                        "fullname": "Edward Choi",
                        "user": "forgetnight",
                        "type": "user"
                    },
                    "name": "Edward Choi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:21:36.315Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-19T01:37:10.000Z",
            "title": "DialSim: A Real-Time Simulator for Evaluating Long-Term Dialogue\n  Understanding of Conversational Agents",
            "summary": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced the capabilities of conversational agents, making them applicable to\nvarious fields (e.g., education). Despite their progress, the evaluation of the\nagents often overlooks the complexities of real-world conversations, such as\nreal-time interactions, multi-party dialogues, and extended contextual\ndependencies. To bridge this gap, we introduce DialSim, a real-time dialogue\nsimulator. In this simulator, an agent is assigned the role of a character from\npopular TV shows, requiring it to respond to spontaneous questions using past\ndialogue information and to distinguish between known and unknown information.\nKey features of DialSim include evaluating the agent's ability to respond\nwithin a reasonable time limit, handling long-term multi-party dialogues, and\nmanaging adversarial settings (e.g., swap character names) to challenge the\nagent's reliance on pre-trained knowledge. We utilized this simulator to\nevaluate the latest conversational agents and analyze their limitations. Our\nexperiments highlight both the strengths and weaknesses of these agents,\nproviding valuable insights for future improvements in the field of\nconversational AI. DialSim is available at\nhttps://github.com/jiho283/Simulator.",
            "upvotes": 2
        },
        "publishedAt": "2024-06-26T06:38:50.064Z",
        "title": "DialSim: A Real-Time Simulator for Evaluating Long-Term Dialogue Understanding of Conversational Agents",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6630eaa52d2b3451e7c0f61e/iVLF_A82OV8zz4AHrVx3F.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.13144.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/d22517d4833f4255fd62fda5280bd8ca.svg",
            "fullname": "Jiho Kim",
            "name": "jiho283",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.15279",
            "authors": [
                {
                    "_id": "667aa83869c3e097d596de29",
                    "user": {
                        "avatarUrl": "/avatars/495dbb73b69c399bae780da3118e332f.svg",
                        "isPro": false,
                        "fullname": "Siyin Wang",
                        "user": "sinwang",
                        "type": "user"
                    },
                    "name": "Siyin Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T13:34:23.735Z",
                    "hidden": false
                },
                {
                    "_id": "667aa83869c3e097d596de2a",
                    "name": "Xingsong Ye",
                    "hidden": false
                },
                {
                    "_id": "667aa83869c3e097d596de2b",
                    "name": "Qinyuan Cheng",
                    "hidden": false
                },
                {
                    "_id": "667aa83869c3e097d596de2c",
                    "name": "Junwen Duan",
                    "hidden": false
                },
                {
                    "_id": "667aa83869c3e097d596de2d",
                    "name": "Shimin Li",
                    "hidden": false
                },
                {
                    "_id": "667aa83869c3e097d596de2e",
                    "name": "Jinlan Fu",
                    "hidden": false
                },
                {
                    "_id": "667aa83869c3e097d596de2f",
                    "name": "Xipeng Qiu",
                    "hidden": false
                },
                {
                    "_id": "667aa83869c3e097d596de30",
                    "name": "Xuanjing Huang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-21T16:14:15.000Z",
            "title": "Cross-Modality Safety Alignment",
            "summary": "As Artificial General Intelligence (AGI) becomes increasingly integrated into\nvarious facets of human life, ensuring the safety and ethical alignment of such\nsystems is paramount. Previous studies primarily focus on single-modality\nthreats, which may not suffice given the integrated and complex nature of\ncross-modality interactions. We introduce a novel safety alignment challenge\ncalled Safe Inputs but Unsafe Output (SIUO) to evaluate cross-modality safety\nalignment. Specifically, it considers cases where single modalities are safe\nindependently but could potentially lead to unsafe or unethical outputs when\ncombined. To empirically investigate this problem, we developed the SIUO, a\ncross-modality benchmark encompassing 9 critical safety domains, such as\nself-harm, illegal activities, and privacy violations. Our findings reveal\nsubstantial safety vulnerabilities in both closed- and open-source LVLMs, such\nas GPT-4V and LLaVA, underscoring the inadequacy of current models to reliably\ninterpret and respond to complex, real-world scenarios.",
            "upvotes": 1
        },
        "publishedAt": "2024-06-26T14:22:31.151Z",
        "title": "Cross-Modality Safety Alignment",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15279.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/495dbb73b69c399bae780da3118e332f.svg",
            "fullname": "Siyin Wang",
            "name": "sinwang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17055",
            "authors": [
                {
                    "_id": "667c2baf18aae25ed3a139fd",
                    "name": "Ryan Liu",
                    "hidden": false
                },
                {
                    "_id": "667c2baf18aae25ed3a139fe",
                    "user": {
                        "avatarUrl": "/avatars/fc9274aeb0dc2071b120acfe52023bbe.svg",
                        "isPro": false,
                        "fullname": "Jiayi Geng",
                        "user": "JiayiG",
                        "type": "user"
                    },
                    "name": "Jiayi Geng",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-26T14:54:42.114Z",
                    "hidden": false
                },
                {
                    "_id": "667c2baf18aae25ed3a139ff",
                    "name": "Joshua C. Peterson",
                    "hidden": false
                },
                {
                    "_id": "667c2baf18aae25ed3a13a00",
                    "name": "Ilia Sucholutsky",
                    "hidden": false
                },
                {
                    "_id": "667c2baf18aae25ed3a13a01",
                    "name": "Thomas L. Griffiths",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T18:15:27.000Z",
            "title": "Large Language Models Assume People are More Rational than We Really are",
            "summary": "In order for AI systems to communicate effectively with people, they must\nunderstand how we make decisions. However, people's decisions are not always\nrational, so the implicit internal models of human decision-making in Large\nLanguage Models (LLMs) must account for this. Previous empirical evidence seems\nto suggest that these implicit models are accurate -- LLMs offer believable\nproxies of human behavior, acting how we expect humans would in everyday\ninteractions. However, by comparing LLM behavior and predictions to a large\ndataset of human decisions, we find that this is actually not the case: when\nboth simulating and predicting people's choices, a suite of cutting-edge LLMs\n(GPT-4o & 4-Turbo, Llama-3-8B & 70B, Claude 3 Opus) assume that people are more\nrational than we really are. Specifically, these models deviate from human\nbehavior and align more closely with a classic model of rational choice --\nexpected value theory. Interestingly, people also tend to assume that other\npeople are rational when interpreting their behavior. As a consequence, when we\ncompare the inferences that LLMs and people draw from the decisions of others\nusing another psychological dataset, we find that these inferences are highly\ncorrelated. Thus, the implicit decision-making models of LLMs appear to be\naligned with the human expectation that other people will act rationally,\nrather than with how people actually act.",
            "upvotes": 1
        },
        "publishedAt": "2024-06-26T13:26:33.731Z",
        "title": "Large Language Models Assume People are More Rational than We Really are",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17055.png",
        "numComments": 4,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/3GEiY7YCU_FzJing5wP-C.jpeg",
            "fullname": "Ryan Liu",
            "name": "theryanliu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17660",
            "authors": [
                {
                    "_id": "667c13f77e940351583d9323",
                    "user": {
                        "avatarUrl": "/avatars/2c50590905f4bd398a4c9991e1b4b5bb.svg",
                        "isPro": false,
                        "fullname": "Aashiq Muhamed",
                        "user": "aashiqmuhamed",
                        "type": "user"
                    },
                    "name": "Aashiq Muhamed",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T13:20:17.469Z",
                    "hidden": false
                },
                {
                    "_id": "667c13f77e940351583d9324",
                    "name": "Oscar Li",
                    "hidden": false
                },
                {
                    "_id": "667c13f77e940351583d9325",
                    "user": {
                        "avatarUrl": "/avatars/519678ea1bafe627aefe79ac13d427de.svg",
                        "isPro": false,
                        "fullname": "David Woodruff",
                        "user": "dmw1101",
                        "type": "user"
                    },
                    "name": "David Woodruff",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:26:07.534Z",
                    "hidden": false
                },
                {
                    "_id": "667c13f77e940351583d9326",
                    "name": "Mona Diab",
                    "hidden": false
                },
                {
                    "_id": "667c13f77e940351583d9327",
                    "name": "Virginia Smith",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T15:50:32.000Z",
            "title": "Grass: Compute Efficient Low-Memory LLM Training with Structured Sparse\n  Gradients",
            "summary": "Large language model (LLM) training and finetuning are often bottlenecked by\nlimited GPU memory. While existing projection-based optimization methods\naddress this by projecting gradients into a lower-dimensional subspace to\nreduce optimizer state memory, they typically rely on dense projection\nmatrices, which can introduce computational and memory overheads. In this work,\nwe propose Grass (GRAdient Stuctured Sparsification), a novel approach that\nleverages sparse projections to transform gradients into structured sparse\nupdates. This design not only significantly reduces memory usage for optimizer\nstates but also minimizes gradient memory footprint, computation, and\ncommunication costs, leading to substantial throughput improvements. Extensive\nexperiments on pretraining and finetuning tasks demonstrate that Grass achieves\ncompetitive performance to full-rank training and existing projection-based\nmethods. Notably, Grass enables half-precision pretraining of a 13B parameter\nLLaMA model on a single 40GB A100 GPU--a feat infeasible for previous\nmethods--and yields up to a 2times throughput improvement on an 8-GPU\nsystem. Code can be found at https://github.com/aashiqmuhamed/GRASS .",
            "upvotes": 1
        },
        "publishedAt": "2024-06-26T11:45:45.732Z",
        "title": "Grass: Compute Efficient Low-Memory LLM Training with Structured Sparse Gradients",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17660.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/2c50590905f4bd398a4c9991e1b4b5bb.svg",
            "fullname": "Aashiq Muhamed",
            "name": "aashiqmuhamed",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17419",
            "authors": [
                {
                    "_id": "667be60309cb8b5498ec90f8",
                    "user": {
                        "avatarUrl": "/avatars/873308203d28115ae1a9e4d0e26508f4.svg",
                        "isPro": false,
                        "fullname": "mz.w",
                        "user": "iiiiwis",
                        "type": "user"
                    },
                    "name": "Minzheng Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T10:18:23.390Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec90f9",
                    "user": {
                        "avatarUrl": "/avatars/10ae481a90bc94f960885b1eed9a9c24.svg",
                        "isPro": false,
                        "fullname": "Longze Chen",
                        "user": "lzchen2001",
                        "type": "user"
                    },
                    "name": "Longze Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:22:16.572Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec90fa",
                    "user": {
                        "avatarUrl": "/avatars/baddbb04c38a6143224031f822e51f56.svg",
                        "isPro": false,
                        "fullname": "cheng-fu",
                        "user": "cfcloud",
                        "type": "user"
                    },
                    "name": "Cheng Fu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:22:26.160Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec90fb",
                    "user": {
                        "avatarUrl": "/avatars/a3b01e482de7b42c9b4de9be347fe187.svg",
                        "isPro": false,
                        "fullname": "LiaoShengyi",
                        "user": "LsyLsyLsyyy",
                        "type": "user"
                    },
                    "name": "Shengyi Liao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:22:37.397Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec90fc",
                    "user": {
                        "avatarUrl": "/avatars/e84aed6b55b0554ad9581ae3c138a16a.svg",
                        "isPro": false,
                        "fullname": "zhangxinghua",
                        "user": "AIRobotZhang",
                        "type": "user"
                    },
                    "name": "Xinghua Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:22:48.990Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec90fd",
                    "user": {
                        "avatarUrl": "/avatars/8ce3ce9901d76ec96574769bdb11b8be.svg",
                        "isPro": false,
                        "fullname": "wubingli",
                        "user": "wubingli",
                        "type": "user"
                    },
                    "name": "Bingli Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:22:59.506Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec90fe",
                    "name": "Haiyang Yu",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec90ff",
                    "user": {
                        "avatarUrl": "/avatars/5aac9ce4f82629a6304c11273fe23f68.svg",
                        "isPro": false,
                        "fullname": "Xu",
                        "user": "Nanxu024",
                        "type": "user"
                    },
                    "name": "Nan Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:23:24.483Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec9100",
                    "name": "Lei Zhang",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec9101",
                    "name": "Run Luo",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec9102",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661829952739-62e670d33651180f7d334ef3.jpeg",
                        "isPro": false,
                        "fullname": "LiYunshui",
                        "user": "Wa2erGo",
                        "type": "user"
                    },
                    "name": "Yunshui Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:23:55.566Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec9103",
                    "name": "Min Yang",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec9104",
                    "user": {
                        "avatarUrl": "/avatars/229fb72180529141515d1df797b33709.svg",
                        "isPro": false,
                        "fullname": "Fei Huang",
                        "user": "hzhwcmhf",
                        "type": "user"
                    },
                    "name": "Fei Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:24:22.098Z",
                    "hidden": false
                },
                {
                    "_id": "667be60309cb8b5498ec9105",
                    "name": "Yongbin Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T09:42:56.000Z",
            "title": "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended\n  Multi-Doc QA",
            "summary": "Long-context modeling capabilities have garnered widespread attention,\nleading to the emergence of Large Language Models (LLMs) with ultra-context\nwindows. Meanwhile, benchmarks for evaluating long-context LLMs are gradually\ncatching up. However, existing benchmarks employ irrelevant noise texts to\nartificially extend the length of test cases, diverging from the real-world\nscenarios of long-context applications. To bridge this gap, we propose a novel\nlong-context benchmark, Loong, aligning with realistic scenarios through\nextended multi-document question answering (QA). Unlike typical document QA, in\nLoong's test cases, each document is relevant to the final answer, ignoring any\ndocument will lead to the failure of the answer. Furthermore, Loong introduces\nfour types of tasks with a range of context lengths: Spotlight Locating,\nComparison, Clustering, and Chain of Reasoning, to facilitate a more realistic\nand comprehensive evaluation of long-context understanding. Extensive\nexperiments indicate that existing long-context language models still exhibit\nconsiderable potential for enhancement. Retrieval augmented generation (RAG)\nachieves poor performance, demonstrating that Loong can reliably assess the\nmodel's long-context modeling capabilities.",
            "upvotes": 1
        },
        "publishedAt": "2024-06-26T09:29:17.771Z",
        "title": "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17419.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/873308203d28115ae1a9e4d0e26508f4.svg",
            "fullname": "mz.w",
            "name": "iiiiwis",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17563",
            "authors": [
                {
                    "_id": "667bd639768e6d3e880609a9",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633e9ae8630ed415eb38073c/-NXweNzXwZGZHwLNJF5fO.png",
                        "isPro": false,
                        "fullname": "Daniel Scalena",
                        "user": "DanielSc4",
                        "type": "user"
                    },
                    "name": "Daniel Scalena",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:24:58.517Z",
                    "hidden": false
                },
                {
                    "_id": "667bd639768e6d3e880609aa",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1670231290373-5e7749883d77a72421292d07.jpeg",
                        "isPro": false,
                        "fullname": "Gabriele Sarti",
                        "user": "gsarti",
                        "type": "user"
                    },
                    "name": "Gabriele Sarti",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-06-26T09:05:13.361Z",
                    "hidden": false
                },
                {
                    "_id": "667bd639768e6d3e880609ab",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1648817396108-6246f49c0569474a9623e05a.jpeg",
                        "isPro": false,
                        "fullname": "Malvina Nissim",
                        "user": "mnissim",
                        "type": "user"
                    },
                    "name": "Malvina Nissim",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-26T08:50:03.677Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-25T14:00:42.000Z",
            "title": "Multi-property Steering of Large Language Models with Dynamic Activation\n  Composition",
            "summary": "Activation steering methods were shown to be effective in conditioning\nlanguage model generation by additively intervening over models' intermediate\nrepresentations. However, the evaluation of these techniques has so far been\nlimited to single conditioning properties and synthetic settings. In this work,\nwe conduct a comprehensive evaluation of various activation steering\nstrategies, highlighting the property-dependent nature of optimal parameters to\nensure a robust effect throughout generation. To address this issue, we propose\nDynamic Activation Composition, an information-theoretic approach to modulate\nthe steering intensity of one or more properties throughout generation. Our\nexperiments on multi-property steering show that our method successfully\nmaintains high conditioning while minimizing the impact of conditioning on\ngeneration fluency.",
            "upvotes": 1
        },
        "publishedAt": "2024-06-26T07:26:36.235Z",
        "title": "Multi-property Steering of Large Language Models with Dynamic Activation Composition",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/5e7749883d77a72421292d07/f7MLtLgZUIojTp3kSa4yx.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17563.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1670231290373-5e7749883d77a72421292d07.jpeg",
            "fullname": "Gabriele Sarti",
            "name": "gsarti",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.17774",
            "authors": [
                {
                    "_id": "667bcd6681adc76dc744d1bf",
                    "user": {
                        "avatarUrl": "/avatars/73ec466ae04e6b788fc4c5114b8dd7fd.svg",
                        "isPro": false,
                        "fullname": "Ruben",
                        "user": "rubenw",
                        "type": "user"
                    },
                    "name": "Ruben Wiersma",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-06-26T08:19:07.764Z",
                    "hidden": true
                },
                {
                    "_id": "667bcd6681adc76dc744d1c0",
                    "user": {
                        "avatarUrl": "/avatars/38a28103b15d93c7d9243bc5418e623e.svg",
                        "isPro": false,
                        "fullname": "Julien Philip",
                        "user": "Jovphi",
                        "type": "user"
                    },
                    "name": "Julien Philip",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-26T08:36:03.227Z",
                    "hidden": true
                },
                {
                    "_id": "667bcd6681adc76dc744d1c1",
                    "user": {
                        "avatarUrl": "/avatars/ce96c03a3ba55394860de485932cab42.svg",
                        "isPro": false,
                        "fullname": "Milos Hasan",
                        "user": "miloshasan",
                        "type": "user"
                    },
                    "name": "Miloš Hašan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:25:23.834Z",
                    "hidden": false
                },
                {
                    "_id": "667bcd6681adc76dc744d1c2",
                    "name": "Krishna Mullia",
                    "hidden": false
                },
                {
                    "_id": "667bcd6681adc76dc744d1c3",
                    "user": {
                        "avatarUrl": "/avatars/2372544e8e5cfeb60a052c793f5e2522.svg",
                        "isPro": false,
                        "fullname": "Fujun Luan",
                        "user": "luanfujun",
                        "type": "user"
                    },
                    "name": "Fujun Luan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-26T13:25:32.757Z",
                    "hidden": false
                },
                {
                    "_id": "667bcd6681adc76dc744d1c4",
                    "name": "Elmar Eisemann",
                    "hidden": false
                },
                {
                    "_id": "667bcd6681adc76dc744d1c5",
                    "user": {
                        "avatarUrl": "/avatars/a30c8ca8850ae120dd409b6f7d204493.svg",
                        "isPro": false,
                        "fullname": "Valentin Deschaintre",
                        "user": "deschain",
                        "type": "user"
                    },
                    "name": "Valentin Deschaintre",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-06-26T08:15:15.193Z",
                    "hidden": true
                }
            ],
            "publishedAt": "2024-06-25T17:59:06.000Z",
            "title": "Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using\n  Frequency Domain Analysis",
            "summary": "Relightable object acquisition is a key challenge in simplifying digital\nasset creation. Complete reconstruction of an object typically requires\ncapturing hundreds to thousands of photographs under controlled illumination,\nwith specialized equipment. The recent progress in differentiable rendering\nimproved the quality and accessibility of inverse rendering optimization.\nNevertheless, under uncontrolled illumination and unstructured viewpoints,\nthere is no guarantee that the observations contain enough information to\nreconstruct the appearance properties of the captured object.\n  We thus propose to consider the acquisition process from a signal-processing\nperspective. Given an object's geometry and a lighting environment, we estimate\nthe properties of the materials on the object's surface in seconds. We do so by\nleveraging frequency domain analysis, considering the recovery of material\nproperties as a deconvolution, enabling fast error estimation. We then quantify\nthe uncertainty of the estimation, based on the available data, highlighting\nthe areas for which priors or additional samples would be required for improved\nacquisition quality. We compare our approach to previous work and\nquantitatively evaluate our results, showing similar quality as previous work\nin a fraction of the time, and providing key information about the certainty of\nthe results.",
            "upvotes": 1
        },
        "publishedAt": "2024-06-26T06:43:04.980Z",
        "title": "Fast and Uncertainty-Aware SVBRDF Recovery from Multi-View Capture using Frequency Domain Analysis",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.17774.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/38a28103b15d93c7d9243bc5418e623e.svg",
            "fullname": "Julien Philip",
            "name": "Jovphi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]