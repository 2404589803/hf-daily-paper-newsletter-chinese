[
  {
    "paper": {
      "id": "2501.08325",
      "authors": [
        {
          "_id": "678719ac5333dfbf8e206077",
          "user": {
            "_id": "64105a6d14215c0775dfdd14",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64105a6d14215c0775dfdd14/-VX-cUYOLjHIg7QnWhRGG.jpeg",
            "isPro": false,
            "fullname": "Jiwen Yu",
            "user": "VictorYuki",
            "type": "user"
          },
          "name": "Jiwen Yu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-15T08:49:01.033Z",
          "hidden": false
        },
        {
          "_id": "678719ac5333dfbf8e206078",
          "name": "Yiran Qin",
          "hidden": false
        },
        {
          "_id": "678719ac5333dfbf8e206079",
          "name": "Xintao Wang",
          "hidden": false
        },
        {
          "_id": "678719ac5333dfbf8e20607a",
          "name": "Pengfei Wan",
          "hidden": false
        },
        {
          "_id": "678719ac5333dfbf8e20607b",
          "name": "Di Zhang",
          "hidden": false
        },
        {
          "_id": "678719ac5333dfbf8e20607c",
          "name": "Xihui Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T18:57:21.000Z",
      "title": "GameFactory: Creating New Games with Generative Interactive Videos",
      "summary": "Generative game engines have the potential to revolutionize game development\nby autonomously creating new content and reducing manual workload. However,\nexisting video-based game generation methods fail to address the critical\nchallenge of scene generalization, limiting their applicability to existing\ngames with fixed styles and scenes. In this paper, we present GameFactory, a\nframework focused on exploring scene generalization in game video generation.\nTo enable the creation of entirely new and diverse games, we leverage\npre-trained video diffusion models trained on open-domain video data. To bridge\nthe domain gap between open-domain priors and small-scale game dataset, we\npropose a multi-phase training strategy that decouples game style learning from\naction control, preserving open-domain generalization while achieving action\ncontrollability. Using Minecraft as our data source, we release GF-Minecraft, a\nhigh-quality and diversity action-annotated video dataset for research.\nFurthermore, we extend our framework to enable autoregressive\naction-controllable game video generation, allowing the production of\nunlimited-length interactive game videos. Experimental results demonstrate that\nGameFactory effectively generates open-domain, diverse, and action-controllable\ngame videos, representing a significant step forward in AI-driven game\ngeneration. Our dataset and project page are publicly available at\nhttps://vvictoryuki.github.io/gamefactory/.",
      "upvotes": 28,
      "discussionId": "678719ae5333dfbf8e206106"
    },
    "publishedAt": "2025-01-20T22:21:50.434Z",
    "title": "GameFactory: Creating New Games with Generative Interactive Videos",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08325.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "64105a6d14215c0775dfdd14",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64105a6d14215c0775dfdd14/-VX-cUYOLjHIg7QnWhRGG.jpeg",
      "fullname": "Jiwen Yu",
      "name": "VictorYuki",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  }
]