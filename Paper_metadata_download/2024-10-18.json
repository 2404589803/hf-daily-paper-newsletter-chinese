[
    {
        "paper": {
            "id": "2410.13754",
            "authors": [
                {
                    "_id": "6711de895b7360457e26dff7",
                    "user": {
                        "_id": "62a7362fd1e7a011fd4e31a7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a7362fd1e7a011fd4e31a7/ZY_mwH-sI0o05SHpLqwc7.png",
                        "isPro": false,
                        "fullname": "Jinjie Ni",
                        "user": "jinjieni",
                        "type": "user"
                    },
                    "name": "Jinjie Ni",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:55:08.722Z",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26dff8",
                    "name": "Yifan Song",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26dff9",
                    "user": {
                        "_id": "62eced5e7e89e8d34df1a1ea",
                        "avatarUrl": "/avatars/99c9d8ba7e7722b7524d5d687cf96a25.svg",
                        "isPro": false,
                        "fullname": "Deepanway Ghosal",
                        "user": "dghosal",
                        "type": "user"
                    },
                    "name": "Deepanway Ghosal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T09:31:24.961Z",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26dffa",
                    "name": "Bo Li",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26dffb",
                    "user": {
                        "_id": "6468855763a564ba347e1efa",
                        "avatarUrl": "/avatars/caa99c3318c1d6d21be44d2d32795a62.svg",
                        "isPro": false,
                        "fullname": "David Junhao ZHANG",
                        "user": "Junhao233",
                        "type": "user"
                    },
                    "name": "David Junhao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T10:33:07.038Z",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26dffc",
                    "user": {
                        "_id": "6230d750d93e84e233882dbc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
                        "isPro": false,
                        "fullname": "Xiang Yue",
                        "user": "yuexiang96",
                        "type": "user"
                    },
                    "name": "Xiang Yue",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T14:55:42.911Z",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26dffd",
                    "user": {
                        "_id": "64a52314978242bb77e05790",
                        "avatarUrl": "/avatars/e97206c653de3446266c80c2943c0a6f.svg",
                        "isPro": false,
                        "fullname": "Fuzhao Xue",
                        "user": "fuzhao",
                        "type": "user"
                    },
                    "name": "Fuzhao Xue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T10:33:15.728Z",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26dffe",
                    "name": "Zian Zheng",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26dfff",
                    "user": {
                        "_id": "64bb77e786e7fb5b8a317a43",
                        "avatarUrl": "/avatars/4c1720db323082e644babeb827c6f5d4.svg",
                        "isPro": false,
                        "fullname": "kcz",
                        "user": "kcz358",
                        "type": "user"
                    },
                    "name": "Kaichen Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:12:13.789Z",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26e000",
                    "name": "Mahir Shah",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26e001",
                    "name": "Kabir Jain",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26e002",
                    "name": "Yang You",
                    "hidden": false
                },
                {
                    "_id": "6711de895b7360457e26e003",
                    "user": {
                        "_id": "64d48e9ef2a3941669810f23",
                        "avatarUrl": "/avatars/495e6785abc44d1facfcf385edd6a222.svg",
                        "isPro": false,
                        "fullname": "Michael Shieh",
                        "user": "Michael2008S",
                        "type": "user"
                    },
                    "name": "Michael Shieh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T09:56:45.883Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T16:52:28.000Z",
            "title": "MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures",
            "summary": "Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any real-world benchmark designed to optimize and\nstandardize evaluations across input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions and the model rankings correlate strongly with that of\ncrowd-sourced real-world evaluations (up to 0.98). We provide comprehensive\nleaderboards to rerank existing models and organizations and offer insights to\nenhance understanding of multi-modal evaluations and inform future research.",
            "upvotes": 48,
            "discussionId": "6711de8b5b7360457e26e0c3"
        },
        "publishedAt": "2024-10-18T03:48:45.327Z",
        "title": "MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62a7362fd1e7a011fd4e31a7/3G8B7yJ_-KLc-m3FsXR6Z.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13754.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a7362fd1e7a011fd4e31a7/ZY_mwH-sI0o05SHpLqwc7.png",
            "fullname": "Jinjie Ni",
            "name": "jinjieni",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13720",
            "authors": [
                {
                    "_id": "6711d977b265bbd413b8320c",
                    "user": {
                        "_id": "6304d514dae2eb7d08413d62",
                        "avatarUrl": "/avatars/02a571bc791b78d3993d9a0484b70a29.svg",
                        "isPro": false,
                        "fullname": "Adam Polyak",
                        "user": "adampo",
                        "type": "user"
                    },
                    "name": "Adam Polyak",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:16:24.972Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8320d",
                    "user": {
                        "_id": "64d8cb34505306fcd2fb89c3",
                        "avatarUrl": "/avatars/4ae9ffe5d494a7d53bc519ff8e402b3e.svg",
                        "isPro": false,
                        "fullname": "Amit Zohar",
                        "user": "amitz",
                        "type": "user"
                    },
                    "name": "Amit Zohar",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:16:30.835Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8320e",
                    "name": "Andrew Brown",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8320f",
                    "user": {
                        "_id": "647779c6c21496284db45835",
                        "avatarUrl": "/avatars/c1176e57f5d0aaa5f50bbde48a19af01.svg",
                        "isPro": false,
                        "fullname": "Andros Tjandra",
                        "user": "androstj",
                        "type": "user"
                    },
                    "name": "Andros Tjandra",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:16:39.991Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83210",
                    "user": {
                        "_id": "63772d28e069bdcdbb8e4a29",
                        "avatarUrl": "/avatars/be71b00e009f2093a3ff79f07815e68e.svg",
                        "isPro": false,
                        "fullname": "Animesh Sinha",
                        "user": "animeshsinha",
                        "type": "user"
                    },
                    "name": "Animesh Sinha",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:17:19.207Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83211",
                    "user": {
                        "_id": "663353017263322326bb044e",
                        "avatarUrl": "/avatars/ac6a5b814592e4c3cd84d7255e31ec88.svg",
                        "isPro": false,
                        "fullname": "Yi-hsuan Lee",
                        "user": "AnnLee",
                        "type": "user"
                    },
                    "name": "Ann Lee",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:17:31.419Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83212",
                    "user": {
                        "_id": "638697308b5acae8d251cdec",
                        "avatarUrl": "/avatars/dcfc47ee012439cc5ecc28e48ff26983.svg",
                        "isPro": false,
                        "fullname": "Apoorv Vyas",
                        "user": "apoorv2904",
                        "type": "user"
                    },
                    "name": "Apoorv Vyas",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:17:01.338Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83213",
                    "user": {
                        "_id": "6477d6e06e6c7ac608c44734",
                        "avatarUrl": "/avatars/c6d126c5b2930531ac4b00a1ad5e6d26.svg",
                        "isPro": false,
                        "fullname": "Bowen Shi",
                        "user": "bowenshi",
                        "type": "user"
                    },
                    "name": "Bowen Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:17:46.422Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83214",
                    "user": {
                        "_id": "6515bf00c2aedaa7e692a1ec",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6515bf00c2aedaa7e692a1ec/PYpS1QwTPdQYW5_BrvwzP.png",
                        "isPro": false,
                        "fullname": "Chih-Yao Ma",
                        "user": "chihyaoma",
                        "type": "user"
                    },
                    "name": "Chih-Yao Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:18:03.265Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83215",
                    "name": "Ching-Yao Chuang",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83216",
                    "name": "David Yan",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83217",
                    "name": "Dhruv Choudhary",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83218",
                    "user": {
                        "_id": "65dbd00d730386b492a88c06",
                        "avatarUrl": "/avatars/362ae2bf1144d0bbb822fad3c33f239c.svg",
                        "isPro": false,
                        "fullname": "Dingkang Wang",
                        "user": "wangdk93",
                        "type": "user"
                    },
                    "name": "Dingkang Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:19:33.523Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83219",
                    "user": {
                        "_id": "653405a002d1ecd5455d4f0a",
                        "avatarUrl": "/avatars/fc5ab33a508dadec6d2e15e992e16dec.svg",
                        "isPro": false,
                        "fullname": "Geet Sethi",
                        "user": "geetsethi",
                        "type": "user"
                    },
                    "name": "Geet Sethi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:19:43.218Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8321a",
                    "user": {
                        "_id": "6573a458d7f487de5f9bb44a",
                        "avatarUrl": "/avatars/4aa5626af43855ad770186f0d4191a01.svg",
                        "isPro": false,
                        "fullname": "Guan Pang",
                        "user": "tbpangolin",
                        "type": "user"
                    },
                    "name": "Guan Pang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:19:51.272Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8321b",
                    "user": {
                        "_id": "650a8979c19e5b4c8a6ff062",
                        "avatarUrl": "/avatars/272385e2246bcfd2ebe9fb2942783fb8.svg",
                        "isPro": false,
                        "fullname": "Haoyu Ma",
                        "user": "haoyum1997",
                        "type": "user"
                    },
                    "name": "Haoyu Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:20:03.497Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8321c",
                    "user": {
                        "_id": "63faa5b04380ab0cb9577a57",
                        "avatarUrl": "/avatars/c71be0acb0553671c9703654e998cbd5.svg",
                        "isPro": false,
                        "fullname": "Ishan Misra",
                        "user": "hayhay404",
                        "type": "user"
                    },
                    "name": "Ishan Misra",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:20:11.699Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8321d",
                    "name": "Ji Hou",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8321e",
                    "name": "Jialiang Wang",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8321f",
                    "name": "Kiran Jagadeesh",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83220",
                    "name": "Kunpeng Li",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83221",
                    "user": {
                        "_id": "65a4fa7d2548c41ad9d9b710",
                        "avatarUrl": "/avatars/3cace2d2f11f7194d8eca4b95b0b57cc.svg",
                        "isPro": false,
                        "fullname": "Luxin Zhang",
                        "user": "Luczzz",
                        "type": "user"
                    },
                    "name": "Luxin Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:21:46.568Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83222",
                    "user": {
                        "_id": "650fece35877b1c077298b81",
                        "avatarUrl": "/avatars/be9c948ecf9c413ad4c8aa6598d3ba86.svg",
                        "isPro": false,
                        "fullname": "Mannat Singh",
                        "user": "mannatsingh",
                        "type": "user"
                    },
                    "name": "Mannat Singh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:22:01.617Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83223",
                    "name": "Mary Williamson",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83224",
                    "user": {
                        "_id": "6311fba9fdb55de45d2245ea",
                        "avatarUrl": "/avatars/5799e56b737d78550bf8d164cbe3d41c.svg",
                        "isPro": false,
                        "fullname": "Matt Le",
                        "user": "lematt1991",
                        "type": "user"
                    },
                    "name": "Matt Le",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T14:16:58.580Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83225",
                    "name": "Matthew Yu",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83226",
                    "name": "Mitesh Kumar Singh",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83227",
                    "user": {
                        "_id": "6433a635a5aed21dd110381e",
                        "avatarUrl": "/avatars/b1fa4fe1c8bd7989875233820fa425af.svg",
                        "isPro": false,
                        "fullname": "Peizhao Zhang",
                        "user": "stzpz",
                        "type": "user"
                    },
                    "name": "Peizhao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:22:59.119Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83228",
                    "user": {
                        "_id": "636f4b35af79dd193603342b",
                        "avatarUrl": "/avatars/577328195738d92ac41a3d0ff3108d7c.svg",
                        "isPro": false,
                        "fullname": "Peter Vajda",
                        "user": "vaphab",
                        "type": "user"
                    },
                    "name": "Peter Vajda",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:23:12.630Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83229",
                    "user": {
                        "_id": "66a1632f40c32a6a39ba0c51",
                        "avatarUrl": "/avatars/5f577e016fa68e65b72fb1f154c88288.svg",
                        "isPro": false,
                        "fullname": "Quentin Duval",
                        "user": "qduval",
                        "type": "user"
                    },
                    "name": "Quentin Duval",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:23:18.989Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8322a",
                    "user": {
                        "_id": "63c6c737656e7822e23732d8",
                        "avatarUrl": "/avatars/3cf062864dbf2b5423eb1f4beaeec1ea.svg",
                        "isPro": false,
                        "fullname": "Rohit Girdhar",
                        "user": "rgirdhar",
                        "type": "user"
                    },
                    "name": "Rohit Girdhar",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:23:27.698Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8322b",
                    "user": {
                        "_id": "6515c595f464644a73b50064",
                        "avatarUrl": "/avatars/119102c41fb8a7986c72b3f55ec6200f.svg",
                        "isPro": false,
                        "fullname": "Roshan sumbaly",
                        "user": "rsumbaly",
                        "type": "user"
                    },
                    "name": "Roshan Sumbaly",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:23:34.133Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8322c",
                    "name": "Sai Saketh Rambhatla",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8322d",
                    "user": {
                        "_id": "67127b753a058517519fabe8",
                        "avatarUrl": "/avatars/6fabb1634efb8ad8a8a2ae96fd6cf1c6.svg",
                        "isPro": false,
                        "fullname": "Sam Tsai",
                        "user": "sstsai-adl",
                        "type": "user"
                    },
                    "name": "Sam Tsai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T15:31:35.305Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8322e",
                    "name": "Samaneh Azadi",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8322f",
                    "user": {
                        "_id": "657c9c9242fc53e18b00a3bc",
                        "avatarUrl": "/avatars/0365d677a8151632f05eff140d8cdb62.svg",
                        "isPro": false,
                        "fullname": "Samyak Datta",
                        "user": "samyakdatta",
                        "type": "user"
                    },
                    "name": "Samyak Datta",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:24:02.672Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83230",
                    "user": {
                        "_id": "6465843ce27766e8921b9cab",
                        "avatarUrl": "/avatars/6017db24da593c9afb21edfcedcddfd4.svg",
                        "isPro": false,
                        "fullname": "Sanyuan Chen",
                        "user": "Sanyuan-Chen",
                        "type": "user"
                    },
                    "name": "Sanyuan Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:24:10.750Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83231",
                    "name": "Sean Bell",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83232",
                    "name": "Sharadh Ramaswamy",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83233",
                    "user": {
                        "_id": "63468e6ca6f101c7f9049132",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1665662111525-63468e6ca6f101c7f9049132.png",
                        "isPro": false,
                        "fullname": "Shelly Sheynin",
                        "user": "shellysheynin",
                        "type": "user"
                    },
                    "name": "Shelly Sheynin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:24:59.545Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83234",
                    "user": {
                        "_id": "65d3c3fe974775cbcbf3397a",
                        "avatarUrl": "/avatars/06c1a26cee0ffad7d318a24c4a16ad9d.svg",
                        "isPro": false,
                        "fullname": "Siddharth Bhattacharya",
                        "user": "Siddharth96",
                        "type": "user"
                    },
                    "name": "Siddharth Bhattacharya",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:24:19.232Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83235",
                    "user": {
                        "_id": "6515bb7e99e8060f1e792047",
                        "avatarUrl": "/avatars/9c6400f83c3165de3154b0e6bee2e5a1.svg",
                        "isPro": false,
                        "fullname": "Simran Motwani",
                        "user": "smotwani",
                        "type": "user"
                    },
                    "name": "Simran Motwani",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:25:07.110Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83236",
                    "user": {
                        "_id": "632bc84fca316c73cd40ca5c",
                        "avatarUrl": "/avatars/5b000f86f8161f7a4bc4200e4b76a6e1.svg",
                        "isPro": false,
                        "fullname": "Tao Xu",
                        "user": "taoxu",
                        "type": "user"
                    },
                    "name": "Tao Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:25:15.774Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83237",
                    "name": "Tianhe Li",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83238",
                    "user": {
                        "_id": "655846d7ed8df83128f5826a",
                        "avatarUrl": "/avatars/d7ce174d7d1b8614d5f6f071225c0057.svg",
                        "isPro": false,
                        "fullname": "Hou",
                        "user": "Tingbo",
                        "type": "user"
                    },
                    "name": "Tingbo Hou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:25:44.779Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83239",
                    "user": {
                        "_id": "64c143d484887aa2b43bac0d",
                        "avatarUrl": "/avatars/817dba24739676aa0f34692702bb00d6.svg",
                        "isPro": false,
                        "fullname": "Wei-Ning Hsu",
                        "user": "wnhsu",
                        "type": "user"
                    },
                    "name": "Wei-Ning Hsu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:25:56.603Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8323a",
                    "name": "Xi Yin",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8323b",
                    "user": {
                        "_id": "6549417b3ce45eb764faf993",
                        "avatarUrl": "/avatars/d310f475d0697f5f13b3d4141ea0ccaf.svg",
                        "isPro": false,
                        "fullname": "Xiaoliang Dai",
                        "user": "daixl1992",
                        "type": "user"
                    },
                    "name": "Xiaoliang Dai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:26:10.362Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8323c",
                    "name": "Yaniv Taigman",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8323d",
                    "user": {
                        "_id": "63d2a5a6c20657d24347000c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674749322268-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Luo",
                        "user": "Yaqiao",
                        "type": "user"
                    },
                    "name": "Yaqiao Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:26:55.559Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8323e",
                    "user": {
                        "_id": "620607bc980cf06cf5b1cd3b",
                        "avatarUrl": "/avatars/3a49b4bd068ca4ec9e16edd65862ce5b.svg",
                        "isPro": false,
                        "fullname": "Yen-Cheng Liu",
                        "user": "ycliu",
                        "type": "user"
                    },
                    "name": "Yen-Cheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:27:11.636Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8323f",
                    "user": {
                        "_id": "6410ebe8028e6f7153df0842",
                        "avatarUrl": "/avatars/96960d2c7d713510d25903fdabe5b825.svg",
                        "isPro": false,
                        "fullname": "Yi-Chiao Wu",
                        "user": "yichiaowu",
                        "type": "user"
                    },
                    "name": "Yi-Chiao Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:27:04.005Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83240",
                    "name": "Yue Zhao",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83241",
                    "user": {
                        "_id": "6551fa1b5491c57ee900108b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6551fa1b5491c57ee900108b/HXEfGUJRExQpfGpX3F8N0.png",
                        "isPro": false,
                        "fullname": "Yuval Kirstain",
                        "user": "yuvalkirstainmeta",
                        "type": "user"
                    },
                    "name": "Yuval Kirstain",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:27:22.706Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83242",
                    "user": {
                        "_id": "641b7d42ec5b871c0bcf2955",
                        "avatarUrl": "/avatars/f6e24742b4befa889e72c7e5eefd6cf6.svg",
                        "isPro": false,
                        "fullname": "He",
                        "user": "zechengh",
                        "type": "user"
                    },
                    "name": "Zecheng He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:27:38.060Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83243",
                    "name": "Zijian He",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83244",
                    "name": "Albert Pumarola",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83245",
                    "name": "Ali Thabet",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83246",
                    "name": "Artsiom Sanakoyeu",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83247",
                    "user": {
                        "_id": "6513374d2f79557a90c0f0fe",
                        "avatarUrl": "/avatars/96eadc6f0e0f91ea3d874df207a9db71.svg",
                        "isPro": false,
                        "fullname": "Arun Mallya",
                        "user": "ammp",
                        "type": "user"
                    },
                    "name": "Arun Mallya",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:28:09.467Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83248",
                    "user": {
                        "_id": "66a8050feb641bdde6e60b6b",
                        "avatarUrl": "/avatars/b239d0eeaecda333a04d15fdd0a106c7.svg",
                        "isPro": false,
                        "fullname": "Baishan Guo",
                        "user": "edwardguo",
                        "type": "user"
                    },
                    "name": "Baishan Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:28:32.745Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83249",
                    "name": "Boris Araya",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8324a",
                    "name": "Breena Kerr",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8324b",
                    "name": "Carleigh Wood",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8324c",
                    "name": "Ce Liu",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8324d",
                    "name": "Cen Peng",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8324e",
                    "name": "Dimitry Vengertsev",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8324f",
                    "user": {
                        "_id": "6571c662d5c6a6d3b0bdae88",
                        "avatarUrl": "/avatars/8080bcdf8b331f62383b724050189660.svg",
                        "isPro": false,
                        "fullname": "Edgar Schoenfeld",
                        "user": "edgarschoenfeld",
                        "type": "user"
                    },
                    "name": "Edgar Schonfeld",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T14:16:57.158Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83250",
                    "user": {
                        "_id": "6563cf4a718b9db5215d07b4",
                        "avatarUrl": "/avatars/20e5be0bd3fcd888959a0af0f0b462e4.svg",
                        "isPro": false,
                        "fullname": "Elliot Blanchard",
                        "user": "elliotblanchard",
                        "type": "user"
                    },
                    "name": "Elliot Blanchard",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:30:11.640Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83251",
                    "name": "Felix Juefei-Xu",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83252",
                    "name": "Fraylie Nord",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83253",
                    "user": {
                        "_id": "63631be58f43a912fc7595d5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1667440137801-63631be58f43a912fc7595d5.jpeg",
                        "isPro": false,
                        "fullname": "Jeff Liang",
                        "user": "JeffLiang",
                        "type": "user"
                    },
                    "name": "Jeff Liang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:30:33.700Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83254",
                    "name": "John Hoffman",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83255",
                    "user": {
                        "_id": "6408a3a19e9f790c905281c2",
                        "avatarUrl": "/avatars/3517962e54bda141018e13f7e21fb1ae.svg",
                        "isPro": false,
                        "fullname": "jonas k√∂hler",
                        "user": "Jonaskohler",
                        "type": "user"
                    },
                    "name": "Jonas Kohler",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:30:01.260Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83256",
                    "name": "Kaolin Fire",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83257",
                    "name": "Karthik Sivakumar",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83258",
                    "user": {
                        "_id": "6303ff0c7b50dd9d0a3777e8",
                        "avatarUrl": "/avatars/1c65d5936fe0cafd1fadd1102fad28db.svg",
                        "isPro": false,
                        "fullname": "Lawrence Chen",
                        "user": "lawrencechen",
                        "type": "user"
                    },
                    "name": "Lawrence Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:31:47.867Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83259",
                    "name": "Licheng Yu",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8325a",
                    "name": "Luya Gao",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8325b",
                    "name": "Markos Georgopoulos",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8325c",
                    "name": "Rashel Moritz",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8325d",
                    "name": "Sara K. Sampson",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8325e",
                    "name": "Shikai Li",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b8325f",
                    "user": {
                        "_id": "66a046fe7bcf5121db35e4a6",
                        "avatarUrl": "/avatars/4d407ab2245f63610c41bba602f1c0f8.svg",
                        "isPro": false,
                        "fullname": "Simone Parmeggiani",
                        "user": "ngb81",
                        "type": "user"
                    },
                    "name": "Simone Parmeggiani",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:32:42.813Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83260",
                    "name": "Steve Fine",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83261",
                    "name": "Tara Fowler",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83262",
                    "user": {
                        "_id": "6515caf71e7b9224c9d23851",
                        "avatarUrl": "/avatars/11b17ba6d4f8e7b97a1644cc551a9fe7.svg",
                        "isPro": false,
                        "fullname": "Vladan Petrovic",
                        "user": "vpetrovi",
                        "type": "user"
                    },
                    "name": "Vladan Petrovic",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:24:45.907Z",
                    "hidden": false
                },
                {
                    "_id": "6711d977b265bbd413b83263",
                    "name": "Yuming Du",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T16:22:46.000Z",
            "title": "Movie Gen: A Cast of Media Foundation Models",
            "summary": "We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.",
            "upvotes": 41,
            "discussionId": "6711d97db265bbd413b83410"
        },
        "publishedAt": "2024-10-18T02:16:45.925Z",
        "title": "Movie Gen: A Cast of Media Foundation Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13720.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13757",
            "authors": [
                {
                    "_id": "6711e2dd1133b5e4de846c00",
                    "user": {
                        "_id": "64d4b50a8ebc404438d86961",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dxdusVp085Lx9hZ-y9fMp.jpeg",
                        "isPro": false,
                        "fullname": "Zichen Zhu",
                        "user": "JamesZhutheThird",
                        "type": "user"
                    },
                    "name": "Zichen Zhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T10:32:58.239Z",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c01",
                    "name": "Hao Tang",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c02",
                    "name": "Yansi Li",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c03",
                    "user": {
                        "_id": "62a430b7f4ec0e5e8760c776",
                        "avatarUrl": "/avatars/708f7558ceeffdc41bb9c871c8f09409.svg",
                        "isPro": false,
                        "fullname": "Kunyao Lan",
                        "user": "lankunyao",
                        "type": "user"
                    },
                    "name": "Kunyao Lan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:34:20.631Z",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c04",
                    "name": "Yixuan Jiang",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c05",
                    "name": "Hao Zhou",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c06",
                    "name": "Yixiao Wang",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c07",
                    "user": {
                        "_id": "64a6217e063f497473d7cab8",
                        "avatarUrl": "/avatars/45e1a7ed953353a3602924374d2ac163.svg",
                        "isPro": false,
                        "fullname": "Situo Zhang",
                        "user": "Situo",
                        "type": "user"
                    },
                    "name": "Situo Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:35:16.260Z",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c08",
                    "name": "Liangtai Sun",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c09",
                    "name": "Lu Chen",
                    "hidden": false
                },
                {
                    "_id": "6711e2dd1133b5e4de846c0a",
                    "name": "Kai Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T16:53:50.000Z",
            "title": "MobA: A Two-Level Agent System for Efficient Mobile Task Automation",
            "summary": "Current mobile assistants are limited by dependence on system APIs or\nstruggle with complex user instructions and diverse interfaces due to\nrestricted comprehension and decision-making abilities. To address these\nchallenges, we propose MobA, a novel Mobile phone Agent powered by multimodal\nlarge language models that enhances comprehension and planning capabilities\nthrough a sophisticated two-level agent architecture. The high-level Global\nAgent (GA) is responsible for understanding user commands, tracking history\nmemories, and planning tasks. The low-level Local Agent (LA) predicts detailed\nactions in the form of function calls, guided by sub-tasks and memory from the\nGA. Integrating a Reflection Module allows for efficient task completion and\nenables the system to handle previously unseen complex tasks. MobA demonstrates\nsignificant improvements in task execution efficiency and completion rate in\nreal-life evaluations, underscoring the potential of MLLM-empowered mobile\nassistants.",
            "upvotes": 26,
            "discussionId": "6711e2de1133b5e4de846c79"
        },
        "publishedAt": "2024-10-18T09:41:59.638Z",
        "title": "MobA: A Two-Level Agent System for Efficient Mobile Task Automation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13757.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dxdusVp085Lx9hZ-y9fMp.jpeg",
            "fullname": "Zichen Zhu",
            "name": "JamesZhutheThird",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13824",
            "authors": [
                {
                    "_id": "6711c43e0babf0ff2ec5f194",
                    "user": {
                        "_id": "6512a2e284bedffb5ac5a511",
                        "avatarUrl": "/avatars/e798f2c8633d77aea41fce684d749390.svg",
                        "isPro": false,
                        "fullname": "Junpeng LIU",
                        "user": "jeepliu",
                        "type": "user"
                    },
                    "name": "Junpeng Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:12:38.288Z",
                    "hidden": false
                },
                {
                    "_id": "6711c43e0babf0ff2ec5f195",
                    "user": {
                        "_id": "65403d8781a8731a1c09a584",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65403d8781a8731a1c09a584/858OEZnMxbJleFiI1UgGs.jpeg",
                        "isPro": false,
                        "fullname": "Tianyue Ou",
                        "user": "oottyy",
                        "type": "user"
                    },
                    "name": "Tianyue Ou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T09:57:06.209Z",
                    "hidden": false
                },
                {
                    "_id": "6711c43e0babf0ff2ec5f196",
                    "name": "Yifan Song",
                    "hidden": false
                },
                {
                    "_id": "6711c43e0babf0ff2ec5f197",
                    "user": {
                        "_id": "6500bbf5e102da55f9ed43fc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6500bbf5e102da55f9ed43fc/QZ6EAFV2CStFsILmTJw5D.jpeg",
                        "isPro": false,
                        "fullname": "Yuxiao Qu",
                        "user": "CohenQu",
                        "type": "user"
                    },
                    "name": "Yuxiao Qu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:33:26.181Z",
                    "hidden": false
                },
                {
                    "_id": "6711c43e0babf0ff2ec5f198",
                    "name": "Wai Lam",
                    "hidden": false
                },
                {
                    "_id": "6711c43e0babf0ff2ec5f199",
                    "user": {
                        "_id": "617ae49bc0ff6006217aa22e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1635543252231-617ae49bc0ff6006217aa22e.jpeg",
                        "isPro": false,
                        "fullname": "Chenyan Xiong",
                        "user": "xiongchenyan",
                        "type": "user"
                    },
                    "name": "Chenyan Xiong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:33:36.903Z",
                    "hidden": false
                },
                {
                    "_id": "6711c43e0babf0ff2ec5f19a",
                    "user": {
                        "_id": "6313a86154e6e5d9f0f94e04",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
                        "isPro": false,
                        "fullname": "Wenhu Chen",
                        "user": "wenhu",
                        "type": "user"
                    },
                    "name": "Wenhu Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:33:42.084Z",
                    "hidden": false
                },
                {
                    "_id": "6711c43e0babf0ff2ec5f19b",
                    "user": {
                        "_id": "60de14638bedd2315529d43f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1625166923504-noauth.png",
                        "isPro": false,
                        "fullname": "Graham Neubig",
                        "user": "gneubig",
                        "type": "user"
                    },
                    "name": "Graham Neubig",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:33:49.506Z",
                    "hidden": false
                },
                {
                    "_id": "6711c43e0babf0ff2ec5f19c",
                    "user": {
                        "_id": "6230d750d93e84e233882dbc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
                        "isPro": false,
                        "fullname": "Xiang Yue",
                        "user": "yuexiang96",
                        "type": "user"
                    },
                    "name": "Xiang Yue",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:12:35.934Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:48:54.000Z",
            "title": "Harnessing Webpage UIs for Text-Rich Visual Understanding",
            "summary": "Text-rich visual understanding-the ability to process environments where\ndense textual content is integrated with visuals-is crucial for multimodal\nlarge language models (MLLMs) to interact effectively with structured\nenvironments. To enhance this capability, we propose synthesizing general\nmultimodal instructions from webpage UIs using text-based large language models\n(LLMs). Despite lacking direct visual input, text-based LLMs are able to\nprocess structured text representations from webpage accessibility trees. These\ninstructions are then paired with UI screenshots to train multimodal models. We\nintroduce MultiUI, a dataset containing 7.3 million samples from 1 million\nwebsites, covering diverse multimodal tasks and UI layouts. Models trained on\nMultiUI not only excel in web UI tasks-achieving up to a 48\\% improvement on\nVisualWebBench and a 19.1\\% boost in action accuracy on a web agent dataset\nMind2Web-but also generalize surprisingly well to non-web UI tasks and even to\nnon-UI domains, such as document understanding, OCR, and chart interpretation.\nThese results highlight the broad applicability of web UI data for advancing\ntext-rich visual understanding across various scenarios.",
            "upvotes": 19,
            "discussionId": "6711c43f0babf0ff2ec5f269"
        },
        "publishedAt": "2024-10-18T01:04:36.527Z",
        "title": "Harnessing Webpage UIs for Text-Rich Visual Understanding",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6230d750d93e84e233882dbc/jMq4Wha4sMCApUp5HRd5G.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13824.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
            "fullname": "Xiang Yue",
            "name": "yuexiang96",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13848",
            "authors": [
                {
                    "_id": "6711d3f2b6b1901abbf8c1f3",
                    "user": {
                        "_id": "617526c9de8feb54b0ce45ad",
                        "avatarUrl": "/avatars/7faf8c6f71fc318a0113d780d376c381.svg",
                        "isPro": true,
                        "fullname": "Wu Chengyue",
                        "user": "WuChengyue",
                        "type": "user"
                    },
                    "name": "Chengyue Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:55:10.857Z",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1f4",
                    "name": "Xiaokang Chen",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1f5",
                    "name": "Zhiyu Wu",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1f6",
                    "user": {
                        "_id": "667282bf992bdf3ecb3bdc86",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/aXQRm8RUJXNJYZaBQzlDu.jpeg",
                        "isPro": false,
                        "fullname": "Ma_Yiyang",
                        "user": "CNMaxwell",
                        "type": "user"
                    },
                    "name": "Yiyang Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T08:58:28.664Z",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1f7",
                    "user": {
                        "_id": "646b0bbdec9a61e871799339",
                        "avatarUrl": "/avatars/b9a4ed9573c49241bd9cb96c919f9e8f.svg",
                        "isPro": false,
                        "fullname": "Xingchao Liu",
                        "user": "XCLiu",
                        "type": "user"
                    },
                    "name": "Xingchao Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T08:58:36.546Z",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1f8",
                    "user": {
                        "_id": "629d55b53a3221bb2117422c",
                        "avatarUrl": "/avatars/e39f25cd7190d282478cdac20a7700ee.svg",
                        "isPro": false,
                        "fullname": "Zizheng Pan",
                        "user": "zizhpan",
                        "type": "user"
                    },
                    "name": "Zizheng Pan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T08:58:43.853Z",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1f9",
                    "name": "Wen Liu",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1fa",
                    "user": {
                        "_id": "6539f6ea26df26ecd1393c37",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6539f6ea26df26ecd1393c37/9VJusLLAiLhUxfBAFggpF.jpeg",
                        "isPro": false,
                        "fullname": "Zhenda Xie",
                        "user": "zdaxie",
                        "type": "user"
                    },
                    "name": "Zhenda Xie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T08:59:00.682Z",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1fb",
                    "user": {
                        "_id": "6475b14a37ed88a749e5e48c",
                        "avatarUrl": "/avatars/973f4662023f0bbbc94c01dc3bb3edd3.svg",
                        "isPro": false,
                        "fullname": "Xingkai Yu",
                        "user": "GeeeekExplorer",
                        "type": "user"
                    },
                    "name": "Xingkai Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T08:59:15.248Z",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1fc",
                    "user": {
                        "_id": "6398203609f12714ed1935c2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6398203609f12714ed1935c2/uXgl0LgKnFYjq1Wz39-a6.jpeg",
                        "isPro": false,
                        "fullname": "Chong Ruan",
                        "user": "Chester111",
                        "type": "user"
                    },
                    "name": "Chong Ruan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T08:59:22.321Z",
                    "hidden": false
                },
                {
                    "_id": "6711d3f2b6b1901abbf8c1fd",
                    "name": "Ping Luo",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:58:37.000Z",
            "title": "Janus: Decoupling Visual Encoding for Unified Multimodal Understanding\n  and Generation",
            "summary": "In this paper, we introduce Janus, an autoregressive framework that unifies\nmultimodal understanding and generation. Prior research often relies on a\nsingle visual encoder for both tasks, such as Chameleon. However, due to the\ndiffering levels of information granularity required by multimodal\nunderstanding and generation, this approach can lead to suboptimal performance,\nparticularly in multimodal understanding. To address this issue, we decouple\nvisual encoding into separate pathways, while still leveraging a single,\nunified transformer architecture for processing. The decoupling not only\nalleviates the conflict between the visual encoder's roles in understanding and\ngeneration, but also enhances the framework's flexibility. For instance, both\nthe multimodal understanding and generation components can independently select\ntheir most suitable encoding methods. Experiments show that Janus surpasses\nprevious unified model and matches or exceeds the performance of task-specific\nmodels. The simplicity, high flexibility, and effectiveness of Janus make it a\nstrong candidate for next-generation unified multimodal models.",
            "upvotes": 15,
            "discussionId": "6711d3f4b6b1901abbf8c246"
        },
        "publishedAt": "2024-10-18T04:23:02.941Z",
        "title": "Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13848.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "/avatars/7faf8c6f71fc318a0113d780d376c381.svg",
            "fullname": "Wu Chengyue",
            "name": "WuChengyue",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13085",
            "authors": [
                {
                    "_id": "6711c6c03a39fce88e963f74",
                    "user": {
                        "_id": "643e9ee6f6bb3c31a26e7bc4",
                        "avatarUrl": "/avatars/acfaa7d6a23dada24c86b954c3be116a.svg",
                        "isPro": false,
                        "fullname": "Peng Xia",
                        "user": "richardxp888",
                        "type": "user"
                    },
                    "name": "Peng Xia",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:12:31.084Z",
                    "hidden": false
                },
                {
                    "_id": "6711c6c03a39fce88e963f75",
                    "user": {
                        "_id": "661af01a8ad066992403cc6f",
                        "avatarUrl": "/avatars/b4680010940a84c23521aa4b043ccab4.svg",
                        "isPro": false,
                        "fullname": "Kangyu Zhu",
                        "user": "zky11235",
                        "type": "user"
                    },
                    "name": "Kangyu Zhu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:39:50.268Z",
                    "hidden": false
                },
                {
                    "_id": "6711c6c03a39fce88e963f76",
                    "name": "Haoran Li",
                    "hidden": false
                },
                {
                    "_id": "6711c6c03a39fce88e963f77",
                    "name": "Tianze Wang",
                    "hidden": false
                },
                {
                    "_id": "6711c6c03a39fce88e963f78",
                    "name": "Weijia Shi",
                    "hidden": false
                },
                {
                    "_id": "6711c6c03a39fce88e963f79",
                    "name": "Sheng Wang",
                    "hidden": false
                },
                {
                    "_id": "6711c6c03a39fce88e963f7a",
                    "name": "Linjun Zhang",
                    "hidden": false
                },
                {
                    "_id": "6711c6c03a39fce88e963f7b",
                    "name": "James Zou",
                    "hidden": false
                },
                {
                    "_id": "6711c6c03a39fce88e963f7c",
                    "user": {
                        "_id": "65f667a455009c4ad9e6ac4c",
                        "avatarUrl": "/avatars/ed10c2cf2ba3fde6d7da93f076961607.svg",
                        "isPro": false,
                        "fullname": "Yao",
                        "user": "Huaxiu",
                        "type": "user"
                    },
                    "name": "Huaxiu Yao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:41:17.646Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-16T23:03:27.000Z",
            "title": "MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language\n  Models",
            "summary": "Artificial Intelligence (AI) has demonstrated significant potential in\nhealthcare, particularly in disease diagnosis and treatment planning. Recent\nprogress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new\npossibilities for interactive diagnostic tools. However, these models often\nsuffer from factual hallucination, which can lead to incorrect diagnoses.\nFine-tuning and retrieval-augmented generation (RAG) have emerged as methods to\naddress these issues. However, the amount of high-quality data and distribution\nshifts between training data and deployment data limit the application of\nfine-tuning methods. Although RAG is lightweight and effective, existing\nRAG-based approaches are not sufficiently general to different medical domains\nand can potentially cause misalignment issues, both between modalities and\nbetween the model and the ground truth. In this paper, we propose a versatile\nmultimodal RAG system, MMed-RAG, designed to enhance the factuality of\nMed-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an\nadaptive retrieved contexts selection method, and a provable RAG-based\npreference fine-tuning strategy. These innovations make the RAG process\nsufficiently general and reliable, significantly improving alignment when\nintroducing retrieved contexts. Experimental results across five medical\ndatasets (involving radiology, ophthalmology, pathology) on medical VQA and\nreport generation demonstrate that MMed-RAG can achieve an average improvement\nof 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available\nin https://github.com/richard-peng-xia/MMed-RAG.",
            "upvotes": 10,
            "discussionId": "6711c6c23a39fce88e963ff5"
        },
        "publishedAt": "2024-10-18T00:55:13.966Z",
        "title": "MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13085.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/acfaa7d6a23dada24c86b954c3be116a.svg",
            "fullname": "Peng Xia",
            "name": "richardxp888",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13841",
            "authors": [
                {
                    "_id": "6711c61c1e98ec0ba6bc418c",
                    "user": {
                        "_id": "64ed96f3067fbb625f83766a",
                        "avatarUrl": "/avatars/e8794ba19bdd965615bd9ead7df77d7d.svg",
                        "isPro": false,
                        "fullname": "Qiaoyu Tang",
                        "user": "TangQiaoYu",
                        "type": "user"
                    },
                    "name": "Qiaoyu Tang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:12:33.542Z",
                    "hidden": false
                },
                {
                    "_id": "6711c61c1e98ec0ba6bc418d",
                    "name": "Le Yu",
                    "hidden": false
                },
                {
                    "_id": "6711c61c1e98ec0ba6bc418e",
                    "user": {
                        "_id": "6438b43ab2ea24b52ebac2b9",
                        "avatarUrl": "/avatars/84133cd719a4b1e2f5c1a74178425f86.svg",
                        "isPro": false,
                        "fullname": "Bowen Yu",
                        "user": "bwy",
                        "type": "user"
                    },
                    "name": "Bowen Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:36:39.144Z",
                    "hidden": false
                },
                {
                    "_id": "6711c61c1e98ec0ba6bc418f",
                    "user": {
                        "_id": "6711c702f858a456b4b9f3a4",
                        "avatarUrl": "/avatars/178e9567c3111ab22717c3c0dd003a6a.svg",
                        "isPro": false,
                        "fullname": "Hongyu  Lin",
                        "user": "sanmusunrise",
                        "type": "user"
                    },
                    "name": "Hongyu Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:36:25.734Z",
                    "hidden": false
                },
                {
                    "_id": "6711c61c1e98ec0ba6bc4190",
                    "user": {
                        "_id": "6453fa96ed6d7fede94408e0",
                        "avatarUrl": "/avatars/e8c9025ef24cec958c87a1008bb54fd7.svg",
                        "isPro": false,
                        "fullname": "Keming Lu",
                        "user": "keminglu",
                        "type": "user"
                    },
                    "name": "Keming Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:36:53.561Z",
                    "hidden": false
                },
                {
                    "_id": "6711c61c1e98ec0ba6bc4191",
                    "user": {
                        "_id": "6216496a9b34d2fb49144599",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6216496a9b34d2fb49144599/41CKA_h1Ffj3RzVabSAkm.jpeg",
                        "isPro": false,
                        "fullname": "Yaojie Lu",
                        "user": "luyaojie",
                        "type": "user"
                    },
                    "name": "Yaojie Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:36:59.079Z",
                    "hidden": false
                },
                {
                    "_id": "6711c61c1e98ec0ba6bc4192",
                    "user": {
                        "_id": "65e99a77e71555ed193609cf",
                        "avatarUrl": "/avatars/38ceb127883944677665da967d17dd18.svg",
                        "isPro": false,
                        "fullname": "Xianpei Han",
                        "user": "xphan",
                        "type": "user"
                    },
                    "name": "Xianpei Han",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:36:19.025Z",
                    "hidden": false
                },
                {
                    "_id": "6711c61c1e98ec0ba6bc4193",
                    "name": "Le Sun",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:56:53.000Z",
            "title": "A Unified View of Delta Parameter Editing in Post-Trained Large-Scale\n  Models",
            "summary": "Post-training has emerged as a crucial paradigm for adapting large-scale\npre-trained models to various tasks, whose effects are fully reflected by delta\nparameters (i.e., the disparity between post-trained and pre-trained\nparameters). While numerous studies have explored delta parameter properties\nvia operations like pruning, quantization, low-rank approximation, and\nextrapolation, a unified framework for systematically examining these\ncharacteristics has been lacking. In this paper, we propose a novel perspective\nbased on Riemann sum approximation of the loss function to elucidate delta\nparameter editing operations. Our analysis categorizes existing methods into\nthree classes based on their post-editing performance: competitive, decreased,\nand improved, explaining how they are expressed by the Riemann sum\napproximation term and how they alter the model performance. Extensive\nexperiments on both visual and language models, including ViT, LLaMA 3, Qwen 2,\nand Mistral, corroborate our theoretical findings. Furthermore, we introduce\nextensions to existing techniques like DARE and BitDelta, highlighting their\nlimitations in leveraging the properties of delta parameters and reorganizing\nthem into general expressions to enhance the applicability and effectiveness of\ndelta parameter editing in post-trained models.",
            "upvotes": 10,
            "discussionId": "6711c61d1e98ec0ba6bc4220"
        },
        "publishedAt": "2024-10-18T00:51:24.060Z",
        "title": "A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13841.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/b5ad98cf269ae5f1fe90861fb4170fae.svg",
            "fullname": "Bowen Yu",
            "name": "Tigerph",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13804",
            "authors": [
                {
                    "_id": "6711d1431133b5e4de7ef097",
                    "name": "Hongyu Zhao",
                    "hidden": false
                },
                {
                    "_id": "6711d1431133b5e4de7ef098",
                    "name": "Ming Li",
                    "hidden": false
                },
                {
                    "_id": "6711d1431133b5e4de7ef099",
                    "user": {
                        "_id": "65a52766215aabac489e3468",
                        "avatarUrl": "/avatars/fe05e22cd7e12e961296426434e17c76.svg",
                        "isPro": false,
                        "fullname": "Lichao Sun",
                        "user": "sunlichao137",
                        "type": "user"
                    },
                    "name": "Lichao Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:00:45.492Z",
                    "hidden": false
                },
                {
                    "_id": "6711d1431133b5e4de7ef09a",
                    "user": {
                        "_id": "647f5af5b0e96764589f3b2a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/VJ4cDyjp5M3V5WmI5gPIU.jpeg",
                        "isPro": false,
                        "fullname": "Tianyi Zhou",
                        "user": "zhoutianyi",
                        "type": "user"
                    },
                    "name": "Tianyi Zhou",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:12:25.345Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:41:15.000Z",
            "title": "BenTo: Benchmark Task Reduction with In-Context Transferability",
            "summary": "Evaluating large language models (LLMs) is costly: it requires the generation\nand examination of LLM outputs on a large-scale benchmark of various tasks.\nThis paper investigates how to efficiently reduce the tasks used to benchmark\nLLMs without affecting the evaluation quality. Our study reveals that task\ntransferability and relevance provide critical information to identify the most\nrepresentative subset of tasks via optimizing a facility location function. We\npropose a practically efficient metric for estimating the transferability\nbetween two tasks via in-context learning (ICL). By analyzing the pairwise\ntransferability, we can reduce tasks in a modern LLM benchmark (e.g., MMLU or\nFLAN) to 5% while inducing only a <4% difference to the evaluation on the\noriginal benchmark. Compared to prior works, our method is training-free,\ngradient-free, and highly efficient requiring ICL only.",
            "upvotes": 9,
            "discussionId": "6711d1441133b5e4de7ef121"
        },
        "publishedAt": "2024-10-18T01:58:57.082Z",
        "title": "BenTo: Benchmark Task Reduction with In-Context Transferability",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13804.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/VJ4cDyjp5M3V5WmI5gPIU.jpeg",
            "fullname": "Tianyi Zhou",
            "name": "zhoutianyi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13785",
            "authors": [
                {
                    "_id": "6711cdb07da5c0a86f649718",
                    "user": {
                        "_id": "6149a9e95347647e6bb68882",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6149a9e95347647e6bb68882/Jddln1FxScCeVgTSCNBpr.png",
                        "isPro": false,
                        "fullname": "Zekun Moore Wang",
                        "user": "ZenMoore",
                        "type": "user"
                    },
                    "name": "Zekun Moore Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:37:40.404Z",
                    "hidden": false
                },
                {
                    "_id": "6711cdb07da5c0a86f649719",
                    "name": "Shawn Wang",
                    "hidden": false
                },
                {
                    "_id": "6711cdb07da5c0a86f64971a",
                    "user": {
                        "_id": "6578265ddea7e2122d02f6ba",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6578265ddea7e2122d02f6ba/Bh6JjoVF5ceLSjV7Z7nTk.jpeg",
                        "isPro": false,
                        "fullname": "kang zhu",
                        "user": "kangz",
                        "type": "user"
                    },
                    "name": "Kang Zhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:55:13.210Z",
                    "hidden": false
                },
                {
                    "_id": "6711cdb07da5c0a86f64971b",
                    "user": {
                        "_id": "65377c30e48353201e6fdda0",
                        "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
                        "isPro": false,
                        "fullname": "Jiaheng Liu",
                        "user": "CheeryLJH",
                        "type": "user"
                    },
                    "name": "Jiaheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:38:22.673Z",
                    "hidden": false
                },
                {
                    "_id": "6711cdb07da5c0a86f64971c",
                    "name": "Ke Xu",
                    "hidden": false
                },
                {
                    "_id": "6711cdb07da5c0a86f64971d",
                    "name": "Jie Fu",
                    "hidden": false
                },
                {
                    "_id": "6711cdb07da5c0a86f64971e",
                    "user": {
                        "_id": "628c8598ef14f971b698107f",
                        "avatarUrl": "/avatars/3a4ad87e6b5f9e836a1160d869df1447.svg",
                        "isPro": false,
                        "fullname": "Zhou",
                        "user": "Wangchunshu",
                        "type": "user"
                    },
                    "name": "Wangchunshu Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:38:57.876Z",
                    "hidden": false
                },
                {
                    "_id": "6711cdb07da5c0a86f64971f",
                    "user": {
                        "_id": "641e5bf65f274a0a92c2f6a2",
                        "avatarUrl": "/avatars/c15a54c51998c0e6367685e8e1737ec9.svg",
                        "isPro": false,
                        "fullname": "Wenhao Huang",
                        "user": "EZ-hwh",
                        "type": "user"
                    },
                    "name": "Wenhao Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:39:13.119Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:22:05.000Z",
            "title": "PopAlign: Diversifying Contrasting Patterns for a More Comprehensive\n  Alignment",
            "summary": "Alignment of large language models (LLMs) involves training models on\npreference-contrastive output pairs to adjust their responses according to\nhuman preferences. To obtain such contrastive pairs, traditional methods like\nRLHF and RLAIF rely on limited contrasting patterns, such as varying model\nvariants or decoding temperatures. This singularity leads to two issues: (1)\nalignment is not comprehensive; and thereby (2) models are susceptible to\njailbreaking attacks. To address these issues, we investigate how to construct\nmore comprehensive and diversified contrasting patterns to enhance preference\ndata (RQ1) and verify the impact of the diversification of contrasting patterns\non model alignment (RQ2). For RQ1, we propose PopAlign, a framework that\nintegrates diversified contrasting patterns across the prompt, model, and\npipeline levels, introducing six contrasting strategies that do not require\nadditional feedback labeling procedures. Regarding RQ2, we conduct thorough\nexperiments demonstrating that PopAlign significantly outperforms existing\nmethods, leading to more comprehensive alignment.",
            "upvotes": 9,
            "discussionId": "6711cdb17da5c0a86f649745"
        },
        "publishedAt": "2024-10-18T01:39:45.788Z",
        "title": "PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13785.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6149a9e95347647e6bb68882/Jddln1FxScCeVgTSCNBpr.png",
            "fullname": "Zekun Moore Wang",
            "name": "ZenMoore",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13830",
            "authors": [
                {
                    "_id": "6711c8f0fe58fd40dde8c60a",
                    "user": {
                        "_id": "637f70d6fab5db9101c3dfc8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637f70d6fab5db9101c3dfc8/NgkYNXWLDavLbrnCby2Fl.jpeg",
                        "isPro": false,
                        "fullname": "Yujie Wei",
                        "user": "weilllllls",
                        "type": "user"
                    },
                    "name": "Yujie Wei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:42:53.127Z",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c60b",
                    "name": "Shiwei Zhang",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c60c",
                    "user": {
                        "_id": "649d54b314afbb10ce2a9eeb",
                        "avatarUrl": "/avatars/15c325d8c2273ff63569f23015e98486.svg",
                        "isPro": false,
                        "fullname": "Hangjie Yuan",
                        "user": "JacobYuan",
                        "type": "user"
                    },
                    "name": "Hangjie Yuan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:53:28.821Z",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c60d",
                    "name": "Xiang Wang",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c60e",
                    "user": {
                        "_id": "63023b6ab002e9a4a2152890",
                        "avatarUrl": "/avatars/cae8ba0a8d61fb4e576934431f43991b.svg",
                        "isPro": false,
                        "fullname": "Haonan Qiu",
                        "user": "MoonQiu",
                        "type": "user"
                    },
                    "name": "Haonan Qiu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:52:59.555Z",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c60f",
                    "name": "Rui Zhao",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c610",
                    "user": {
                        "_id": "64a54e468cfaa458bd6844bf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a54e468cfaa458bd6844bf/5Gmf4tAr59GNl-2VaZDbu.png",
                        "isPro": false,
                        "fullname": "Yutong Feng",
                        "user": "yutongfeng",
                        "type": "user"
                    },
                    "name": "Yutong Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:53:05.174Z",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c611",
                    "name": "Feng Liu",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c612",
                    "user": {
                        "_id": "64c4aad5d68946edad616413",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64c4aad5d68946edad616413/RY2lSiwOP5tDKDQWBF7E1.png",
                        "isPro": false,
                        "fullname": "Zhizhong Huang",
                        "user": "Hzzone",
                        "type": "user"
                    },
                    "name": "Zhizhong Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:53:11.406Z",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c613",
                    "user": {
                        "_id": "6503b02993574a89717b8f91",
                        "avatarUrl": "/avatars/f4d1698f1f7c516c5b849b96351a885e.svg",
                        "isPro": false,
                        "fullname": "JiaxinYe",
                        "user": "JiaxinYe",
                        "type": "user"
                    },
                    "name": "Jiaxin Ye",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:43:21.961Z",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c614",
                    "name": "Yingya Zhang",
                    "hidden": false
                },
                {
                    "_id": "6711c8f0fe58fd40dde8c615",
                    "name": "Hongming Shan",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:52:57.000Z",
            "title": "DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise\n  Motion Control",
            "summary": "Recent advances in customized video generation have enabled users to create\nvideos tailored to both specific subjects and motion trajectories. However,\nexisting methods often require complicated test-time fine-tuning and struggle\nwith balancing subject learning and motion control, limiting their real-world\napplications. In this paper, we present DreamVideo-2, a zero-shot video\ncustomization framework capable of generating videos with a specific subject\nand motion trajectory, guided by a single image and a bounding box sequence,\nrespectively, and without the need for test-time fine-tuning. Specifically, we\nintroduce reference attention, which leverages the model's inherent\ncapabilities for subject learning, and devise a mask-guided motion module to\nachieve precise motion control by fully utilizing the robust motion signal of\nbox masks derived from bounding boxes. While these two components achieve their\nintended functions, we empirically observe that motion control tends to\ndominate over subject learning. To address this, we propose two key designs: 1)\nthe masked reference attention, which integrates a blended latent mask modeling\nscheme into reference attention to enhance subject representations at the\ndesired positions, and 2) a reweighted diffusion loss, which differentiates the\ncontributions of regions inside and outside the bounding boxes to ensure a\nbalance between subject and motion control. Extensive experimental results on a\nnewly curated dataset demonstrate that DreamVideo-2 outperforms\nstate-of-the-art methods in both subject customization and motion control. The\ndataset, code, and models will be made publicly available.",
            "upvotes": 8,
            "discussionId": "6711c8f1fe58fd40dde8c65d"
        },
        "publishedAt": "2024-10-18T01:04:28.158Z",
        "title": "DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13830.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637f70d6fab5db9101c3dfc8/NgkYNXWLDavLbrnCby2Fl.jpeg",
            "fullname": "Yujie Wei",
            "name": "weilllllls",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.11842",
            "authors": [
                {
                    "_id": "6710bf3ff1279fe0dfe4e5b2",
                    "user": {
                        "_id": "651585ea18cfed0d30bee586",
                        "avatarUrl": "/avatars/579e468334102472d870875fe40302e6.svg",
                        "isPro": false,
                        "fullname": "Peng Jin",
                        "user": "Chat-UniVi",
                        "type": "user"
                    },
                    "name": "Peng Jin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-17T11:23:52.506Z",
                    "hidden": false
                },
                {
                    "_id": "6710bf3ff1279fe0dfe4e5b3",
                    "name": "Bo Zhu",
                    "hidden": false
                },
                {
                    "_id": "6710bf3ff1279fe0dfe4e5b4",
                    "user": {
                        "_id": "614030bd8cbdb613b82f36a8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1631596713749-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Li Yuan",
                        "user": "LiYuan",
                        "type": "user"
                    },
                    "name": "Li Yuan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:53:55.346Z",
                    "hidden": false
                },
                {
                    "_id": "6710bf3ff1279fe0dfe4e5b5",
                    "name": "Shuicheng Yan",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-15T17:59:44.000Z",
            "title": "MoH: Multi-Head Attention as Mixture-of-Head Attention",
            "summary": "In this work, we upgrade the multi-head attention mechanism, the core of the\nTransformer model, to improve efficiency while maintaining or surpassing the\nprevious accuracy level. We show that multi-head attention can be expressed in\nthe summation form. Drawing on the insight that not all attention heads hold\nequal significance, we propose Mixture-of-Head attention (MoH), a new\narchitecture that treats attention heads as experts in the Mixture-of-Experts\n(MoE) mechanism. MoH has two significant advantages: First, MoH enables each\ntoken to select the appropriate attention heads, enhancing inference efficiency\nwithout compromising accuracy or increasing the number of parameters. Second,\nMoH replaces the standard summation in multi-head attention with a weighted\nsummation, introducing flexibility to the attention mechanism and unlocking\nextra performance potential. Extensive experiments on ViT, DiT, and LLMs\ndemonstrate that MoH outperforms multi-head attention by using only 50%-90% of\nthe attention heads. Moreover, we demonstrate that pre-trained multi-head\nattention models, such as LLaMA3-8B, can be further continue-tuned into our MoH\nmodels. Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14\nbenchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of the\nattention heads. We believe the proposed MoH is a promising alternative to\nmulti-head attention and provides a strong foundation for developing advanced\nand efficient attention-based models.",
            "upvotes": 7,
            "discussionId": "6710bf40f1279fe0dfe4e5e6"
        },
        "publishedAt": "2024-10-18T03:16:53.005Z",
        "title": "MoH: Multi-Head Attention as Mixture-of-Head Attention",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.11842.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/579e468334102472d870875fe40302e6.svg",
            "fullname": "Peng Jin",
            "name": "Chat-UniVi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13832",
            "authors": [
                {
                    "_id": "6711da38e6f26ad913eac179",
                    "user": {
                        "_id": "634cddac04491d9f71132375",
                        "avatarUrl": "/avatars/2397218ddaca00e89b1207eada295d89.svg",
                        "isPro": false,
                        "fullname": "Jingwei Ma",
                        "user": "jingweim",
                        "type": "user"
                    },
                    "name": "Jingwei Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:54:07.209Z",
                    "hidden": false
                },
                {
                    "_id": "6711da38e6f26ad913eac17a",
                    "name": "Erika Lu",
                    "hidden": false
                },
                {
                    "_id": "6711da38e6f26ad913eac17b",
                    "user": {
                        "_id": "62cab8aeb189b6164d26bfbe",
                        "avatarUrl": "/avatars/7ed117e375dd9280a5750a242cae24ca.svg",
                        "isPro": false,
                        "fullname": "Roni Paiss",
                        "user": "RoniPaiss",
                        "type": "user"
                    },
                    "name": "Roni Paiss",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:54:20.845Z",
                    "hidden": false
                },
                {
                    "_id": "6711da38e6f26ad913eac17c",
                    "user": {
                        "_id": "63510f62cba4ff2e81cb0492",
                        "avatarUrl": "/avatars/2375a841491de8f40f66b6d0fb0df7b1.svg",
                        "isPro": false,
                        "fullname": "Shiran Zada",
                        "user": "shiranzada",
                        "type": "user"
                    },
                    "name": "Shiran Zada",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:54:26.118Z",
                    "hidden": false
                },
                {
                    "_id": "6711da38e6f26ad913eac17d",
                    "user": {
                        "_id": "62f6e2792e53c2efd33faa92",
                        "avatarUrl": "/avatars/85d94b4022577747b8d2d10a82c2f3c7.svg",
                        "isPro": false,
                        "fullname": "Aleksander Holynski",
                        "user": "holynski",
                        "type": "user"
                    },
                    "name": "Aleksander Holynski",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:54:32.095Z",
                    "hidden": false
                },
                {
                    "_id": "6711da38e6f26ad913eac17e",
                    "user": {
                        "_id": "631cddec68f7da9ad24f6fc7",
                        "avatarUrl": "/avatars/7d4f1ce805e5889ca6594bd4a93f2583.svg",
                        "isPro": false,
                        "fullname": "Tali Dekel",
                        "user": "talidekel",
                        "type": "user"
                    },
                    "name": "Tali Dekel",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:54:38.194Z",
                    "hidden": false
                },
                {
                    "_id": "6711da38e6f26ad913eac17f",
                    "name": "Brian Curless",
                    "hidden": false
                },
                {
                    "_id": "6711da38e6f26ad913eac180",
                    "name": "Michael Rubinstein",
                    "hidden": false
                },
                {
                    "_id": "6711da38e6f26ad913eac181",
                    "user": {
                        "_id": "635003011d81beb8e244e68d",
                        "avatarUrl": "/avatars/32f46e6778d1c52ebdd6f2511ba48257.svg",
                        "isPro": false,
                        "fullname": "Forrester Cole",
                        "user": "fcole",
                        "type": "user"
                    },
                    "name": "Forrester Cole",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-18T03:47:06.381Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:53:24.000Z",
            "title": "VidPanos: Generative Panoramic Videos from Casual Panning Videos",
            "summary": "Panoramic image stitching provides a unified, wide-angle view of a scene that\nextends beyond the camera's field of view. Stitching frames of a panning video\ninto a panoramic photograph is a well-understood problem for stationary scenes,\nbut when objects are moving, a still panorama cannot capture the scene. We\npresent a method for synthesizing a panoramic video from a casually-captured\npanning video, as if the original video were captured with a wide-angle camera.\nWe pose panorama synthesis as a space-time outpainting problem, where we aim to\ncreate a full panoramic video of the same length as the input video. Consistent\ncompletion of the space-time volume requires a powerful, realistic prior over\nvideo content and motion, for which we adapt generative video models. Existing\ngenerative models do not, however, immediately extend to panorama completion,\nas we show. We instead apply video generation as a component of our panorama\nsynthesis system, and demonstrate how to exploit the strengths of the models\nwhile minimizing their limitations. Our system can create video panoramas for a\nrange of in-the-wild scenes including people, vehicles, and flowing water, as\nwell as stationary background features.",
            "upvotes": 7,
            "discussionId": "6711da3ae6f26ad913eac223"
        },
        "publishedAt": "2024-10-18T02:17:13.515Z",
        "title": "VidPanos: Generative Panoramic Videos from Casual Panning Videos",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13832.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.09426",
            "authors": [
                {
                    "_id": "670e0d355cde0d9af5333564",
                    "name": "Yuxuan Sun",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af5333565",
                    "user": {
                        "_id": "6411c22dd52c57f628f7c331",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678885386428-noauth.jpeg",
                        "isPro": false,
                        "fullname": "ruikang liu",
                        "user": "lianlio",
                        "type": "user"
                    },
                    "name": "Ruikang Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-15T08:07:45.453Z",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af5333566",
                    "user": {
                        "_id": "667e1a0fa0ffad3dbc60df9d",
                        "avatarUrl": "/avatars/e16c7a3620ae5c82b7b636296a975ae1.svg",
                        "isPro": false,
                        "fullname": "Haoli Bai",
                        "user": "baihaoli",
                        "type": "user"
                    },
                    "name": "Haoli Bai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:56:22.165Z",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af5333567",
                    "name": "Han Bao",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af5333568",
                    "name": "Kang Zhao",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af5333569",
                    "name": "Yuening Li",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af533356a",
                    "user": {
                        "_id": "65268cb23427b73cb325a0b2",
                        "avatarUrl": "/avatars/29b5cca4182aebaf11250d6250c8e278.svg",
                        "isPro": false,
                        "fullname": "hu",
                        "user": "jiaxinhu",
                        "type": "user"
                    },
                    "name": "Jiaxin Hu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:56:35.178Z",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af533356b",
                    "name": "Xianzhi Yu",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af533356c",
                    "name": "Lu Hou",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af533356d",
                    "name": "Chun Yuan",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af533356e",
                    "user": {
                        "_id": "647415007afa69c3c7a98f1f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647415007afa69c3c7a98f1f/pEl0PozmzNK8_PwUMiikd.jpeg",
                        "isPro": false,
                        "fullname": "Xin Jiang",
                        "user": "horiz94",
                        "type": "user"
                    },
                    "name": "Xin Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:57:12.223Z",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af533356f",
                    "name": "Wulong Liu",
                    "hidden": false
                },
                {
                    "_id": "670e0d355cde0d9af5333570",
                    "name": "Jun Yao",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-12T08:10:28.000Z",
            "title": "FlatQuant: Flatness Matters for LLM Quantization",
            "summary": "Recently, quantization has been widely used for the compression and\nacceleration of large language models~(LLMs). Due to the outliers in LLMs, it\nis crucial to flatten weights and activations to minimize quantization error\nwith the equally spaced quantization points. Prior research explores various\npre-quantization transformations to suppress outliers, such as per-channel\nscaling and Hadamard transformation. However, we observe that these transformed\nweights and activations can still remain steep and outspread. In this paper, we\npropose FlatQuant (Fast and Learnable Affine Transformation), a new\npost-training quantization approach to enhance flatness of weights and\nactivations. Our approach identifies optimal affine transformations tailored to\neach linear layer, calibrated in hours via a lightweight objective. To reduce\nruntime overhead, we apply Kronecker decomposition to the transformation\nmatrices, and fuse all operations in FlatQuant into a single kernel. Extensive\nexperiments show that FlatQuant sets up a new state-of-the-art quantization\nbenchmark. For instance, it achieves less than 1% accuracy drop for\nW4A4 quantization on the LLaMA-3-70B model, surpassing SpinQuant by\n7.5%. For inference latency, FlatQuant reduces the slowdown induced\nby pre-quantization transformation from 0.26x of QuaRot to merely\n0.07x, bringing up to 2.3x speedup for prefill and\n1.7x speedup for decoding, respectively. Code is available at:\nhttps://github.com/ruikangliu/FlatQuant.",
            "upvotes": 6,
            "discussionId": "670e0d375cde0d9af5333602"
        },
        "publishedAt": "2024-10-18T00:05:54.718Z",
        "title": "FlatQuant: Flatness Matters for LLM Quantization",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.09426.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678885386428-noauth.jpeg",
            "fullname": "ruikang liu",
            "name": "lianlio",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13852",
            "authors": [
                {
                    "_id": "6711c3ba7da5c0a86f61f0c5",
                    "user": {
                        "_id": "634642c17393804ce0d83879",
                        "avatarUrl": "/avatars/36ef4df22b9faaf76a8a03e2c55a66e8.svg",
                        "isPro": false,
                        "fullname": "zizhao chen",
                        "user": "czz",
                        "type": "user"
                    },
                    "name": "Zizhao Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:54:54.582Z",
                    "hidden": false
                },
                {
                    "_id": "6711c3ba7da5c0a86f61f0c6",
                    "user": {
                        "_id": "640261cc06c715b934025f4e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640261cc06c715b934025f4e/aXnh-ZGvEahSovuivi6dr.jpeg",
                        "isPro": true,
                        "fullname": "Mustafa Omer Gul",
                        "user": "momergul",
                        "type": "user"
                    },
                    "name": "Mustafa Omer Gul",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:55:00.071Z",
                    "hidden": false
                },
                {
                    "_id": "6711c3ba7da5c0a86f61f0c7",
                    "name": "Yiwei Chen",
                    "hidden": false
                },
                {
                    "_id": "6711c3ba7da5c0a86f61f0c8",
                    "name": "Gloria Geng",
                    "hidden": false
                },
                {
                    "_id": "6711c3ba7da5c0a86f61f0c9",
                    "user": {
                        "_id": "64515bda110343638e38b3df",
                        "avatarUrl": "/avatars/a69ccb8cc40a58d49fa907a00a1397fd.svg",
                        "isPro": true,
                        "fullname": "Anne Wu",
                        "user": "anneyouw",
                        "type": "user"
                    },
                    "name": "Anne Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:55:59.916Z",
                    "hidden": false
                },
                {
                    "_id": "6711c3ba7da5c0a86f61f0ca",
                    "user": {
                        "_id": "637c23489495870ef76d7880",
                        "avatarUrl": "/avatars/4fd2f23d9a487b1ec0c749c1e11b8ffc.svg",
                        "isPro": false,
                        "fullname": "Yoav Artzi",
                        "user": "yoavartzi",
                        "type": "user"
                    },
                    "name": "Yoav Artzi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:56:05.282Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:59:03.000Z",
            "title": "Retrospective Learning from Interactions",
            "summary": "Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.",
            "upvotes": 5,
            "discussionId": "6711c3bb7da5c0a86f61f11e"
        },
        "publishedAt": "2024-10-18T00:43:05.886Z",
        "title": "Retrospective Learning from Interactions",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/637c23489495870ef76d7880/piR4_KuQtejFzvZdIuXEY.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13852.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/4fd2f23d9a487b1ec0c749c1e11b8ffc.svg",
            "fullname": "Yoav Artzi",
            "name": "yoavartzi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13198",
            "authors": [
                {
                    "_id": "6711bfbd035ddf7e14b22417",
                    "name": "Sreyan Ghosh",
                    "hidden": false
                },
                {
                    "_id": "6711bfbd035ddf7e14b22418",
                    "user": {
                        "_id": "658dd50b315340de5fcb1321",
                        "avatarUrl": "/avatars/72b0030ff3f5f47002e0ff4e2d665b46.svg",
                        "isPro": false,
                        "fullname": "Mohammad Sadegh Rasooli",
                        "user": "rasoolims",
                        "type": "user"
                    },
                    "name": "Mohammad Sadegh Rasooli",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:58:14.910Z",
                    "hidden": false
                },
                {
                    "_id": "6711bfbd035ddf7e14b22419",
                    "name": "Michael Levit",
                    "hidden": false
                },
                {
                    "_id": "6711bfbd035ddf7e14b2241a",
                    "name": "Peidong Wang",
                    "hidden": false
                },
                {
                    "_id": "6711bfbd035ddf7e14b2241b",
                    "name": "Jian Xue",
                    "hidden": false
                },
                {
                    "_id": "6711bfbd035ddf7e14b2241c",
                    "user": {
                        "_id": "6537a569568d8be8fa096b8c",
                        "avatarUrl": "/avatars/bfda5cb252d8b5bc3ad737d99c0d7f49.svg",
                        "isPro": false,
                        "fullname": "Dinesh Manocha",
                        "user": "manocha",
                        "type": "user"
                    },
                    "name": "Dinesh Manocha",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:59:11.285Z",
                    "hidden": false
                },
                {
                    "_id": "6711bfbd035ddf7e14b2241d",
                    "name": "Jinyu Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T04:00:29.000Z",
            "title": "Failing Forward: Improving Generative Error Correction for ASR with\n  Synthetic Data and Retrieval Augmentation",
            "summary": "Generative Error Correction (GEC) has emerged as a powerful post-processing\nmethod to enhance the performance of Automatic Speech Recognition (ASR)\nsystems. However, we show that GEC models struggle to generalize beyond the\nspecific types of errors encountered during training, limiting their ability to\ncorrect new, unseen errors at test time, particularly in out-of-domain (OOD)\nscenarios. This phenomenon amplifies with named entities (NEs), where, in\naddition to insufficient contextual information or knowledge about the NEs,\nnovel NEs keep emerging. To address these issues, we propose DARAG (Data- and\nRetrieval-Augmented Generative Error Correction), a novel approach designed to\nimprove GEC for ASR in in-domain (ID) and OOD scenarios. We augment the GEC\ntraining dataset with synthetic data generated by prompting LLMs and\ntext-to-speech models, thereby simulating additional errors from which the\nmodel can learn. For OOD scenarios, we simulate test-time errors from new\ndomains similarly and in an unsupervised fashion. Additionally, to better\nhandle named entities, we introduce retrieval-augmented correction by\naugmenting the input with entities retrieved from a database. Our approach is\nsimple, scalable, and both domain- and language-agnostic. We experiment on\nmultiple datasets and settings, showing that DARAG outperforms all our\nbaselines, achieving 8\\% -- 30\\% relative WER improvements in ID and 10\\% --\n33\\% improvements in OOD settings.",
            "upvotes": 5,
            "discussionId": "6711bfbf035ddf7e14b22493"
        },
        "publishedAt": "2024-10-18T00:25:05.027Z",
        "title": "Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13198.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/ca23ecdec2d31c99ecce97d9b180ae0c.svg",
            "fullname": "Ghosh",
            "name": "Sreyan88",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13854",
            "authors": [
                {
                    "_id": "6712196cf92689ddb66f3434",
                    "user": {
                        "_id": "647daf00cfca67bc50f9a99f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647daf00cfca67bc50f9a99f/8Snmk1V6lZ8ecdTW3POfm.jpeg",
                        "isPro": false,
                        "fullname": "Chenhao Zhang",
                        "user": "MING-ZCH",
                        "type": "user"
                    },
                    "name": "Chenhao Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:25:08.521Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3435",
                    "name": "Xi Feng",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3436",
                    "name": "Yuelin Bai",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3437",
                    "name": "Xinrun Du",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3438",
                    "name": "Jinchang Hou",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3439",
                    "name": "Kaixin Deng",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f343a",
                    "user": {
                        "_id": "63337b0073c07e8aebb3df0d",
                        "avatarUrl": "/avatars/f0e55c3c61538d9521a28eda78cf31db.svg",
                        "isPro": false,
                        "fullname": "GUANGZENG HAN",
                        "user": "kwangju",
                        "type": "user"
                    },
                    "name": "Guangzeng Han",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:04:53.176Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f343b",
                    "name": "Qinrui Li",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f343c",
                    "user": {
                        "_id": "658d0a228cff48d3a4612689",
                        "avatarUrl": "/avatars/70e297c6cb12d1bdde6d91c23f590b63.svg",
                        "isPro": false,
                        "fullname": "Bingli Wang",
                        "user": "BingliW",
                        "type": "user"
                    },
                    "name": "Bingli Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:05:06.585Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f343d",
                    "user": {
                        "_id": "65377c30e48353201e6fdda0",
                        "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
                        "isPro": false,
                        "fullname": "Jiaheng Liu",
                        "user": "CheeryLJH",
                        "type": "user"
                    },
                    "name": "Jiaheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:05:12.954Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f343e",
                    "name": "Xingwei Qu",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f343f",
                    "user": {
                        "_id": "638efcf4c67af472d316d424",
                        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                        "isPro": false,
                        "fullname": "Ge Zhang",
                        "user": "zhangysk",
                        "type": "user"
                    },
                    "name": "Yifei Zhang",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-18T08:16:45.518Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3440",
                    "user": {
                        "_id": "6416fcaf249360df28d81237",
                        "avatarUrl": "/avatars/814d59b1e382b4b41c5334d95612483b.svg",
                        "isPro": false,
                        "fullname": "Qixuan Zhao",
                        "user": "MakiseKurisu",
                        "type": "user"
                    },
                    "name": "Qixuan Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:05:26.660Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3441",
                    "user": {
                        "_id": "6555e8d8a0c34cd61a6b9ce3",
                        "avatarUrl": "/avatars/71dc562cef4bd42f6b762f036357c800.svg",
                        "isPro": false,
                        "fullname": "yimingliang",
                        "user": "yimingliang",
                        "type": "user"
                    },
                    "name": "Yiming Liang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:08:40.195Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3442",
                    "user": {
                        "_id": "61b9b5f9fd429dff1ed3bd58",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61b9b5f9fd429dff1ed3bd58/GrfeNU4K1zts-gmQdGbVE.jpeg",
                        "isPro": false,
                        "fullname": "Ziqiang Liu",
                        "user": "icoderzqliu",
                        "type": "user"
                    },
                    "name": "Ziqiang Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:06:53.846Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3443",
                    "user": {
                        "_id": "634d4284f0a69955f66489f3",
                        "avatarUrl": "/avatars/9fac134537e6ef802f26d6d54c0e0bca.svg",
                        "isPro": false,
                        "fullname": "feitengfang",
                        "user": "feltoner",
                        "type": "user"
                    },
                    "name": "Feiteng Fang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:07:05.165Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3444",
                    "name": "Min Yang",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3445",
                    "name": "Wenhao Huang",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3446",
                    "user": {
                        "_id": "6442ba123610a28a4ad5382f",
                        "avatarUrl": "/avatars/97f2d3d2c10058ea41d7bf9087e1f619.svg",
                        "isPro": false,
                        "fullname": "Chenghua Lin",
                        "user": "chenghualin",
                        "type": "user"
                    },
                    "name": "Chenghua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:06:18.628Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3447",
                    "user": {
                        "_id": "638efcf4c67af472d316d424",
                        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                        "isPro": false,
                        "fullname": "Ge Zhang",
                        "user": "zhangysk",
                        "type": "user"
                    },
                    "name": "Ge Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:06:24.181Z",
                    "hidden": false
                },
                {
                    "_id": "6712196cf92689ddb66f3448",
                    "user": {
                        "_id": "641944acf9d6f1d772ede902",
                        "avatarUrl": "/avatars/a2f88017f7ab0cbea6862201e35fe747.svg",
                        "isPro": false,
                        "fullname": "ShiwenNi",
                        "user": "ShiwenNi",
                        "type": "user"
                    },
                    "name": "Shiwen Ni",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:04:09.904Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:59:24.000Z",
            "title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?",
            "summary": "As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.",
            "upvotes": 4,
            "discussionId": "6712196df92689ddb66f34ad"
        },
        "publishedAt": "2024-10-18T06:54:13.083Z",
        "title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13854.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647daf00cfca67bc50f9a99f/8Snmk1V6lZ8ecdTW3POfm.jpeg",
            "fullname": "Chenhao Zhang",
            "name": "MING-ZCH",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.09019",
            "authors": [
                {
                    "_id": "6711ce7841ad206aabb63260",
                    "user": {
                        "_id": "66a02bb71bb371390c4ae519",
                        "avatarUrl": "/avatars/2c4791516aae0b20a9c9ce0542dc966e.svg",
                        "isPro": false,
                        "fullname": "Krithik Vishwanath",
                        "user": "KrithikV",
                        "type": "user"
                    },
                    "name": "Krithik Vishwanath",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-18T02:56:57.499Z",
                    "hidden": false
                },
                {
                    "_id": "6711ce7841ad206aabb63261",
                    "user": {
                        "_id": "6490f001f049c475bdb5178f",
                        "avatarUrl": "/avatars/97523fda9a37a16282e427e8862b0d84.svg",
                        "isPro": false,
                        "fullname": "Jaden Stryker",
                        "user": "JadenStryker",
                        "type": "user"
                    },
                    "name": "Jaden Stryker",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T12:57:32.723Z",
                    "hidden": false
                },
                {
                    "_id": "6711ce7841ad206aabb63262",
                    "name": "Anton Alaykin",
                    "hidden": false
                },
                {
                    "_id": "6711ce7841ad206aabb63263",
                    "name": "Daniel Alexander Alber",
                    "hidden": false
                },
                {
                    "_id": "6711ce7841ad206aabb63264",
                    "name": "Eric Karl Oermann",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-11T17:32:59.000Z",
            "title": "MedMobile: A mobile-sized language model with expert-level clinical\n  capabilities",
            "summary": "Language models (LMs) have demonstrated expert-level reasoning and recall\nabilities in medicine. However, computational costs and privacy concerns are\nmounting barriers to wide-scale implementation. We introduce a parsimonious\nadaptation of phi-3-mini, MedMobile, a 3.8 billion parameter LM capable of\nrunning on a mobile device, for medical applications. We demonstrate that\nMedMobile scores 75.7% on the MedQA (USMLE), surpassing the passing mark for\nphysicians (~60%), and approaching the scores of models 100 times its size. We\nsubsequently perform a careful set of ablations, and demonstrate that chain of\nthought, ensembling, and fine-tuning lead to the greatest performance gains,\nwhile unexpectedly retrieval augmented generation fails to demonstrate\nsignificant improvements",
            "upvotes": 4,
            "discussionId": "6711ce7941ad206aabb632a0"
        },
        "publishedAt": "2024-10-18T01:31:56.264Z",
        "title": "MedMobile: A mobile-sized language model with expert-level clinical capabilities",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.09019.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/2c4791516aae0b20a9c9ce0542dc966e.svg",
            "fullname": "Krithik Vishwanath",
            "name": "KrithikV",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.12705",
            "authors": [
                {
                    "_id": "6710a473796c1ddb6f61fba5",
                    "user": {
                        "_id": "5f5c4b20e56d546cd6233098",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1637813888895-5f5c4b20e56d546cd6233098.jpeg",
                        "isPro": false,
                        "fullname": "Genta Indra Winata",
                        "user": "gentaiscool",
                        "type": "user"
                    },
                    "name": "Genta Indra Winata",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:31:19.454Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fba6",
                    "user": {
                        "_id": "626d38835651e31a7a2e150b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626d38835651e31a7a2e150b/xi-Rpvi8Hm-AzNM4dVYnZ.jpeg",
                        "isPro": false,
                        "fullname": "Frederikus Hudi",
                        "user": "fhudi",
                        "type": "user"
                    },
                    "name": "Frederikus Hudi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:31:42.599Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fba7",
                    "user": {
                        "_id": "64d1e3a87e20ec9ea0020d03",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64d1e3a87e20ec9ea0020d03/xm-afh1AaqS0e9qpaPo7y.jpeg",
                        "isPro": false,
                        "fullname": "Patrick Amadeus Irawan",
                        "user": "patrickamadeus",
                        "type": "user"
                    },
                    "name": "Patrick Amadeus Irawan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T15:55:09.689Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fba8",
                    "user": {
                        "_id": "651803f834c26962535eb022",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651803f834c26962535eb022/oXWbvY5xsjEz1N_5dnbnu.png",
                        "isPro": false,
                        "fullname": "David Anugraha",
                        "user": "davidanugraha",
                        "type": "user"
                    },
                    "name": "David Anugraha",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:31:53.691Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fba9",
                    "user": {
                        "_id": "6177a42348ce96fe95f80e0a",
                        "avatarUrl": "/avatars/71d2f94e191c484f86558e6f5cbbf043.svg",
                        "isPro": false,
                        "fullname": "Rifki Afina Putri",
                        "user": "rifkiaputri",
                        "type": "user"
                    },
                    "name": "Rifki Afina Putri",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:31:59.447Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbaa",
                    "name": "Yutong Wang",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbab",
                    "user": {
                        "_id": "62236dc0841d3b0a0efd43ec",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62236dc0841d3b0a0efd43ec/VHWnWnmaXnV70lAPt1WRT.png",
                        "isPro": false,
                        "fullname": "Adam Nohejl",
                        "user": "adno",
                        "type": "user"
                    },
                    "name": "Adam Nohejl",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:32:25.687Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbac",
                    "user": {
                        "_id": "657833d80e0d4703ffb4a48c",
                        "avatarUrl": "/avatars/b37a9c604d44f3e26991d6864d4b2676.svg",
                        "isPro": false,
                        "fullname": "Ubaidillah Ariq Prathama",
                        "user": "ubaidillah-ariq",
                        "type": "user"
                    },
                    "name": "Ubaidillah Ariq Prathama",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:32:31.203Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbad",
                    "name": "Nedjma Ousidhoum",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbae",
                    "user": {
                        "_id": "63ba2457205688cd2f95efcb",
                        "avatarUrl": "/avatars/fb5f572cf96312c4553093353ec3ab80.svg",
                        "isPro": false,
                        "fullname": "Aulia Adila",
                        "user": "auliaadila",
                        "type": "user"
                    },
                    "name": "Afifa Amriani",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:38:52.604Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbaf",
                    "user": {
                        "_id": "62b2c3768c8fac72c9602903",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655882584229-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Anar Rzayev",
                        "user": "AnarSnowball",
                        "type": "user"
                    },
                    "name": "Anar Rzayev",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:33:32.172Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb0",
                    "name": "Anirban Das",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb1",
                    "name": "Ashmari Pramodya",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb2",
                    "user": {
                        "_id": "63ba2457205688cd2f95efcb",
                        "avatarUrl": "/avatars/fb5f572cf96312c4553093353ec3ab80.svg",
                        "isPro": false,
                        "fullname": "Aulia Adila",
                        "user": "auliaadila",
                        "type": "user"
                    },
                    "name": "Aulia Adila",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:33:49.398Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb3",
                    "user": {
                        "_id": "5f5c4e7de56d546cd623309d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1599884906291-noauth.png",
                        "isPro": false,
                        "fullname": "Bryan Wilie",
                        "user": "bryanwilie",
                        "type": "user"
                    },
                    "name": "Bryan Wilie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:33:54.940Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb4",
                    "name": "Candy Olivia Mawalim",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb5",
                    "name": "Ching Lam Cheng",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb6",
                    "name": "Daud Abolade",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb7",
                    "name": "Emmanuele Chersoni",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb8",
                    "user": {
                        "_id": "60dca903d78dd6a5d680d89b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1625073904013-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Enrico Santus",
                        "user": "esantus",
                        "type": "user"
                    },
                    "name": "Enrico Santus",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:39:16.416Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbb9",
                    "user": {
                        "_id": "638edfc32cc490759feb3293",
                        "avatarUrl": "/avatars/9308f5f855761353d99ed098b4e82573.svg",
                        "isPro": false,
                        "fullname": "Fariz Ikhwantri",
                        "user": "farizikhwantri",
                        "type": "user"
                    },
                    "name": "Fariz Ikhwantri",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:39:22.848Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbba",
                    "user": {
                        "_id": "60d3d7640c54a218bc7752b0",
                        "avatarUrl": "/avatars/923dc199cff7d6e8fd7f6cad924c831a.svg",
                        "isPro": false,
                        "fullname": "Garry Kuwanto",
                        "user": "gkuwanto",
                        "type": "user"
                    },
                    "name": "Garry Kuwanto",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:39:50.809Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbbb",
                    "user": {
                        "_id": "65543320520d9bb9d9d3d47d",
                        "avatarUrl": "/avatars/89808c80248af4e234bdd42abea94d91.svg",
                        "isPro": false,
                        "fullname": "Hanyang Zhao",
                        "user": "BraceZHY",
                        "type": "user"
                    },
                    "name": "Hanyang Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:39:58.582Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbbc",
                    "name": "Haryo Akbarianto Wibowo",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbbd",
                    "user": {
                        "_id": "616cd2e040e2f69baa1c7af2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/616cd2e040e2f69baa1c7af2/11C_1dowE-ZVzk6GUht5s.jpeg",
                        "isPro": false,
                        "fullname": "Holy Lovenia",
                        "user": "holylovenia",
                        "type": "user"
                    },
                    "name": "Holy Lovenia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:40:11.540Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbbe",
                    "name": "Jan Christian Blaise Cruz",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbbf",
                    "name": "Jan Wira Gotama Putra",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc0",
                    "name": "Junho Myung",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc1",
                    "name": "Lucky Susanto",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc2",
                    "name": "Maria Angelica Riera Machin",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc3",
                    "user": {
                        "_id": "639f67c50d679f539438c807",
                        "avatarUrl": "/avatars/987b65b82e3dcdab51dd5ba76391590e.svg",
                        "isPro": false,
                        "fullname": "Marina Zhukova",
                        "user": "mzhukova",
                        "type": "user"
                    },
                    "name": "Marina Zhukova",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:55:20.394Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc4",
                    "name": "Michael Anugraha",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc5",
                    "user": {
                        "_id": "60c7fe961ef9b0a2ad1d398e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60c7fe961ef9b0a2ad1d398e/S4ewjcFp_q0Fj6QK8GwtL.jpeg",
                        "isPro": false,
                        "fullname": "Muhammad Farid Adilazuarda",
                        "user": "faridlazuarda",
                        "type": "user"
                    },
                    "name": "Muhammad Farid Adilazuarda",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:42:56.564Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc6",
                    "name": "Natasha Santosa",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc7",
                    "user": {
                        "_id": "612cc140ed7fc620ce36dbe0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633414888277-612cc140ed7fc620ce36dbe0.jpeg",
                        "isPro": false,
                        "fullname": "Peerat Limkonchotiwat",
                        "user": "mrp",
                        "type": "user"
                    },
                    "name": "Peerat Limkonchotiwat",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:42:48.306Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc8",
                    "name": "Raj Dabre",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbc9",
                    "name": "Rio Alexander Audino",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbca",
                    "name": "Samuel Cahyawijaya",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbcb",
                    "user": {
                        "_id": "650cfd41e31a6f18f003a975",
                        "avatarUrl": "/avatars/493aed8a453257a4d17e73fbb4bcd33c.svg",
                        "isPro": false,
                        "fullname": " zhang",
                        "user": "zhangshixiongyourbrother",
                        "type": "user"
                    },
                    "name": "Shi-Xiong Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:42:38.875Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbcc",
                    "name": "Stephanie Yulia Salim",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbcd",
                    "name": "Yi Zhou",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbce",
                    "name": "Yinxuan Gui",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbcf",
                    "name": "David Ifeoluwa Adelani",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbd0",
                    "name": "En-Shiun Annie Lee",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbd1",
                    "name": "Shogo Okada",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbd2",
                    "user": {
                        "_id": "5f5f21fa3c67af20d9945a58",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1600070118464-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Ayu Purwarianti",
                        "user": "ayupurwarianti",
                        "type": "user"
                    },
                    "name": "Ayu Purwarianti",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T15:42:13.719Z",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbd3",
                    "name": "Alham Fikri Aji",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbd4",
                    "name": "Taro Watanabe",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbd5",
                    "name": "Derry Tanti Wijaya",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbd6",
                    "name": "Alice Oh",
                    "hidden": false
                },
                {
                    "_id": "6710a473796c1ddb6f61fbd7",
                    "name": "Chong-Wah Ngo",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-16T16:11:49.000Z",
            "title": "WorldCuisines: A Massive-Scale Benchmark for Multilingual and\n  Multicultural Visual Question Answering on Global Cuisines",
            "summary": "Vision Language Models (VLMs) often struggle with culture-specific knowledge,\nparticularly in languages other than English and in underrepresented cultural\ncontexts. To evaluate their understanding of such knowledge, we introduce\nWorldCuisines, a massive-scale benchmark for multilingual and multicultural,\nvisually grounded language understanding. This benchmark includes a visual\nquestion answering (VQA) dataset with text-image pairs across 30 languages and\ndialects, spanning 9 language families and featuring over 1 million data\npoints, making it the largest multicultural VQA benchmark to date. It includes\ntasks for identifying dish names and their origins. We provide evaluation\ndatasets in two sizes (12k and 60k instances) alongside a training dataset (1\nmillion instances). Our findings show that while VLMs perform better with\ncorrect location context, they struggle with adversarial contexts and\npredicting specific regional cuisines and languages. To support future\nresearch, we release a knowledge base with annotated food entries and images\nalong with the VQA data.",
            "upvotes": 3,
            "discussionId": "6710a476796c1ddb6f61fc9b"
        },
        "publishedAt": "2024-10-18T14:10:54.279Z",
        "title": "WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.12705.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1637813888895-5f5c4b20e56d546cd6233098.jpeg",
            "fullname": "Genta Indra Winata",
            "name": "gentaiscool",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13859",
            "authors": [
                {
                    "_id": "6712229d0babf0ff2ee7d3a6",
                    "user": {
                        "_id": "653cb809b424289c5f384a02",
                        "avatarUrl": "/avatars/0757cb749fd8924d8e74cc4ad04e5088.svg",
                        "isPro": false,
                        "fullname": "YaxinLuo",
                        "user": "YaxinLuo",
                        "type": "user"
                    },
                    "name": "Yaxin Luo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T09:25:01.030Z",
                    "hidden": false
                },
                {
                    "_id": "6712229d0babf0ff2ee7d3a7",
                    "user": {
                        "_id": "650aac7c23196fb2d86a0b37",
                        "avatarUrl": "/avatars/418035a2e8f514118bc67d16ee41b6b0.svg",
                        "isPro": false,
                        "fullname": "Gen Luo",
                        "user": "favor123",
                        "type": "user"
                    },
                    "name": "Gen Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:03:57.293Z",
                    "hidden": false
                },
                {
                    "_id": "6712229d0babf0ff2ee7d3a8",
                    "user": {
                        "_id": "61c7cb3fc4157c1d283da869",
                        "avatarUrl": "/avatars/8707bcb8b4e3725fe43115a88fe14be9.svg",
                        "isPro": false,
                        "fullname": "Jiayi Ji",
                        "user": "amy1254",
                        "type": "user"
                    },
                    "name": "Jiayi Ji",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:03:51.931Z",
                    "hidden": false
                },
                {
                    "_id": "6712229d0babf0ff2ee7d3a9",
                    "user": {
                        "_id": "64e0d3b0c20c27fcc8cb0b86",
                        "avatarUrl": "/avatars/eab7ee1f2d61d336c105a1d07c57df1c.svg",
                        "isPro": false,
                        "fullname": "zhouyiyi",
                        "user": "zhouyi1989",
                        "type": "user"
                    },
                    "name": "Yiyi Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:03:46.428Z",
                    "hidden": false
                },
                {
                    "_id": "6712229d0babf0ff2ee7d3aa",
                    "name": "Xiaoshuai Sun",
                    "hidden": false
                },
                {
                    "_id": "6712229d0babf0ff2ee7d3ab",
                    "user": {
                        "_id": "649d5a3f4e08d59d20014652",
                        "avatarUrl": "/avatars/017eccd6aec02137c1beebfe4c951720.svg",
                        "isPro": false,
                        "fullname": "Zhiqiang Shen",
                        "user": "Jason0214",
                        "type": "user"
                    },
                    "name": "Zhiqiang Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:03:19.045Z",
                    "hidden": false
                },
                {
                    "_id": "6712229d0babf0ff2ee7d3ac",
                    "name": "Rongrong Ji",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:59:53.000Z",
            "title": "Œ≥-MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large\n  Language Models",
            "summary": "Despite the significant progress in multimodal large language models (MLLMs),\ntheir high computational cost remains a barrier to real-world deployment.\nInspired by the mixture of depths (MoDs) in natural language processing, we aim\nto address this limitation from the perspective of ``activated tokens''. Our\nkey insight is that if most tokens are redundant for the layer computation,\nthen can be skipped directly via the MoD layer. However, directly converting\nthe dense layers of MLLMs to MoD layers leads to substantial performance\ndegradation. To address this issue, we propose an innovative MoD adaptation\nstrategy for existing MLLMs called gamma-MoD. In gamma-MoD, a novel\nmetric is proposed to guide the deployment of MoDs in the MLLM, namely rank of\nattention maps (ARank). Through ARank, we can effectively identify which layer\nis redundant and should be replaced with the MoD layer. Based on ARank, we\nfurther propose two novel designs to maximize the computational sparsity of\nMLLM while maintaining its performance, namely shared vision-language router\nand masked routing learning. With these designs, more than 90% dense layers of\nthe MLLM can be effectively converted to the MoD ones. To validate our method,\nwe apply it to three popular MLLMs, and conduct extensive experiments on 9\nbenchmark datasets. Experimental results not only validate the significant\nefficiency benefit of gamma-MoD to existing MLLMs but also confirm its\ngeneralization ability on various MLLMs. For example, with a minor performance\ndrop, i.e., -1.5%, gamma-MoD can reduce the training and inference time of\nLLaVA-HR by 31.0% and 53.2%, respectively.",
            "upvotes": 3,
            "discussionId": "6712229e0babf0ff2ee7d419"
        },
        "publishedAt": "2024-10-18T08:06:48.236Z",
        "title": "$Œ≥-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/653cb809b424289c5f384a02/V4xLsjaNkIR6Hixau-8gt.png",
            "https://cdn-uploads.huggingface.co/production/uploads/653cb809b424289c5f384a02/8FzZEEXxgoaWtYfYyH-Fw.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13859.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/0757cb749fd8924d8e74cc4ad04e5088.svg",
            "fullname": "YaxinLuo",
            "name": "YaxinLuo",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13360",
            "authors": [
                {
                    "_id": "6712176ef8feb84b4a03f70a",
                    "user": {
                        "_id": "669e221425f2081c6e3d8b61",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/669e221425f2081c6e3d8b61/OearXzKrvoIZtDKTH4kje.jpeg",
                        "isPro": false,
                        "fullname": "Haoran Hao",
                        "user": "Hoar012",
                        "type": "user"
                    },
                    "name": "Haoran Hao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:12:22.907Z",
                    "hidden": false
                },
                {
                    "_id": "6712176ef8feb84b4a03f70b",
                    "name": "Jiaming Han",
                    "hidden": false
                },
                {
                    "_id": "6712176ef8feb84b4a03f70c",
                    "user": {
                        "_id": "653a54c87e372a9e13642952",
                        "avatarUrl": "/avatars/0f34962610b4b22b8509c4b724821b96.svg",
                        "isPro": false,
                        "fullname": "CHANGSHENG LI",
                        "user": "Praised414",
                        "type": "user"
                    },
                    "name": "Changsheng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:03:04.912Z",
                    "hidden": false
                },
                {
                    "_id": "6712176ef8feb84b4a03f70d",
                    "user": {
                        "_id": "64e76d5f31f7cea634cbeadc",
                        "avatarUrl": "/avatars/f9708afafe1cb935bae80c1a1fc4359c.svg",
                        "isPro": false,
                        "fullname": "Li, Yufeng",
                        "user": "yufengli",
                        "type": "user"
                    },
                    "name": "Yu-Feng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:02:58.587Z",
                    "hidden": false
                },
                {
                    "_id": "6712176ef8feb84b4a03f70e",
                    "user": {
                        "_id": "666a8f24e2990b0cb16b7bf9",
                        "avatarUrl": "/avatars/fcbaf8f1e3e53a2a4a819b7cb2c53aa4.svg",
                        "isPro": false,
                        "fullname": "Xiangyu Yue",
                        "user": "xyyue",
                        "type": "user"
                    },
                    "name": "Xiangyu Yue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:02:47.827Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T09:10:26.000Z",
            "title": "Remember, Retrieve and Generate: Understanding Infinite Visual Concepts\n  as Your Personalized Assistant",
            "summary": "The development of large language models (LLMs) has significantly enhanced\nthe capabilities of multimodal LLMs (MLLMs) as general assistants. However,\nlack of user-specific knowledge still restricts their application in human's\ndaily life. In this paper, we introduce the Retrieval Augmented Personalization\n(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we\nturn it into a personalized assistant in three steps. (a) Remember: We design a\nkey-value database to store user-related information, e.g., user's name, avatar\nand other attributes. (b) Retrieve: When the user initiates a conversation, RAP\nwill retrieve relevant information from the database using a multimodal\nretriever. (c) Generate: The input query and retrieved concepts' information\nare fed into MLLMs to generate personalized, knowledge-augmented responses.\nUnlike previous methods, RAP allows real-time concept editing via updating the\nexternal database. To further improve generation quality and alignment with\nuser-specific information, we design a pipeline for data collection and create\na specialized dataset for personalized training of MLLMs. Based on the dataset,\nwe train a series of MLLMs as personalized multimodal assistants. By\npretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual\nconcepts without additional finetuning. Our models demonstrate outstanding\nflexibility and generation quality across a variety of tasks, such as\npersonalized image captioning, question answering and visual recognition. The\ncode, data and models are available at https://github.com/Hoar012/RAP-MLLM.",
            "upvotes": 3,
            "discussionId": "67121770f8feb84b4a03f7f5"
        },
        "publishedAt": "2024-10-18T06:47:51.127Z",
        "title": "Remember, Retrieve and Generate: Understanding Infinite Visual Concepts as Your Personalized Assistant",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13360.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/669e221425f2081c6e3d8b61/OearXzKrvoIZtDKTH4kje.jpeg",
            "fullname": "Haoran Hao",
            "name": "Hoar012",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.12957",
            "authors": [
                {
                    "_id": "6712157b48e62600e97219d8",
                    "name": "Ruiqi Li",
                    "hidden": false
                },
                {
                    "_id": "6712157b48e62600e97219d9",
                    "name": "Siqi Zheng",
                    "hidden": false
                },
                {
                    "_id": "6712157b48e62600e97219da",
                    "user": {
                        "_id": "657543227068a85089680147",
                        "avatarUrl": "/avatars/a0e3371cc018deec7f18a12181eda3b0.svg",
                        "isPro": false,
                        "fullname": "xize cheng",
                        "user": "Exgc",
                        "type": "user"
                    },
                    "name": "Xize Cheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:38:50.836Z",
                    "hidden": false
                },
                {
                    "_id": "6712157b48e62600e97219db",
                    "name": "Ziang Zhang",
                    "hidden": false
                },
                {
                    "_id": "6712157b48e62600e97219dc",
                    "name": "Shengpeng Ji",
                    "hidden": false
                },
                {
                    "_id": "6712157b48e62600e97219dd",
                    "name": "Zhou Zhao",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-16T18:44:56.000Z",
            "title": "MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic\n  Synchronization",
            "summary": "Generating music that aligns with the visual content of a video has been a\nchallenging task, as it requires a deep understanding of visual semantics and\ninvolves generating music whose melody, rhythm, and dynamics harmonize with the\nvisual narratives. This paper presents MuVi, a novel framework that effectively\naddresses these challenges to enhance the cohesion and immersive experience of\naudio-visual content. MuVi analyzes video content through a specially designed\nvisual adaptor to extract contextually and temporally relevant features. These\nfeatures are used to generate music that not only matches the video's mood and\ntheme but also its rhythm and pacing. We also introduce a contrastive\nmusic-visual pre-training scheme to ensure synchronization, based on the\nperiodicity nature of music phrases. In addition, we demonstrate that our\nflow-matching-based music generator has in-context learning ability, allowing\nus to control the style and genre of the generated music. Experimental results\nshow that MuVi demonstrates superior performance in both audio quality and\ntemporal synchronization. The generated music video samples are available at\nhttps://muvi-v2m.github.io.",
            "upvotes": 3,
            "discussionId": "6712157c48e62600e9721a1f"
        },
        "publishedAt": "2024-10-18T06:33:00.233Z",
        "title": "MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic Synchronization",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.12957.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/ceadd0bb06a116eba5b45081f92d3243.svg",
            "fullname": "Siqi Zheng",
            "name": "ckzheng",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13618",
            "authors": [
                {
                    "_id": "6711dc54b265bbd413b8ec7b",
                    "user": {
                        "_id": "642ebcefd09a9c63c2124bd2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642ebcefd09a9c63c2124bd2/NffVWOEPI4DEbRv-u7-2l.jpeg",
                        "isPro": false,
                        "fullname": "Yiming Shi",
                        "user": "Shiym",
                        "type": "user"
                    },
                    "name": "Yiming Shi",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-10-18T04:03:46.223Z",
                    "hidden": false
                },
                {
                    "_id": "6711dc54b265bbd413b8ec7c",
                    "name": "Jiwei Wei",
                    "hidden": false
                },
                {
                    "_id": "6711dc54b265bbd413b8ec7d",
                    "name": "Yujia Wu",
                    "hidden": false
                },
                {
                    "_id": "6711dc54b265bbd413b8ec7e",
                    "name": "Ran Ran",
                    "hidden": false
                },
                {
                    "_id": "6711dc54b265bbd413b8ec7f",
                    "name": "Chengwei Sun",
                    "hidden": false
                },
                {
                    "_id": "6711dc54b265bbd413b8ec80",
                    "name": "Shiyuan He",
                    "hidden": false
                },
                {
                    "_id": "6711dc54b265bbd413b8ec81",
                    "name": "Yang Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T14:51:17.000Z",
            "title": "LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for\n  Parameter-Efficient Fine-Tuning",
            "summary": "The rapid growth of model scale has necessitated substantial computational\nresources for fine-tuning. Existing approach such as Low-Rank Adaptation (LoRA)\nhas sought to address the problem of handling the large updated parameters in\nfull fine-tuning. However, LoRA utilize random initialization and optimization\nof low-rank matrices to approximate updated weights, which can result in\nsuboptimal convergence and an accuracy gap compared to full fine-tuning. To\naddress these issues, we propose LoLDU, a Parameter-Efficient Fine-Tuning\n(PEFT) approach that significantly reduces trainable parameters by 2600 times\ncompared to regular PEFT methods while maintaining comparable performance.\nLoLDU leverages Lower-Diag-Upper Decomposition (LDU) to initialize low-rank\nmatrices for faster convergence and orthogonality. We focus on optimizing the\ndiagonal matrix for scaling transformations. To the best of our knowledge,\nLoLDU has the fewest parameters among all PEFT approaches. We conducted\nextensive experiments across 4 instruction-following datasets, 6 natural\nlanguage understanding (NLU) datasets, 8 image classification datasets, and\nimage generation datasets with multiple model types (LLaMA2, RoBERTa, ViT, and\nStable Diffusion), providing a comprehensive and detailed analysis. Our\nopen-source code can be accessed at\nhttps://github.com/SKDDJ/LoLDU{https://github.com/SKDDJ/LoLDU}.",
            "upvotes": 3,
            "discussionId": "6711dc55b265bbd413b8ecc6"
        },
        "publishedAt": "2024-10-18T02:30:02.014Z",
        "title": "LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13618.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642ebcefd09a9c63c2124bd2/NffVWOEPI4DEbRv-u7-2l.jpeg",
            "fullname": "Yiming Shi",
            "name": "Shiym",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13060",
            "authors": [
                {
                    "_id": "6711c3fea79b431fea2c3b48",
                    "user": {
                        "_id": "670ec3f6db1a6bcfe832e0a6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/-mZNLeLJoXzkwPgYO38lF.png",
                        "isPro": false,
                        "fullname": "Nandan Kumar Jha",
                        "user": "nandan523",
                        "type": "user"
                    },
                    "name": "Nandan Kumar Jha",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:02:37.993Z",
                    "hidden": false
                },
                {
                    "_id": "6711c3fea79b431fea2c3b49",
                    "name": "Brandon Reagen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-16T21:40:49.000Z",
            "title": "AERO: Softmax-Only LLMs for Efficient Private Inference",
            "summary": "The pervasiveness of proprietary language models has raised privacy concerns\nfor users' sensitive data, emphasizing the need for private inference (PI),\nwhere inference is performed directly on encrypted inputs. However, current PI\nmethods face prohibitively higher communication and latency overheads,\nprimarily due to nonlinear operations. In this paper, we present a\ncomprehensive analysis to understand the role of nonlinearities in\ntransformer-based decoder-only language models. We introduce AERO, a four-step\narchitectural optimization framework that refines the existing LLM architecture\nfor efficient PI by systematically removing nonlinearities such as LayerNorm\nand GELU and reducing FLOPs counts. For the first time, we propose a\nSoftmax-only architecture with significantly fewer FLOPs tailored for efficient\nPI. Furthermore, we devise a novel entropy regularization technique to improve\nthe performance of Softmax-only models. AERO achieves up to 4.23times\ncommunication and 1.94times latency reduction. We validate the effectiveness\nof AERO by benchmarking it against the state-of-the-art.",
            "upvotes": 3,
            "discussionId": "6711c3ffa79b431fea2c3baa"
        },
        "publishedAt": "2024-10-18T00:45:35.847Z",
        "title": "AERO: Softmax-Only LLMs for Efficient Private Inference",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13060.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/-mZNLeLJoXzkwPgYO38lF.png",
            "fullname": "Nandan Kumar Jha",
            "name": "nandan523",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13268",
            "authors": [
                {
                    "_id": "671224b95fcebe9dcaa7b73d",
                    "user": {
                        "_id": "668e7f46c243a12604035758",
                        "avatarUrl": "/avatars/35bd20032fafb7d7603266cf9a72d1e0.svg",
                        "isPro": false,
                        "fullname": "Fan Bu",
                        "user": "FanBuCUHK",
                        "type": "user"
                    },
                    "name": "Fan Bu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T09:24:58.638Z",
                    "hidden": false
                },
                {
                    "_id": "671224b95fcebe9dcaa7b73e",
                    "name": "Yuhao Zhang",
                    "hidden": false
                },
                {
                    "_id": "671224b95fcebe9dcaa7b73f",
                    "name": "Xidong Wang",
                    "hidden": false
                },
                {
                    "_id": "671224b95fcebe9dcaa7b740",
                    "name": "Benyou Wang",
                    "hidden": false
                },
                {
                    "_id": "671224b95fcebe9dcaa7b741",
                    "name": "Qun Liu",
                    "hidden": false
                },
                {
                    "_id": "671224b95fcebe9dcaa7b742",
                    "name": "Haizhou Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T06:44:06.000Z",
            "title": "Roadmap towards Superhuman Speech Understanding using Large Language\n  Models",
            "summary": "The success of large language models (LLMs) has prompted efforts to integrate\nspeech and audio data, aiming to create general foundation models capable of\nprocessing both textual and non-textual inputs. Recent advances, such as\nGPT-4o, highlight the potential for end-to-end speech LLMs, which preserves\nnon-semantic information and world knowledge for deeper speech understanding.\nTo guide the development of speech LLMs, we propose a five-level roadmap,\nranging from basic automatic speech recognition (ASR) to advanced superhuman\nmodels capable of integrating non-semantic information with abstract acoustic\nknowledge for complex tasks. Moreover, we design a benchmark, SAGI Bechmark,\nthat standardizes critical aspects across various tasks in these five levels,\nuncovering challenges in using abstract acoustic knowledge and completeness of\ncapability. Our findings reveal gaps in handling paralinguistic cues and\nabstract acoustic knowledge, and we offer future directions. This paper\noutlines a roadmap for advancing speech LLMs, introduces a benchmark for\nevaluation, and provides key insights into their current limitations and\npotential.",
            "upvotes": 2,
            "discussionId": "671224ba5fcebe9dcaa7b77a"
        },
        "publishedAt": "2024-10-18T12:46:43.099Z",
        "title": "Roadmap towards Superhuman Speech Understanding using Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13268.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/35bd20032fafb7d7603266cf9a72d1e0.svg",
            "fullname": "Fan Bu",
            "name": "FanBuCUHK",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.12183",
            "authors": [
                {
                    "_id": "6711c90dfe58fd40dde8cc17",
                    "user": {
                        "_id": "6711c8a16019f85716ef2f34",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/W8f4Tbwx3LjTWoK39oR3s.png",
                        "isPro": false,
                        "fullname": "Yiwei Guo",
                        "user": "markywg",
                        "type": "user"
                    },
                    "name": "Yiwei Guo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:12:28.191Z",
                    "hidden": false
                },
                {
                    "_id": "6711c90dfe58fd40dde8cc18",
                    "user": {
                        "_id": "644d3c3ad1945fe77a15ce35",
                        "avatarUrl": "/avatars/61ca3587eed853f69df89f1e0d02bb03.svg",
                        "isPro": false,
                        "fullname": "shaobin zhuang",
                        "user": "greysunshine",
                        "type": "user"
                    },
                    "name": "Shaobin Zhuang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:02:47.949Z",
                    "hidden": false
                },
                {
                    "_id": "6711c90dfe58fd40dde8cc19",
                    "user": {
                        "_id": "61fb81006374891646732f37",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1643872995181-61fb81006374891646732f37.jpeg",
                        "isPro": false,
                        "fullname": "Kunchang Li",
                        "user": "Andy1621",
                        "type": "user"
                    },
                    "name": "Kunchang Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:02:53.724Z",
                    "hidden": false
                },
                {
                    "_id": "6711c90dfe58fd40dde8cc1a",
                    "name": "Yu Qiao",
                    "hidden": false
                },
                {
                    "_id": "6711c90dfe58fd40dde8cc1b",
                    "name": "Yali Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-16T03:01:44.000Z",
            "title": "TransAgent: Transfer Vision-Language Foundation Models with\n  Heterogeneous Agent Collaboration",
            "summary": "Vision-language foundation models (such as CLIP) have recently shown their\npower in transfer learning, owing to large-scale image-text pre-training.\nHowever, target domain data in the downstream tasks can be highly different\nfrom the pre-training phase, which makes it hard for such a single model to\ngeneralize well. Alternatively, there exists a wide range of expert models that\ncontain diversified vision and/or language knowledge pre-trained on different\nmodalities, tasks, networks, and datasets. Unfortunately, these models are\n\"isolated agents\" with heterogeneous structures, and how to integrate their\nknowledge for generalizing CLIP-like models has not been fully explored. To\nbridge this gap, we propose a general and concise TransAgent framework, which\ntransports the knowledge of the isolated agents in a unified manner, and\neffectively guides CLIP to generalize with multi-source knowledge distillation.\nWith such a distinct framework, we flexibly collaborate with 11 heterogeneous\nagents to empower vision-language foundation models, without further cost in\nthe inference phase. Finally, our TransAgent achieves state-of-the-art\nperformance on 11 visual recognition datasets. Under the same low-shot setting,\nit outperforms the popular CoOp with around 10% on average, and 20% on EuroSAT\nwhich contains large domain shifts.",
            "upvotes": 2,
            "discussionId": "6711c90efe58fd40dde8cc36"
        },
        "publishedAt": "2024-10-18T07:10:06.957Z",
        "title": "TransAgent: Transfer Vision-Language Foundation Models with Heterogeneous Agent Collaboration",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.12183.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/W8f4Tbwx3LjTWoK39oR3s.png",
            "fullname": "Yiwei Guo",
            "name": "markywg",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.12781",
            "authors": [
                {
                    "_id": "671155f28f706a2159128b02",
                    "user": {
                        "_id": "668ddf7fe990292e5fcb2ab3",
                        "avatarUrl": "/avatars/0f9c0f845c40a662a5045261b22607c6.svg",
                        "isPro": false,
                        "fullname": "Ziwen Chen",
                        "user": "arthurhero",
                        "type": "user"
                    },
                    "name": "Chen Ziwen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:13:31.879Z",
                    "hidden": false
                },
                {
                    "_id": "671155f28f706a2159128b03",
                    "name": "Hao Tan",
                    "hidden": false
                },
                {
                    "_id": "671155f28f706a2159128b04",
                    "user": {
                        "_id": "63e0a50242591dda0b9dca5c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e0a50242591dda0b9dca5c/c7cBPEBWQDFYimfGnO_SI.png",
                        "isPro": false,
                        "fullname": "Kai Zhang",
                        "user": "drogozhang",
                        "type": "user"
                    },
                    "name": "Kai Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:04:41.959Z",
                    "hidden": false
                },
                {
                    "_id": "671155f28f706a2159128b05",
                    "user": {
                        "_id": "66303560597dc7c535168f07",
                        "avatarUrl": "/avatars/a69d52a4a198c6c8451c1d137031bf07.svg",
                        "isPro": false,
                        "fullname": "Sai Bi",
                        "user": "saibi",
                        "type": "user"
                    },
                    "name": "Sai Bi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:04:34.774Z",
                    "hidden": false
                },
                {
                    "_id": "671155f28f706a2159128b06",
                    "name": "Fujun Luan",
                    "hidden": false
                },
                {
                    "_id": "671155f28f706a2159128b07",
                    "user": {
                        "_id": "654ca66fe1671abcbc50a6e4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654ca66fe1671abcbc50a6e4/VqcnC17YcqC9Hk65_LxtE.jpeg",
                        "isPro": false,
                        "fullname": "Yicong Hong",
                        "user": "YicongHong",
                        "type": "user"
                    },
                    "name": "Yicong Hong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:04:13.211Z",
                    "hidden": false
                },
                {
                    "_id": "671155f28f706a2159128b08",
                    "name": "Li Fuxin",
                    "hidden": false
                },
                {
                    "_id": "671155f28f706a2159128b09",
                    "user": {
                        "_id": "65565b1b8616d8d740abb976",
                        "avatarUrl": "/avatars/c245b19ed05292bf1bf4a9d8cf2a409c.svg",
                        "isPro": false,
                        "fullname": "Zexiang Xu",
                        "user": "zexiangxu",
                        "type": "user"
                    },
                    "name": "Zexiang Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:04:18.449Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-16T17:54:06.000Z",
            "title": "Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage\n  Gaussian Splats",
            "summary": "We propose Long-LRM, a generalizable 3D Gaussian reconstruction model that is\ncapable of reconstructing a large scene from a long sequence of input images.\nSpecifically, our model can process 32 source images at 960x540 resolution\nwithin only 1.3 seconds on a single A100 80G GPU. Our architecture features a\nmixture of the recent Mamba2 blocks and the classical transformer blocks which\nallowed many more tokens to be processed than prior work, enhanced by efficient\ntoken merging and Gaussian pruning steps that balance between quality and\nefficiency. Unlike previous feed-forward models that are limited to processing\n1~4 input images and can only reconstruct a small portion of a large scene,\nLong-LRM reconstructs the entire scene in a single feed-forward step. On\nlarge-scale scene datasets such as DL3DV-140 and Tanks and Temples, our method\nachieves performance comparable to optimization-based approaches while being\ntwo orders of magnitude more efficient. Project page:\nhttps://arthurhero.github.io/projects/llrm",
            "upvotes": 2,
            "discussionId": "671155f48f706a2159128b95"
        },
        "publishedAt": "2024-10-18T06:59:14.545Z",
        "title": "Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.12781.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/0f9c0f845c40a662a5045261b22607c6.svg",
            "fullname": "Ziwen Chen",
            "name": "arthurhero",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13334",
            "authors": [
                {
                    "_id": "671210b6d86855660a264b96",
                    "name": "Isack Lee",
                    "hidden": false
                },
                {
                    "_id": "671210b6d86855660a264b97",
                    "user": {
                        "_id": "63a9379e2e05ca32e352d93b",
                        "avatarUrl": "/avatars/6cda37befc873a92ed6d5dcba507954a.svg",
                        "isPro": false,
                        "fullname": "Haebin Seong",
                        "user": "hbseong",
                        "type": "user"
                    },
                    "name": "Haebin Seong",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-10-18T07:39:40.919Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T08:46:09.000Z",
            "title": "Do LLMs Have Political Correctness? Analyzing Ethical Biases and\n  Jailbreak Vulnerabilities in AI Systems",
            "summary": "Although large language models (LLMs) demonstrate impressive proficiency in\nvarious tasks, they present potential safety risks, such as `jailbreaks', where\nmalicious inputs can coerce LLMs into generating harmful content. To address\nthese issues, many LLM developers have implemented various safety measures to\nalign these models. This alignment involves several techniques, including data\nfiltering during pre-training, supervised fine-tuning, reinforcement learning\nfrom human feedback, and red-teaming exercises. These methods often introduce\ndeliberate and intentional biases similar to Political Correctness (PC) to\nensure the ethical behavior of LLMs. In this paper, we delve into the\nintentional biases injected into LLMs for safety purposes and examine methods\nto circumvent these safety alignment techniques. Notably, these intentional\nbiases result in a jailbreaking success rate in GPT-4o models that differs by\n20% between non-binary and cisgender keywords and by 16% between white and\nblack keywords, even when the other parts of the prompts are identical. We\nintroduce the concept of PCJailbreak, highlighting the inherent risks posed by\nthese safety-induced biases. Additionally, we propose an efficient defense\nmethod PCDefense, which prevents jailbreak attempts by injecting defense\nprompts prior to generation. PCDefense stands as an appealing alternative to\nGuard Models, such as Llama-Guard, that require additional inference cost after\ntext generation. Our findings emphasize the urgent need for LLM developers to\nadopt a more responsible approach when designing and implementing safety\nmeasures.",
            "upvotes": 2,
            "discussionId": "671210b8d86855660a264c07"
        },
        "publishedAt": "2024-10-18T06:13:36.272Z",
        "title": "Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63a9379e2e05ca32e352d93b/1tC3m95DL__ksP9_xTElH.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13334.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/6cda37befc873a92ed6d5dcba507954a.svg",
            "fullname": "Haebin Seong",
            "name": "hbseong",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13293",
            "authors": [
                {
                    "_id": "6711e3d35550f581fcbf99a6",
                    "user": {
                        "_id": "659a0143ac728bc3039a82c5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/659a0143ac728bc3039a82c5/JGf3SXs8AeOqC8i1fRyLu.jpeg",
                        "isPro": false,
                        "fullname": "Prakhar Dixit",
                        "user": "pdx97",
                        "type": "user"
                    },
                    "name": "Prakhar Dixit",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:09:44.032Z",
                    "hidden": false
                },
                {
                    "_id": "6711e3d35550f581fcbf99a7",
                    "name": "Tim Oates",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T07:46:49.000Z",
            "title": "SBI-RAG: Enhancing Math Word Problem Solving for Students through\n  Schema-Based Instruction and Retrieval-Augmented Generation",
            "summary": "Many students struggle with math word problems (MWPs), often finding it\ndifficult to identify key information and select the appropriate mathematical\noperations.Schema-based instruction (SBI) is an evidence-based strategy that\nhelps students categorize problems based on their structure, improving\nproblem-solving accuracy. Building on this, we propose a Schema-Based\nInstruction Retrieval-Augmented Generation (SBI-RAG) framework that\nincorporates a large language model (LLM).Our approach emphasizes step-by-step\nreasoning by leveraging schemas to guide solution generation. We evaluate its\nperformance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo,\nand introduce a \"reasoning score\" metric to assess solution quality. Our\nfindings suggest that SBI-RAG enhances reasoning clarity and problem-solving\naccuracy, potentially providing educational benefits for students",
            "upvotes": 2,
            "discussionId": "6711e3d45550f581fcbf99fe"
        },
        "publishedAt": "2024-10-18T02:59:02.721Z",
        "title": "SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13293.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/659a0143ac728bc3039a82c5/JGf3SXs8AeOqC8i1fRyLu.jpeg",
            "fullname": "Prakhar Dixit",
            "name": "pdx97",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.09347",
            "authors": [
                {
                    "_id": "6711f37b3eea86736062288b",
                    "user": {
                        "_id": "65571135bfb62d747abc8129",
                        "avatarUrl": "/avatars/5f4542daa34597f17e6280b9cce18c91.svg",
                        "isPro": false,
                        "fullname": "Hugging",
                        "user": "ChenDRAG",
                        "type": "user"
                    },
                    "name": "Huayu Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:09:41.392Z",
                    "hidden": false
                },
                {
                    "_id": "6711f37b3eea86736062288c",
                    "name": "Hang Su",
                    "hidden": false
                },
                {
                    "_id": "6711f37b3eea86736062288d",
                    "user": {
                        "_id": "640dc9bf8512ec51d7f0ac1a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640dc9bf8512ec51d7f0ac1a/sT4rdEoQbzfW6D3xDVdqt.jpeg",
                        "isPro": false,
                        "fullname": "peizesun",
                        "user": "peizesun",
                        "type": "user"
                    },
                    "name": "Peize Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T16:40:52.212Z",
                    "hidden": false
                },
                {
                    "_id": "6711f37b3eea86736062288e",
                    "name": "Jun Zhu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-12T03:31:25.000Z",
            "title": "Toward Guidance-Free AR Visual Generation via Condition Contrastive\n  Alignment",
            "summary": "Classifier-Free Guidance (CFG) is a critical technique for enhancing the\nsample quality of visual generative models. However, in autoregressive (AR)\nmulti-modal generation, CFG introduces design inconsistencies between language\nand visual content, contradicting the design philosophy of unifying different\nmodalities for visual AR. Motivated by language model alignment methods, we\npropose Condition Contrastive Alignment (CCA) to facilitate\nguidance-free AR visual generation with high performance and analyze its\ntheoretical connection with guided sampling methods. Unlike guidance methods\nthat alter the sampling process to achieve the ideal sampling distribution, CCA\ndirectly fine-tunes pretrained models to fit the same distribution target.\nExperimental results show that CCA can significantly enhance the guidance-free\nperformance of all tested models with just one epoch of fine-tuning (sim 1\\%\nof pretraining epochs) on the pretraining dataset, on par with guided sampling\nmethods. This largely removes the need for guided sampling in AR visual\ngeneration and cuts the sampling cost by half. Moreover, by adjusting training\nparameters, CCA can achieve trade-offs between sample diversity and fidelity\nsimilar to CFG. This experimentally confirms the strong theoretical connection\nbetween language-targeted alignment and visual-targeted guidance methods,\nunifying two previously independent research fields. Code and model weights:\nhttps://github.com/thu-ml/CCA.",
            "upvotes": 1,
            "discussionId": "6711f3813eea867360622af4"
        },
        "publishedAt": "2024-10-18T07:42:08.408Z",
        "title": "Toward Guidance-Free AR Visual Generation via Condition Contrastive Alignment",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.09347.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/5f4542daa34597f17e6280b9cce18c91.svg",
            "fullname": "Hugging",
            "name": "ChenDRAG",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.12771",
            "authors": [
                {
                    "_id": "67112541c8d0ef79daa54ed8",
                    "name": "Luis Barroso-Luque",
                    "hidden": false
                },
                {
                    "_id": "67112541c8d0ef79daa54ed9",
                    "user": {
                        "_id": "67004f02d66ad0efb0d494c3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67004f02d66ad0efb0d494c3/eIGYDUVAovab9ssRFotAK.jpeg",
                        "isPro": false,
                        "fullname": "Muhammed Shuaibi",
                        "user": "mshuaibi",
                        "type": "user"
                    },
                    "name": "Muhammed Shuaibi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T08:13:58.305Z",
                    "hidden": false
                },
                {
                    "_id": "67112541c8d0ef79daa54eda",
                    "name": "Xiang Fu",
                    "hidden": false
                },
                {
                    "_id": "67112541c8d0ef79daa54edb",
                    "name": "Brandon M. Wood",
                    "hidden": false
                },
                {
                    "_id": "67112541c8d0ef79daa54edc",
                    "name": "Misko Dzamba",
                    "hidden": false
                },
                {
                    "_id": "67112541c8d0ef79daa54edd",
                    "name": "Meng Gao",
                    "hidden": false
                },
                {
                    "_id": "67112541c8d0ef79daa54ede",
                    "name": "Ammar Rizvi",
                    "hidden": false
                },
                {
                    "_id": "67112541c8d0ef79daa54edf",
                    "name": "C. Lawrence Zitnick",
                    "hidden": false
                },
                {
                    "_id": "67112541c8d0ef79daa54ee0",
                    "user": {
                        "_id": "6712520b971ea2188b33f7d4",
                        "avatarUrl": "/avatars/05c98ccb37ce3c4ec83bfdae7c5b1b44.svg",
                        "isPro": false,
                        "fullname": "Zachary Ulissi",
                        "user": "zulissimeta",
                        "type": "user"
                    },
                    "name": "Zachary W. Ulissi",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-18T12:19:06.410Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-16T17:48:34.000Z",
            "title": "Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models",
            "summary": "The ability to discover new materials with desirable properties is critical\nfor numerous applications from helping mitigate climate change to advances in\nnext generation computing hardware. AI has the potential to accelerate\nmaterials discovery and design by more effectively exploring the chemical space\ncompared to other computational methods or by trial-and-error. While\nsubstantial progress has been made on AI for materials data, benchmarks, and\nmodels, a barrier that has emerged is the lack of publicly available training\ndata and open pre-trained models. To address this, we present a Meta FAIR\nrelease of the Open Materials 2024 (OMat24) large-scale open dataset and an\naccompanying set of pre-trained models. OMat24 contains over 110 million\ndensity functional theory (DFT) calculations focused on structural and\ncompositional diversity. Our EquiformerV2 models achieve state-of-the-art\nperformance on the Matbench Discovery leaderboard and are capable of predicting\nground-state stability and formation energies to an F1 score above 0.9 and an\naccuracy of 20 meV/atom, respectively. We explore the impact of model size,\nauxiliary denoising objectives, and fine-tuning on performance across a range\nof datasets including OMat24, MPtraj, and Alexandria. The open release of the\nOMat24 dataset and models enables the research community to build upon our\nefforts and drive further advancements in AI-assisted materials science.",
            "upvotes": 0,
            "discussionId": "67112543c8d0ef79daa54f24"
        },
        "publishedAt": "2024-10-18T13:03:29.562Z",
        "title": "Open Materials 2024 (OMat24) Inorganic Materials Dataset and Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/67004f02d66ad0efb0d494c3/g0Ln8UwAUt-AeEM1maFLS.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.12771.png",
        "numComments": 0,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67004f02d66ad0efb0d494c3/eIGYDUVAovab9ssRFotAK.jpeg",
            "fullname": "Muhammed Shuaibi",
            "name": "mshuaibi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.10210",
            "authors": [
                {
                    "_id": "67122a1054c8572e476f32a3",
                    "user": {
                        "_id": "6215ca5692c0ecfba9186921",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1645595695434-6215ca5692c0ecfba9186921.png",
                        "isPro": false,
                        "fullname": "Yingda Chen",
                        "user": "Yingda",
                        "type": "user"
                    },
                    "name": "Yingda Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T09:54:53.711Z",
                    "hidden": false
                },
                {
                    "_id": "67122a1054c8572e476f32a4",
                    "user": {
                        "_id": "62f612e22e53c2efd33943c6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1679249371815-62f612e22e53c2efd33943c6.jpeg",
                        "isPro": false,
                        "fullname": "xingjun wang",
                        "user": "wangxingjun778",
                        "type": "user"
                    },
                    "name": "Xingjun Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T09:54:56.405Z",
                    "hidden": false
                },
                {
                    "_id": "67122a1054c8572e476f32a5",
                    "user": {
                        "_id": "6624e6b111772517e5db916c",
                        "avatarUrl": "/avatars/cd7f14216e63689a3ede587224e35ead.svg",
                        "isPro": false,
                        "fullname": "Jintao Huang",
                        "user": "feifeiyu-hjt",
                        "type": "user"
                    },
                    "name": "Jintao Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-18T13:03:40.531Z",
                    "hidden": false
                },
                {
                    "_id": "67122a1054c8572e476f32a6",
                    "name": "Yunlin Mao",
                    "hidden": false
                },
                {
                    "_id": "67122a1054c8572e476f32a7",
                    "user": {
                        "_id": "664dabaade412305ff2c984e",
                        "avatarUrl": "/avatars/9dd55d8078f0534f2bdb8cfb84333b8e.svg",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "Daoze",
                        "type": "user"
                    },
                    "name": "Daoze Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T09:54:59.082Z",
                    "hidden": false
                },
                {
                    "_id": "67122a1054c8572e476f32a8",
                    "name": "Yuze Zhao",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-14T07:09:02.000Z",
            "title": "Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as\n  the Key",
            "summary": "As large language models rapidly evolve to support longer context, there is a\nnotable disparity in their capability to generate output at greater lengths.\nRecent study suggests that the primary cause for this imbalance may arise from\nthe lack of data with long-output during alignment training. In light of this\nobservation, attempts are made to re-align foundation models with data that\nfills the gap, which result in models capable of generating lengthy output when\ninstructed. In this paper, we explore the impact of data-quality in tuning a\nmodel for long output, and the possibility of doing so from the starting points\nof human-aligned (instruct or chat) models. With careful data curation, we show\nthat it possible to achieve similar performance improvement in our tuned\nmodels, with only a small fraction of training data instances and compute. In\naddition, we assess the generalizability of such approaches by applying our\ntuning-recipes to several models. our findings suggest that, while capacities\nfor generating long output vary across different models out-of-the-box, our\napproach to tune them with high-quality data using lite compute, consistently\nyields notable improvement across all models we experimented on. We have made\npublic our curated dataset for tuning long-writing capability, the\nimplementations of model tuning and evaluation, as well as the fine-tuned\nmodels, all of which can be openly-accessed.",
            "upvotes": 0,
            "discussionId": "67122a1254c8572e476f32f1"
        },
        "publishedAt": "2024-10-18T08:01:07.815Z",
        "title": "Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.10210.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1645595695434-6215ca5692c0ecfba9186921.png",
            "fullname": "Yingda Chen",
            "name": "Yingda",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]