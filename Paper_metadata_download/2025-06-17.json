[
  {
    "paper": {
      "id": "2506.13585",
      "authors": [
        {
          "_id": "6850d0105e07650ecce89009",
          "name": "MiniMax",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8900b",
          "user": {
            "_id": "63f86b099f87cc3e645b51d9",
            "avatarUrl": "/avatars/27ca5ba425640bf67474cee871e8e53a.svg",
            "isPro": false,
            "fullname": "Ellie Chen",
            "user": "sheep33333",
            "type": "user"
          },
          "name": "Aili Chen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:27.223Z",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8900c",
          "name": "Aonian Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8900d",
          "name": "Bangwei Gong",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8900e",
          "name": "Binyang Jiang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8900f",
          "name": "Bo Fei",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89010",
          "name": "Bo Yang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89011",
          "name": "Boji Shan",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89012",
          "name": "Changqing Yu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89013",
          "name": "Chao Wang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89014",
          "name": "Cheng Zhu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89015",
          "name": "Chengjun Xiao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89016",
          "name": "Chengyu Du",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89017",
          "name": "Chi Zhang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89018",
          "name": "Chu Qiao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89019",
          "user": {
            "_id": "642662fa22bddcea3d289f0a",
            "avatarUrl": "/avatars/9b28e1325d866a24d33fdfafcaa85c4b.svg",
            "isPro": false,
            "fullname": "Enoch Zhang",
            "user": "enochzhang",
            "type": "user"
          },
          "name": "Chunhao Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:43.093Z",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8901a",
          "name": "Chunhui Du",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8901b",
          "name": "Congchao Guo",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8901c",
          "name": "Da Chen",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8901d",
          "name": "Deming Ding",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8901e",
          "name": "Dianjun Sun",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8901f",
          "name": "Dong Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89020",
          "name": "Enwei Jiao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89021",
          "name": "Haigang Zhou",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89022",
          "name": "Haimo Zhang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89023",
          "name": "Han Ding",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89024",
          "name": "Haohai Sun",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89025",
          "name": "Haoyu Feng",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89026",
          "name": "Huaiguang Cai",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89027",
          "name": "Haichao Zhu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89028",
          "name": "Jian Sun",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89029",
          "name": "Jiaqi Zhuang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8902a",
          "name": "Jiaren Cai",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8902b",
          "name": "Jiayuan Song",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8902c",
          "name": "Jin Zhu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8902d",
          "name": "Jingyang Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8902e",
          "name": "Jinhao Tian",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8902f",
          "name": "Jinli Liu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89030",
          "name": "Junhao Xu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89031",
          "name": "Junjie Yan",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89032",
          "name": "Junteng Liu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89033",
          "name": "Junxian He",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89034",
          "name": "Kaiyi Feng",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89035",
          "name": "Ke Yang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89036",
          "name": "Kecheng Xiao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89037",
          "name": "Le Han",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89038",
          "name": "Leyang Wang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89039",
          "name": "Lianfei Yu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8903a",
          "name": "Liheng Feng",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8903b",
          "name": "Lin Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8903c",
          "name": "Lin Zheng",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8903d",
          "name": "Linge Du",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8903e",
          "name": "Lingyu Yang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8903f",
          "name": "Lunbin Zeng",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89040",
          "name": "Minghui Yu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89041",
          "name": "Mingliang Tao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89042",
          "name": "Mingyuan Chi",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89043",
          "name": "Mozhi Zhang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89044",
          "user": {
            "_id": "67ac4d69a122ac29aed98f3c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/5NBmaUAoutU4RA85qH8mw.png",
            "isPro": false,
            "fullname": "LINMUJIE",
            "user": "LINMUJIE-judy",
            "type": "user"
          },
          "name": "Mujie Lin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:37.448Z",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89045",
          "name": "Nan Hu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89046",
          "name": "Nongyu Di",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89047",
          "name": "Peng Gao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89048",
          "name": "Pengfei Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89049",
          "name": "Pengyu Zhao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8904a",
          "name": "Qibing Ren",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8904b",
          "name": "Qidi Xu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8904c",
          "name": "Qile Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8904d",
          "name": "Qin Wang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8904e",
          "name": "Rong Tian",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8904f",
          "name": "Ruitao Leng",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89050",
          "name": "Shaoxiang Chen",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89051",
          "name": "Shaoyu Chen",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89052",
          "name": "Shengmin Shi",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89053",
          "name": "Shitong Weng",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89054",
          "name": "Shuchang Guan",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89055",
          "name": "Shuqi Yu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89056",
          "name": "Sichen Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89057",
          "name": "Songquan Zhu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89058",
          "name": "Tengfei Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89059",
          "name": "Tianchi Cai",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8905a",
          "name": "Tianrun Liang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8905b",
          "name": "Weiyu Cheng",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8905c",
          "name": "Weize Kong",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8905d",
          "name": "Wenkai Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8905e",
          "name": "Xiancai Chen",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8905f",
          "name": "Xiangjun Song",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89060",
          "user": {
            "_id": "612741a391de43c1101df014",
            "avatarUrl": "/avatars/1461b1c7d3cedd91cea6cf3b0ecb14ae.svg",
            "isPro": false,
            "fullname": "Rock Luo",
            "user": "windlx",
            "type": "user"
          },
          "name": "Xiao Luo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:57.356Z",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89061",
          "name": "Xiao Su",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89062",
          "name": "Xiaobo Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89063",
          "name": "Xiaodong Han",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89064",
          "name": "Xinzhu Hou",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89065",
          "name": "Xuan Lu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89066",
          "name": "Xun Zou",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89067",
          "name": "Xuyang Shen",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89068",
          "name": "Yan Gong",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89069",
          "user": {
            "_id": "633fc70529b5a95f6e15a6b7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633fc70529b5a95f6e15a6b7/Fzh7wWuqU-fBbzdupOUtF.jpeg",
            "isPro": false,
            "fullname": "Yan Ma",
            "user": "ManTle",
            "type": "user"
          },
          "name": "Yan Ma",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:39.279Z",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8906a",
          "name": "Yang Wang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8906b",
          "name": "Yiqi Shi",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8906c",
          "name": "Yiran Zhong",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8906d",
          "name": "Yonghong Duan",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8906e",
          "name": "Yongxiang Fu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8906f",
          "name": "Yongyi Hu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89070",
          "name": "Yu Gao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89071",
          "name": "Yuanxiang Fan",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89072",
          "name": "Yufeng Yang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89073",
          "name": "Yuhao Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89074",
          "name": "Yulin Hu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89075",
          "name": "Yunan Huang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89076",
          "name": "Yunji Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89077",
          "name": "Yunzhi Xu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89078",
          "name": "Yuxin Mao",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89079",
          "name": "Yuxuan Shi",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8907a",
          "name": "Yuze Wenren",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8907b",
          "name": "Zehan Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8907c",
          "name": "Zelin Li",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8907d",
          "name": "Zhanxu Tian",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8907e",
          "name": "Zhengmao Zhu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce8907f",
          "name": "Zhenhua Fan",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89080",
          "name": "Zhenzhen Wu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89081",
          "name": "Zhichao Xu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89082",
          "name": "Zhihang Yu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89083",
          "name": "Zhiheng Lyu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89084",
          "name": "Zhuo Jiang",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89085",
          "user": {
            "_id": "6690a4b6a4d0df7e51b93392",
            "avatarUrl": "/avatars/6d3694c39344854221f6ca0ed3cf0557.svg",
            "isPro": false,
            "fullname": "gao zibo",
            "user": "afhhl",
            "type": "user"
          },
          "name": "Zibo Gao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:41.298Z",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89086",
          "name": "Zijia Wu",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89087",
          "name": "Zijian Song",
          "hidden": false
        },
        {
          "_id": "6850d0105e07650ecce89088",
          "name": "Zijun Sun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T15:08:02.000Z",
      "submittedOnDailyAt": "2025-06-17T00:48:14.831Z",
      "title": "MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning\n  Attention",
      "submittedOnDailyBy": {
        "_id": "676e38ad04af5bec20bc9faf",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/676e38ad04af5bec20bc9faf/AG8Q9wAUzGtPWyjd5QO2l.jpeg",
        "isPro": false,
        "fullname": "MiniMax",
        "user": "MiniMax-AI",
        "type": "user"
      },
      "summary": "We introduce MiniMax-M1, the world's first open-weight, large-scale\nhybrid-attention reasoning model. MiniMax-M1 is powered by a hybrid\nMixture-of-Experts (MoE) architecture combined with a lightning attention\nmechanism. The model is developed based on our previous MiniMax-Text-01 model,\nwhich contains a total of 456 billion parameters with 45.9 billion parameters\nactivated per token. The M1 model natively supports a context length of 1\nmillion tokens, 8x the context size of DeepSeek R1. Furthermore, the lightning\nattention mechanism in MiniMax-M1 enables efficient scaling of test-time\ncompute. These properties make M1 particularly suitable for complex tasks that\nrequire processing long inputs and thinking extensively. MiniMax-M1 is trained\nusing large-scale reinforcement learning (RL) on diverse problems including\nsandbox-based, real-world software engineering environments. In addition to\nM1's inherent efficiency advantage for RL training, we propose CISPO, a novel\nRL algorithm to further enhance RL efficiency. CISPO clips importance sampling\nweights rather than token updates, outperforming other competitive RL variants.\nCombining hybrid-attention and CISPO enables MiniMax-M1's full RL training on\n512 H800 GPUs to complete in only three weeks, with a rental cost of just\n$534,700. We release two versions of MiniMax-M1 models with 40K and 80K\nthinking budgets respectively, where the 40K model represents an intermediate\nphase of the 80K training. Experiments on standard benchmarks show that our\nmodels are comparable or superior to strong open-weight models such as the\noriginal DeepSeek-R1 and Qwen3-235B, with particular strengths in complex\nsoftware engineering, tool utilization, and long-context tasks. We publicly\nrelease MiniMax-M1 at https://github.com/MiniMax-AI/MiniMax-M1.",
      "upvotes": 148,
      "discussionId": "6850d0105e07650ecce89089",
      "projectPage": "https://huggingface.co/MiniMaxAI/MiniMax-M1-80k",
      "githubRepo": "https://github.com/MiniMax-AI/MiniMax-M1",
      "ai_summary": "A hybrid-attention reasoning model called MiniMax-M1, featuring a Mixture-of-Experts architecture and lightning attention mechanism, is introduced for efficient long-input processing and reinforcement learning.",
      "ai_keywords": [
        "Mixture-of-Experts (MoE)",
        "lightning attention mechanism",
        "reinforcement learning (RL)",
        "CISPO",
        "importance sampling weights",
        "token updates"
      ]
    },
    "publishedAt": "2025-06-16T11:08:02.000Z",
    "title": "MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning\n  Attention",
    "summary": "We introduce MiniMax-M1, the world's first open-weight, large-scale\nhybrid-attention reasoning model. MiniMax-M1 is powered by a hybrid\nMixture-of-Experts (MoE) architecture combined with a lightning attention\nmechanism. The model is developed based on our previous MiniMax-Text-01 model,\nwhich contains a total of 456 billion parameters with 45.9 billion parameters\nactivated per token. The M1 model natively supports a context length of 1\nmillion tokens, 8x the context size of DeepSeek R1. Furthermore, the lightning\nattention mechanism in MiniMax-M1 enables efficient scaling of test-time\ncompute. These properties make M1 particularly suitable for complex tasks that\nrequire processing long inputs and thinking extensively. MiniMax-M1 is trained\nusing large-scale reinforcement learning (RL) on diverse problems including\nsandbox-based, real-world software engineering environments. In addition to\nM1's inherent efficiency advantage for RL training, we propose CISPO, a novel\nRL algorithm to further enhance RL efficiency. CISPO clips importance sampling\nweights rather than token updates, outperforming other competitive RL variants.\nCombining hybrid-attention and CISPO enables MiniMax-M1's full RL training on\n512 H800 GPUs to complete in only three weeks, with a rental cost of just\n$534,700. We release two versions of MiniMax-M1 models with 40K and 80K\nthinking budgets respectively, where the 40K model represents an intermediate\nphase of the 80K training. Experiments on standard benchmarks show that our\nmodels are comparable or superior to strong open-weight models such as the\noriginal DeepSeek-R1 and Qwen3-235B, with particular strengths in complex\nsoftware engineering, tool utilization, and long-context tasks. We publicly\nrelease MiniMax-M1 at https://github.com/MiniMax-AI/MiniMax-M1.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13585.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "676e38ad04af5bec20bc9faf",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/676e38ad04af5bec20bc9faf/AG8Q9wAUzGtPWyjd5QO2l.jpeg",
      "fullname": "MiniMax",
      "name": "MiniMax-AI",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 160
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.10521",
      "authors": [
        {
          "_id": "684b8c603b733ba333686ffe",
          "name": "Yuhao Zhou",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333686fff",
          "name": "Yiheng Wang",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687000",
          "name": "Xuming He",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687001",
          "name": "Ruoyao Xiao",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687002",
          "name": "Zhiwei Li",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687003",
          "name": "Qiantai Feng",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687004",
          "name": "Zijie Guo",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687005",
          "name": "Yuejin Yang",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687006",
          "name": "Hao Wu",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687007",
          "user": {
            "_id": "675118b088a927f8898f81b4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/qVVgc2kuR37QqO5-Lu8Xq.png",
            "isPro": false,
            "fullname": "Wilson Huang",
            "user": "WilsonHwang",
            "type": "user"
          },
          "name": "Wenxuan Huang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:22:33.270Z",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687008",
          "name": "Jiaqi Wei",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687009",
          "name": "Dan Si",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba33368700a",
          "name": "Xiuqi Yao",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba33368700b",
          "name": "Jia Bu",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba33368700c",
          "name": "Haiwen Huang",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba33368700d",
          "name": "Tianfan Fu",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba33368700e",
          "name": "Shixiang Tang",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba33368700f",
          "name": "Ben Fei",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687010",
          "name": "Dongzhan Zhou",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687011",
          "name": "Fenghua Ling",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687012",
          "name": "Yan Lu",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687013",
          "name": "Siqi Sun",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687014",
          "name": "Chenhui Li",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687015",
          "name": "Guanjie Zheng",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687016",
          "name": "Jiancheng Lv",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687017",
          "name": "Wenlong Zhang",
          "hidden": false
        },
        {
          "_id": "684b8c603b733ba333687018",
          "name": "Lei Bai",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-12T09:29:16.000Z",
      "submittedOnDailyAt": "2025-06-17T02:12:14.955Z",
      "title": "Scientists' First Exam: Probing Cognitive Abilities of MLLM via\n  Perception, Understanding, and Reasoning",
      "submittedOnDailyBy": {
        "_id": "6538b861613fe158bd581e35",
        "avatarUrl": "/avatars/6817dbfe903675721fd227058b0a91ac.svg",
        "isPro": false,
        "fullname": "Dongzhan Zhou",
        "user": "schrodingers-tiger",
        "type": "user"
      },
      "summary": "Scientific discoveries increasingly rely on complex multimodal reasoning\nbased on information-intensive scientific data and domain-specific expertise.\nEmpowered by expert-level scientific benchmarks, scientific Multimodal Large\nLanguage Models (MLLMs) hold the potential to significantly enhance this\ndiscovery process in realistic workflows. However, current scientific\nbenchmarks mostly focus on evaluating the knowledge understanding capabilities\nof MLLMs, leading to an inadequate assessment of their perception and reasoning\nabilities. To address this gap, we present the Scientists' First Exam (SFE)\nbenchmark, designed to evaluate the scientific cognitive capacities of MLLMs\nthrough three interconnected levels: scientific signal perception, scientific\nattribute understanding, scientific comparative reasoning. Specifically, SFE\ncomprises 830 expert-verified VQA pairs across three question types, spanning\n66 multimodal tasks across five high-value disciplines. Extensive experiments\nreveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08%\nand 26.52% on SFE, highlighting significant room for MLLMs to improve in\nscientific realms. We hope the insights obtained in SFE will facilitate further\ndevelopments in AI-enhanced scientific discoveries.",
      "upvotes": 38,
      "discussionId": "684b8c603b733ba333687019",
      "ai_summary": "Scientists' First Exam (SFE) benchmark assesses scientific cognitive capacities of Multimodal Large Language Models through perception, understanding, and comparative reasoning.",
      "ai_keywords": [
        "Multimodal Large Language Models",
        "SFE benchmark",
        "scientific signal perception",
        "scientific attribute understanding",
        "scientific comparative reasoning",
        "expert-verified VQA",
        "GPT-o3",
        "InternVL-3"
      ]
    },
    "publishedAt": "2025-06-12T05:29:16.000Z",
    "title": "Scientists' First Exam: Probing Cognitive Abilities of MLLM via\n  Perception, Understanding, and Reasoning",
    "summary": "Scientific discoveries increasingly rely on complex multimodal reasoning\nbased on information-intensive scientific data and domain-specific expertise.\nEmpowered by expert-level scientific benchmarks, scientific Multimodal Large\nLanguage Models (MLLMs) hold the potential to significantly enhance this\ndiscovery process in realistic workflows. However, current scientific\nbenchmarks mostly focus on evaluating the knowledge understanding capabilities\nof MLLMs, leading to an inadequate assessment of their perception and reasoning\nabilities. To address this gap, we present the Scientists' First Exam (SFE)\nbenchmark, designed to evaluate the scientific cognitive capacities of MLLMs\nthrough three interconnected levels: scientific signal perception, scientific\nattribute understanding, scientific comparative reasoning. Specifically, SFE\ncomprises 830 expert-verified VQA pairs across three question types, spanning\n66 multimodal tasks across five high-value disciplines. Extensive experiments\nreveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08%\nand 26.52% on SFE, highlighting significant room for MLLMs to improve in\nscientific realms. We hope the insights obtained in SFE will facilitate further\ndevelopments in AI-enhanced scientific discoveries.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.10521.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6538b861613fe158bd581e35",
      "avatarUrl": "/avatars/6817dbfe903675721fd227058b0a91ac.svg",
      "fullname": "Dongzhan Zhou",
      "name": "schrodingers-tiger",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.11763",
      "authors": [
        {
          "_id": "684ff5051d9b438aa3957a7f",
          "user": {
            "_id": "646dbba74ad7f907279dd486",
            "avatarUrl": "/avatars/fe2b95e9a55711164e9624e1d15e0af2.svg",
            "isPro": false,
            "fullname": "Mingxuan Du",
            "user": "Ayanami0730",
            "type": "user"
          },
          "name": "Mingxuan Du",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T12:56:12.158Z",
          "hidden": false
        },
        {
          "_id": "684ff5051d9b438aa3957a80",
          "name": "Benfeng Xu",
          "hidden": false
        },
        {
          "_id": "684ff5051d9b438aa3957a81",
          "user": {
            "_id": "663b22a80966eef8686aadaf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/663b22a80966eef8686aadaf/iBzyQTyGZKf33RPVIFh9a.jpeg",
            "isPro": false,
            "fullname": "Chiwei Zhu",
            "user": "IgnoraZ",
            "type": "user"
          },
          "name": "Chiwei Zhu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T12:56:09.702Z",
          "hidden": false
        },
        {
          "_id": "684ff5051d9b438aa3957a82",
          "name": "Xiaorui Wang",
          "hidden": false
        },
        {
          "_id": "684ff5051d9b438aa3957a83",
          "name": "Zhendong Mao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T13:17:32.000Z",
      "submittedOnDailyAt": "2025-06-17T00:31:26.473Z",
      "title": "DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents",
      "submittedOnDailyBy": {
        "_id": "646dbba74ad7f907279dd486",
        "avatarUrl": "/avatars/fe2b95e9a55711164e9624e1d15e0af2.svg",
        "isPro": false,
        "fullname": "Mingxuan Du",
        "user": "Ayanami0730",
        "type": "user"
      },
      "summary": "Deep Research Agents are a prominent category of LLM-based agents. By\nautonomously orchestrating multistep web exploration, targeted retrieval, and\nhigher-order synthesis, they transform vast amounts of online information into\nanalyst-grade, citation-rich reports--compressing hours of manual desk research\ninto minutes. However, a comprehensive benchmark for systematically evaluating\nthe capabilities of these agents remains absent. To bridge this gap, we present\nDeepResearch Bench, a benchmark consisting of 100 PhD-level research tasks,\neach meticulously crafted by domain experts across 22 distinct fields.\nEvaluating DRAs is inherently complex and labor-intensive. We therefore propose\ntwo novel methodologies that achieve strong alignment with human judgment. The\nfirst is a reference-based method with adaptive criteria to assess the quality\nof generated research reports. The other framework is introduced to evaluate\nDRA's information retrieval and collection capabilities by assessing its\neffective citation count and overall citation accuracy. We have open-sourced\nDeepResearch Bench and key components of these frameworks at\nhttps://github.com/Ayanami0730/deep_research_bench to accelerate the\ndevelopment of practical LLM-based agents.",
      "upvotes": 26,
      "discussionId": "684ff5051d9b438aa3957a84",
      "projectPage": "https://deepresearch-bench.github.io",
      "githubRepo": "https://github.com/Ayanami0730/deep_research_bench",
      "ai_summary": "DeepResearch Bench offers a benchmark framework to evaluate the capabilities of Deep Research Agents in terms of research quality and information retrieval accuracy across multiple fields.",
      "ai_keywords": [
        "Deep Research Agents",
        "LLM-based agents",
        "multistep web exploration",
        "targeted retrieval",
        "higher-order synthesis",
        "PhD-level research tasks",
        "reference-based method",
        "effective citation count",
        "citation accuracy"
      ]
    },
    "publishedAt": "2025-06-13T09:17:32.000Z",
    "title": "DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents",
    "summary": "Deep Research Agents are a prominent category of LLM-based agents. By\nautonomously orchestrating multistep web exploration, targeted retrieval, and\nhigher-order synthesis, they transform vast amounts of online information into\nanalyst-grade, citation-rich reports--compressing hours of manual desk research\ninto minutes. However, a comprehensive benchmark for systematically evaluating\nthe capabilities of these agents remains absent. To bridge this gap, we present\nDeepResearch Bench, a benchmark consisting of 100 PhD-level research tasks,\neach meticulously crafted by domain experts across 22 distinct fields.\nEvaluating DRAs is inherently complex and labor-intensive. We therefore propose\ntwo novel methodologies that achieve strong alignment with human judgment. The\nfirst is a reference-based method with adaptive criteria to assess the quality\nof generated research reports. The other framework is introduced to evaluate\nDRA's information retrieval and collection capabilities by assessing its\neffective citation count and overall citation accuracy. We have open-sourced\nDeepResearch Bench and key components of these frameworks at\nhttps://github.com/Ayanami0730/deep_research_bench to accelerate the\ndevelopment of practical LLM-based agents.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11763.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646dbba74ad7f907279dd486",
      "avatarUrl": "/avatars/fe2b95e9a55711164e9624e1d15e0af2.svg",
      "fullname": "Mingxuan Du",
      "name": "Ayanami0730",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.13654",
      "authors": [
        {
          "_id": "6850e2a05e07650ecce89106",
          "user": {
            "_id": "6658d01c6f1a71ba56d6c273",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/tc4nZrMuZQLfgt5aVxtH4.jpeg",
            "isPro": false,
            "fullname": "Tian Shulin",
            "user": "shulin16",
            "type": "user"
          },
          "name": "Shulin Tian",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:00.696Z",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce89107",
          "user": {
            "_id": "6303e551d14428368d194477",
            "avatarUrl": "/avatars/b3c583e4525747b314379a7613e3b115.svg",
            "isPro": false,
            "fullname": "Ruiqi Wang",
            "user": "ruiqiw",
            "type": "user"
          },
          "name": "Ruiqi Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:03.098Z",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce89108",
          "name": "Hongming Guo",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce89109",
          "name": "Penghao Wu",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce8910a",
          "name": "Yuhao Dong",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce8910b",
          "name": "Xiuying Wang",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce8910c",
          "name": "Jingkang Yang",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce8910d",
          "name": "Hao Zhang",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce8910e",
          "name": "Hongyuan Zhu",
          "hidden": false
        },
        {
          "_id": "6850e2a05e07650ecce8910f",
          "name": "Ziwei Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T16:17:08.000Z",
      "submittedOnDailyAt": "2025-06-17T02:14:02.144Z",
      "title": "Ego-R1: Chain-of-Tool-Thought for Ultra-Long Egocentric Video Reasoning",
      "submittedOnDailyBy": {
        "_id": "6658d01c6f1a71ba56d6c273",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/tc4nZrMuZQLfgt5aVxtH4.jpeg",
        "isPro": false,
        "fullname": "Tian Shulin",
        "user": "shulin16",
        "type": "user"
      },
      "summary": "We introduce Ego-R1, a novel framework for reasoning over ultra-long (i.e.,\nin days and weeks) egocentric videos, which leverages a structured\nChain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained\nvia reinforcement learning (RL). Inspired by human problem-solving strategies,\nCoTT decomposes complex reasoning into modular steps, with the RL agent\ninvoking specific tools, one per step, to iteratively and collaboratively\nanswer sub-questions tackling such tasks as temporal retrieval and multi-modal\nunderstanding. We design a two-stage training paradigm involving supervised\nfinetuning (SFT) of a pretrained language model using CoTT data and RL to\nenable our agent to dynamically propose step-by-step tools for long-range\nreasoning. To facilitate training, we construct a dataset called Ego-R1 Data,\nwhich consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our\nEgo-R1 agent is evaluated on a newly curated week-long video QA benchmark,\nEgo-R1 Bench, which contains human-verified QA pairs from hybrid sources.\nExtensive results demonstrate that the dynamic, tool-augmented chain-of-thought\nreasoning by our Ego-R1 Agent can effectively tackle the unique challenges of\nunderstanding ultra-long egocentric videos, significantly extending the time\ncoverage from few hours to a week.",
      "upvotes": 21,
      "discussionId": "6850e2a05e07650ecce89110",
      "ai_summary": "Ego-R1, a reinforcement learning-based framework, uses a structured tool-augmented chain-of-thought process to reason over ultra-long egocentric videos, achieving better performance than existing methods by extending time coverage to a week.",
      "ai_keywords": [
        "Chain-of-Tool-Thought",
        "CoTT",
        "reinforcement learning",
        "RL",
        "pretrained language model",
        "supervised finetuning",
        "SFT",
        "Ego-CoTT-25K",
        "Ego-QA-4.4K",
        "Ego-R1 Bench",
        "video QA",
        "temporal retrieval",
        "multi-modal understanding"
      ]
    },
    "publishedAt": "2025-06-16T12:17:08.000Z",
    "title": "Ego-R1: Chain-of-Tool-Thought for Ultra-Long Egocentric Video Reasoning",
    "summary": "We introduce Ego-R1, a novel framework for reasoning over ultra-long (i.e.,\nin days and weeks) egocentric videos, which leverages a structured\nChain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained\nvia reinforcement learning (RL). Inspired by human problem-solving strategies,\nCoTT decomposes complex reasoning into modular steps, with the RL agent\ninvoking specific tools, one per step, to iteratively and collaboratively\nanswer sub-questions tackling such tasks as temporal retrieval and multi-modal\nunderstanding. We design a two-stage training paradigm involving supervised\nfinetuning (SFT) of a pretrained language model using CoTT data and RL to\nenable our agent to dynamically propose step-by-step tools for long-range\nreasoning. To facilitate training, we construct a dataset called Ego-R1 Data,\nwhich consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our\nEgo-R1 agent is evaluated on a newly curated week-long video QA benchmark,\nEgo-R1 Bench, which contains human-verified QA pairs from hybrid sources.\nExtensive results demonstrate that the dynamic, tool-augmented chain-of-thought\nreasoning by our Ego-R1 Agent can effectively tackle the unique challenges of\nunderstanding ultra-long egocentric videos, significantly extending the time\ncoverage from few hours to a week.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13654.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6658d01c6f1a71ba56d6c273",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/tc4nZrMuZQLfgt5aVxtH4.jpeg",
      "fullname": "Tian Shulin",
      "name": "shulin16",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.13759",
      "authors": [
        {
          "_id": "6850ccab5e07650ecce88fd7",
          "name": "Runpeng Yu",
          "hidden": false
        },
        {
          "_id": "6850ccab5e07650ecce88fd8",
          "name": "Qi Li",
          "hidden": false
        },
        {
          "_id": "6850ccab5e07650ecce88fd9",
          "name": "Xinchao Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T17:59:08.000Z",
      "submittedOnDailyAt": "2025-06-17T00:51:24.409Z",
      "title": "Discrete Diffusion in Large Language and Multimodal Models: A Survey",
      "submittedOnDailyBy": {
        "_id": "635364b3c41f548fe39db945",
        "avatarUrl": "/avatars/ad1916bbfabca0b6651c8eabacc5eba8.svg",
        "isPro": false,
        "fullname": "Runpeng Yu",
        "user": "rp-yu",
        "type": "user"
      },
      "summary": "In this work, we provide a systematic survey of Discrete Diffusion Language\nModels (dLLMs) and Discrete Diffusion Multimodal Language Models (dMLLMs).\nUnlike autoregressive (AR) models, dLLMs and dMLLMs adopt a multi-token,\nparallel decoding paradigm using full attention and a denoising-based\ngeneration strategy. This paradigm naturally enables parallel generation,\nfine-grained output controllability, and dynamic, response-aware perception.\nThese capabilities are previously difficult to achieve with AR models.\nRecently, a growing number of industrial-scale proprietary d(M)LLMs, as well as\na large number of open-source academic d(M)LLMs, have demonstrated performance\ncomparable to their autoregressive counterparts, while achieving up to 10x\nacceleration in inference speed.\n  The advancement of discrete diffusion LLMs and MLLMs has been largely driven\nby progress in two domains. The first is the development of autoregressive LLMs\nand MLLMs, which has accumulated vast amounts of data, benchmarks, and\nfoundational infrastructure for training and inference. The second contributing\ndomain is the evolution of the mathematical models underlying discrete\ndiffusion. Together, these advancements have catalyzed a surge in dLLMs and\ndMLLMs research in early 2025.\n  In this work, we present a comprehensive overview of the research in the dLLM\nand dMLLM domains. We trace the historical development of dLLMs and dMLLMs,\nformalize the underlying mathematical frameworks, and categorize representative\nmodels. We further analyze key techniques for training and inference, and\nsummarize emerging applications across language, vision-language, and\nbiological domains. We conclude by discussing future directions for research\nand deployment.\n  Paper collection: https://github.com/LiQiiiii/DLLM-Survey",
      "upvotes": 16,
      "discussionId": "6850ccab5e07650ecce88fda",
      "githubRepo": "https://github.com/LiQiiiii/DLLM-Survey",
      "ai_summary": "Discrete Diffusion Language Models (dLLMs) and Discrete Diffusion Multimodal Language Models (dMLLMs) enable parallel generation and faster inference compared to autoregressive models through denoising-based strategies and full attention mechanisms.",
      "ai_keywords": [
        "Discrete Diffusion Language Models",
        "Discrete Diffusion Multimodal Language Models",
        "autoregressive models",
        "multi-token",
        "parallel decoding",
        "full attention",
        "denoising-based generation",
        "response-aware perception",
        "inference speed",
        "autoregressive LLMs",
        "autoregressive MLLMs",
        "mathematical models",
        "historical development",
        "training",
        "inference",
        "language applications",
        "vision-language applications",
        "biological applications",
        "future research directions",
        "deployment"
      ]
    },
    "publishedAt": "2025-06-16T13:59:08.000Z",
    "title": "Discrete Diffusion in Large Language and Multimodal Models: A Survey",
    "summary": "In this work, we provide a systematic survey of Discrete Diffusion Language\nModels (dLLMs) and Discrete Diffusion Multimodal Language Models (dMLLMs).\nUnlike autoregressive (AR) models, dLLMs and dMLLMs adopt a multi-token,\nparallel decoding paradigm using full attention and a denoising-based\ngeneration strategy. This paradigm naturally enables parallel generation,\nfine-grained output controllability, and dynamic, response-aware perception.\nThese capabilities are previously difficult to achieve with AR models.\nRecently, a growing number of industrial-scale proprietary d(M)LLMs, as well as\na large number of open-source academic d(M)LLMs, have demonstrated performance\ncomparable to their autoregressive counterparts, while achieving up to 10x\nacceleration in inference speed.\n  The advancement of discrete diffusion LLMs and MLLMs has been largely driven\nby progress in two domains. The first is the development of autoregressive LLMs\nand MLLMs, which has accumulated vast amounts of data, benchmarks, and\nfoundational infrastructure for training and inference. The second contributing\ndomain is the evolution of the mathematical models underlying discrete\ndiffusion. Together, these advancements have catalyzed a surge in dLLMs and\ndMLLMs research in early 2025.\n  In this work, we present a comprehensive overview of the research in the dLLM\nand dMLLM domains. We trace the historical development of dLLMs and dMLLMs,\nformalize the underlying mathematical frameworks, and categorize representative\nmodels. We further analyze key techniques for training and inference, and\nsummarize emerging applications across language, vision-language, and\nbiological domains. We conclude by discussing future directions for research\nand deployment.\n  Paper collection: https://github.com/LiQiiiii/DLLM-Survey",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13759.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "635364b3c41f548fe39db945",
      "avatarUrl": "/avatars/ad1916bbfabca0b6651c8eabacc5eba8.svg",
      "fullname": "Runpeng Yu",
      "name": "rp-yu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.08343",
      "authors": [
        {
          "_id": "684ae1f5dbd21a9cc27b0f3a",
          "name": "Chenlong Wang",
          "hidden": false
        },
        {
          "_id": "684ae1f5dbd21a9cc27b0f3b",
          "name": "Yuanning Feng",
          "hidden": false
        },
        {
          "_id": "684ae1f5dbd21a9cc27b0f3c",
          "name": "Dongping Chen",
          "hidden": false
        },
        {
          "_id": "684ae1f5dbd21a9cc27b0f3d",
          "name": "Zhaoyang Chu",
          "hidden": false
        },
        {
          "_id": "684ae1f5dbd21a9cc27b0f3e",
          "name": "Ranjay Krishna",
          "hidden": false
        },
        {
          "_id": "684ae1f5dbd21a9cc27b0f3f",
          "name": "Tianyi Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-10T01:54:04.000Z",
      "submittedOnDailyAt": "2025-06-17T00:33:58.377Z",
      "title": "Wait, We Don't Need to \"Wait\"! Removing Thinking Tokens Improves\n  Reasoning Efficiency",
      "submittedOnDailyBy": {
        "_id": "643be8879f5d314db2d9ed23",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643be8879f5d314db2d9ed23/VrW2UtJ7ppOnGIYjTWd7b.png",
        "isPro": false,
        "fullname": "Chen Dongping",
        "user": "shuaishuaicdp",
        "type": "user"
      },
      "summary": "Recent advances in large reasoning models have enabled complex, step-by-step\nreasoning but often introduce significant overthinking, resulting in verbose\nand redundant outputs that hinder efficiency. In this study, we examine whether\nexplicit self-reflection, signaled by tokens such as \"Wait\" and \"Hmm\", is\nnecessary for advanced reasoning. We propose NoWait, a simple yet effective\napproach that disables explicit self-reflection by suppressing these tokens\nduring inference. Extensive experiments on ten benchmarks across textual,\nvisual, and video reasoning tasks show that NoWait reduces chain-of-thought\ntrajectory length by up to 27%-51% in five R1-style model series, without\ncompromising model utility. NoWait thus offers a plug-and-play solution for\nefficient and utility-preserving multimodal reasoning.",
      "upvotes": 16,
      "discussionId": "684ae1f5dbd21a9cc27b0f40",
      "ai_summary": "NoWait suppresses explicit self-reflection tokens during inference to enhance efficiency in multimodal reasoning without reducing model utility.",
      "ai_keywords": [
        "reasoning models",
        "self-reflection",
        "tokens",
        "NoWait",
        "chain-of-thought trajectory length",
        "R1-style model series",
        "multimodal reasoning"
      ]
    },
    "publishedAt": "2025-06-09T21:54:04.000Z",
    "title": "Wait, We Don't Need to \"Wait\"! Removing Thinking Tokens Improves\n  Reasoning Efficiency",
    "summary": "Recent advances in large reasoning models have enabled complex, step-by-step\nreasoning but often introduce significant overthinking, resulting in verbose\nand redundant outputs that hinder efficiency. In this study, we examine whether\nexplicit self-reflection, signaled by tokens such as \"Wait\" and \"Hmm\", is\nnecessary for advanced reasoning. We propose NoWait, a simple yet effective\napproach that disables explicit self-reflection by suppressing these tokens\nduring inference. Extensive experiments on ten benchmarks across textual,\nvisual, and video reasoning tasks show that NoWait reduces chain-of-thought\ntrajectory length by up to 27%-51% in five R1-style model series, without\ncompromising model utility. NoWait thus offers a plug-and-play solution for\nefficient and utility-preserving multimodal reasoning.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.08343.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "643be8879f5d314db2d9ed23",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643be8879f5d314db2d9ed23/VrW2UtJ7ppOnGIYjTWd7b.png",
      "fullname": "Chen Dongping",
      "name": "shuaishuaicdp",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.12915",
      "authors": [
        {
          "_id": "6850da255e07650ecce890d3",
          "name": "Meiling Tao",
          "hidden": false
        },
        {
          "_id": "6850da255e07650ecce890d4",
          "name": "Chenghao Zhu",
          "hidden": false
        },
        {
          "_id": "6850da255e07650ecce890d5",
          "name": "Dongyi Ding",
          "hidden": false
        },
        {
          "_id": "6850da255e07650ecce890d6",
          "name": "Tiannan Wang",
          "hidden": false
        },
        {
          "_id": "6850da255e07650ecce890d7",
          "name": "Yuchen Eleanor Jiang",
          "hidden": false
        },
        {
          "_id": "6850da255e07650ecce890d8",
          "name": "Wangchunshu Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-15T17:19:19.000Z",
      "submittedOnDailyAt": "2025-06-17T01:37:16.408Z",
      "title": "PersonaFeedback: A Large-scale Human-annotated Benchmark For\n  Personalization",
      "submittedOnDailyBy": {
        "_id": "632bfaebea6e62428ab0e9c2",
        "avatarUrl": "/avatars/344aaf371bbba9aea091b12741c451e5.svg",
        "isPro": false,
        "fullname": "Tiannan Wang",
        "user": "WTNswaggy",
        "type": "user"
      },
      "summary": "With the rapid improvement in the general capabilities of LLMs, LLM\npersonalization, i.e., how to build LLM systems that can generate personalized\nresponses or services that are tailored to distinct user personas, has become\nan increasingly important research and engineering problem. However, unlike\nmany new challenging benchmarks being released for evaluating the\ngeneral/reasoning capabilities, the lack of high-quality benchmarks for\nevaluating LLM personalization greatly hinders progress in this field. To\naddress this, we introduce PersonaFeedback, a new benchmark that directly\nevaluates LLMs' ability to provide personalized responses given pre-defined\nuser personas and queries. Unlike existing benchmarks that require models to\ninfer implicit user personas from historical interactions, PersonaFeedback\ndecouples persona inference from personalization, focusing on evaluating the\nmodel's ability to generate responses tailored to explicit personas.\nPersonaFeedback consists of 8298 human-annotated test cases, which are\ncategorized into easy, medium, and hard tiers based on the contextual\ncomplexity of the user personas and the difficulty in distinguishing subtle\ndifferences between two personalized responses. We conduct comprehensive\nevaluations across a wide range of models. The empirical results reveal that\neven state-of-the-art LLMs that can solve complex real-world reasoning tasks\ncould fall short on the hard tier of PersonaFeedback where even human\nevaluators may find the distinctions challenging. Furthermore, we conduct an\nin-depth analysis of failure modes across various types of systems,\ndemonstrating that the current retrieval-augmented framework should not be seen\nas a de facto solution for personalization tasks. All benchmark data,\nannotation protocols, and the evaluation pipeline will be publicly available to\nfacilitate future research on LLM personalization.",
      "upvotes": 11,
      "discussionId": "6850da255e07650ecce890d9",
      "ai_summary": "A new benchmark, PersonaFeedback, evaluates Large Language Models' ability to generate personalized responses given explicit user personas, revealing limitations in current systems.",
      "ai_keywords": [
        "Large Language Models (LLMs)",
        "LLM personalization",
        "PersonaFeedback",
        "user personas",
        "personalized responses",
        "contextual complexity",
        "human-annotated test cases",
        "retrieval-augmented framework"
      ]
    },
    "publishedAt": "2025-06-15T13:19:19.000Z",
    "title": "PersonaFeedback: A Large-scale Human-annotated Benchmark For\n  Personalization",
    "summary": "With the rapid improvement in the general capabilities of LLMs, LLM\npersonalization, i.e., how to build LLM systems that can generate personalized\nresponses or services that are tailored to distinct user personas, has become\nan increasingly important research and engineering problem. However, unlike\nmany new challenging benchmarks being released for evaluating the\ngeneral/reasoning capabilities, the lack of high-quality benchmarks for\nevaluating LLM personalization greatly hinders progress in this field. To\naddress this, we introduce PersonaFeedback, a new benchmark that directly\nevaluates LLMs' ability to provide personalized responses given pre-defined\nuser personas and queries. Unlike existing benchmarks that require models to\ninfer implicit user personas from historical interactions, PersonaFeedback\ndecouples persona inference from personalization, focusing on evaluating the\nmodel's ability to generate responses tailored to explicit personas.\nPersonaFeedback consists of 8298 human-annotated test cases, which are\ncategorized into easy, medium, and hard tiers based on the contextual\ncomplexity of the user personas and the difficulty in distinguishing subtle\ndifferences between two personalized responses. We conduct comprehensive\nevaluations across a wide range of models. The empirical results reveal that\neven state-of-the-art LLMs that can solve complex real-world reasoning tasks\ncould fall short on the hard tier of PersonaFeedback where even human\nevaluators may find the distinctions challenging. Furthermore, we conduct an\nin-depth analysis of failure modes across various types of systems,\ndemonstrating that the current retrieval-augmented framework should not be seen\nas a de facto solution for personalization tasks. All benchmark data,\nannotation protocols, and the evaluation pipeline will be publicly available to\nfacilitate future research on LLM personalization.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12915.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "632bfaebea6e62428ab0e9c2",
      "avatarUrl": "/avatars/344aaf371bbba9aea091b12741c451e5.svg",
      "fullname": "Tiannan Wang",
      "name": "WTNswaggy",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.03968",
      "authors": [
        {
          "_id": "684169b041d567923aa6c5be",
          "user": {
            "_id": "663b22a80966eef8686aadaf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/663b22a80966eef8686aadaf/iBzyQTyGZKf33RPVIFh9a.jpeg",
            "isPro": false,
            "fullname": "Chiwei Zhu",
            "user": "IgnoraZ",
            "type": "user"
          },
          "name": "Chiwei Zhu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-05T09:59:41.997Z",
          "hidden": false
        },
        {
          "_id": "684169b041d567923aa6c5bf",
          "name": "Benfeng Xu",
          "hidden": false
        },
        {
          "_id": "684169b041d567923aa6c5c0",
          "name": "Xiaorui Wang",
          "hidden": false
        },
        {
          "_id": "684169b041d567923aa6c5c1",
          "name": "Zhendong Mao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-04T14:00:47.000Z",
      "submittedOnDailyAt": "2025-06-17T00:33:16.832Z",
      "title": "From Real to Synthetic: Synthesizing Millions of Diversified and\n  Complicated User Instructions with Attributed Grounding",
      "submittedOnDailyBy": {
        "_id": "663b22a80966eef8686aadaf",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/663b22a80966eef8686aadaf/iBzyQTyGZKf33RPVIFh9a.jpeg",
        "isPro": false,
        "fullname": "Chiwei Zhu",
        "user": "IgnoraZ",
        "type": "user"
      },
      "summary": "The pursuit of diverse, complex, and large-scale instruction data is crucial\nfor automatically aligning large language models (LLMs). While there are\nmethods capable of generating synthetic instructions at scale, they either\nsuffer from limited grounding sources, leading to a narrow distribution, or\nrely on trivial extensions that fail to produce meaningful trajectories in\nterms of complexity. In contrast, instructions that benefit efficient alignment\nare typically crafted with cognitive insights and grounded in real-world use\ncases. In this paper, we synthesize such instructions using attributed\ngrounding, which involves 1) a top-down attribution process that grounds a\nselective set of real instructions to situated users, and 2) a bottom-up\nsynthesis process that leverages web documents to first generate a situation,\nthen a meaningful instruction. This framework allows us to harvest diverse and\ncomplex instructions at scale, utilizing the vast range of web documents.\nSpecifically, we construct a dataset of 1 million instructions, called\nSynthQuestions, and demonstrate that models trained on it achieve leading\nperformance on several common benchmarks, with improvements that continually\nscale with more web corpora. Data, models and codes will be available at\nhttps://github.com/Ignoramus0817/SynthQuestions.",
      "upvotes": 11,
      "discussionId": "684169b141d567923aa6c603",
      "githubRepo": "https://github.com/Ignoramus0817/SynthQuestions",
      "ai_summary": "The paper presents a method for generating diverse and complex instruction data for large language models using attributed grounding, achieving top performance on benchmarks with a large synthesized dataset.",
      "ai_keywords": [
        "acknowledged grounding",
        "top-down attribution process",
        "bottom-up synthesis process",
        "web documents",
        "large language models",
        "SynthQuestions"
      ]
    },
    "publishedAt": "2025-06-04T10:00:47.000Z",
    "title": "From Real to Synthetic: Synthesizing Millions of Diversified and\n  Complicated User Instructions with Attributed Grounding",
    "summary": "The pursuit of diverse, complex, and large-scale instruction data is crucial\nfor automatically aligning large language models (LLMs). While there are\nmethods capable of generating synthetic instructions at scale, they either\nsuffer from limited grounding sources, leading to a narrow distribution, or\nrely on trivial extensions that fail to produce meaningful trajectories in\nterms of complexity. In contrast, instructions that benefit efficient alignment\nare typically crafted with cognitive insights and grounded in real-world use\ncases. In this paper, we synthesize such instructions using attributed\ngrounding, which involves 1) a top-down attribution process that grounds a\nselective set of real instructions to situated users, and 2) a bottom-up\nsynthesis process that leverages web documents to first generate a situation,\nthen a meaningful instruction. This framework allows us to harvest diverse and\ncomplex instructions at scale, utilizing the vast range of web documents.\nSpecifically, we construct a dataset of 1 million instructions, called\nSynthQuestions, and demonstrate that models trained on it achieve leading\nperformance on several common benchmarks, with improvements that continually\nscale with more web corpora. Data, models and codes will be available at\nhttps://github.com/Ignoramus0817/SynthQuestions.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.03968.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "663b22a80966eef8686aadaf",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/663b22a80966eef8686aadaf/iBzyQTyGZKf33RPVIFh9a.jpeg",
      "fullname": "Chiwei Zhu",
      "name": "IgnoraZ",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.11991",
      "authors": [
        {
          "_id": "684fc67360b4a34dbe007b3c",
          "user": {
            "_id": "64d201b1c2bd235422fb1d14",
            "avatarUrl": "/avatars/e50581aa66391cedae94e116e759b9ec.svg",
            "isPro": false,
            "fullname": "wang",
            "user": "stormthunder",
            "type": "user"
          },
          "name": "Jiacong Wang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:22:25.360Z",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b3d",
          "name": "Zijiang Kang",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b3e",
          "name": "Haochen Wang",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b3f",
          "name": "Haiyong Jiang",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b40",
          "name": "Jiawen Li",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b41",
          "user": {
            "_id": "64722a616facfb01d8ae8349",
            "avatarUrl": "/avatars/1dce23ae5ebd9996770cf5efe910b857.svg",
            "isPro": false,
            "fullname": "Wu Bohong",
            "user": "bongbohong",
            "type": "user"
          },
          "name": "Bohong Wu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T09:52:40.461Z",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b42",
          "name": "Ya Wang",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b43",
          "name": "Jiao Ran",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b44",
          "name": "Xiao Liang",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b45",
          "name": "Chao Feng",
          "hidden": false
        },
        {
          "_id": "684fc67360b4a34dbe007b46",
          "name": "Jun Xiao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T17:47:43.000Z",
      "submittedOnDailyAt": "2025-06-17T05:58:53.901Z",
      "title": "VGR: Visual Grounded Reasoning",
      "submittedOnDailyBy": {
        "_id": "64d201b1c2bd235422fb1d14",
        "avatarUrl": "/avatars/e50581aa66391cedae94e116e759b9ec.svg",
        "isPro": false,
        "fullname": "wang",
        "user": "stormthunder",
        "type": "user"
      },
      "summary": "In the field of multimodal chain-of-thought (CoT) reasoning, existing\napproaches predominantly rely on reasoning on pure language space, which\ninherently suffers from language bias and is largely confined to math or\nscience domains. This narrow focus limits their ability to handle complex\nvisual reasoning tasks that demand comprehensive understanding of image\ndetails. To address these limitations, this paper introduces VGR, a novel\nreasoning multimodal large language model (MLLM) with enhanced fine-grained\nvisual perception capabilities. Unlike traditional MLLMs that answer the\nquestion or reasoning solely on the language space, our VGR first detects\nrelevant regions that may help to solve problems, and then provides precise\nanswers based on replayed image regions. To achieve this, we conduct a\nlarge-scale SFT dataset called VGR -SFT that contains reasoning data with mixed\nvision grounding and language deduction. The inference pipeline of VGR allows\nthe model to choose bounding boxes for visual reference and a replay stage is\nintroduced to integrates the corresponding regions into the reasoning process,\nenhancing multimodel comprehension. Experiments on the LLaVA-NeXT-7B baseline\nshow that VGR achieves superior performance on multi-modal benchmarks requiring\ncomprehensive image detail understanding. Compared to the baseline, VGR uses\nonly 30\\% of the image token count while delivering scores of +4.1 on MMStar,\n+7.1 on AI2D, and a +12.9 improvement on ChartQA.",
      "upvotes": 10,
      "discussionId": "684fc67460b4a34dbe007b47",
      "projectPage": "https://huggingface.co/BytedanceDouyinContent/VGR",
      "ai_summary": "VGR, a novel multimodal large language model, improves visual reasoning by detecting relevant image regions and integrating them into the reasoning process, outperforming existing models on multimodal benchmarks with reduced resource usage.",
      "ai_keywords": [
        "multimodal chain-of-thought reasoning",
        "MLLM",
        "VGR",
        "enhanced fine-grained visual perception",
        "SFT dataset",
        "bounding boxes",
        "replay stage",
        "multimodal comprehension",
        "LLaVA-NeXT-7B",
        "MMStar",
        "AI2D",
        "ChartQA"
      ]
    },
    "publishedAt": "2025-06-13T13:47:43.000Z",
    "title": "VGR: Visual Grounded Reasoning",
    "summary": "In the field of multimodal chain-of-thought (CoT) reasoning, existing\napproaches predominantly rely on reasoning on pure language space, which\ninherently suffers from language bias and is largely confined to math or\nscience domains. This narrow focus limits their ability to handle complex\nvisual reasoning tasks that demand comprehensive understanding of image\ndetails. To address these limitations, this paper introduces VGR, a novel\nreasoning multimodal large language model (MLLM) with enhanced fine-grained\nvisual perception capabilities. Unlike traditional MLLMs that answer the\nquestion or reasoning solely on the language space, our VGR first detects\nrelevant regions that may help to solve problems, and then provides precise\nanswers based on replayed image regions. To achieve this, we conduct a\nlarge-scale SFT dataset called VGR -SFT that contains reasoning data with mixed\nvision grounding and language deduction. The inference pipeline of VGR allows\nthe model to choose bounding boxes for visual reference and a replay stage is\nintroduced to integrates the corresponding regions into the reasoning process,\nenhancing multimodel comprehension. Experiments on the LLaVA-NeXT-7B baseline\nshow that VGR achieves superior performance on multi-modal benchmarks requiring\ncomprehensive image detail understanding. Compared to the baseline, VGR uses\nonly 30\\% of the image token count while delivering scores of +4.1 on MMStar,\n+7.1 on AI2D, and a +12.9 improvement on ChartQA.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11991.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64d201b1c2bd235422fb1d14",
      "avatarUrl": "/avatars/e50581aa66391cedae94e116e759b9ec.svg",
      "fullname": "wang",
      "name": "stormthunder",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.10055",
      "authors": [
        {
          "_id": "6850ca685e07650ecce88fb6",
          "name": "Dingfeng Shi",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fb7",
          "name": "Jingyi Cao",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fb8",
          "name": "Qianben Chen",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fb9",
          "name": "Weichen Sun",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fba",
          "name": "Weizhen Li",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fbb",
          "name": "Hongxuan Lu",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fbc",
          "name": "Fangchen Dong",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fbd",
          "name": "Tianrui Qin",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fbe",
          "name": "King Zhu",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fbf",
          "name": "Minghao Yang",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fc0",
          "name": "Jian Yang",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fc1",
          "name": "Ge Zhang",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fc2",
          "name": "Jiaheng Liu",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fc3",
          "name": "Changwang Zhang",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fc4",
          "name": "Jun Wang",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fc5",
          "name": "Yuchen Eleanor Jiang",
          "hidden": false
        },
        {
          "_id": "6850ca685e07650ecce88fc6",
          "name": "Wangchunshu Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-11T17:58:14.000Z",
      "submittedOnDailyAt": "2025-06-17T05:04:25.899Z",
      "title": "TaskCraft: Automated Generation of Agentic Tasks",
      "submittedOnDailyBy": {
        "_id": "628c8598ef14f971b698107f",
        "avatarUrl": "/avatars/3a4ad87e6b5f9e836a1160d869df1447.svg",
        "isPro": false,
        "fullname": "Zhou",
        "user": "Wangchunshu",
        "type": "user"
      },
      "summary": "Agentic tasks, which require multi-step problem solving with autonomy, tool\nuse, and adaptive reasoning, are becoming increasingly central to the\nadvancement of NLP and AI. However, existing instruction data lacks tool\ninteraction, and current agentic benchmarks rely on costly human annotation,\nlimiting their scalability. We introduce TaskCraft, an automated\nworkflow for generating difficulty-scalable, multi-tool, and verifiable agentic\ntasks with execution trajectories. TaskCraft expands atomic tasks using\ndepth-based and width-based extensions to create structurally and\nhierarchically complex challenges. Empirical results show that these tasks\nimprove prompt optimization in the generation workflow and enhance supervised\nfine-tuning of agentic foundation models. We present a large-scale synthetic\ndataset of approximately 36,000 tasks with varying difficulty to support future\nresearch on agent tuning and evaluation.",
      "upvotes": 10,
      "discussionId": "6850ca695e07650ecce88fc7",
      "ai_summary": "TaskCraft automates the generation of scalable, multi-tool, and complex agentic tasks to enhance prompt optimization and fine-tuning of agentic models.",
      "ai_keywords": [
        "agentic tasks",
        "multi-step problem solving",
        "tool use",
        "adaptive reasoning",
        "instruction data",
        "human annotation",
        "difficulty-scalable",
        "multi-tool",
        "verifiable tasks",
        "execution trajectories",
        "depth-based extensions",
        "width-based extensions",
        "hierarchical complexity",
        "prompt optimization",
        "supervised fine-tuning",
        "agentic foundation models",
        "large-scale synthetic dataset"
      ]
    },
    "publishedAt": "2025-06-11T13:58:14.000Z",
    "title": "TaskCraft: Automated Generation of Agentic Tasks",
    "summary": "Agentic tasks, which require multi-step problem solving with autonomy, tool\nuse, and adaptive reasoning, are becoming increasingly central to the\nadvancement of NLP and AI. However, existing instruction data lacks tool\ninteraction, and current agentic benchmarks rely on costly human annotation,\nlimiting their scalability. We introduce TaskCraft, an automated\nworkflow for generating difficulty-scalable, multi-tool, and verifiable agentic\ntasks with execution trajectories. TaskCraft expands atomic tasks using\ndepth-based and width-based extensions to create structurally and\nhierarchically complex challenges. Empirical results show that these tasks\nimprove prompt optimization in the generation workflow and enhance supervised\nfine-tuning of agentic foundation models. We present a large-scale synthetic\ndataset of approximately 36,000 tasks with varying difficulty to support future\nresearch on agent tuning and evaluation.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.10055.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "628c8598ef14f971b698107f",
      "avatarUrl": "/avatars/3a4ad87e6b5f9e836a1160d869df1447.svg",
      "fullname": "Zhou",
      "name": "Wangchunshu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.07961",
      "authors": [
        {
          "_id": "684eae5e60b4a34dbe0079ea",
          "user": {
            "_id": "6337e04b171879571956212f",
            "avatarUrl": "/avatars/aa69142bf92e4c50b192463490251ed9.svg",
            "isPro": false,
            "fullname": "Li Peiyan",
            "user": "LPY",
            "type": "user"
          },
          "name": "Peiyan Li",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T07:16:27.694Z",
          "hidden": false
        },
        {
          "_id": "684eae5e60b4a34dbe0079eb",
          "name": "Yixiang Chen",
          "hidden": false
        },
        {
          "_id": "684eae5e60b4a34dbe0079ec",
          "name": "Hongtao Wu",
          "hidden": false
        },
        {
          "_id": "684eae5e60b4a34dbe0079ed",
          "name": "Xiao Ma",
          "hidden": false
        },
        {
          "_id": "684eae5e60b4a34dbe0079ee",
          "name": "Xiangnan Wu",
          "hidden": false
        },
        {
          "_id": "684eae5e60b4a34dbe0079ef",
          "name": "Yan Huang",
          "hidden": false
        },
        {
          "_id": "684eae5e60b4a34dbe0079f0",
          "name": "Liang Wang",
          "hidden": false
        },
        {
          "_id": "684eae5e60b4a34dbe0079f1",
          "name": "Tao Kong",
          "hidden": false
        },
        {
          "_id": "684eae5e60b4a34dbe0079f2",
          "name": "Tieniu Tan",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6337e04b171879571956212f/-CQCtJRF01UYHt7QmTwPl.mp4"
      ],
      "publishedAt": "2025-06-09T17:36:34.000Z",
      "submittedOnDailyAt": "2025-06-17T00:45:03.925Z",
      "title": "BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning\n  with Vision-Language Models",
      "submittedOnDailyBy": {
        "_id": "6337e04b171879571956212f",
        "avatarUrl": "/avatars/aa69142bf92e4c50b192463490251ed9.svg",
        "isPro": false,
        "fullname": "Li Peiyan",
        "user": "LPY",
        "type": "user"
      },
      "summary": "Recently, leveraging pre-trained vision-language models (VLMs) for building\nvision-language-action (VLA) models has emerged as a promising approach to\neffective robot manipulation learning. However, only few methods incorporate 3D\nsignals into VLMs for action prediction, and they do not fully leverage the\nspatial structure inherent in 3D data, leading to low sample efficiency. In\nthis paper, we introduce BridgeVLA, a novel 3D VLA model that (1) projects 3D\ninputs to multiple 2D images, ensuring input alignment with the VLM backbone,\nand (2) utilizes 2D heatmaps for action prediction, unifying the input and\noutput spaces within a consistent 2D image space. In addition, we propose a\nscalable pre-training method that equips the VLM backbone with the capability\nto predict 2D heatmaps before downstream policy learning. Extensive experiments\nshow the proposed method is able to learn 3D manipulation efficiently and\neffectively. BridgeVLA outperforms state-of-the-art baseline methods across\nthree simulation benchmarks. In RLBench, it improves the average success rate\nfrom 81.4% to 88.2%. In COLOSSEUM, it demonstrates significantly better\nperformance in challenging generalization settings, boosting the average\nsuccess rate from 56.7% to 64.0%. In GemBench, it surpasses all the comparing\nbaseline methods in terms of average success rate. In real-robot experiments,\nBridgeVLA outperforms a state-of-the-art baseline method by 32% on average. It\ngeneralizes robustly in multiple out-of-distribution settings, including visual\ndisturbances and unseen instructions. Remarkably, it is able to achieve a\nsuccess rate of 96.8% on 10+ tasks with only 3 trajectories per task,\nhighlighting its extraordinary sample efficiency. Project\nWebsite:https://bridgevla.github.io/",
      "upvotes": 8,
      "discussionId": "684eae5e60b4a34dbe0079f3",
      "projectPage": "https://bridgevla.github.io/",
      "githubRepo": "https://github.com/BridgeVLA/BridgeVLA",
      "ai_summary": "BridgeVLA is a 3D vision-language-action model that projects 3D inputs to 2D images and uses 2D heatmaps for efficient and effective action prediction, outperforming baselines in various benchmarks.",
      "ai_keywords": [
        "pre-trained vision-language models",
        "3D VLA model",
        "3D signals",
        "2D images",
        "VLM backbone",
        "2D heatmaps",
        "scalable pre-training method"
      ]
    },
    "publishedAt": "2025-06-09T13:36:34.000Z",
    "title": "BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning\n  with Vision-Language Models",
    "summary": "Recently, leveraging pre-trained vision-language models (VLMs) for building\nvision-language-action (VLA) models has emerged as a promising approach to\neffective robot manipulation learning. However, only few methods incorporate 3D\nsignals into VLMs for action prediction, and they do not fully leverage the\nspatial structure inherent in 3D data, leading to low sample efficiency. In\nthis paper, we introduce BridgeVLA, a novel 3D VLA model that (1) projects 3D\ninputs to multiple 2D images, ensuring input alignment with the VLM backbone,\nand (2) utilizes 2D heatmaps for action prediction, unifying the input and\noutput spaces within a consistent 2D image space. In addition, we propose a\nscalable pre-training method that equips the VLM backbone with the capability\nto predict 2D heatmaps before downstream policy learning. Extensive experiments\nshow the proposed method is able to learn 3D manipulation efficiently and\neffectively. BridgeVLA outperforms state-of-the-art baseline methods across\nthree simulation benchmarks. In RLBench, it improves the average success rate\nfrom 81.4% to 88.2%. In COLOSSEUM, it demonstrates significantly better\nperformance in challenging generalization settings, boosting the average\nsuccess rate from 56.7% to 64.0%. In GemBench, it surpasses all the comparing\nbaseline methods in terms of average success rate. In real-robot experiments,\nBridgeVLA outperforms a state-of-the-art baseline method by 32% on average. It\ngeneralizes robustly in multiple out-of-distribution settings, including visual\ndisturbances and unseen instructions. Remarkably, it is able to achieve a\nsuccess rate of 96.8% on 10+ tasks with only 3 trajectories per task,\nhighlighting its extraordinary sample efficiency. Project\nWebsite:https://bridgevla.github.io/",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6337e04b171879571956212f/-CQCtJRF01UYHt7QmTwPl.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.07961.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6337e04b171879571956212f",
      "avatarUrl": "/avatars/aa69142bf92e4c50b192463490251ed9.svg",
      "fullname": "Li Peiyan",
      "name": "LPY",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.13750",
      "authors": [
        {
          "_id": "6850d08d5e07650ecce8908b",
          "name": "Yuheng Yuan",
          "hidden": false
        },
        {
          "_id": "6850d08d5e07650ecce8908c",
          "user": {
            "_id": "643a6e89a856622f9788bf67",
            "avatarUrl": "/avatars/419c0379f072295b27d4bfe2f8fb946d.svg",
            "isPro": false,
            "fullname": "qiuhong shen",
            "user": "florinshum",
            "type": "user"
          },
          "name": "Qiuhong Shen",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:24.996Z",
          "hidden": false
        },
        {
          "_id": "6850d08d5e07650ecce8908d",
          "name": "Shizun Wang",
          "hidden": false
        },
        {
          "_id": "6850d08d5e07650ecce8908e",
          "name": "Xingyi Yang",
          "hidden": false
        },
        {
          "_id": "6850d08d5e07650ecce8908f",
          "name": "Xinchao Wang",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/67ac56c90f861b63617d153d/RxoJjrMeG2lKENvLl_bR0.mp4"
      ],
      "publishedAt": "2025-06-16T17:56:22.000Z",
      "submittedOnDailyAt": "2025-06-17T00:54:48.920Z",
      "title": "Test3R: Learning to Reconstruct 3D at Test Time",
      "submittedOnDailyBy": {
        "_id": "67ac56c90f861b63617d153d",
        "avatarUrl": "/avatars/96f5e60031fe4fe677159dccfecaa65c.svg",
        "isPro": false,
        "fullname": "Yuan Yuheng",
        "user": "nopyyh",
        "type": "user"
      },
      "summary": "Dense matching methods like DUSt3R regress pairwise pointmaps for 3D\nreconstruction. However, the reliance on pairwise prediction and the limited\ngeneralization capability inherently restrict the global geometric consistency.\nIn this work, we introduce Test3R, a surprisingly simple test-time learning\ntechnique that significantly boosts geometric accuracy. Using image triplets\n(I_1,I_2,I_3), Test3R generates reconstructions from pairs (I_1,I_2) and\n(I_1,I_3). The core idea is to optimize the network at test time via a\nself-supervised objective: maximizing the geometric consistency between these\ntwo reconstructions relative to the common image I_1. This ensures the model\nproduces cross-pair consistent outputs, regardless of the inputs. Extensive\nexperiments demonstrate that our technique significantly outperforms previous\nstate-of-the-art methods on the 3D reconstruction and multi-view depth\nestimation tasks. Moreover, it is universally applicable and nearly cost-free,\nmaking it easily applied to other models and implemented with minimal test-time\ntraining overhead and parameter footprint. Code is available at\nhttps://github.com/nopQAQ/Test3R.",
      "upvotes": 7,
      "discussionId": "6850d08e5e07650ecce89090",
      "ai_summary": "Test3R, a test-time learning technique for 3D reconstruction, enhances geometric accuracy by optimizing network consistency using self-supervised learning on image triplets.",
      "ai_keywords": [
        "DUSt3R",
        "dense matching",
        "3D reconstruction",
        "geometric accuracy",
        "test-time learning",
        "image triplets",
        "self-supervised objective",
        "cross-pair consistency"
      ]
    },
    "publishedAt": "2025-06-16T13:56:22.000Z",
    "title": "Test3R: Learning to Reconstruct 3D at Test Time",
    "summary": "Dense matching methods like DUSt3R regress pairwise pointmaps for 3D\nreconstruction. However, the reliance on pairwise prediction and the limited\ngeneralization capability inherently restrict the global geometric consistency.\nIn this work, we introduce Test3R, a surprisingly simple test-time learning\ntechnique that significantly boosts geometric accuracy. Using image triplets\n(I_1,I_2,I_3), Test3R generates reconstructions from pairs (I_1,I_2) and\n(I_1,I_3). The core idea is to optimize the network at test time via a\nself-supervised objective: maximizing the geometric consistency between these\ntwo reconstructions relative to the common image I_1. This ensures the model\nproduces cross-pair consistent outputs, regardless of the inputs. Extensive\nexperiments demonstrate that our technique significantly outperforms previous\nstate-of-the-art methods on the 3D reconstruction and multi-view depth\nestimation tasks. Moreover, it is universally applicable and nearly cost-free,\nmaking it easily applied to other models and implemented with minimal test-time\ntraining overhead and parameter footprint. Code is available at\nhttps://github.com/nopQAQ/Test3R.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/67ac56c90f861b63617d153d/RxoJjrMeG2lKENvLl_bR0.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13750.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67ac56c90f861b63617d153d",
      "avatarUrl": "/avatars/96f5e60031fe4fe677159dccfecaa65c.svg",
      "fullname": "Yuan Yuheng",
      "name": "nopyyh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.12450",
      "authors": [
        {
          "_id": "6850dfc85e07650ecce890e7",
          "user": {
            "_id": "61728a033edf4cc38a81237a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1652231681579-61728a033edf4cc38a81237a.jpeg",
            "isPro": false,
            "fullname": "Joanito Agili Lopo",
            "user": "joanitolopo",
            "type": "user"
          },
          "name": "Joanito Agili Lopo",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:08.064Z",
          "hidden": false
        },
        {
          "_id": "6850dfc85e07650ecce890e8",
          "user": {
            "_id": "63ddfced5ea8577c8d5fb421",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677144169806-63ddfced5ea8577c8d5fb421.jpeg",
            "isPro": false,
            "fullname": "Muhammad Ravi Shulthan Habibi",
            "user": "muhammadravi251001",
            "type": "user"
          },
          "name": "Muhammad Ravi Shulthan Habibi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:10.071Z",
          "hidden": false
        },
        {
          "_id": "6850dfc85e07650ecce890e9",
          "user": {
            "_id": "65a378339b0ac6aafca9bb9c",
            "avatarUrl": "/avatars/d5e8c2714f025adfe1487384664ddff6.svg",
            "isPro": false,
            "fullname": "wong tack hwa",
            "user": "tackhwa",
            "type": "user"
          },
          "name": "Tack Hwa Wong",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:05.829Z",
          "hidden": false
        },
        {
          "_id": "6850dfc85e07650ecce890ea",
          "name": "Muhammad Ilham Ghozali",
          "hidden": false
        },
        {
          "_id": "6850dfc85e07650ecce890eb",
          "name": "Fajri Koto",
          "hidden": false
        },
        {
          "_id": "6850dfc85e07650ecce890ec",
          "name": "Genta Indra Winata",
          "hidden": false
        },
        {
          "_id": "6850dfc85e07650ecce890ed",
          "name": "Peerat Limkonchotiwat",
          "hidden": false
        },
        {
          "_id": "6850dfc85e07650ecce890ee",
          "name": "Alham Fikri Aji",
          "hidden": false
        },
        {
          "_id": "6850dfc85e07650ecce890ef",
          "user": {
            "_id": "66f1af390ae00cd951861005",
            "avatarUrl": "/avatars/eeab3bf515e911c3250f99a1a73d43d3.svg",
            "isPro": false,
            "fullname": "Samuel Cahyawijaya",
            "user": "samuel-cahyawijaya",
            "type": "user"
          },
          "name": "Samuel Cahyawijaya",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-06-17T03:23:52.870Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-14T11:09:50.000Z",
      "submittedOnDailyAt": "2025-06-17T01:58:16.211Z",
      "title": "Language Surgery in Multilingual Large Language Models",
      "submittedOnDailyBy": {
        "_id": "61728a033edf4cc38a81237a",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1652231681579-61728a033edf4cc38a81237a.jpeg",
        "isPro": false,
        "fullname": "Joanito Agili Lopo",
        "user": "joanitolopo",
        "type": "user"
      },
      "summary": "Large Language Models (LLMs) have demonstrated remarkable generalization\ncapabilities across tasks and languages, revolutionizing natural language\nprocessing. This paper investigates the naturally emerging representation\nalignment in LLMs, particularly in the middle layers, and its implications for\ndisentangling language-specific and language-agnostic information. We\nempirically confirm the existence of this alignment, analyze its behavior in\ncomparison to explicitly designed alignment models, and demonstrate its\npotential for language-specific manipulation without semantic degradation.\nBuilding on these findings, we propose Inference-Time Language Control (ITLC),\na novel method that leverages latent injection to enable precise cross-lingual\nlanguage control and mitigate language confusion in LLMs. Our experiments\nhighlight ITLC's strong cross-lingual control capabilities while preserving\nsemantic integrity in target languages. Furthermore, we demonstrate its\neffectiveness in alleviating the cross-lingual language confusion problem,\nwhich persists even in current large-scale LLMs, leading to inconsistent\nlanguage generation. This work advances our understanding of representation\nalignment in LLMs and introduces a practical solution for enhancing their\ncross-lingual performance.",
      "upvotes": 4,
      "discussionId": "6850dfc85e07650ecce890f0",
      "githubRepo": "https://github.com/SEACrowd/itlc",
      "ai_summary": "Research confirms natural representation alignment in large language models and introduces Inference-Time Language Control to enhance cross-lingual performance.",
      "ai_keywords": [
        "Large Language Models",
        "representation alignment",
        "middle layers",
        "language-specific information",
        "language-agnostic information",
        "explicitly designed alignment models",
        "latent injection",
        "cross-lingual language control",
        "semantic integrity",
        "language confusion"
      ]
    },
    "publishedAt": "2025-06-14T07:09:50.000Z",
    "title": "Language Surgery in Multilingual Large Language Models",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable generalization\ncapabilities across tasks and languages, revolutionizing natural language\nprocessing. This paper investigates the naturally emerging representation\nalignment in LLMs, particularly in the middle layers, and its implications for\ndisentangling language-specific and language-agnostic information. We\nempirically confirm the existence of this alignment, analyze its behavior in\ncomparison to explicitly designed alignment models, and demonstrate its\npotential for language-specific manipulation without semantic degradation.\nBuilding on these findings, we propose Inference-Time Language Control (ITLC),\na novel method that leverages latent injection to enable precise cross-lingual\nlanguage control and mitigate language confusion in LLMs. Our experiments\nhighlight ITLC's strong cross-lingual control capabilities while preserving\nsemantic integrity in target languages. Furthermore, we demonstrate its\neffectiveness in alleviating the cross-lingual language confusion problem,\nwhich persists even in current large-scale LLMs, leading to inconsistent\nlanguage generation. This work advances our understanding of representation\nalignment in LLMs and introduces a practical solution for enhancing their\ncross-lingual performance.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12450.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61728a033edf4cc38a81237a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1652231681579-61728a033edf4cc38a81237a.jpeg",
      "fullname": "Joanito Agili Lopo",
      "name": "joanitolopo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.09050",
      "authors": [
        {
          "_id": "684909e942e4f9106973f386",
          "name": "Yuki Imajuku",
          "hidden": false
        },
        {
          "_id": "684909e942e4f9106973f387",
          "name": "Kohki Horie",
          "hidden": false
        },
        {
          "_id": "684909e942e4f9106973f388",
          "name": "Yoichi Iwata",
          "hidden": false
        },
        {
          "_id": "684909e942e4f9106973f389",
          "name": "Kensho Aoki",
          "hidden": false
        },
        {
          "_id": "684909e942e4f9106973f38a",
          "name": "Naohiro Takahashi",
          "hidden": false
        },
        {
          "_id": "684909e942e4f9106973f38b",
          "user": {
            "_id": "6482810dba6c556892f6f257",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6482810dba6c556892f6f257/c7-wiVKenXiRtwnRpnjZN.jpeg",
            "isPro": false,
            "fullname": "Takuya Akiba",
            "user": "iwiwi",
            "type": "user"
          },
          "name": "Takuya Akiba",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:23:16.335Z",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6482810dba6c556892f6f257/J5fdxZ7P_40qJ4qJPqPcI.png"
      ],
      "publishedAt": "2025-06-10T17:59:56.000Z",
      "submittedOnDailyAt": "2025-06-17T04:32:07.528Z",
      "title": "ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm\n  Engineering",
      "submittedOnDailyBy": {
        "_id": "6482810dba6c556892f6f257",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6482810dba6c556892f6f257/c7-wiVKenXiRtwnRpnjZN.jpeg",
        "isPro": false,
        "fullname": "Takuya Akiba",
        "user": "iwiwi",
        "type": "user"
      },
      "summary": "How well do AI systems perform in algorithm engineering for hard optimization\nproblems in domains such as package-delivery routing, crew scheduling, factory\nproduction planning, and power-grid balancing? We introduce ALE-Bench, a new\nbenchmark for evaluating AI systems on score-based algorithmic programming\ncontests. Drawing on real tasks from the AtCoder Heuristic Contests, ALE-Bench\npresents optimization problems that are computationally hard and admit no known\nexact solution. Unlike short-duration, pass/fail coding benchmarks, ALE-Bench\nencourages iterative solution refinement over long time horizons. Our software\nframework supports interactive agent architectures that leverage test-run\nfeedback and visualizations. Our evaluation of frontier LLMs revealed that\nwhile they demonstrate high performance on specific problems, a notable gap\nremains compared to humans in terms of consistency across problems and\nlong-horizon problem-solving capabilities. This highlights the need for this\nbenchmark to foster future AI advancements.",
      "upvotes": 4,
      "discussionId": "684909ea42e4f9106973f38c",
      "githubRepo": "https://github.com/SakanaAI/ALE-Bench",
      "ai_summary": "ALE-Bench evaluates AI systems on score-based algorithmic programming contests drawn from AtCoder, focusing on long-term iterative problem-solving in domains like package-delivery routing, crew scheduling, factory production, and power-grid balancing.",
      "ai_keywords": [
        "algorithm engineering",
        "optimization problems",
        "ALE-Bench",
        "AtCoder Heuristic Contests",
        "interactive agent architectures",
        "long-horizon problem-solving",
        "frontier LLMs"
      ]
    },
    "publishedAt": "2025-06-10T13:59:56.000Z",
    "title": "ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm\n  Engineering",
    "summary": "How well do AI systems perform in algorithm engineering for hard optimization\nproblems in domains such as package-delivery routing, crew scheduling, factory\nproduction planning, and power-grid balancing? We introduce ALE-Bench, a new\nbenchmark for evaluating AI systems on score-based algorithmic programming\ncontests. Drawing on real tasks from the AtCoder Heuristic Contests, ALE-Bench\npresents optimization problems that are computationally hard and admit no known\nexact solution. Unlike short-duration, pass/fail coding benchmarks, ALE-Bench\nencourages iterative solution refinement over long time horizons. Our software\nframework supports interactive agent architectures that leverage test-run\nfeedback and visualizations. Our evaluation of frontier LLMs revealed that\nwhile they demonstrate high performance on specific problems, a notable gap\nremains compared to humans in terms of consistency across problems and\nlong-horizon problem-solving capabilities. This highlights the need for this\nbenchmark to foster future AI advancements.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6482810dba6c556892f6f257/J5fdxZ7P_40qJ4qJPqPcI.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09050.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6482810dba6c556892f6f257",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6482810dba6c556892f6f257/c7-wiVKenXiRtwnRpnjZN.jpeg",
      "fullname": "Takuya Akiba",
      "name": "iwiwi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.06454",
      "authors": [
        {
          "_id": "6848ed6142e4f9106973f2b7",
          "user": {
            "_id": "647e61c2e4d52fe0e0205d94",
            "avatarUrl": "/avatars/d7a2327ab10494fb471496e85eed8ff0.svg",
            "isPro": false,
            "fullname": "Alpha Omega",
            "user": "alphaomeaga",
            "type": "user"
          },
          "name": "Abrar Majeedi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-13T07:41:53.817Z",
          "hidden": false
        },
        {
          "_id": "6848ed6142e4f9106973f2b8",
          "user": {
            "_id": "658708e06b17c068728f436a",
            "avatarUrl": "/avatars/b51f36d1bce76c195350ff6e523bb036.svg",
            "isPro": false,
            "fullname": "Viswa",
            "user": "viswa-98",
            "type": "user"
          },
          "name": "Viswanatha Reddy Gajjala",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-11T08:35:02.871Z",
          "hidden": false
        },
        {
          "_id": "6848ed6142e4f9106973f2b9",
          "name": "Satya Sai Srinath Namburi GNVV",
          "hidden": false
        },
        {
          "_id": "6848ed6142e4f9106973f2ba",
          "name": "Nada Magdi Elkordi",
          "hidden": false
        },
        {
          "_id": "6848ed6142e4f9106973f2bb",
          "name": "Yin Li",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/658708e06b17c068728f436a/CeZkFqf8ZE6bTIgIAyoFS.png"
      ],
      "publishedAt": "2025-06-06T18:24:12.000Z",
      "submittedOnDailyAt": "2025-06-17T05:37:39.544Z",
      "title": "LETS Forecast: Learning Embedology for Time Series Forecasting",
      "submittedOnDailyBy": {
        "_id": "658708e06b17c068728f436a",
        "avatarUrl": "/avatars/b51f36d1bce76c195350ff6e523bb036.svg",
        "isPro": false,
        "fullname": "Viswa",
        "user": "viswa-98",
        "type": "user"
      },
      "summary": "Real-world time series are often governed by complex nonlinear dynamics.\nUnderstanding these underlying dynamics is crucial for precise future\nprediction. While deep learning has achieved major success in time series\nforecasting, many existing approaches do not explicitly model the dynamics. To\nbridge this gap, we introduce DeepEDM, a framework that integrates nonlinear\ndynamical systems modeling with deep neural networks. Inspired by empirical\ndynamic modeling (EDM) and rooted in Takens' theorem, DeepEDM presents a novel\ndeep model that learns a latent space from time-delayed embeddings, and employs\nkernel regression to approximate the underlying dynamics, while leveraging\nefficient implementation of softmax attention and allowing for accurate\nprediction of future time steps. To evaluate our method, we conduct\ncomprehensive experiments on synthetic data of nonlinear dynamical systems as\nwell as real-world time series across domains. Our results show that DeepEDM is\nrobust to input noise, and outperforms state-of-the-art methods in forecasting\naccuracy. Our code is available at: https://abrarmajeedi.github.io/deep_edm.",
      "upvotes": 3,
      "discussionId": "6848ed6242e4f9106973f2bc",
      "projectPage": "https://abrarmajeedi.github.io/deep_edm/",
      "githubRepo": "https://github.com/abrarmajeedi/DeepEDM",
      "ai_summary": "DeepEDM integrates empirical dynamic modeling with deep neural networks to learn latent spaces and approximate complex nonlinear dynamics for improved time series forecasting.",
      "ai_keywords": [
        "nonlinear dynamical systems",
        "empirical dynamic modeling",
        "EDM",
        "Takens' theorem",
        "latent space",
        "time-delayed embeddings",
        "kernel regression",
        "softmax attention",
        "time series forecasting"
      ]
    },
    "publishedAt": "2025-06-06T14:24:12.000Z",
    "title": "LETS Forecast: Learning Embedology for Time Series Forecasting",
    "summary": "Real-world time series are often governed by complex nonlinear dynamics.\nUnderstanding these underlying dynamics is crucial for precise future\nprediction. While deep learning has achieved major success in time series\nforecasting, many existing approaches do not explicitly model the dynamics. To\nbridge this gap, we introduce DeepEDM, a framework that integrates nonlinear\ndynamical systems modeling with deep neural networks. Inspired by empirical\ndynamic modeling (EDM) and rooted in Takens' theorem, DeepEDM presents a novel\ndeep model that learns a latent space from time-delayed embeddings, and employs\nkernel regression to approximate the underlying dynamics, while leveraging\nefficient implementation of softmax attention and allowing for accurate\nprediction of future time steps. To evaluate our method, we conduct\ncomprehensive experiments on synthetic data of nonlinear dynamical systems as\nwell as real-world time series across domains. Our results show that DeepEDM is\nrobust to input noise, and outperforms state-of-the-art methods in forecasting\naccuracy. Our code is available at: https://abrarmajeedi.github.io/deep_edm.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/658708e06b17c068728f436a/CeZkFqf8ZE6bTIgIAyoFS.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.06454.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "658708e06b17c068728f436a",
      "avatarUrl": "/avatars/b51f36d1bce76c195350ff6e523bb036.svg",
      "fullname": "Viswa",
      "name": "viswa-98",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.06366",
      "authors": [
        {
          "_id": "684ae229dbd21a9cc27b1099",
          "name": "Lin Chen",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b109a",
          "name": "Yunke Zhang",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b109b",
          "user": {
            "_id": "6465d3bd63e7e09dd02e95c3",
            "avatarUrl": "/avatars/b2798bd5f8368f956bf7fab79d9432f0.svg",
            "isPro": false,
            "fullname": "Jie Feng",
            "user": "JJ-TMT",
            "type": "user"
          },
          "name": "Jie Feng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-15T07:03:58.220Z",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b109c",
          "name": "Haoye Chai",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b109d",
          "name": "Honglin Zhang",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b109e",
          "name": "Bingbing Fan",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b109f",
          "name": "Yibo Ma",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a0",
          "name": "Shiyuan Zhang",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a1",
          "name": "Nian Li",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a2",
          "name": "Tianhui Liu",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a3",
          "name": "Nicholas Sukiennik",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a4",
          "name": "Keyu Zhao",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a5",
          "name": "Yu Li",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a6",
          "name": "Ziyi Liu",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a7",
          "name": "Fengli Xu",
          "hidden": false
        },
        {
          "_id": "684ae229dbd21a9cc27b10a8",
          "name": "Yong Li",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6465d3bd63e7e09dd02e95c3/Q7lRl1w4-YqKvGsijYryV.jpeg"
      ],
      "publishedAt": "2025-06-04T08:12:32.000Z",
      "submittedOnDailyAt": "2025-06-17T02:23:25.961Z",
      "title": "AI Agent Behavioral Science",
      "submittedOnDailyBy": {
        "_id": "6465d3bd63e7e09dd02e95c3",
        "avatarUrl": "/avatars/b2798bd5f8368f956bf7fab79d9432f0.svg",
        "isPro": false,
        "fullname": "Jie Feng",
        "user": "JJ-TMT",
        "type": "user"
      },
      "summary": "Recent advances in large language models (LLMs) have enabled the development\nof AI agents that exhibit increasingly human-like behaviors, including\nplanning, adaptation, and social dynamics across diverse, interactive, and\nopen-ended scenarios. These behaviors are not solely the product of the\ninternal architectures of the underlying models, but emerge from their\nintegration into agentic systems operating within specific contexts, where\nenvironmental factors, social cues, and interaction feedbacks shape behavior\nover time. This evolution necessitates a new scientific perspective: AI Agent\nBehavioral Science. Rather than focusing only on internal mechanisms, this\nperspective emphasizes the systematic observation of behavior, design of\ninterventions to test hypotheses, and theory-guided interpretation of how AI\nagents act, adapt, and interact over time. We systematize a growing body of\nresearch across individual agent, multi-agent, and human-agent interaction\nsettings, and further demonstrate how this perspective informs responsible AI\nby treating fairness, safety, interpretability, accountability, and privacy as\nbehavioral properties. By unifying recent findings and laying out future\ndirections, we position AI Agent Behavioral Science as a necessary complement\nto traditional model-centric approaches, providing essential tools for\nunderstanding, evaluating, and governing the real-world behavior of\nincreasingly autonomous AI systems.",
      "upvotes": 3,
      "discussionId": "684ae229dbd21a9cc27b10a9",
      "ai_summary": "A new field, AI Agent Behavioral Science, is proposed to systematically study the behaviors of AI agents in diverse contexts, emphasizing external factors and their interactions, and addressing responsible AI aspects.",
      "ai_keywords": [
        "large language models",
        "AI agents",
        "planning",
        "adaptation",
        "social dynamics",
        "internal architectures",
        "agentic systems",
        "AI Agent Behavioral Science",
        "individual agent",
        "multi-agent",
        "human-agent interaction",
        "fairness",
        "safety",
        "interpretability",
        "accountability",
        "privacy"
      ]
    },
    "publishedAt": "2025-06-04T04:12:32.000Z",
    "title": "AI Agent Behavioral Science",
    "summary": "Recent advances in large language models (LLMs) have enabled the development\nof AI agents that exhibit increasingly human-like behaviors, including\nplanning, adaptation, and social dynamics across diverse, interactive, and\nopen-ended scenarios. These behaviors are not solely the product of the\ninternal architectures of the underlying models, but emerge from their\nintegration into agentic systems operating within specific contexts, where\nenvironmental factors, social cues, and interaction feedbacks shape behavior\nover time. This evolution necessitates a new scientific perspective: AI Agent\nBehavioral Science. Rather than focusing only on internal mechanisms, this\nperspective emphasizes the systematic observation of behavior, design of\ninterventions to test hypotheses, and theory-guided interpretation of how AI\nagents act, adapt, and interact over time. We systematize a growing body of\nresearch across individual agent, multi-agent, and human-agent interaction\nsettings, and further demonstrate how this perspective informs responsible AI\nby treating fairness, safety, interpretability, accountability, and privacy as\nbehavioral properties. By unifying recent findings and laying out future\ndirections, we position AI Agent Behavioral Science as a necessary complement\nto traditional model-centric approaches, providing essential tools for\nunderstanding, evaluating, and governing the real-world behavior of\nincreasingly autonomous AI systems.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6465d3bd63e7e09dd02e95c3/Q7lRl1w4-YqKvGsijYryV.jpeg"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.06366.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6465d3bd63e7e09dd02e95c3",
      "avatarUrl": "/avatars/b2798bd5f8368f956bf7fab79d9432f0.svg",
      "fullname": "Jie Feng",
      "name": "JJ-TMT",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.12189",
      "authors": [
        {
          "_id": "6850cb005e07650ecce88fc9",
          "user": {
            "_id": "64b89f096c57038f205a7751",
            "avatarUrl": "/avatars/c268578685cf5b9f0e37ffbdcf239827.svg",
            "isPro": false,
            "fullname": "Pranav Agarwal",
            "user": "pranavAL2109",
            "type": "user"
          },
          "name": "Pranav Agarwal",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-06-17T01:55:41.273Z",
          "hidden": false
        },
        {
          "_id": "6850cb005e07650ecce88fca",
          "name": "Ioana Ciuc",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T19:31:52.000Z",
      "submittedOnDailyAt": "2025-06-17T00:35:05.037Z",
      "title": "Supernova Event Dataset: Interpreting Large Language Model's Personality\n  through Critical Event Analysis",
      "submittedOnDailyBy": {
        "_id": "64b89f096c57038f205a7751",
        "avatarUrl": "/avatars/c268578685cf5b9f0e37ffbdcf239827.svg",
        "isPro": false,
        "fullname": "Pranav Agarwal",
        "user": "pranavAL2109",
        "type": "user"
      },
      "summary": "Large Language Models (LLMs) are increasingly integrated into everyday\napplications. As their influence grows, understanding their decision making and\nunderlying personality becomes essential. In this work, we interpret model\npersonality using our proposed Supernova Event Dataset, a novel dataset with\ndiverse articles spanning biographies, historical events, news, and scientific\ndiscoveries. We use this dataset to benchmark LLMs on extracting and ranking\nkey events from text, a subjective and complex challenge that requires\nreasoning over long-range context and modeling causal chains. We evaluate small\nmodels like Phi-4, Orca 2, and Qwen 2.5, and large, stronger models such as\nClaude 3.7, Gemini 2.5, and OpenAI o3, and propose a framework where another\nLLM acts as a judge to infer each model's personality based on its selection\nand classification of events. Our analysis shows distinct personality traits:\nfor instance, Orca 2 demonstrates emotional reasoning focusing on interpersonal\ndynamics, while Qwen 2.5 displays a more strategic, analytical style. When\nanalyzing scientific discovery events, Claude Sonnet 3.7 emphasizes conceptual\nframing, Gemini 2.5 Pro prioritizes empirical validation, and o3 favors\nstep-by-step causal reasoning. This analysis improves model interpretability,\nmaking them user-friendly for a wide range of diverse applications.",
      "upvotes": 2,
      "discussionId": "6850cb005e07650ecce88fcb",
      "projectPage": "https://supernova-event.ai/",
      "githubRepo": "https://github.com/pranavAL/Supernova-Event-Dataset",
      "ai_summary": "The study evaluates various LLMs on diverse text tasks using a new dataset, revealing distinct personality traits and improving model interpretability.",
      "ai_keywords": [
        "Supernova Event Dataset",
        "LLMs",
        "key event extraction",
        "reasoning",
        "long-range context",
        "causal chains",
        "model personality",
        "emotional reasoning",
        "strategic",
        "analytical style",
        "conceptual framing",
        "empirical validation",
        "step-by-step causal reasoning"
      ]
    },
    "publishedAt": "2025-06-13T15:31:52.000Z",
    "title": "Supernova Event Dataset: Interpreting Large Language Model's Personality\n  through Critical Event Analysis",
    "summary": "Large Language Models (LLMs) are increasingly integrated into everyday\napplications. As their influence grows, understanding their decision making and\nunderlying personality becomes essential. In this work, we interpret model\npersonality using our proposed Supernova Event Dataset, a novel dataset with\ndiverse articles spanning biographies, historical events, news, and scientific\ndiscoveries. We use this dataset to benchmark LLMs on extracting and ranking\nkey events from text, a subjective and complex challenge that requires\nreasoning over long-range context and modeling causal chains. We evaluate small\nmodels like Phi-4, Orca 2, and Qwen 2.5, and large, stronger models such as\nClaude 3.7, Gemini 2.5, and OpenAI o3, and propose a framework where another\nLLM acts as a judge to infer each model's personality based on its selection\nand classification of events. Our analysis shows distinct personality traits:\nfor instance, Orca 2 demonstrates emotional reasoning focusing on interpersonal\ndynamics, while Qwen 2.5 displays a more strategic, analytical style. When\nanalyzing scientific discovery events, Claude Sonnet 3.7 emphasizes conceptual\nframing, Gemini 2.5 Pro prioritizes empirical validation, and o3 favors\nstep-by-step causal reasoning. This analysis improves model interpretability,\nmaking them user-friendly for a wide range of diverse applications.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12189.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b89f096c57038f205a7751",
      "avatarUrl": "/avatars/c268578685cf5b9f0e37ffbdcf239827.svg",
      "fullname": "Pranav Agarwal",
      "name": "pranavAL2109",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.12953",
      "authors": [
        {
          "_id": "6850d2345e07650ecce89092",
          "name": "Mayank Bumb",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce89093",
          "name": "Anshul Vemulapalli",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce89094",
          "name": "Sri Harsha Vardhan Prasad Jella",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce89095",
          "name": "Anish Gupta",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce89096",
          "name": "An La",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce89097",
          "name": "Ryan A. Rossi",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce89098",
          "name": "Hongjie Chen",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce89099",
          "user": {
            "_id": "62c5947524171688a9feb992",
            "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
            "isPro": false,
            "fullname": "Franck Dernoncourt",
            "user": "Franck-Dernoncourt",
            "type": "user"
          },
          "name": "Franck Dernoncourt",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:22.624Z",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce8909a",
          "name": "Nesreen K. Ahmed",
          "hidden": false
        },
        {
          "_id": "6850d2345e07650ecce8909b",
          "name": "Yu Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-15T19:42:58.000Z",
      "submittedOnDailyAt": "2025-06-17T00:55:59.045Z",
      "title": "Forecasting Time Series with LLMs via Patch-Based Prompting and\n  Decomposition",
      "submittedOnDailyBy": {
        "_id": "62c5947524171688a9feb992",
        "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
        "isPro": false,
        "fullname": "Franck Dernoncourt",
        "user": "Franck-Dernoncourt",
        "type": "user"
      },
      "summary": "Recent advances in Large Language Models (LLMs) have demonstrated new\npossibilities for accurate and efficient time series analysis, but prior work\noften required heavy fine-tuning and/or ignored inter-series correlations. In\nthis work, we explore simple and flexible prompt-based strategies that enable\nLLMs to perform time series forecasting without extensive retraining or the use\nof a complex external architecture. Through the exploration of specialized\nprompting methods that leverage time series decomposition, patch-based\ntokenization, and similarity-based neighbor augmentation, we find that it is\npossible to enhance LLM forecasting quality while maintaining simplicity and\nrequiring minimal preprocessing of data. To this end, we propose our own\nmethod, PatchInstruct, which enables LLMs to make precise and effective\npredictions.",
      "upvotes": 1,
      "discussionId": "6850d2355e07650ecce8909c",
      "ai_summary": "PatchInstruct enhances LLM forecasting quality through specialized prompting methods that include time series decomposition, patch-based tokenization, and similarity-based neighbor augmentation.",
      "ai_keywords": [
        "Large Language Models",
        "LLMs",
        "time series forecasting",
        "prompt-based strategies",
        "time series decomposition",
        "patch-based tokenization",
        "similarity-based neighbor augmentation",
        "PatchInstruct"
      ]
    },
    "publishedAt": "2025-06-15T15:42:58.000Z",
    "title": "Forecasting Time Series with LLMs via Patch-Based Prompting and\n  Decomposition",
    "summary": "Recent advances in Large Language Models (LLMs) have demonstrated new\npossibilities for accurate and efficient time series analysis, but prior work\noften required heavy fine-tuning and/or ignored inter-series correlations. In\nthis work, we explore simple and flexible prompt-based strategies that enable\nLLMs to perform time series forecasting without extensive retraining or the use\nof a complex external architecture. Through the exploration of specialized\nprompting methods that leverage time series decomposition, patch-based\ntokenization, and similarity-based neighbor augmentation, we find that it is\npossible to enhance LLM forecasting quality while maintaining simplicity and\nrequiring minimal preprocessing of data. To this end, we propose our own\nmethod, PatchInstruct, which enables LLMs to make precise and effective\npredictions.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12953.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62c5947524171688a9feb992",
      "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
      "fullname": "Franck Dernoncourt",
      "name": "Franck-Dernoncourt",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.12623",
      "authors": [
        {
          "_id": "6850d25d5e07650ecce8909e",
          "name": "Yuan Zang",
          "hidden": false
        },
        {
          "_id": "6850d25d5e07650ecce8909f",
          "name": "Hao Tan",
          "hidden": false
        },
        {
          "_id": "6850d25d5e07650ecce890a0",
          "name": "Seunghyun Yoon",
          "hidden": false
        },
        {
          "_id": "6850d25d5e07650ecce890a1",
          "user": {
            "_id": "62c5947524171688a9feb992",
            "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
            "isPro": false,
            "fullname": "Franck Dernoncourt",
            "user": "Franck-Dernoncourt",
            "type": "user"
          },
          "name": "Franck Dernoncourt",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:21:15.407Z",
          "hidden": false
        },
        {
          "_id": "6850d25d5e07650ecce890a2",
          "name": "Jiuxiang Gu",
          "hidden": false
        },
        {
          "_id": "6850d25d5e07650ecce890a3",
          "name": "Kushal Kafle",
          "hidden": false
        },
        {
          "_id": "6850d25d5e07650ecce890a4",
          "name": "Chen Sun",
          "hidden": false
        },
        {
          "_id": "6850d25d5e07650ecce890a5",
          "name": "Trung Bui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-14T20:39:32.000Z",
      "submittedOnDailyAt": "2025-06-17T00:56:38.375Z",
      "title": "MS4UI: A Dataset for Multi-modal Summarization of User Interface\n  Instructional Videos",
      "submittedOnDailyBy": {
        "_id": "62c5947524171688a9feb992",
        "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
        "isPro": false,
        "fullname": "Franck Dernoncourt",
        "user": "Franck-Dernoncourt",
        "type": "user"
      },
      "summary": "We study multi-modal summarization for instructional videos, whose goal is to\nprovide users an efficient way to learn skills in the form of text instructions\nand key video frames. We observe that existing benchmarks focus on generic\nsemantic-level video summarization, and are not suitable for providing\nstep-by-step executable instructions and illustrations, both of which are\ncrucial for instructional videos. We propose a novel benchmark for user\ninterface (UI) instructional video summarization to fill the gap. We collect a\ndataset of 2,413 UI instructional videos, which spans over 167 hours. These\nvideos are manually annotated for video segmentation, text summarization, and\nvideo summarization, which enable the comprehensive evaluations for concise and\nexecutable video summarization. We conduct extensive experiments on our\ncollected MS4UI dataset, which suggest that state-of-the-art multi-modal\nsummarization methods struggle on UI video summarization, and highlight the\nimportance of new methods for UI instructional video summarization.",
      "upvotes": 1,
      "discussionId": "6850d25d5e07650ecce890a6",
      "ai_summary": "A novel benchmark and dataset are proposed for multi-modal summarization of UI instructional videos, addressing the need for step-by-step executable instructions and key video frames.",
      "ai_keywords": [
        "multi-modal summarization",
        "instructional videos",
        "video segmentation",
        "text summarization",
        "video summarization",
        "MS4UI dataset"
      ]
    },
    "publishedAt": "2025-06-14T16:39:32.000Z",
    "title": "MS4UI: A Dataset for Multi-modal Summarization of User Interface\n  Instructional Videos",
    "summary": "We study multi-modal summarization for instructional videos, whose goal is to\nprovide users an efficient way to learn skills in the form of text instructions\nand key video frames. We observe that existing benchmarks focus on generic\nsemantic-level video summarization, and are not suitable for providing\nstep-by-step executable instructions and illustrations, both of which are\ncrucial for instructional videos. We propose a novel benchmark for user\ninterface (UI) instructional video summarization to fill the gap. We collect a\ndataset of 2,413 UI instructional videos, which spans over 167 hours. These\nvideos are manually annotated for video segmentation, text summarization, and\nvideo summarization, which enable the comprehensive evaluations for concise and\nexecutable video summarization. We conduct extensive experiments on our\ncollected MS4UI dataset, which suggest that state-of-the-art multi-modal\nsummarization methods struggle on UI video summarization, and highlight the\nimportance of new methods for UI instructional video summarization.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12623.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62c5947524171688a9feb992",
      "avatarUrl": "/avatars/5a151713b9eae8dc566f5957acee3475.svg",
      "fullname": "Franck Dernoncourt",
      "name": "Franck-Dernoncourt",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 10
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.09968",
      "authors": [
        {
          "_id": "68504ea12932e11c891b5871",
          "user": {
            "_id": "6465995994327a238f5a4f03",
            "avatarUrl": "/avatars/e8e29603977b8ac2ddf62b20bd97a8f2.svg",
            "isPro": false,
            "fullname": "Ge Wentao",
            "user": "Owenngt",
            "type": "user"
          },
          "name": "Wentao Ge",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:22:12.913Z",
          "hidden": false
        },
        {
          "_id": "68504ea12932e11c891b5872",
          "name": "Yuqing Sun",
          "hidden": false
        },
        {
          "_id": "68504ea12932e11c891b5873",
          "name": "Ziyan Wang",
          "hidden": false
        },
        {
          "_id": "68504ea12932e11c891b5874",
          "name": "Haoyue Zheng",
          "hidden": false
        },
        {
          "_id": "68504ea12932e11c891b5875",
          "name": "Weiyang He",
          "hidden": false
        },
        {
          "_id": "68504ea12932e11c891b5876",
          "name": "Piaohong Wang",
          "hidden": false
        },
        {
          "_id": "68504ea12932e11c891b5877",
          "name": "Qianyu Zhu",
          "hidden": false
        },
        {
          "_id": "68504ea12932e11c891b5878",
          "name": "Benyou Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-11T17:45:03.000Z",
      "submittedOnDailyAt": "2025-06-17T05:54:34.208Z",
      "title": "SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification\n  and LLM Assistance",
      "submittedOnDailyBy": {
        "_id": "6465995994327a238f5a4f03",
        "avatarUrl": "/avatars/e8e29603977b8ac2ddf62b20bd97a8f2.svg",
        "isPro": false,
        "fullname": "Ge Wentao",
        "user": "Owenngt",
        "type": "user"
      },
      "summary": "Self-regulated learning (SRL) is crucial for college students navigating\nincreased academic demands and independence. Insufficient SRL skills can lead\nto disorganized study habits, low motivation, and poor time management,\nundermining learners ability to thrive in challenging environments. Through a\nformative study involving 59 college students, we identified key challenges\nstudents face in developing SRL skills, including difficulties with\ngoal-setting, time management, and reflective learning. To address these\nchallenges, we introduce SRLAgent, an LLM-assisted system that fosters SRL\nskills through gamification and adaptive support from large language models\n(LLMs). Grounded in Zimmermans three-phase SRL framework, SRLAgent enables\nstudents to engage in goal-setting, strategy execution, and self-reflection\nwithin an interactive game-based environment. The system offers real-time\nfeedback and scaffolding powered by LLMs to support students independent study\nefforts. We evaluated SRLAgent using a between-subjects design, comparing it to\na baseline system (SRL without Agent features) and a traditional multimedia\nlearning condition. Results showed significant improvements in SRL skills\nwithin the SRLAgent group (p < .001, Cohens d = 0.234) and higher engagement\ncompared to the baselines. This work highlights the value of embedding SRL\nscaffolding and real-time AI support within gamified environments, offering\ndesign implications for educational technologies that aim to promote deeper\nlearning and metacognitive skill development.",
      "upvotes": 1,
      "discussionId": "68504ea12932e11c891b5879",
      "ai_summary": "A gamified LLM-assisted system, SRLAgent, significantly improves self-regulated learning skills in college students through interactive, goal-setting, and real-time AI feedback.",
      "ai_keywords": [
        "LLM-assisted system",
        "gamification",
        "adaptive support",
        "large language models",
        "SRL (Self-regulated learning)",
        "Zimmermans three-phase SRL framework",
        "goal-setting",
        "strategy execution",
        "self-reflection",
        "between-subjects design",
        "baseline system",
        "traditional multimedia learning condition"
      ]
    },
    "publishedAt": "2025-06-11T13:45:03.000Z",
    "title": "SRLAgent: Enhancing Self-Regulated Learning Skills through Gamification\n  and LLM Assistance",
    "summary": "Self-regulated learning (SRL) is crucial for college students navigating\nincreased academic demands and independence. Insufficient SRL skills can lead\nto disorganized study habits, low motivation, and poor time management,\nundermining learners ability to thrive in challenging environments. Through a\nformative study involving 59 college students, we identified key challenges\nstudents face in developing SRL skills, including difficulties with\ngoal-setting, time management, and reflective learning. To address these\nchallenges, we introduce SRLAgent, an LLM-assisted system that fosters SRL\nskills through gamification and adaptive support from large language models\n(LLMs). Grounded in Zimmermans three-phase SRL framework, SRLAgent enables\nstudents to engage in goal-setting, strategy execution, and self-reflection\nwithin an interactive game-based environment. The system offers real-time\nfeedback and scaffolding powered by LLMs to support students independent study\nefforts. We evaluated SRLAgent using a between-subjects design, comparing it to\na baseline system (SRL without Agent features) and a traditional multimedia\nlearning condition. Results showed significant improvements in SRL skills\nwithin the SRLAgent group (p < .001, Cohens d = 0.234) and higher engagement\ncompared to the baselines. This work highlights the value of embedding SRL\nscaffolding and real-time AI support within gamified environments, offering\ndesign implications for educational technologies that aim to promote deeper\nlearning and metacognitive skill development.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09968.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6465995994327a238f5a4f03",
      "avatarUrl": "/avatars/e8e29603977b8ac2ddf62b20bd97a8f2.svg",
      "fullname": "Ge Wentao",
      "name": "Owenngt",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.11115",
      "authors": [
        {
          "_id": "685107725e07650ecce891d6",
          "user": {
            "_id": "65e746079cf349af294e1f10",
            "avatarUrl": "/avatars/0a3f13e03b1f9249595b387001203908.svg",
            "isPro": false,
            "fullname": "yerim Oh",
            "user": "yerim0210",
            "type": "user"
          },
          "name": "Yerim Oh",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:20:35.446Z",
          "hidden": false
        },
        {
          "_id": "685107725e07650ecce891d7",
          "name": "Jun-Hyung Park",
          "hidden": false
        },
        {
          "_id": "685107725e07650ecce891d8",
          "name": "Junho Kim",
          "hidden": false
        },
        {
          "_id": "685107725e07650ecce891d9",
          "name": "SungHo Kim",
          "hidden": false
        },
        {
          "_id": "685107725e07650ecce891da",
          "name": "SangKeun Lee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-09T04:59:13.000Z",
      "submittedOnDailyAt": "2025-06-17T05:52:24.545Z",
      "title": "Incorporating Domain Knowledge into Materials Tokenization",
      "submittedOnDailyBy": {
        "_id": "65e746079cf349af294e1f10",
        "avatarUrl": "/avatars/0a3f13e03b1f9249595b387001203908.svg",
        "isPro": false,
        "fullname": "yerim Oh",
        "user": "yerim0210",
        "type": "user"
      },
      "summary": "While language models are increasingly utilized in materials science, typical\nmodels rely on frequency-centric tokenization methods originally developed for\nnatural language processing. However, these methods frequently produce\nexcessive fragmentation and semantic loss, failing to maintain the structural\nand semantic integrity of material concepts. To address this issue, we propose\nMATTER, a novel tokenization approach that integrates material knowledge into\ntokenization. Based on MatDetector trained on our materials knowledge base and\na re-ranking method prioritizing material concepts in token merging, MATTER\nmaintains the structural integrity of identified material concepts and prevents\nfragmentation during tokenization, ensuring their semantic meaning remains\nintact. The experimental results demonstrate that MATTER outperforms existing\ntokenization methods, achieving an average performance gain of 4% and 2%\nin the generation and classification tasks, respectively. These results\nunderscore the importance of domain knowledge for tokenization strategies in\nscientific text processing. Our code is available at\nhttps://github.com/yerimoh/MATTER",
      "upvotes": 1,
      "discussionId": "685107735e07650ecce891db",
      "ai_summary": "MATTER, a novel tokenization approach incorporating material knowledge, improves performance in scientific text processing tasks by maintaining structural and semantic material integrity.",
      "ai_keywords": [
        "MATTER",
        "MatDetector",
        "tokenization",
        "material knowledge",
        "token merging",
        "semantic integrity",
        "generation tasks",
        "classification tasks"
      ]
    },
    "publishedAt": "2025-06-09T00:59:13.000Z",
    "title": "Incorporating Domain Knowledge into Materials Tokenization",
    "summary": "While language models are increasingly utilized in materials science, typical\nmodels rely on frequency-centric tokenization methods originally developed for\nnatural language processing. However, these methods frequently produce\nexcessive fragmentation and semantic loss, failing to maintain the structural\nand semantic integrity of material concepts. To address this issue, we propose\nMATTER, a novel tokenization approach that integrates material knowledge into\ntokenization. Based on MatDetector trained on our materials knowledge base and\na re-ranking method prioritizing material concepts in token merging, MATTER\nmaintains the structural integrity of identified material concepts and prevents\nfragmentation during tokenization, ensuring their semantic meaning remains\nintact. The experimental results demonstrate that MATTER outperforms existing\ntokenization methods, achieving an average performance gain of 4% and 2%\nin the generation and classification tasks, respectively. These results\nunderscore the importance of domain knowledge for tokenization strategies in\nscientific text processing. Our code is available at\nhttps://github.com/yerimoh/MATTER",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11115.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65e746079cf349af294e1f10",
      "avatarUrl": "/avatars/0a3f13e03b1f9249595b387001203908.svg",
      "fullname": "yerim Oh",
      "name": "yerim0210",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.13752",
      "authors": [
        {
          "_id": "6850e1645e07650ecce890fa",
          "name": "Junyan Li",
          "hidden": false
        },
        {
          "_id": "6850e1645e07650ecce890fb",
          "name": "Wenshuo Zhao",
          "hidden": false
        },
        {
          "_id": "6850e1645e07650ecce890fc",
          "name": "Yang Zhang",
          "hidden": false
        },
        {
          "_id": "6850e1645e07650ecce890fd",
          "name": "Chuang Gan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T17:57:05.000Z",
      "submittedOnDailyAt": "2025-06-17T02:01:57.062Z",
      "title": "Steering LLM Thinking with Budget Guidance",
      "submittedOnDailyBy": {
        "_id": "62d09eb86a61a88ea0d83918",
        "avatarUrl": "/avatars/81b511d94cced304ffca058caff662d4.svg",
        "isPro": false,
        "fullname": "Junyan Li",
        "user": "senfu",
        "type": "user"
      },
      "summary": "Recent deep-thinking large language models often reason extensively to\nimprove performance, but such lengthy reasoning is not always desirable, as it\nincurs excessive inference costs with disproportionate performance gains.\nControlling reasoning length without sacrificing performance is therefore\nimportant, but remains challenging, especially under tight thinking budgets. We\npropose budget guidance, a simple yet effective method for steering the\nreasoning process of LLMs toward a target budget without requiring any LLM\nfine-tuning. Our approach introduces a lightweight predictor that models a\nGamma distribution over the remaining thinking length during next-token\ngeneration. This signal is then used to guide generation in a soft, token-level\nmanner, ensuring that the overall reasoning trace adheres to the specified\nthinking budget. Budget guidance enables natural control of the thinking\nlength, along with significant token efficiency improvements over baseline\nmethods on challenging math benchmarks. For instance, it achieves up to a 26%\naccuracy gain on the MATH-500 benchmark under tight budgets compared to\nbaseline methods, while maintaining competitive accuracy with only 63% of the\nthinking tokens used by the full-thinking model. Budget guidance also\ngeneralizes to broader task domains and exhibits emergent capabilities, such as\nestimating question difficulty. The source code is available at:\nhttps://github.com/UMass-Embodied-AGI/BudgetGuidance.",
      "upvotes": 0,
      "discussionId": "6850e1655e07650ecce890fe",
      "ai_summary": "Budget guidance is a method that steers LLM reasoning within a targeted budget without fine-tuning and achieves improved efficiency and performance on math benchmarks.",
      "ai_keywords": [
        "deep-thinking large language models",
        "next-token generation",
        "Gamma distribution",
        "budget guidance",
        "thinking budget",
        "token efficiency",
        "natural control",
        "question difficulty estimation"
      ]
    },
    "publishedAt": "2025-06-16T13:57:05.000Z",
    "title": "Steering LLM Thinking with Budget Guidance",
    "summary": "Recent deep-thinking large language models often reason extensively to\nimprove performance, but such lengthy reasoning is not always desirable, as it\nincurs excessive inference costs with disproportionate performance gains.\nControlling reasoning length without sacrificing performance is therefore\nimportant, but remains challenging, especially under tight thinking budgets. We\npropose budget guidance, a simple yet effective method for steering the\nreasoning process of LLMs toward a target budget without requiring any LLM\nfine-tuning. Our approach introduces a lightweight predictor that models a\nGamma distribution over the remaining thinking length during next-token\ngeneration. This signal is then used to guide generation in a soft, token-level\nmanner, ensuring that the overall reasoning trace adheres to the specified\nthinking budget. Budget guidance enables natural control of the thinking\nlength, along with significant token efficiency improvements over baseline\nmethods on challenging math benchmarks. For instance, it achieves up to a 26%\naccuracy gain on the MATH-500 benchmark under tight budgets compared to\nbaseline methods, while maintaining competitive accuracy with only 63% of the\nthinking tokens used by the full-thinking model. Budget guidance also\ngeneralizes to broader task domains and exhibits emergent capabilities, such as\nestimating question difficulty. The source code is available at:\nhttps://github.com/UMass-Embodied-AGI/BudgetGuidance.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13752.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62d09eb86a61a88ea0d83918",
      "avatarUrl": "/avatars/81b511d94cced304ffca058caff662d4.svg",
      "fullname": "Junyan Li",
      "name": "senfu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.13172",
      "authors": [
        {
          "_id": "6850fc485e07650ecce8918b",
          "user": {
            "_id": "68264aa0e6a0ae8670403081",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/68264aa0e6a0ae8670403081/a6V9yE1cf6-lFf7G8Ih-H.png",
            "isPro": false,
            "fullname": "Evgeny Markhasin",
            "user": "PChemGuy",
            "type": "user"
          },
          "name": "Evgeny Markhasin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-17T07:20:37.574Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-16T07:34:31.000Z",
      "submittedOnDailyAt": "2025-06-17T04:00:54.011Z",
      "title": "Ai-Facilitated Analysis of Abstracts and Conclusions: Flagging\n  Unsubstantiated Claims and Ambiguous Pronouns",
      "submittedOnDailyBy": {
        "_id": "68264aa0e6a0ae8670403081",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/68264aa0e6a0ae8670403081/a6V9yE1cf6-lFf7G8Ih-H.png",
        "isPro": false,
        "fullname": "Evgeny Markhasin",
        "user": "PChemGuy",
        "type": "user"
      },
      "summary": "We present and evaluate a suite of proof-of-concept (PoC), structured\nworkflow prompts designed to elicit human-like hierarchical reasoning while\nguiding Large Language Models (LLMs) in high-level semantic and linguistic\nanalysis of scholarly manuscripts. The prompts target two non-trivial\nanalytical tasks: identifying unsubstantiated claims in summaries\n(informational integrity) and flagging ambiguous pronoun references (linguistic\nclarity). We conducted a systematic, multi-run evaluation on two frontier\nmodels (Gemini Pro 2.5 Pro and ChatGPT Plus o3) under varied context\nconditions. Our results for the informational integrity task reveal a\nsignificant divergence in model performance: while both models successfully\nidentified an unsubstantiated head of a noun phrase (95% success), ChatGPT\nconsistently failed (0% success) to identify an unsubstantiated adjectival\nmodifier that Gemini correctly flagged (95% success), raising a question\nregarding potential influence of the target's syntactic role. For the\nlinguistic analysis task, both models performed well (80-90% success) with full\nmanuscript context. In a summary-only setting, however, ChatGPT achieved a\nperfect (100%) success rate, while Gemini's performance was substantially\ndegraded. Our findings suggest that structured prompting is a viable\nmethodology for complex textual analysis but show that prompt performance may\nbe highly dependent on the interplay between the model, task type, and context,\nhighlighting the need for rigorous, model-specific testing.",
      "upvotes": 0,
      "discussionId": "6850fc495e07650ecce8918c",
      "ai_summary": "Structured workflow prompts improve hierarchical reasoning in LLMs for scholarly manuscript analysis, but their effectiveness varies with the model, task type, and context.",
      "ai_keywords": [
        "Large Language Models",
        "LLMs",
        "Gemini Pro 2.5 Pro",
        "ChatGPT Plus o3",
        "unsubstantiated claims",
        "informational integrity",
        "ambiguous pronoun references",
        "linguistic clarity",
        "hierarchical reasoning",
        "textual analysis"
      ]
    },
    "publishedAt": "2025-06-16T03:34:31.000Z",
    "title": "Ai-Facilitated Analysis of Abstracts and Conclusions: Flagging\n  Unsubstantiated Claims and Ambiguous Pronouns",
    "summary": "We present and evaluate a suite of proof-of-concept (PoC), structured\nworkflow prompts designed to elicit human-like hierarchical reasoning while\nguiding Large Language Models (LLMs) in high-level semantic and linguistic\nanalysis of scholarly manuscripts. The prompts target two non-trivial\nanalytical tasks: identifying unsubstantiated claims in summaries\n(informational integrity) and flagging ambiguous pronoun references (linguistic\nclarity). We conducted a systematic, multi-run evaluation on two frontier\nmodels (Gemini Pro 2.5 Pro and ChatGPT Plus o3) under varied context\nconditions. Our results for the informational integrity task reveal a\nsignificant divergence in model performance: while both models successfully\nidentified an unsubstantiated head of a noun phrase (95% success), ChatGPT\nconsistently failed (0% success) to identify an unsubstantiated adjectival\nmodifier that Gemini correctly flagged (95% success), raising a question\nregarding potential influence of the target's syntactic role. For the\nlinguistic analysis task, both models performed well (80-90% success) with full\nmanuscript context. In a summary-only setting, however, ChatGPT achieved a\nperfect (100%) success rate, while Gemini's performance was substantially\ndegraded. Our findings suggest that structured prompting is a viable\nmethodology for complex textual analysis but show that prompt performance may\nbe highly dependent on the interplay between the model, task type, and context,\nhighlighting the need for rigorous, model-specific testing.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.13172.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "68264aa0e6a0ae8670403081",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/68264aa0e6a0ae8670403081/a6V9yE1cf6-lFf7G8Ih-H.png",
      "fullname": "Evgeny Markhasin",
      "name": "PChemGuy",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.12299",
      "authors": [
        {
          "_id": "6850e32c5e07650ecce89112",
          "name": "Taegyeong Lee",
          "hidden": false
        },
        {
          "_id": "6850e32c5e07650ecce89113",
          "name": "Jeonghwa Yoo",
          "hidden": false
        },
        {
          "_id": "6850e32c5e07650ecce89114",
          "name": "Hyoungseo Cho",
          "hidden": false
        },
        {
          "_id": "6850e32c5e07650ecce89115",
          "name": "Soo Yong Kim",
          "hidden": false
        },
        {
          "_id": "6850e32c5e07650ecce89116",
          "name": "Yunho Maeng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-14T01:23:50.000Z",
      "submittedOnDailyAt": "2025-06-17T05:43:52.729Z",
      "title": "QGuard:Question-based Zero-shot Guard for Multi-modal LLM Safety",
      "submittedOnDailyBy": {
        "_id": "65019c5420cfd12a88a74078",
        "avatarUrl": "/avatars/fdcfe7be656e9c5aa7236e3b076c7897.svg",
        "isPro": false,
        "fullname": "Taegyeong Lee",
        "user": "Taegyeonglee",
        "type": "user"
      },
      "summary": "The recent advancements in Large Language Models(LLMs) have had a significant\nimpact on a wide range of fields, from general domains to specialized areas.\nHowever, these advancements have also significantly increased the potential for\nmalicious users to exploit harmful and jailbreak prompts for malicious attacks.\nAlthough there have been many efforts to prevent harmful prompts and jailbreak\nprompts, protecting LLMs from such malicious attacks remains an important and\nchallenging task. In this paper, we propose QGuard, a simple yet effective\nsafety guard method, that utilizes question prompting to block harmful prompts\nin a zero-shot manner. Our method can defend LLMs not only from text-based\nharmful prompts but also from multi-modal harmful prompt attacks. Moreover, by\ndiversifying and modifying guard questions, our approach remains robust against\nthe latest harmful prompts without fine-tuning. Experimental results show that\nour model performs competitively on both text-only and multi-modal harmful\ndatasets. Additionally, by providing an analysis of question prompting, we\nenable a white-box analysis of user inputs. We believe our method provides\nvaluable insights for real-world LLM services in mitigating security risks\nassociated with harmful prompts.",
      "upvotes": 0,
      "discussionId": "6850e32c5e07650ecce89117",
      "ai_summary": "QGuard, a safety guard method using question prompting, effectively defends LLMs against harmful and multi-modal malicious prompts without fine-tuning.",
      "ai_keywords": [
        "Large Language Models",
        "LLMs",
        "harmful prompts",
        "jailbreak prompts",
        "safety guard",
        "question prompting",
        "multi-modal harmful prompts"
      ]
    },
    "publishedAt": "2025-06-13T21:23:50.000Z",
    "title": "QGuard:Question-based Zero-shot Guard for Multi-modal LLM Safety",
    "summary": "The recent advancements in Large Language Models(LLMs) have had a significant\nimpact on a wide range of fields, from general domains to specialized areas.\nHowever, these advancements have also significantly increased the potential for\nmalicious users to exploit harmful and jailbreak prompts for malicious attacks.\nAlthough there have been many efforts to prevent harmful prompts and jailbreak\nprompts, protecting LLMs from such malicious attacks remains an important and\nchallenging task. In this paper, we propose QGuard, a simple yet effective\nsafety guard method, that utilizes question prompting to block harmful prompts\nin a zero-shot manner. Our method can defend LLMs not only from text-based\nharmful prompts but also from multi-modal harmful prompt attacks. Moreover, by\ndiversifying and modifying guard questions, our approach remains robust against\nthe latest harmful prompts without fine-tuning. Experimental results show that\nour model performs competitively on both text-only and multi-modal harmful\ndatasets. Additionally, by providing an analysis of question prompting, we\nenable a white-box analysis of user inputs. We believe our method provides\nvaluable insights for real-world LLM services in mitigating security risks\nassociated with harmful prompts.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.12299.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65019c5420cfd12a88a74078",
      "avatarUrl": "/avatars/fdcfe7be656e9c5aa7236e3b076c7897.svg",
      "fullname": "Taegyeong Lee",
      "name": "Taegyeonglee",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  }
]