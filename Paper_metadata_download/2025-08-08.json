[
  {
    "paper": {
      "id": "2508.05629",
      "authors": [
        {
          "_id": "6895566648b0ae5ca2710d05",
          "name": "Yongliang Wu",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d06",
          "name": "Yizhou Zhou",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d07",
          "name": "Zhou Ziheng",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d08",
          "name": "Yingzhe Peng",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d09",
          "name": "Xinyu Ye",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d0a",
          "name": "Xinting Hu",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d0b",
          "name": "Wenbo Zhu",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d0c",
          "name": "Lu Qi",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d0d",
          "name": "Ming-Hsuan Yang",
          "hidden": false
        },
        {
          "_id": "6895566648b0ae5ca2710d0e",
          "name": "Xu Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-07T17:59:04.000Z",
      "submittedOnDailyAt": "2025-08-08T00:15:11.093Z",
      "title": "On the Generalization of SFT: A Reinforcement Learning Perspective with\n  Reward Rectification",
      "submittedOnDailyBy": {
        "_id": "66f6bc97980d52c75c300511",
        "avatarUrl": "/avatars/f7c23c4b09701580b533212ec9b6e306.svg",
        "isPro": false,
        "fullname": "Yongliang Wu",
        "user": "Liang0223",
        "type": "user"
      },
      "summary": "We present a simple yet theoretically motivated improvement to Supervised\nFine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited\ngeneralization compared to reinforcement learning (RL). Through mathematical\nanalysis, we reveal that standard SFT gradients implicitly encode a problematic\nreward structure that may severely restrict the generalization capabilities of\nmodel. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing\ngradient updates for each token by dynamically rescaling the objective function\nwith the probability of this token. Remarkably, this single-line code change\nsignificantly outperforms standard SFT across multiple challenging benchmarks\nand base models, demonstrating greatly improved generalization. Additionally,\nour approach shows competitive results in offline RL settings, offering an\neffective yet simpler alternative. This work bridges theoretical insight and\npractical solutions, substantially advancing SFT performance. The code will be\navailable at https://github.com/yongliang-wu/DFT.",
      "upvotes": 44,
      "discussionId": "6895566648b0ae5ca2710d0f",
      "ai_summary": "Dynamic Fine-Tuning (DFT) improves the generalization of Large Language Models (LLMs) by dynamically rescaling gradients, outperforming standard Supervised Fine-Tuning (SFT) and showing competitive results in offline reinforcement learning.",
      "ai_keywords": [
        "Supervised Fine-Tuning",
        "Large Language Model",
        "reinforcement learning",
        "gradient updates",
        "token probability",
        "Dynamic Fine-Tuning",
        "offline RL"
      ]
    },
    "publishedAt": "2025-08-07T13:59:04.000Z",
    "title": "On the Generalization of SFT: A Reinforcement Learning Perspective with\n  Reward Rectification",
    "summary": "We present a simple yet theoretically motivated improvement to Supervised\nFine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited\ngeneralization compared to reinforcement learning (RL). Through mathematical\nanalysis, we reveal that standard SFT gradients implicitly encode a problematic\nreward structure that may severely restrict the generalization capabilities of\nmodel. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing\ngradient updates for each token by dynamically rescaling the objective function\nwith the probability of this token. Remarkably, this single-line code change\nsignificantly outperforms standard SFT across multiple challenging benchmarks\nand base models, demonstrating greatly improved generalization. Additionally,\nour approach shows competitive results in offline RL settings, offering an\neffective yet simpler alternative. This work bridges theoretical insight and\npractical solutions, substantially advancing SFT performance. The code will be\navailable at https://github.com/yongliang-wu/DFT.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.05629.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "66f6bc97980d52c75c300511",
      "avatarUrl": "/avatars/f7c23c4b09701580b533212ec9b6e306.svg",
      "fullname": "Yongliang Wu",
      "name": "Liang0223",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.05004",
      "authors": [
        {
          "_id": "68955cff48b0ae5ca2710d2b",
          "name": "Chengsong Huang",
          "hidden": false
        },
        {
          "_id": "68955cff48b0ae5ca2710d2c",
          "name": "Wenhao Yu",
          "hidden": false
        },
        {
          "_id": "68955cff48b0ae5ca2710d2d",
          "name": "Xiaoyang Wang",
          "hidden": false
        },
        {
          "_id": "68955cff48b0ae5ca2710d2e",
          "name": "Hongming Zhang",
          "hidden": false
        },
        {
          "_id": "68955cff48b0ae5ca2710d2f",
          "name": "Zongxia Li",
          "hidden": false
        },
        {
          "_id": "68955cff48b0ae5ca2710d30",
          "name": "Ruosen Li",
          "hidden": false
        },
        {
          "_id": "68955cff48b0ae5ca2710d31",
          "name": "Jiaxin Huang",
          "hidden": false
        },
        {
          "_id": "68955cff48b0ae5ca2710d32",
          "name": "Haitao Mi",
          "hidden": false
        },
        {
          "_id": "68955cff48b0ae5ca2710d33",
          "name": "Dong Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-07T03:38:16.000Z",
      "submittedOnDailyAt": "2025-08-08T00:42:59.915Z",
      "title": "R-Zero: Self-Evolving Reasoning LLM from Zero Data",
      "submittedOnDailyBy": {
        "_id": "62ea79dd01ed9b0e8f61ccd3",
        "avatarUrl": "/avatars/70af83e0e267be39fcd5f23b85e2dafa.svg",
        "isPro": false,
        "fullname": "Chengsong Huang",
        "user": "ChengsongHuang",
        "type": "user"
      },
      "summary": "Self-evolving Large Language Models (LLMs) offer a scalable path toward\nsuper-intelligence by autonomously generating, refining, and learning from\ntheir own experiences. However, existing methods for training such models still\nrely heavily on vast human-curated tasks and labels, typically via fine-tuning\nor reinforcement learning, which poses a fundamental bottleneck to advancing AI\nsystems toward capabilities beyond human intelligence. To overcome this\nlimitation, we introduce R-Zero, a fully autonomous framework that generates\nits own training data from scratch. Starting from a single base LLM, R-Zero\ninitializes two independent models with distinct roles, a Challenger and a\nSolver. These models are optimized separately and co-evolve through\ninteraction: the Challenger is rewarded for proposing tasks near the edge of\nthe Solver capability, and the Solver is rewarded for solving increasingly\nchallenging tasks posed by the Challenger. This process yields a targeted,\nself-improving curriculum without any pre-existing tasks and labels.\nEmpirically, R-Zero substantially improves reasoning capability across\ndifferent backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on\nmath-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.",
      "upvotes": 43,
      "discussionId": "68955cff48b0ae5ca2710d34",
      "projectPage": "https://chengsong-huang.github.io/R-Zero.github.io/",
      "githubRepo": "https://github.com/Chengsong-Huang/R-Zero",
      "ai_summary": "R-Zero is a self-evolving framework that autonomously generates and learns from its own training data, improving reasoning capabilities in LLMs without human-curated tasks.",
      "ai_keywords": [
        "Self-evolving Large Language Models",
        "LLMs",
        "R-Zero",
        "Challenger",
        "Solver",
        "co-evolve",
        "math-reasoning benchmarks",
        "general-domain reasoning benchmarks"
      ],
      "githubStars": 18
    },
    "publishedAt": "2025-08-06T23:38:16.000Z",
    "title": "R-Zero: Self-Evolving Reasoning LLM from Zero Data",
    "summary": "Self-evolving Large Language Models (LLMs) offer a scalable path toward\nsuper-intelligence by autonomously generating, refining, and learning from\ntheir own experiences. However, existing methods for training such models still\nrely heavily on vast human-curated tasks and labels, typically via fine-tuning\nor reinforcement learning, which poses a fundamental bottleneck to advancing AI\nsystems toward capabilities beyond human intelligence. To overcome this\nlimitation, we introduce R-Zero, a fully autonomous framework that generates\nits own training data from scratch. Starting from a single base LLM, R-Zero\ninitializes two independent models with distinct roles, a Challenger and a\nSolver. These models are optimized separately and co-evolve through\ninteraction: the Challenger is rewarded for proposing tasks near the edge of\nthe Solver capability, and the Solver is rewarded for solving increasingly\nchallenging tasks posed by the Challenger. This process yields a targeted,\nself-improving curriculum without any pre-existing tasks and labels.\nEmpirically, R-Zero substantially improves reasoning capability across\ndifferent backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on\nmath-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.05004.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62ea79dd01ed9b0e8f61ccd3",
      "avatarUrl": "/avatars/70af83e0e267be39fcd5f23b85e2dafa.svg",
      "fullname": "Chengsong Huang",
      "name": "ChengsongHuang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.05405",
      "authors": [
        {
          "_id": "68956dc548b0ae5ca2710dc1",
          "name": "Xinrun Xu",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dc2",
          "name": "Pi Bu",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dc3",
          "name": "Ye Wang",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dc4",
          "name": "Börje F. Karlsson",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dc5",
          "name": "Ziming Wang",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dc6",
          "name": "Tengtao Song",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dc7",
          "name": "Qi Zhu",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dc8",
          "name": "Jun Song",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dc9",
          "name": "Zhiming Ding",
          "hidden": false
        },
        {
          "_id": "68956dc548b0ae5ca2710dca",
          "name": "Bo Zheng",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/61e52be53d6dbb1da842316a/g9vIa19LQudehpP9m9rEs.png"
      ],
      "publishedAt": "2025-08-07T13:58:19.000Z",
      "submittedOnDailyAt": "2025-08-08T01:55:08.314Z",
      "title": "DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning",
      "submittedOnDailyBy": {
        "_id": "61e52be53d6dbb1da842316a",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61e52be53d6dbb1da842316a/gx0WGPcOCClXPymoKglc4.jpeg",
        "isPro": false,
        "fullname": "Börje Karlsson",
        "user": "tellarin",
        "type": "user"
      },
      "summary": "Although Vision Language Models (VLMs) exhibit strong perceptual abilities\nand impressive visual reasoning, they struggle with attention to detail and\nprecise action planning in complex, dynamic environments, leading to subpar\nperformance. Real-world tasks typically require complex interactions, advanced\nspatial reasoning, long-term planning, and continuous strategy refinement,\nusually necessitating understanding the physics rules of the target scenario.\nHowever, evaluating these capabilities in real-world scenarios is often\nprohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel\nbenchmark framework designed to systematically evaluate VLMs' understanding and\nreasoning about fundamental physical principles through a series of challenging\nsimulated environments. DeepPHY integrates multiple physical reasoning\nenvironments of varying difficulty levels and incorporates fine-grained\nevaluation metrics. Our evaluation finds that even state-of-the-art VLMs\nstruggle to translate descriptive physical knowledge into precise, predictive\ncontrol.",
      "upvotes": 35,
      "discussionId": "68956dc648b0ae5ca2710dcb",
      "projectPage": "https://github.com/XinrunXu/DeepPHY",
      "githubRepo": "https://github.com/XinrunXu/DeepPHY",
      "ai_summary": "DeepPHY evaluates Vision Language Models' physical reasoning and control through simulated environments with varying difficulty levels.",
      "ai_keywords": [
        "Vision Language Models",
        "DeepPHY",
        "physical reasoning",
        "simulated environments",
        "evaluation metrics"
      ],
      "githubStars": 10
    },
    "publishedAt": "2025-08-07T09:58:19.000Z",
    "title": "DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning",
    "summary": "Although Vision Language Models (VLMs) exhibit strong perceptual abilities\nand impressive visual reasoning, they struggle with attention to detail and\nprecise action planning in complex, dynamic environments, leading to subpar\nperformance. Real-world tasks typically require complex interactions, advanced\nspatial reasoning, long-term planning, and continuous strategy refinement,\nusually necessitating understanding the physics rules of the target scenario.\nHowever, evaluating these capabilities in real-world scenarios is often\nprohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel\nbenchmark framework designed to systematically evaluate VLMs' understanding and\nreasoning about fundamental physical principles through a series of challenging\nsimulated environments. DeepPHY integrates multiple physical reasoning\nenvironments of varying difficulty levels and incorporates fine-grained\nevaluation metrics. Our evaluation finds that even state-of-the-art VLMs\nstruggle to translate descriptive physical knowledge into precise, predictive\ncontrol.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/61e52be53d6dbb1da842316a/g9vIa19LQudehpP9m9rEs.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.05405.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61e52be53d6dbb1da842316a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61e52be53d6dbb1da842316a/gx0WGPcOCClXPymoKglc4.jpeg",
      "fullname": "Börje Karlsson",
      "name": "tellarin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 26
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.05635",
      "authors": [
        {
          "_id": "689554ee48b0ae5ca2710ce7",
          "name": "Yue Liao",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710ce8",
          "name": "Pengfei Zhou",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710ce9",
          "name": "Siyuan Huang",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cea",
          "name": "Donglin Yang",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710ceb",
          "name": "Shengcong Chen",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cec",
          "name": "Yuxin Jiang",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710ced",
          "name": "Yue Hu",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cee",
          "name": "Jingbin Cai",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cef",
          "name": "Si Liu",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cf0",
          "name": "Jianlan Luo",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cf1",
          "name": "Liliang Chen",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cf2",
          "name": "Shuicheng Yan",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cf3",
          "name": "Maoqing Yao",
          "hidden": false
        },
        {
          "_id": "689554ee48b0ae5ca2710cf4",
          "name": "Guanghui Ren",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-07T17:59:44.000Z",
      "submittedOnDailyAt": "2025-08-08T02:24:08.299Z",
      "title": "Genie Envisioner: A Unified World Foundation Platform for Robotic\n  Manipulation",
      "submittedOnDailyBy": {
        "_id": "646ec9b135f55eb49e405faa",
        "avatarUrl": "/avatars/a17194be585d20e2a021e77a5a20e213.svg",
        "isPro": false,
        "fullname": "Guanghui Ren",
        "user": "sundrops",
        "type": "user"
      },
      "summary": "We introduce Genie Envisioner (GE), a unified world foundation platform for\nrobotic manipulation that integrates policy learning, evaluation, and\nsimulation within a single video-generative framework. At its core, GE-Base is\na large-scale, instruction-conditioned video diffusion model that captures the\nspatial, temporal, and semantic dynamics of real-world robotic interactions in\na structured latent space. Built upon this foundation, GE-Act maps latent\nrepresentations to executable action trajectories through a lightweight,\nflow-matching decoder, enabling precise and generalizable policy inference\nacross diverse embodiments with minimal supervision. To support scalable\nevaluation and training, GE-Sim serves as an action-conditioned neural\nsimulator, producing high-fidelity rollouts for closed-loop policy development.\nThe platform is further equipped with EWMBench, a standardized benchmark suite\nmeasuring visual fidelity, physical consistency, and instruction-action\nalignment. Together, these components establish Genie Envisioner as a scalable\nand practical foundation for instruction-driven, general-purpose embodied\nintelligence. All code, models, and benchmarks will be released publicly.",
      "upvotes": 31,
      "discussionId": "689554ee48b0ae5ca2710cf5",
      "projectPage": "https://genie-envisioner.github.io/",
      "githubRepo": "https://github.com/AgibotTech/Genie-Envisioner",
      "ai_summary": "Genie Envisioner integrates policy learning, evaluation, and simulation using a video diffusion model and neural simulator for instruction-driven robotic manipulation.",
      "ai_keywords": [
        "video diffusion model",
        "latent space",
        "flow-matching decoder",
        "action trajectories",
        "neural simulator",
        "high-fidelity rollouts",
        "EWMBench",
        "visual fidelity",
        "physical consistency",
        "instruction-action alignment"
      ],
      "githubStars": 7
    },
    "publishedAt": "2025-08-07T13:59:44.000Z",
    "title": "Genie Envisioner: A Unified World Foundation Platform for Robotic\n  Manipulation",
    "summary": "We introduce Genie Envisioner (GE), a unified world foundation platform for\nrobotic manipulation that integrates policy learning, evaluation, and\nsimulation within a single video-generative framework. At its core, GE-Base is\na large-scale, instruction-conditioned video diffusion model that captures the\nspatial, temporal, and semantic dynamics of real-world robotic interactions in\na structured latent space. Built upon this foundation, GE-Act maps latent\nrepresentations to executable action trajectories through a lightweight,\nflow-matching decoder, enabling precise and generalizable policy inference\nacross diverse embodiments with minimal supervision. To support scalable\nevaluation and training, GE-Sim serves as an action-conditioned neural\nsimulator, producing high-fidelity rollouts for closed-loop policy development.\nThe platform is further equipped with EWMBench, a standardized benchmark suite\nmeasuring visual fidelity, physical consistency, and instruction-action\nalignment. Together, these components establish Genie Envisioner as a scalable\nand practical foundation for instruction-driven, general-purpose embodied\nintelligence. All code, models, and benchmarks will be released publicly.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.05635.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "646ec9b135f55eb49e405faa",
      "avatarUrl": "/avatars/a17194be585d20e2a021e77a5a20e213.svg",
      "fullname": "Guanghui Ren",
      "name": "sundrops",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.05609",
      "authors": [
        {
          "_id": "6895575348b0ae5ca2710d11",
          "name": "Yuhan Zhang",
          "hidden": false
        },
        {
          "_id": "6895575348b0ae5ca2710d12",
          "name": "Long Zhuo",
          "hidden": false
        },
        {
          "_id": "6895575348b0ae5ca2710d13",
          "name": "Ziyang Chu",
          "hidden": false
        },
        {
          "_id": "6895575348b0ae5ca2710d14",
          "name": "Tong Wu",
          "hidden": false
        },
        {
          "_id": "6895575348b0ae5ca2710d15",
          "name": "Zhibing Li",
          "hidden": false
        },
        {
          "_id": "6895575348b0ae5ca2710d16",
          "name": "Liang Pan",
          "hidden": false
        },
        {
          "_id": "6895575348b0ae5ca2710d17",
          "name": "Dahua Lin",
          "hidden": false
        },
        {
          "_id": "6895575348b0ae5ca2710d18",
          "name": "Ziwei Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-07T17:50:13.000Z",
      "submittedOnDailyAt": "2025-08-08T00:28:08.152Z",
      "title": "Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity",
      "submittedOnDailyBy": {
        "_id": "604599a0e6aa3e130cb9286c",
        "avatarUrl": "/avatars/c9c723a4911b1a1b8870f44595fc9ca6.svg",
        "isPro": false,
        "fullname": "Zyh",
        "user": "ZhangYuhan",
        "type": "user"
      },
      "summary": "Despite rapid advances in 3D content generation, quality assessment for the\ngenerated 3D assets remains challenging. Existing methods mainly rely on\nimage-based metrics and operate solely at the object level, limiting their\nability to capture spatial coherence, material authenticity, and high-fidelity\nlocal details. 1) To address these challenges, we introduce Hi3DEval, a\nhierarchical evaluation framework tailored for 3D generative content. It\ncombines both object-level and part-level evaluation, enabling holistic\nassessments across multiple dimensions as well as fine-grained quality\nanalysis. Additionally, we extend texture evaluation beyond aesthetic\nappearance by explicitly assessing material realism, focusing on attributes\nsuch as albedo, saturation, and metallicness. 2) To support this framework, we\nconstruct Hi3DBench, a large-scale dataset comprising diverse 3D assets and\nhigh-quality annotations, accompanied by a reliable multi-agent annotation\npipeline. We further propose a 3D-aware automated scoring system based on\nhybrid 3D representations. Specifically, we leverage video-based\nrepresentations for object-level and material-subject evaluations to enhance\nmodeling of spatio-temporal consistency and employ pretrained 3D features for\npart-level perception. Extensive experiments demonstrate that our approach\noutperforms existing image-based metrics in modeling 3D characteristics and\nachieves superior alignment with human preference, providing a scalable\nalternative to manual evaluations. The project page is available at\nhttps://zyh482.github.io/Hi3DEval/.",
      "upvotes": 19,
      "discussionId": "6895575348b0ae5ca2710d19",
      "projectPage": "https://zyh482.github.io/Hi3DEval/",
      "ai_summary": "Hi3DEval is a hierarchical evaluation framework for 3D generative content that combines object-level and part-level assessments, including material realism, using a large-scale dataset and hybrid 3D representations.",
      "ai_keywords": [
        "Hi3DEval",
        "hierarchical evaluation framework",
        "object-level evaluation",
        "part-level evaluation",
        "material realism",
        "Hi3DBench",
        "multi-agent annotation pipeline",
        "3D-aware automated scoring system",
        "video-based representations",
        "pretrained 3D features",
        "spatio-temporal consistency",
        "part-level perception"
      ]
    },
    "publishedAt": "2025-08-07T13:50:13.000Z",
    "title": "Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity",
    "summary": "Despite rapid advances in 3D content generation, quality assessment for the\ngenerated 3D assets remains challenging. Existing methods mainly rely on\nimage-based metrics and operate solely at the object level, limiting their\nability to capture spatial coherence, material authenticity, and high-fidelity\nlocal details. 1) To address these challenges, we introduce Hi3DEval, a\nhierarchical evaluation framework tailored for 3D generative content. It\ncombines both object-level and part-level evaluation, enabling holistic\nassessments across multiple dimensions as well as fine-grained quality\nanalysis. Additionally, we extend texture evaluation beyond aesthetic\nappearance by explicitly assessing material realism, focusing on attributes\nsuch as albedo, saturation, and metallicness. 2) To support this framework, we\nconstruct Hi3DBench, a large-scale dataset comprising diverse 3D assets and\nhigh-quality annotations, accompanied by a reliable multi-agent annotation\npipeline. We further propose a 3D-aware automated scoring system based on\nhybrid 3D representations. Specifically, we leverage video-based\nrepresentations for object-level and material-subject evaluations to enhance\nmodeling of spatio-temporal consistency and employ pretrained 3D features for\npart-level perception. Extensive experiments demonstrate that our approach\noutperforms existing image-based metrics in modeling 3D characteristics and\nachieves superior alignment with human preference, providing a scalable\nalternative to manual evaluations. The project page is available at\nhttps://zyh482.github.io/Hi3DEval/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.05609.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "604599a0e6aa3e130cb9286c",
      "avatarUrl": "/avatars/c9c723a4911b1a1b8870f44595fc9ca6.svg",
      "fullname": "Zyh",
      "name": "ZhangYuhan",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.03644",
      "authors": [
        {
          "_id": "6892c4f18da45ffb0a2b2440",
          "name": "Wenxuan Shen",
          "hidden": false
        },
        {
          "_id": "6892c4f18da45ffb0a2b2441",
          "name": "Mingjia Wang",
          "hidden": false
        },
        {
          "_id": "6892c4f18da45ffb0a2b2442",
          "name": "Yaochen Wang",
          "hidden": false
        },
        {
          "_id": "6892c4f18da45ffb0a2b2443",
          "name": "Dongping Chen",
          "hidden": false
        },
        {
          "_id": "6892c4f18da45ffb0a2b2444",
          "name": "Junjie Yang",
          "hidden": false
        },
        {
          "_id": "6892c4f18da45ffb0a2b2445",
          "name": "Yao Wan",
          "hidden": false
        },
        {
          "_id": "6892c4f18da45ffb0a2b2446",
          "name": "Weiwei Lin",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/643be8879f5d314db2d9ed23/4jw8iNVeKaGDTvS5um9XL.png"
      ],
      "publishedAt": "2025-08-05T16:55:02.000Z",
      "submittedOnDailyAt": "2025-08-08T02:43:21.621Z",
      "title": "Are We on the Right Way for Assessing Document Retrieval-Augmented\n  Generation?",
      "submittedOnDailyBy": {
        "_id": "643be8879f5d314db2d9ed23",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643be8879f5d314db2d9ed23/VrW2UtJ7ppOnGIYjTWd7b.png",
        "isPro": false,
        "fullname": "Chen Dongping",
        "user": "shuaishuaicdp",
        "type": "user"
      },
      "summary": "Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language\nModels (MLLMs) show great promise for complex document understanding, yet their\ndevelopment is critically hampered by inadequate evaluation. Current benchmarks\noften focus on specific part of document RAG system and use synthetic data with\nincomplete ground truth and evidence labels, therefore failing to reflect\nreal-world bottlenecks and challenges. To overcome these limitations, we\nintroduce Double-Bench: a new large-scale, multilingual, and multimodal\nevaluation system that is able to produce fine-grained assessment to each\ncomponent within document RAG systems. It comprises 3,276 documents (72,880\npages) and 5,168 single- and multi-hop queries across 6 languages and 4\ndocument types with streamlined dynamic update support for potential data\ncontamination issues. Queries are grounded in exhaustively scanned evidence\npages and verified by human experts to ensure maximum quality and completeness.\nOur comprehensive experiments across 9 state-of-the-art embedding models, 4\nMLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text\nand visual embedding models is narrowing, highlighting the need in building\nstronger document retrieval models. Our findings also reveal the\nover-confidence dilemma within current document RAG frameworks that tend to\nprovide answer even without evidence support. We hope our fully open-source\nDouble-Bench provide a rigorous foundation for future research in advanced\ndocument RAG systems. We plan to retrieve timely corpus and release new\nbenchmarks on an annual basis.",
      "upvotes": 13,
      "discussionId": "6892c4f18da45ffb0a2b2447",
      "projectPage": "https://double-bench.github.io/",
      "githubRepo": "https://github.com/Episoode/Double-Bench",
      "ai_summary": "Double-Bench is a large-scale, multilingual, and multimodal evaluation system for document Retrieval-Augmented Generation (RAG) systems, addressing limitations in current benchmarks and providing comprehensive assessments of system components.",
      "ai_keywords": [
        "Retrieval-Augmented Generation",
        "Multimodal Large Language Models",
        "document RAG system",
        "Double-Bench",
        "large-scale",
        "multilingual",
        "multimodal",
        "evaluation system",
        "document retrieval models",
        "over-confidence dilemma"
      ],
      "githubStars": 9
    },
    "publishedAt": "2025-08-05T12:55:02.000Z",
    "title": "Are We on the Right Way for Assessing Document Retrieval-Augmented\n  Generation?",
    "summary": "Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language\nModels (MLLMs) show great promise for complex document understanding, yet their\ndevelopment is critically hampered by inadequate evaluation. Current benchmarks\noften focus on specific part of document RAG system and use synthetic data with\nincomplete ground truth and evidence labels, therefore failing to reflect\nreal-world bottlenecks and challenges. To overcome these limitations, we\nintroduce Double-Bench: a new large-scale, multilingual, and multimodal\nevaluation system that is able to produce fine-grained assessment to each\ncomponent within document RAG systems. It comprises 3,276 documents (72,880\npages) and 5,168 single- and multi-hop queries across 6 languages and 4\ndocument types with streamlined dynamic update support for potential data\ncontamination issues. Queries are grounded in exhaustively scanned evidence\npages and verified by human experts to ensure maximum quality and completeness.\nOur comprehensive experiments across 9 state-of-the-art embedding models, 4\nMLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text\nand visual embedding models is narrowing, highlighting the need in building\nstronger document retrieval models. Our findings also reveal the\nover-confidence dilemma within current document RAG frameworks that tend to\nprovide answer even without evidence support. We hope our fully open-source\nDouble-Bench provide a rigorous foundation for future research in advanced\ndocument RAG systems. We plan to retrieve timely corpus and release new\nbenchmarks on an annual basis.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/643be8879f5d314db2d9ed23/4jw8iNVeKaGDTvS5um9XL.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.03644.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "643be8879f5d314db2d9ed23",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643be8879f5d314db2d9ed23/VrW2UtJ7ppOnGIYjTWd7b.png",
      "fullname": "Chen Dongping",
      "name": "shuaishuaicdp",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.03990",
      "authors": [
        {
          "_id": "68955a4548b0ae5ca2710d24",
          "name": "Bohan Jiang",
          "hidden": false
        },
        {
          "_id": "68955a4548b0ae5ca2710d25",
          "name": "Dawei Li",
          "hidden": false
        },
        {
          "_id": "68955a4548b0ae5ca2710d26",
          "name": "Zhen Tan",
          "hidden": false
        },
        {
          "_id": "68955a4548b0ae5ca2710d27",
          "name": "Chengshuai Zhao",
          "hidden": false
        },
        {
          "_id": "68955a4548b0ae5ca2710d28",
          "name": "Huan Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-06T00:45:02.000Z",
      "submittedOnDailyAt": "2025-08-08T00:37:55.642Z",
      "title": "Are Today's LLMs Ready to Explain Well-Being Concepts?",
      "submittedOnDailyBy": {
        "_id": "61f087a0a57920a251ec1a6f",
        "avatarUrl": "/avatars/4402b7986152bb37e02f1305c6bcce2e.svg",
        "isPro": false,
        "fullname": "Bohan Jiang",
        "user": "Bohan-Jiang",
        "type": "user"
      },
      "summary": "Well-being encompasses mental, physical, and social dimensions essential to\npersonal growth and informed life decisions. As individuals increasingly\nconsult Large Language Models (LLMs) to understand well-being, a key challenge\nemerges: Can LLMs generate explanations that are not only accurate but also\ntailored to diverse audiences? High-quality explanations require both factual\ncorrectness and the ability to meet the expectations of users with varying\nexpertise. In this work, we construct a large-scale dataset comprising 43,880\nexplanations of 2,194 well-being concepts, generated by ten diverse LLMs. We\nintroduce a principle-guided LLM-as-a-judge evaluation framework, employing\ndual judges to assess explanation quality. Furthermore, we show that\nfine-tuning an open-source LLM using Supervised Fine-Tuning (SFT) and Direct\nPreference Optimization (DPO) can significantly enhance the quality of\ngenerated explanations. Our results reveal: (1) The proposed LLM judges align\nwell with human evaluations; (2) explanation quality varies significantly\nacross models, audiences, and categories; and (3) DPO- and SFT-finetuned models\noutperform their larger counterparts, demonstrating the effectiveness of\npreference-based learning for specialized explanation tasks.",
      "upvotes": 7,
      "discussionId": "68955a4648b0ae5ca2710d29",
      "ai_summary": "LLMs can be fine-tuned to generate high-quality, audience-tailored explanations of well-being concepts using Supervised Fine-Tuning and Direct Preference Optimization.",
      "ai_keywords": [
        "Large Language Models",
        "LLMs",
        "Supervised Fine-Tuning",
        "Direct Preference Optimization",
        "LLM-as-a-judge",
        "explanation quality",
        "fine-tuning",
        "preference-based learning"
      ]
    },
    "publishedAt": "2025-08-05T20:45:02.000Z",
    "title": "Are Today's LLMs Ready to Explain Well-Being Concepts?",
    "summary": "Well-being encompasses mental, physical, and social dimensions essential to\npersonal growth and informed life decisions. As individuals increasingly\nconsult Large Language Models (LLMs) to understand well-being, a key challenge\nemerges: Can LLMs generate explanations that are not only accurate but also\ntailored to diverse audiences? High-quality explanations require both factual\ncorrectness and the ability to meet the expectations of users with varying\nexpertise. In this work, we construct a large-scale dataset comprising 43,880\nexplanations of 2,194 well-being concepts, generated by ten diverse LLMs. We\nintroduce a principle-guided LLM-as-a-judge evaluation framework, employing\ndual judges to assess explanation quality. Furthermore, we show that\nfine-tuning an open-source LLM using Supervised Fine-Tuning (SFT) and Direct\nPreference Optimization (DPO) can significantly enhance the quality of\ngenerated explanations. Our results reveal: (1) The proposed LLM judges align\nwell with human evaluations; (2) explanation quality varies significantly\nacross models, audiences, and categories; and (3) DPO- and SFT-finetuned models\noutperform their larger counterparts, demonstrating the effectiveness of\npreference-based learning for specialized explanation tasks.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.03990.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61f087a0a57920a251ec1a6f",
      "avatarUrl": "/avatars/4402b7986152bb37e02f1305c6bcce2e.svg",
      "fullname": "Bohan Jiang",
      "name": "Bohan-Jiang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.04017",
      "authors": [
        {
          "_id": "68957a1b48b0ae5ca2710de5",
          "name": "Haiqi Yang",
          "hidden": false
        },
        {
          "_id": "68957a1b48b0ae5ca2710de6",
          "name": "Jinzhe Li",
          "hidden": false
        },
        {
          "_id": "68957a1b48b0ae5ca2710de7",
          "name": "Gengxu Li",
          "hidden": false
        },
        {
          "_id": "68957a1b48b0ae5ca2710de8",
          "name": "Yi Chang",
          "hidden": false
        },
        {
          "_id": "68957a1b48b0ae5ca2710de9",
          "name": "Yuan Wu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-06T02:13:46.000Z",
      "submittedOnDailyAt": "2025-08-08T02:49:53.355Z",
      "title": "Can Large Multimodal Models Actively Recognize Faulty Inputs? A\n  Systematic Evaluation Framework of Their Input Scrutiny Ability",
      "submittedOnDailyBy": {
        "_id": "670e57b3391f1a7021182bff",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/N0tuHZVz8KFPCv8G1qUX2.png",
        "isPro": false,
        "fullname": "Yuan Wu",
        "user": "WhiteCatY",
        "type": "user"
      },
      "summary": "Large Multimodal Models (LMMs) have witnessed remarkable growth, showcasing\nformidable capabilities in handling intricate multimodal tasks with exceptional\nperformance. Recent research has underscored the inclination of large language\nmodels to passively accept defective inputs, often resulting in futile\nreasoning on invalid prompts. However, the same critical question of whether\nLMMs can actively detect and scrutinize erroneous inputs still remains\nunexplored. To address this gap, we introduce the Input Scrutiny Ability\nEvaluation Framework (ISEval), which encompasses seven categories of flawed\npremises and three evaluation metrics. Our extensive evaluation of ten advanced\nLMMs has identified key findings. Most models struggle to actively detect\nflawed textual premises without guidance, which reflects a strong reliance on\nexplicit prompts for premise error identification. Error type affects\nperformance: models excel at identifying logical fallacies but struggle with\nsurface-level linguistic errors and certain conditional flaws. Modality trust\nvaries-Gemini 2.5 pro and Claude Sonnet 4 balance visual and textual info,\nwhile aya-vision-8b over-rely on text in conflicts. These insights underscore\nthe urgent need to enhance LMMs' proactive verification of input validity and\nshed novel insights into mitigating the problem. The code is available at\nhttps://github.com/MLGroupJLU/LMM_ISEval.",
      "upvotes": 6,
      "discussionId": "68957a1b48b0ae5ca2710dea",
      "ai_summary": "ISEval framework evaluates large multimodal models' ability to detect flawed inputs, revealing challenges in identifying certain types of errors and modality-specific biases.",
      "ai_keywords": [
        "Large Multimodal Models",
        "Input Scrutiny Ability Evaluation Framework",
        "flawed premises",
        "evaluation metrics",
        "logical fallacies",
        "surface-level linguistic errors",
        "conditional flaws",
        "modality trust",
        "Gemini 2.5 pro",
        "Claude Sonnet 4",
        "aya-vision-8b"
      ]
    },
    "publishedAt": "2025-08-05T22:13:46.000Z",
    "title": "Can Large Multimodal Models Actively Recognize Faulty Inputs? A\n  Systematic Evaluation Framework of Their Input Scrutiny Ability",
    "summary": "Large Multimodal Models (LMMs) have witnessed remarkable growth, showcasing\nformidable capabilities in handling intricate multimodal tasks with exceptional\nperformance. Recent research has underscored the inclination of large language\nmodels to passively accept defective inputs, often resulting in futile\nreasoning on invalid prompts. However, the same critical question of whether\nLMMs can actively detect and scrutinize erroneous inputs still remains\nunexplored. To address this gap, we introduce the Input Scrutiny Ability\nEvaluation Framework (ISEval), which encompasses seven categories of flawed\npremises and three evaluation metrics. Our extensive evaluation of ten advanced\nLMMs has identified key findings. Most models struggle to actively detect\nflawed textual premises without guidance, which reflects a strong reliance on\nexplicit prompts for premise error identification. Error type affects\nperformance: models excel at identifying logical fallacies but struggle with\nsurface-level linguistic errors and certain conditional flaws. Modality trust\nvaries-Gemini 2.5 pro and Claude Sonnet 4 balance visual and textual info,\nwhile aya-vision-8b over-rely on text in conflicts. These insights underscore\nthe urgent need to enhance LMMs' proactive verification of input validity and\nshed novel insights into mitigating the problem. The code is available at\nhttps://github.com/MLGroupJLU/LMM_ISEval.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.04017.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "670e57b3391f1a7021182bff",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/N0tuHZVz8KFPCv8G1qUX2.png",
      "fullname": "Yuan Wu",
      "name": "WhiteCatY",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.05496",
      "authors": [
        {
          "_id": "689594c848b0ae5ca2710e22",
          "name": "Shuo Cai",
          "hidden": false
        },
        {
          "_id": "689594c848b0ae5ca2710e23",
          "name": "Su Lu",
          "hidden": false
        },
        {
          "_id": "689594c848b0ae5ca2710e24",
          "name": "Qi Zhou",
          "hidden": false
        },
        {
          "_id": "689594c848b0ae5ca2710e25",
          "name": "Kejing Yang",
          "hidden": false
        },
        {
          "_id": "689594c848b0ae5ca2710e26",
          "name": "Zhijie Sang",
          "hidden": false
        },
        {
          "_id": "689594c848b0ae5ca2710e27",
          "name": "Congkai Xie",
          "hidden": false
        },
        {
          "_id": "689594c848b0ae5ca2710e28",
          "name": "Hongxia Yang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-07T15:34:06.000Z",
      "submittedOnDailyAt": "2025-08-08T04:51:32.588Z",
      "title": "InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs\n  to Enhance Reasoning Capabilities",
      "submittedOnDailyBy": {
        "_id": "62722849517c0ca41f7cd13d",
        "avatarUrl": "/avatars/bb1f8f2f2665944930cb5a7ce19c47d4.svg",
        "isPro": false,
        "fullname": "Yuhang Liu",
        "user": "SiriusL",
        "type": "user"
      },
      "summary": "Large language models (LLMs) have exhibited impressive reasoning abilities on\na wide range of complex tasks. However, enhancing these capabilities through\npost-training remains resource intensive, particularly in terms of data and\ncomputational cost. Although recent efforts have sought to improve sample\nefficiency through selective data curation, existing methods often rely on\nheuristic or task-specific strategies that hinder scalability. In this work, we\nintroduce InfiAlign, a scalable and sample-efficient post-training framework\nthat integrates supervised fine-tuning (SFT) with Direct Preference\nOptimization (DPO) to align LLMs for enhanced reasoning. At the core of\nInfiAlign is a robust data selection pipeline that automatically curates\nhigh-quality alignment data from open-source reasoning datasets using\nmultidimensional quality metrics. This pipeline enables significant performance\ngains while drastically reducing data requirements and remains extensible to\nnew data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model\nachieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only\napproximately 12% of the training data, and demonstrates strong generalization\nacross diverse reasoning tasks. Additional improvements are obtained through\nthe application of DPO, with particularly notable gains in mathematical\nreasoning tasks. The model achieves an average improvement of 3.89% on AIME\n24/25 benchmarks. Our results highlight the effectiveness of combining\nprincipled data selection with full-stage post-training, offering a practical\nsolution for aligning large reasoning models in a scalable and data-efficient\nmanner. The model checkpoints are available at\nhttps://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.",
      "upvotes": 5,
      "discussionId": "689594c848b0ae5ca2710e29",
      "ai_summary": "InfiAlign, a scalable and sample-efficient post-training framework, combines supervised fine-tuning and Direct Preference Optimization to enhance large language models' reasoning abilities with minimal data and computational cost.",
      "ai_keywords": [
        "supervised fine-tuning",
        "Direct Preference Optimization",
        "data selection pipeline",
        "multidimensional quality metrics",
        "Qwen2.5-Math-7B-Base",
        "DeepSeek-R1-Distill-Qwen-7B",
        "AIME 24/25 benchmarks"
      ]
    },
    "publishedAt": "2025-08-07T11:34:06.000Z",
    "title": "InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs\n  to Enhance Reasoning Capabilities",
    "summary": "Large language models (LLMs) have exhibited impressive reasoning abilities on\na wide range of complex tasks. However, enhancing these capabilities through\npost-training remains resource intensive, particularly in terms of data and\ncomputational cost. Although recent efforts have sought to improve sample\nefficiency through selective data curation, existing methods often rely on\nheuristic or task-specific strategies that hinder scalability. In this work, we\nintroduce InfiAlign, a scalable and sample-efficient post-training framework\nthat integrates supervised fine-tuning (SFT) with Direct Preference\nOptimization (DPO) to align LLMs for enhanced reasoning. At the core of\nInfiAlign is a robust data selection pipeline that automatically curates\nhigh-quality alignment data from open-source reasoning datasets using\nmultidimensional quality metrics. This pipeline enables significant performance\ngains while drastically reducing data requirements and remains extensible to\nnew data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model\nachieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only\napproximately 12% of the training data, and demonstrates strong generalization\nacross diverse reasoning tasks. Additional improvements are obtained through\nthe application of DPO, with particularly notable gains in mathematical\nreasoning tasks. The model achieves an average improvement of 3.89% on AIME\n24/25 benchmarks. Our results highlight the effectiveness of combining\nprincipled data selection with full-stage post-training, offering a practical\nsolution for aligning large reasoning models in a scalable and data-efficient\nmanner. The model checkpoints are available at\nhttps://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.05496.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "62722849517c0ca41f7cd13d",
      "avatarUrl": "/avatars/bb1f8f2f2665944930cb5a7ce19c47d4.svg",
      "fullname": "Yuhang Liu",
      "name": "SiriusL",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 6
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.04423",
      "authors": [
        {
          "_id": "6895590348b0ae5ca2710d1b",
          "name": "Jie Zhu",
          "hidden": false
        },
        {
          "_id": "6895590348b0ae5ca2710d1c",
          "name": "Huaixia Dou",
          "hidden": false
        },
        {
          "_id": "6895590348b0ae5ca2710d1d",
          "name": "Junhui Li",
          "hidden": false
        },
        {
          "_id": "6895590348b0ae5ca2710d1e",
          "name": "Lifan Guo",
          "hidden": false
        },
        {
          "_id": "6895590348b0ae5ca2710d1f",
          "name": "Feng Chen",
          "hidden": false
        },
        {
          "_id": "6895590348b0ae5ca2710d20",
          "name": "Chi Zhang",
          "hidden": false
        },
        {
          "_id": "6895590348b0ae5ca2710d21",
          "name": "Fang Kong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-06T13:11:17.000Z",
      "submittedOnDailyAt": "2025-08-08T00:25:48.382Z",
      "title": "Evaluating, Synthesizing, and Enhancing for Customer Support\n  Conversation",
      "submittedOnDailyBy": {
        "_id": "642656cbad1e3b0e6e91b752",
        "avatarUrl": "/avatars/3bf0ee15fd528e09b2b889f5cce3cbd0.svg",
        "isPro": false,
        "fullname": "Jie Zhu",
        "user": "amazingj",
        "type": "user"
      },
      "summary": "Effective customer support requires not only accurate problem solving but\nalso structured and empathetic communication aligned with professional\nstandards. However, existing dialogue datasets often lack strategic guidance,\nand real-world service data is difficult to access and annotate. To address\nthis, we introduce the task of Customer Support Conversation (CSC), aimed at\ntraining customer service agents to respond using well-defined support\nstrategies. We propose a structured CSC framework grounded in COPC guidelines,\ndefining five conversational stages and twelve strategies to guide high-quality\ninteractions. Based on this, we construct CSConv, an evaluation dataset of\n1,855 real-world customer-agent conversations rewritten using LLMs to reflect\ndeliberate strategy use, and annotated accordingly. Additionally, we develop a\nrole-playing approach that simulates strategy-rich conversations using\nLLM-powered roles aligned with the CSC framework, resulting in the training\ndataset RoleCS. Experiments show that fine-tuning strong LLMs on RoleCS\nsignificantly improves their ability to generate high-quality, strategy-aligned\nresponses on CSConv. Human evaluations further confirm gains in problem\nresolution. All code and data will be made publicly available at\nhttps://github.com/aliyun/qwen-dianjin.",
      "upvotes": 5,
      "discussionId": "6895590348b0ae5ca2710d22",
      "ai_summary": "A structured framework and datasets for training customer service agents using well-defined support strategies improve the quality of customer support interactions and problem resolution.",
      "ai_keywords": [
        "COPC guidelines",
        "conversational stages",
        "support strategies",
        "CSConv",
        "LLMs",
        "role-playing approach",
        "RoleCS",
        "fine-tuning",
        "high-quality responses"
      ]
    },
    "publishedAt": "2025-08-06T09:11:17.000Z",
    "title": "Evaluating, Synthesizing, and Enhancing for Customer Support\n  Conversation",
    "summary": "Effective customer support requires not only accurate problem solving but\nalso structured and empathetic communication aligned with professional\nstandards. However, existing dialogue datasets often lack strategic guidance,\nand real-world service data is difficult to access and annotate. To address\nthis, we introduce the task of Customer Support Conversation (CSC), aimed at\ntraining customer service agents to respond using well-defined support\nstrategies. We propose a structured CSC framework grounded in COPC guidelines,\ndefining five conversational stages and twelve strategies to guide high-quality\ninteractions. Based on this, we construct CSConv, an evaluation dataset of\n1,855 real-world customer-agent conversations rewritten using LLMs to reflect\ndeliberate strategy use, and annotated accordingly. Additionally, we develop a\nrole-playing approach that simulates strategy-rich conversations using\nLLM-powered roles aligned with the CSC framework, resulting in the training\ndataset RoleCS. Experiments show that fine-tuning strong LLMs on RoleCS\nsignificantly improves their ability to generate high-quality, strategy-aligned\nresponses on CSConv. Human evaluations further confirm gains in problem\nresolution. All code and data will be made publicly available at\nhttps://github.com/aliyun/qwen-dianjin.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.04423.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642656cbad1e3b0e6e91b752",
      "avatarUrl": "/avatars/3bf0ee15fd528e09b2b889f5cce3cbd0.svg",
      "fullname": "Jie Zhu",
      "name": "amazingj",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.02120",
      "authors": [
        {
          "_id": "68956be848b0ae5ca2710d9c",
          "name": "Linan Yue",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710d9d",
          "name": "Yichao Du",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710d9e",
          "name": "Yizhi Wang",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710d9f",
          "name": "Weibo Gao",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710da0",
          "name": "Fangzhou Yao",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710da1",
          "name": "Li Wang",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710da2",
          "name": "Ye Liu",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710da3",
          "name": "Ziyu Xu",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710da4",
          "name": "Qi Liu",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710da5",
          "name": "Shimin Di",
          "hidden": false
        },
        {
          "_id": "68956be848b0ae5ca2710da6",
          "name": "Min-Ling Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-04T06:54:31.000Z",
      "submittedOnDailyAt": "2025-08-08T01:48:28.213Z",
      "title": "Don't Overthink It: A Survey of Efficient R1-style Large Reasoning\n  Models",
      "submittedOnDailyBy": {
        "_id": "63e1d3451e5a4f34b7a728ef",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e1d3451e5a4f34b7a728ef/kHE5JHF9iZJOG0uBkvJr-.jpeg",
        "isPro": false,
        "fullname": "yichaodu",
        "user": "yichaodu",
        "type": "user"
      },
      "summary": "Recently, Large Reasoning Models (LRMs) have gradually become a research\nhotspot due to their outstanding performance in handling complex tasks. Among\nthem, DeepSeek R1 has garnered significant attention for its exceptional\nperformance and open-source nature, driving advancements in the research of\nR1-style LRMs. Unlike traditional Large Language Models (LLMs), these models\nenhance logical deduction and decision-making capabilities during reasoning by\nincorporating mechanisms such as long chain-of-thought and self-reflection\nthrough reinforcement learning. However, with the widespread application of\nthese models, the problem of overthinking has gradually emerged. Specifically,\nwhen generating answers, these models often construct excessively long\nreasoning chains with redundant or repetitive steps, which leads to reduced\nreasoning efficiency and may affect the accuracy of the final answer. To this\nend, various efficient reasoning methods have been proposed, aiming to reduce\nthe length of reasoning paths without compromising model performance and\nreasoning capability. By reviewing the current research advancements in the\nfield of efficient reasoning methods systematically, we categorize existing\nworks into two main directions based on the lens of single-model optimization\nversus model collaboration: (1) Efficient Reasoning with Single Model, which\nfocuses on improving the reasoning efficiency of individual models; and (2)\nEfficient Reasoning with Model Collaboration, which explores optimizing\nreasoning paths through collaboration among multiple models. Besides, we\nmaintain a public GitHub repository that tracks the latest progress in\nefficient reasoning methods.",
      "upvotes": 3,
      "discussionId": "68956be848b0ae5ca2710da7",
      "projectPage": "https://github.com/yuelinan/Awesome-Efficient-R1-style-LRMs",
      "githubRepo": "https://github.com/yuelinan/Awesome-Efficient-R1-style-LRMs",
      "ai_summary": "Research on efficient reasoning methods for Large Reasoning Models (LRMs) aims to reduce reasoning path length without sacrificing performance, through single-model optimization and model collaboration.",
      "ai_keywords": [
        "Large Reasoning Models",
        "DeepSeek R1",
        "Large Language Models",
        "long chain-of-thought",
        "self-reflection",
        "reinforcement learning",
        "efficient reasoning methods",
        "single-model optimization",
        "model collaboration"
      ],
      "githubStars": 9
    },
    "publishedAt": "2025-08-04T02:54:31.000Z",
    "title": "Don't Overthink It: A Survey of Efficient R1-style Large Reasoning\n  Models",
    "summary": "Recently, Large Reasoning Models (LRMs) have gradually become a research\nhotspot due to their outstanding performance in handling complex tasks. Among\nthem, DeepSeek R1 has garnered significant attention for its exceptional\nperformance and open-source nature, driving advancements in the research of\nR1-style LRMs. Unlike traditional Large Language Models (LLMs), these models\nenhance logical deduction and decision-making capabilities during reasoning by\nincorporating mechanisms such as long chain-of-thought and self-reflection\nthrough reinforcement learning. However, with the widespread application of\nthese models, the problem of overthinking has gradually emerged. Specifically,\nwhen generating answers, these models often construct excessively long\nreasoning chains with redundant or repetitive steps, which leads to reduced\nreasoning efficiency and may affect the accuracy of the final answer. To this\nend, various efficient reasoning methods have been proposed, aiming to reduce\nthe length of reasoning paths without compromising model performance and\nreasoning capability. By reviewing the current research advancements in the\nfield of efficient reasoning methods systematically, we categorize existing\nworks into two main directions based on the lens of single-model optimization\nversus model collaboration: (1) Efficient Reasoning with Single Model, which\nfocuses on improving the reasoning efficiency of individual models; and (2)\nEfficient Reasoning with Model Collaboration, which explores optimizing\nreasoning paths through collaboration among multiple models. Besides, we\nmaintain a public GitHub repository that tracks the latest progress in\nefficient reasoning methods.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.02120.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63e1d3451e5a4f34b7a728ef",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e1d3451e5a4f34b7a728ef/kHE5JHF9iZJOG0uBkvJr-.jpeg",
      "fullname": "yichaodu",
      "name": "yichaodu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.05630",
      "authors": [
        {
          "_id": "689554af48b0ae5ca2710cdd",
          "name": "Henghui Ding",
          "hidden": false
        },
        {
          "_id": "689554af48b0ae5ca2710cde",
          "name": "Kaining Ying",
          "hidden": false
        },
        {
          "_id": "689554af48b0ae5ca2710cdf",
          "name": "Chang Liu",
          "hidden": false
        },
        {
          "_id": "689554af48b0ae5ca2710ce0",
          "name": "Shuting He",
          "hidden": false
        },
        {
          "_id": "689554af48b0ae5ca2710ce1",
          "name": "Xudong Jiang",
          "hidden": false
        },
        {
          "_id": "689554af48b0ae5ca2710ce2",
          "name": "Yu-Gang Jiang",
          "hidden": false
        },
        {
          "_id": "689554af48b0ae5ca2710ce3",
          "name": "Philip H. S. Torr",
          "hidden": false
        },
        {
          "_id": "689554af48b0ae5ca2710ce4",
          "name": "Song Bai",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-07T17:59:27.000Z",
      "submittedOnDailyAt": "2025-08-08T00:08:51.130Z",
      "title": "MOSEv2: A More Challenging Dataset for Video Object Segmentation in\n  Complex Scenes",
      "submittedOnDailyBy": {
        "_id": "67ff29ecbf6889a333c69c7a",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67ff29ecbf6889a333c69c7a/zilMQrxIgUKYvHBVCHaKL.jpeg",
        "isPro": false,
        "fullname": "Henghui Ding",
        "user": "HenghuiDing",
        "type": "user"
      },
      "summary": "Video object segmentation (VOS) aims to segment specified target objects\nthroughout a video. Although state-of-the-art methods have achieved impressive\nperformance (e.g., 90+% J&F) on existing benchmarks such as DAVIS and\nYouTube-VOS, these datasets primarily contain salient, dominant, and isolated\nobjects, limiting their generalization to real-world scenarios. To advance VOS\ntoward more realistic environments, coMplex video Object SEgmentation (MOSEv1)\nwas introduced to facilitate VOS research in complex scenes. Building on the\nstrengths and limitations of MOSEv1, we present MOSEv2, a significantly more\nchallenging dataset designed to further advance VOS methods under real-world\nconditions. MOSEv2 consists of 5,024 videos and over 701,976 high-quality masks\nfor 10,074 objects across 200 categories. Compared to its predecessor, MOSEv2\nintroduces significantly greater scene complexity, including more frequent\nobject disappearance and reappearance, severe occlusions and crowding, smaller\nobjects, as well as a range of new challenges such as adverse weather (e.g.,\nrain, snow, fog), low-light scenes (e.g., nighttime, underwater), multi-shot\nsequences, camouflaged objects, non-physical targets (e.g., shadows,\nreflections), scenarios requiring external knowledge, etc. We benchmark 20\nrepresentative VOS methods under 5 different settings and observe consistent\nperformance drops. For example, SAM2 drops from 76.4% on MOSEv1 to only 50.9%\non MOSEv2. We further evaluate 9 video object tracking methods and find similar\ndeclines, demonstrating that MOSEv2 presents challenges across tasks. These\nresults highlight that despite high accuracy on existing datasets, current VOS\nmethods still struggle under real-world complexities. MOSEv2 is publicly\navailable at https://MOSE.video.",
      "upvotes": 2,
      "discussionId": "689554af48b0ae5ca2710ce5",
      "ai_summary": "MOSEv2, a more challenging dataset, highlights the limitations of current VOS methods in real-world scenarios with increased complexity and diverse challenges.",
      "ai_keywords": [
        "Video object segmentation",
        "VOS",
        "DAVIS",
        "YouTube-VOS",
        "J&F",
        "MOSEv1",
        "MOSEv2",
        "high-quality masks",
        "scene complexity",
        "object disappearance",
        "occlusions",
        "crowding",
        "adverse weather",
        "low-light scenes",
        "multi-shot sequences",
        "camouflaged objects",
        "non-physical targets",
        "external knowledge",
        "SAM2",
        "video object tracking"
      ]
    },
    "publishedAt": "2025-08-07T13:59:27.000Z",
    "title": "MOSEv2: A More Challenging Dataset for Video Object Segmentation in\n  Complex Scenes",
    "summary": "Video object segmentation (VOS) aims to segment specified target objects\nthroughout a video. Although state-of-the-art methods have achieved impressive\nperformance (e.g., 90+% J&F) on existing benchmarks such as DAVIS and\nYouTube-VOS, these datasets primarily contain salient, dominant, and isolated\nobjects, limiting their generalization to real-world scenarios. To advance VOS\ntoward more realistic environments, coMplex video Object SEgmentation (MOSEv1)\nwas introduced to facilitate VOS research in complex scenes. Building on the\nstrengths and limitations of MOSEv1, we present MOSEv2, a significantly more\nchallenging dataset designed to further advance VOS methods under real-world\nconditions. MOSEv2 consists of 5,024 videos and over 701,976 high-quality masks\nfor 10,074 objects across 200 categories. Compared to its predecessor, MOSEv2\nintroduces significantly greater scene complexity, including more frequent\nobject disappearance and reappearance, severe occlusions and crowding, smaller\nobjects, as well as a range of new challenges such as adverse weather (e.g.,\nrain, snow, fog), low-light scenes (e.g., nighttime, underwater), multi-shot\nsequences, camouflaged objects, non-physical targets (e.g., shadows,\nreflections), scenarios requiring external knowledge, etc. We benchmark 20\nrepresentative VOS methods under 5 different settings and observe consistent\nperformance drops. For example, SAM2 drops from 76.4% on MOSEv1 to only 50.9%\non MOSEv2. We further evaluate 9 video object tracking methods and find similar\ndeclines, demonstrating that MOSEv2 presents challenges across tasks. These\nresults highlight that despite high accuracy on existing datasets, current VOS\nmethods still struggle under real-world complexities. MOSEv2 is publicly\navailable at https://MOSE.video.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.05630.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "67ff29ecbf6889a333c69c7a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67ff29ecbf6889a333c69c7a/zilMQrxIgUKYvHBVCHaKL.jpeg",
      "fullname": "Henghui Ding",
      "name": "HenghuiDing",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.04699",
      "authors": [
        {
          "_id": "68955ed748b0ae5ca2710d36",
          "name": "Anushka Yadav",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d37",
          "name": "Isha Nalawade",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d38",
          "name": "Srujana Pillarichety",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d39",
          "name": "Yashwanth Babu",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d3a",
          "name": "Reshmi Ghosh",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d3b",
          "name": "Samyadeep Basu",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d3c",
          "name": "Wenlong Zhao",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d3d",
          "name": "Ali Nasaeh",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d3e",
          "name": "Sriram Balasubramanian",
          "hidden": false
        },
        {
          "_id": "68955ed748b0ae5ca2710d3f",
          "name": "Soundararajan Srinivasan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-06T17:58:36.000Z",
      "submittedOnDailyAt": "2025-08-08T00:51:05.999Z",
      "title": "Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during\n  Multi-Hop Analysis",
      "submittedOnDailyBy": {
        "_id": "63228cad95d6f717a8c8e1ec",
        "avatarUrl": "/avatars/5fa606f63f841879af1a7617366d18b4.svg",
        "isPro": false,
        "fullname": "Reshmi Ghosh",
        "user": "reshmighosh",
        "type": "user"
      },
      "summary": "The emergence of reasoning models and their integration into practical AI\nchat bots has led to breakthroughs in solving advanced math, deep search, and\nextractive question answering problems that requires a complex and multi-step\nthought process. Yet, a complete understanding of why these models hallucinate\nmore than general purpose language models is missing. In this investigative\nstudy, we systematicallyexplore reasoning failures of contemporary language\nmodels on multi-hop question answering tasks. We introduce a novel, nuanced\nerror categorization framework that examines failures across three critical\ndimensions: the diversity and uniqueness of source documents involved (\"hops\"),\ncompleteness in capturing relevant information (\"coverage\"), and cognitive\ninefficiency (\"overthinking\"). Through rigorous hu-man annotation, supported by\ncomplementary automated metrics, our exploration uncovers intricate error\npatterns often hidden by accuracy-centric evaluations. This investigative\napproach provides deeper insights into the cognitive limitations of current\nmodels and offers actionable guidance toward enhancing reasoning fidelity,\ntransparency, and robustness in future language modeling efforts.",
      "upvotes": 2,
      "discussionId": "68955ed848b0ae5ca2710d40",
      "ai_summary": "Research investigates reasoning failures in language models for multi-hop question answering, introducing a framework to categorize errors and improve model fidelity.",
      "ai_keywords": [
        "reasoning models",
        "multi-hop question answering",
        "error categorization",
        "cognitive limitations",
        "reasoning fidelity",
        "transparency",
        "robustness"
      ]
    },
    "publishedAt": "2025-08-06T13:58:36.000Z",
    "title": "Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during\n  Multi-Hop Analysis",
    "summary": "The emergence of reasoning models and their integration into practical AI\nchat bots has led to breakthroughs in solving advanced math, deep search, and\nextractive question answering problems that requires a complex and multi-step\nthought process. Yet, a complete understanding of why these models hallucinate\nmore than general purpose language models is missing. In this investigative\nstudy, we systematicallyexplore reasoning failures of contemporary language\nmodels on multi-hop question answering tasks. We introduce a novel, nuanced\nerror categorization framework that examines failures across three critical\ndimensions: the diversity and uniqueness of source documents involved (\"hops\"),\ncompleteness in capturing relevant information (\"coverage\"), and cognitive\ninefficiency (\"overthinking\"). Through rigorous hu-man annotation, supported by\ncomplementary automated metrics, our exploration uncovers intricate error\npatterns often hidden by accuracy-centric evaluations. This investigative\napproach provides deeper insights into the cognitive limitations of current\nmodels and offers actionable guidance toward enhancing reasoning fidelity,\ntransparency, and robustness in future language modeling efforts.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.04699.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63228cad95d6f717a8c8e1ec",
      "avatarUrl": "/avatars/5fa606f63f841879af1a7617366d18b4.svg",
      "fullname": "Reshmi Ghosh",
      "name": "reshmighosh",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.03923",
      "authors": [
        {
          "_id": "689452e1741a16f544fbd009",
          "name": "Linxin Song",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd00a",
          "name": "Yutong Dai",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd00b",
          "name": "Viraj Prabhu",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd00c",
          "name": "Jieyu Zhang",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd00d",
          "name": "Taiwei Shi",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd00e",
          "name": "Li Li",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd00f",
          "name": "Junnan Li",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd010",
          "name": "Silvio Savarese",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd011",
          "name": "Zeyuan Chen",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd012",
          "name": "Jieyu Zhao",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd013",
          "name": "Ran Xu",
          "hidden": false
        },
        {
          "_id": "689452e1741a16f544fbd014",
          "name": "Caiming Xiong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-05T21:33:36.000Z",
      "submittedOnDailyAt": "2025-08-08T05:41:50.817Z",
      "title": "CoAct-1: Computer-using Agents with Coding as Actions",
      "submittedOnDailyBy": {
        "_id": "64d660308ebc40443813f014",
        "avatarUrl": "/avatars/516bb2d2383be99794e366dfb41636b6.svg",
        "isPro": false,
        "fullname": "Linxin Song",
        "user": "linxinso",
        "type": "user"
      },
      "summary": "Autonomous agents that operate computers via Graphical User Interfaces (GUIs)\noften struggle with efficiency and reliability on complex, long-horizon tasks.\nWhile augmenting these agents with planners can improve task decomposition,\nthey remain constrained by the inherent limitations of performing all actions\nthrough GUI manipulation, leading to brittleness and inefficiency. In this\nwork, we introduce a more robust and flexible paradigm: enabling agents to use\ncoding as a enhanced action. We present CoAct-1, a novel multi-agent system\nthat synergistically combines GUI-based control with direct programmatic\nexecution. CoAct-1 features an Orchestrator that dynamically delegates subtasks\nto either a conventional GUI Operator or a specialized Programmer agent, which\ncan write and execute Python or Bash scripts. This hybrid approach allows the\nagent to bypass inefficient GUI action sequences for tasks like file management\nand data processing, while still leveraging visual interaction when necessary.\nWe evaluate our system on the challenging OSWorld benchmark, where CoAct-1\nachieves a new state-of-the-art success rate of 60.76%, significantly\noutperforming prior methods. Furthermore, our approach dramatically improves\nefficiency, reducing the average number of steps required to complete a task to\njust 10.15, compared to 15 for leading GUI agents. Our results demonstrate that\nintegrating coding as a core action provides a more powerful, efficient, and\nscalable path toward generalized computer automation.",
      "upvotes": 2,
      "discussionId": "689452e1741a16f544fbd015",
      "ai_summary": "A multi-agent system that combines GUI control with programmatic execution improves efficiency and success in complex computer automation tasks.",
      "ai_keywords": [
        "Graphical User Interfaces (GUIs)",
        "planners",
        "task decomposition",
        "coding",
        "CoAct-1",
        "Orchestrator",
        "GUI Operator",
        "Programmer agent",
        "OSWorld benchmark",
        "success rate",
        "efficiency",
        "steps",
        "computer automation"
      ]
    },
    "publishedAt": "2025-08-05T17:33:36.000Z",
    "title": "CoAct-1: Computer-using Agents with Coding as Actions",
    "summary": "Autonomous agents that operate computers via Graphical User Interfaces (GUIs)\noften struggle with efficiency and reliability on complex, long-horizon tasks.\nWhile augmenting these agents with planners can improve task decomposition,\nthey remain constrained by the inherent limitations of performing all actions\nthrough GUI manipulation, leading to brittleness and inefficiency. In this\nwork, we introduce a more robust and flexible paradigm: enabling agents to use\ncoding as a enhanced action. We present CoAct-1, a novel multi-agent system\nthat synergistically combines GUI-based control with direct programmatic\nexecution. CoAct-1 features an Orchestrator that dynamically delegates subtasks\nto either a conventional GUI Operator or a specialized Programmer agent, which\ncan write and execute Python or Bash scripts. This hybrid approach allows the\nagent to bypass inefficient GUI action sequences for tasks like file management\nand data processing, while still leveraging visual interaction when necessary.\nWe evaluate our system on the challenging OSWorld benchmark, where CoAct-1\nachieves a new state-of-the-art success rate of 60.76%, significantly\noutperforming prior methods. Furthermore, our approach dramatically improves\nefficiency, reducing the average number of steps required to complete a task to\njust 10.15, compared to 15 for leading GUI agents. Our results demonstrate that\nintegrating coding as a core action provides a more powerful, efficient, and\nscalable path toward generalized computer automation.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.03923.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "64d660308ebc40443813f014",
      "avatarUrl": "/avatars/516bb2d2383be99794e366dfb41636b6.svg",
      "fullname": "Linxin Song",
      "name": "linxinso",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.01650",
      "authors": [
        {
          "_id": "68956b8448b0ae5ca2710d91",
          "name": "Na Zhang",
          "hidden": false
        },
        {
          "_id": "68956b8448b0ae5ca2710d92",
          "name": "Moran Li",
          "hidden": false
        },
        {
          "_id": "68956b8448b0ae5ca2710d93",
          "name": "Chengming Xu",
          "hidden": false
        },
        {
          "_id": "68956b8448b0ae5ca2710d94",
          "name": "Han Feng",
          "hidden": false
        },
        {
          "_id": "68956b8448b0ae5ca2710d95",
          "name": "Xiaobin Hu",
          "hidden": false
        },
        {
          "_id": "68956b8448b0ae5ca2710d96",
          "name": "Jiangning Zhang",
          "hidden": false
        },
        {
          "_id": "68956b8448b0ae5ca2710d97",
          "name": "Weijian Cao",
          "hidden": false
        },
        {
          "_id": "68956b8448b0ae5ca2710d98",
          "name": "Chengjie Wang",
          "hidden": false
        },
        {
          "_id": "68956b8448b0ae5ca2710d99",
          "name": "Yanwei Fu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-03T08:17:50.000Z",
      "submittedOnDailyAt": "2025-08-08T01:45:00.424Z",
      "title": "StrandDesigner: Towards Practical Strand Generation with Sketch Guidance",
      "submittedOnDailyBy": {
        "_id": "652fab9d04a34a9282bf29d6",
        "avatarUrl": "/avatars/cd5967b37ebb1225e9ae1d46f196e2e2.svg",
        "isPro": false,
        "fullname": "Chengming Xu",
        "user": "ChengmingX",
        "type": "user"
      },
      "summary": "Realistic hair strand generation is crucial for applications like computer\ngraphics and virtual reality. While diffusion models can generate hairstyles\nfrom text or images, these inputs lack precision and user-friendliness.\nInstead, we propose the first sketch-based strand generation model, which\noffers finer control while remaining user-friendly. Our framework tackles key\nchallenges, such as modeling complex strand interactions and diverse sketch\npatterns, through two main innovations: a learnable strand upsampling strategy\nthat encodes 3D strands into multi-scale latent spaces, and a multi-scale\nadaptive conditioning mechanism using a transformer with diffusion heads to\nensure consistency across granularity levels. Experiments on several benchmark\ndatasets show our method outperforms existing approaches in realism and\nprecision. Qualitative results further confirm its effectiveness. Code will be\nreleased at [GitHub](https://github.com/fighting-Zhang/StrandDesigner).",
      "upvotes": 2,
      "discussionId": "68956b8548b0ae5ca2710d9a",
      "githubRepo": "https://github.com/fighting-Zhang/StrandDesigner",
      "ai_summary": "A sketch-based strand generation model using a learnable upsampling strategy and multi-scale adaptive conditioning mechanism outperforms existing methods in realism and precision for hair strand generation.",
      "ai_keywords": [
        "diffusion models",
        "sketch-based generation",
        "learnable strand upsampling",
        "multi-scale latent spaces",
        "multi-scale adaptive conditioning",
        "transformer",
        "diffusion heads"
      ],
      "githubStars": 1
    },
    "publishedAt": "2025-08-03T04:17:50.000Z",
    "title": "StrandDesigner: Towards Practical Strand Generation with Sketch Guidance",
    "summary": "Realistic hair strand generation is crucial for applications like computer\ngraphics and virtual reality. While diffusion models can generate hairstyles\nfrom text or images, these inputs lack precision and user-friendliness.\nInstead, we propose the first sketch-based strand generation model, which\noffers finer control while remaining user-friendly. Our framework tackles key\nchallenges, such as modeling complex strand interactions and diverse sketch\npatterns, through two main innovations: a learnable strand upsampling strategy\nthat encodes 3D strands into multi-scale latent spaces, and a multi-scale\nadaptive conditioning mechanism using a transformer with diffusion heads to\nensure consistency across granularity levels. Experiments on several benchmark\ndatasets show our method outperforms existing approaches in realism and\nprecision. Qualitative results further confirm its effectiveness. Code will be\nreleased at [GitHub](https://github.com/fighting-Zhang/StrandDesigner).",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.01650.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "652fab9d04a34a9282bf29d6",
      "avatarUrl": "/avatars/cd5967b37ebb1225e9ae1d46f196e2e2.svg",
      "fullname": "Chengming Xu",
      "name": "ChengmingX",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.05545",
      "authors": [
        {
          "_id": "6895810a48b0ae5ca2710df2",
          "name": "Leon Garza",
          "hidden": false
        },
        {
          "_id": "6895810a48b0ae5ca2710df3",
          "name": "Anantaa Kotal",
          "hidden": false
        },
        {
          "_id": "6895810a48b0ae5ca2710df4",
          "name": "Aritran Piplai",
          "hidden": false
        },
        {
          "_id": "6895810a48b0ae5ca2710df5",
          "name": "Lavanya Elluri",
          "hidden": false
        },
        {
          "_id": "6895810a48b0ae5ca2710df6",
          "name": "Prajit Das",
          "hidden": false
        },
        {
          "_id": "6895810a48b0ae5ca2710df7",
          "name": "Aman Chadha",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-07T16:22:49.000Z",
      "submittedOnDailyAt": "2025-08-08T03:17:48.266Z",
      "title": "PRvL: Quantifying the Capabilities and Risks of Large Language Models\n  for PII Redaction",
      "submittedOnDailyBy": {
        "_id": "63a4754927f1f64ed7238dac",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
        "isPro": false,
        "fullname": "Aman Chadha",
        "user": "amanchadha",
        "type": "user"
      },
      "summary": "Redacting Personally Identifiable Information (PII) from unstructured text is\ncritical for ensuring data privacy in regulated domains. While earlier\napproaches have relied on rule-based systems and domain-specific Named Entity\nRecognition (NER) models, these methods fail to generalize across formats and\ncontexts. Recent advances in Large Language Models (LLMs) offer a promising\nalternative, yet the effect of architectural and training choices on redaction\nperformance remains underexplored. LLMs have demonstrated strong performance in\ntasks that require contextual language understanding, including the redaction\nof PII in free-form text. Prior work suggests that with appropriate adaptation,\nLLMs can become effective contextual privacy learners. However, the\nconsequences of architectural and training choices for PII Redaction remain\nunderexplored. In this work, we present a comprehensive analysis of LLMs as\nprivacy-preserving PII Redaction systems. We evaluate a range of LLM\narchitectures and training strategies for their effectiveness in PII Redaction.\nOur analysis measures redaction performance, semantic preservation, and PII\nleakage, and compares these outcomes against latency and computational cost.\nThe results provide practical guidance for configuring LLM-based redactors that\nare accurate, efficient, and privacy-aware. To support reproducibility and\nreal-world deployment, we release PRvL, an open-source suite of fine-tuned\nmodels, and evaluation tools for general-purpose PII Redaction. PRvL is built\nentirely on open-source LLMs and supports multiple inference settings for\nflexibility and compliance. It is designed to be easily customized for\ndifferent domains and fully operable within secure, self-managed environments.\nThis enables data owners to perform redactions without relying on third-party\nservices or exposing sensitive content beyond their own infrastructure.",
      "upvotes": 1,
      "discussionId": "6895810a48b0ae5ca2710df8",
      "ai_summary": "A comprehensive analysis of Large Language Models for PII redaction evaluates various architectures and training strategies, providing guidance for accurate, efficient, and privacy-aware redaction systems.",
      "ai_keywords": [
        "Large Language Models",
        "Named Entity Recognition",
        "PII Redaction",
        "semantic preservation",
        "PII leakage",
        "latency",
        "computational cost",
        "fine-tuned models",
        "evaluation tools",
        "open-source LLMs",
        "inference settings",
        "secure",
        "self-managed environments"
      ]
    },
    "publishedAt": "2025-08-07T12:22:49.000Z",
    "title": "PRvL: Quantifying the Capabilities and Risks of Large Language Models\n  for PII Redaction",
    "summary": "Redacting Personally Identifiable Information (PII) from unstructured text is\ncritical for ensuring data privacy in regulated domains. While earlier\napproaches have relied on rule-based systems and domain-specific Named Entity\nRecognition (NER) models, these methods fail to generalize across formats and\ncontexts. Recent advances in Large Language Models (LLMs) offer a promising\nalternative, yet the effect of architectural and training choices on redaction\nperformance remains underexplored. LLMs have demonstrated strong performance in\ntasks that require contextual language understanding, including the redaction\nof PII in free-form text. Prior work suggests that with appropriate adaptation,\nLLMs can become effective contextual privacy learners. However, the\nconsequences of architectural and training choices for PII Redaction remain\nunderexplored. In this work, we present a comprehensive analysis of LLMs as\nprivacy-preserving PII Redaction systems. We evaluate a range of LLM\narchitectures and training strategies for their effectiveness in PII Redaction.\nOur analysis measures redaction performance, semantic preservation, and PII\nleakage, and compares these outcomes against latency and computational cost.\nThe results provide practical guidance for configuring LLM-based redactors that\nare accurate, efficient, and privacy-aware. To support reproducibility and\nreal-world deployment, we release PRvL, an open-source suite of fine-tuned\nmodels, and evaluation tools for general-purpose PII Redaction. PRvL is built\nentirely on open-source LLMs and supports multiple inference settings for\nflexibility and compliance. It is designed to be easily customized for\ndifferent domains and fully operable within secure, self-managed environments.\nThis enables data owners to perform redactions without relying on third-party\nservices or exposing sensitive content beyond their own infrastructure.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.05545.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a4754927f1f64ed7238dac",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
      "fullname": "Aman Chadha",
      "name": "amanchadha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.04946",
      "authors": [
        {
          "_id": "68958b7348b0ae5ca2710e0e",
          "name": "Nameer Hirschkind",
          "hidden": false
        },
        {
          "_id": "68958b7348b0ae5ca2710e0f",
          "name": "Joseph Liu",
          "hidden": false
        },
        {
          "_id": "68958b7348b0ae5ca2710e10",
          "name": "Mahesh Kumar Nandwana",
          "hidden": false
        },
        {
          "_id": "68958b7348b0ae5ca2710e11",
          "name": "Xiao Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-07T00:25:58.000Z",
      "submittedOnDailyAt": "2025-08-08T04:03:02.436Z",
      "title": "REINA: Regularized Entropy Information-Based Loss for Efficient\n  Simultaneous Speech Translation",
      "submittedOnDailyBy": {
        "_id": "667f437aa94430cd2e723346",
        "avatarUrl": "/avatars/c7d71f6789756082e129b0b9cf9dcfda.svg",
        "isPro": false,
        "fullname": "Mahesh Nandwana",
        "user": "mnandwana",
        "type": "user"
      },
      "summary": "Simultaneous Speech Translation (SimulST) systems stream in audio while\nsimultaneously emitting translated text or speech. Such systems face the\nsignificant challenge of balancing translation quality and latency. We\nintroduce a strategy to optimize this tradeoff: wait for more input only if you\ngain information by doing so. Based on this strategy, we present Regularized\nEntropy INformation Adaptation (REINA), a novel loss to train an adaptive\npolicy using an existing non-streaming translation model. We derive REINA from\ninformation theory principles and show that REINA helps push the reported\nPareto frontier of the latency/quality tradeoff over prior works. Utilizing\nREINA, we train a SimulST model on French, Spanish and German, both from and\ninto English. Training on only open source or synthetically generated data, we\nachieve state-of-the-art (SOTA) streaming results for models of comparable\nsize. We also introduce a metric for streaming efficiency, quantitatively\nshowing REINA improves the latency/quality trade-off by as much as 21% compared\nto prior approaches, normalized against non-streaming baseline BLEU scores.",
      "upvotes": 1,
      "discussionId": "68958b7348b0ae5ca2710e12",
      "ai_summary": "A novel loss function, REINA, optimizes the latency-quality tradeoff in Simultaneous Speech Translation by adaptively waiting for more input based on information gain.",
      "ai_keywords": [
        "Simultaneous Speech Translation",
        "SimulST",
        "Regularized Entropy INformation Adaptation",
        "REINA",
        "information theory",
        "Pareto frontier",
        "streaming efficiency",
        "BLEU scores"
      ]
    },
    "publishedAt": "2025-08-06T20:25:58.000Z",
    "title": "REINA: Regularized Entropy Information-Based Loss for Efficient\n  Simultaneous Speech Translation",
    "summary": "Simultaneous Speech Translation (SimulST) systems stream in audio while\nsimultaneously emitting translated text or speech. Such systems face the\nsignificant challenge of balancing translation quality and latency. We\nintroduce a strategy to optimize this tradeoff: wait for more input only if you\ngain information by doing so. Based on this strategy, we present Regularized\nEntropy INformation Adaptation (REINA), a novel loss to train an adaptive\npolicy using an existing non-streaming translation model. We derive REINA from\ninformation theory principles and show that REINA helps push the reported\nPareto frontier of the latency/quality tradeoff over prior works. Utilizing\nREINA, we train a SimulST model on French, Spanish and German, both from and\ninto English. Training on only open source or synthetically generated data, we\nachieve state-of-the-art (SOTA) streaming results for models of comparable\nsize. We also introduce a metric for streaming efficiency, quantitatively\nshowing REINA improves the latency/quality trade-off by as much as 21% compared\nto prior approaches, normalized against non-streaming baseline BLEU scores.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.04946.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "667f437aa94430cd2e723346",
      "avatarUrl": "/avatars/c7d71f6789756082e129b0b9cf9dcfda.svg",
      "fullname": "Mahesh Nandwana",
      "name": "mnandwana",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.04939",
      "authors": [
        {
          "_id": "6895813348b0ae5ca2710e03",
          "name": "Julia Kharchenko",
          "hidden": false
        },
        {
          "_id": "6895813348b0ae5ca2710e04",
          "name": "Tanya Roosta",
          "hidden": false
        },
        {
          "_id": "6895813348b0ae5ca2710e05",
          "name": "Aman Chadha",
          "hidden": false
        },
        {
          "_id": "6895813348b0ae5ca2710e06",
          "name": "Chirag Shah",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-06T23:51:03.000Z",
      "submittedOnDailyAt": "2025-08-08T03:17:24.461Z",
      "title": "I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating\n  Linguistic Shibboleth Detection in LLM Hiring Evaluations",
      "submittedOnDailyBy": {
        "_id": "63a4754927f1f64ed7238dac",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
        "isPro": false,
        "fullname": "Aman Chadha",
        "user": "amanchadha",
        "type": "user"
      },
      "summary": "This paper introduces a comprehensive benchmark for evaluating how Large\nLanguage Models (LLMs) respond to linguistic shibboleths: subtle linguistic\nmarkers that can inadvertently reveal demographic attributes such as gender,\nsocial class, or regional background. Through carefully constructed interview\nsimulations using 100 validated question-response pairs, we demonstrate how\nLLMs systematically penalize certain linguistic patterns, particularly hedging\nlanguage, despite equivalent content quality. Our benchmark generates\ncontrolled linguistic variations that isolate specific phenomena while\nmaintaining semantic equivalence, which enables the precise measurement of\ndemographic bias in automated evaluation systems. We validate our approach\nalong multiple linguistic dimensions, showing that hedged responses receive\n25.6% lower ratings on average, and demonstrate the benchmark's effectiveness\nin identifying model-specific biases. This work establishes a foundational\nframework for detecting and measuring linguistic discrimination in AI systems,\nwith broad applications to fairness in automated decision-making contexts.",
      "upvotes": 1,
      "discussionId": "6895813348b0ae5ca2710e07",
      "ai_summary": "A benchmark evaluates Large Language Models' response to linguistic markers that reveal demographic attributes, demonstrating systematic penalization of hedging language despite equivalent content quality.",
      "ai_keywords": [
        "Large Language Models",
        "linguistic shibboleths",
        "hedging language",
        "interview simulations",
        "linguistic dimensions",
        "demographic bias",
        "automated evaluation systems",
        "linguistic discrimination",
        "fairness in automated decision-making"
      ]
    },
    "publishedAt": "2025-08-06T19:51:03.000Z",
    "title": "I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating\n  Linguistic Shibboleth Detection in LLM Hiring Evaluations",
    "summary": "This paper introduces a comprehensive benchmark for evaluating how Large\nLanguage Models (LLMs) respond to linguistic shibboleths: subtle linguistic\nmarkers that can inadvertently reveal demographic attributes such as gender,\nsocial class, or regional background. Through carefully constructed interview\nsimulations using 100 validated question-response pairs, we demonstrate how\nLLMs systematically penalize certain linguistic patterns, particularly hedging\nlanguage, despite equivalent content quality. Our benchmark generates\ncontrolled linguistic variations that isolate specific phenomena while\nmaintaining semantic equivalence, which enables the precise measurement of\ndemographic bias in automated evaluation systems. We validate our approach\nalong multiple linguistic dimensions, showing that hedged responses receive\n25.6% lower ratings on average, and demonstrate the benchmark's effectiveness\nin identifying model-specific biases. This work establishes a foundational\nframework for detecting and measuring linguistic discrimination in AI systems,\nwith broad applications to fairness in automated decision-making contexts.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.04939.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a4754927f1f64ed7238dac",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
      "fullname": "Aman Chadha",
      "name": "amanchadha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  }
]