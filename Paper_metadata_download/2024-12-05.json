[
    {
        "paper": {
            "id": "2412.02687",
            "authors": [
                {
                    "_id": "674fd4fe696ab96e57021fbf",
                    "user": {
                        "_id": "643684cdc81d1646aa6b93a5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643684cdc81d1646aa6b93a5/iyLQfKMBCJJjfOJB2zvfp.png",
                        "isPro": false,
                        "fullname": "Viet Nguyen",
                        "user": "viettmab",
                        "type": "user"
                    },
                    "name": "Viet Nguyen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-04T09:44:28.182Z",
                    "hidden": false
                },
                {
                    "_id": "674fd4fe696ab96e57021fc0",
                    "user": {
                        "_id": "6397329eb3d9042831c885af",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6397329eb3d9042831c885af/sEIXpwBDv6dl5iUdsjA1I.jpeg",
                        "isPro": false,
                        "fullname": "Anh Nguyen (Aengus)",
                        "user": "aengusng",
                        "type": "user"
                    },
                    "name": "Anh Aengus Nguyen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-04T09:44:30.839Z",
                    "hidden": false
                },
                {
                    "_id": "674fd4fe696ab96e57021fc1",
                    "user": {
                        "_id": "64d265019badd06a0587c848",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64d265019badd06a0587c848/qrOtJ7gxUCzgVwduFDktf.jpeg",
                        "isPro": false,
                        "fullname": "Dao Tuan Trung",
                        "user": "termanteus",
                        "type": "user"
                    },
                    "name": "Trung Dao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:18:50.613Z",
                    "hidden": false
                },
                {
                    "_id": "674fd4fe696ab96e57021fc2",
                    "name": "Khoi Nguyen",
                    "hidden": false
                },
                {
                    "_id": "674fd4fe696ab96e57021fc3",
                    "name": "Cuong Pham",
                    "hidden": false
                },
                {
                    "_id": "674fd4fe696ab96e57021fc4",
                    "name": "Toan Tran",
                    "hidden": false
                },
                {
                    "_id": "674fd4fe696ab96e57021fc5",
                    "user": {
                        "_id": "63e9fc6174f940d171e4c5e9",
                        "avatarUrl": "/avatars/0c34fdaecd7bd8aaffb3d68e83c0eeaf.svg",
                        "isPro": false,
                        "fullname": "Anh Tran",
                        "user": "anhttran1111",
                        "type": "user"
                    },
                    "name": "Anh Tran",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:18:48.756Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-03T18:56:32.000Z",
            "title": "SNOOPI: Supercharged One-step Diffusion Distillation with Proper\n  Guidance",
            "summary": "Recent approaches have yielded promising results in distilling multi-step\ntext-to-image diffusion models into one-step ones. The state-of-the-art\nefficient distillation technique, i.e., SwiftBrushv2 (SBv2), even surpasses the\nteacher model's performance with limited resources. However, our study reveals\nits instability when handling different diffusion model backbones due to using\na fixed guidance scale within the Variational Score Distillation (VSD) loss.\nAnother weakness of the existing one-step diffusion models is the missing\nsupport for negative prompt guidance, which is crucial in practical image\ngeneration. This paper presents SNOOPI, a novel framework designed to address\nthese limitations by enhancing the guidance in one-step diffusion models during\nboth training and inference. First, we effectively enhance training stability\nthrough Proper Guidance-SwiftBrush (PG-SB), which employs a random-scale\nclassifier-free guidance approach. By varying the guidance scale of both\nteacher models, we broaden their output distributions, resulting in a more\nrobust VSD loss that enables SB to perform effectively across diverse backbones\nwhile maintaining competitive performance. Second, we propose a training-free\nmethod called Negative-Away Steer Attention (NASA), which integrates negative\nprompts into one-step diffusion models via cross-attention to suppress\nundesired elements in generated images. Our experimental results show that our\nproposed methods significantly improve baseline models across various metrics.\nRemarkably, we achieve an HPSv2 score of 31.08, setting a new state-of-the-art\nbenchmark for one-step diffusion models.",
            "upvotes": 36,
            "discussionId": "674fd501696ab96e570221b8"
        },
        "publishedAt": "2024-12-05T02:10:17.743Z",
        "title": "SNOOPI: Supercharged One-step Diffusion Distillation with Proper Guidance",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/643684cdc81d1646aa6b93a5/Spgg_HwQ_pYsmG5nDc4wZ.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.02687.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "643684cdc81d1646aa6b93a5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643684cdc81d1646aa6b93a5/iyLQfKMBCJJjfOJB2zvfp.png",
            "fullname": "Viet Nguyen",
            "name": "viettmab",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.03555",
            "authors": [
                {
                    "_id": "675159fd74b66f2e014ede09",
                    "name": "Andreas Steiner",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede0a",
                    "name": "AndrÃ© Susano Pinto",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede0b",
                    "user": {
                        "_id": "6489893e1ec8356ba5bb9777",
                        "avatarUrl": "/avatars/54354c1e5774cadd1d83d42054e9d96b.svg",
                        "isPro": false,
                        "fullname": "Michael Tschannen",
                        "user": "mitsch",
                        "type": "user"
                    },
                    "name": "Michael Tschannen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:40:57.297Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede0c",
                    "user": {
                        "_id": "662fc73ccee11621a1067db1",
                        "avatarUrl": "/avatars/4fbfbc0621f631d8e95a2a642fa0cd27.svg",
                        "isPro": false,
                        "fullname": "Daniel Keysers",
                        "user": "dkeysers",
                        "type": "user"
                    },
                    "name": "Daniel Keysers",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:43:54.472Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede0d",
                    "name": "Xiao Wang",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede0e",
                    "user": {
                        "_id": "632e0771ae0a7b1fc95630bf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1663961181981-632e0771ae0a7b1fc95630bf.jpeg",
                        "isPro": false,
                        "fullname": "Yonatan",
                        "user": "yonatanbitton",
                        "type": "user"
                    },
                    "name": "Yonatan Bitton",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:40:46.933Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede0f",
                    "user": {
                        "_id": "62d8f9887b8dc0ba17271415",
                        "avatarUrl": "/avatars/12ec78d34fd849bad44217b212f31e98.svg",
                        "isPro": false,
                        "fullname": "Alexey Gritsenko",
                        "user": "AlexeyG",
                        "type": "user"
                    },
                    "name": "Alexey Gritsenko",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:40:40.352Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede10",
                    "user": {
                        "_id": "649ac6e57c36fc2dc6e6b0f4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/649ac6e57c36fc2dc6e6b0f4/Scd3LiYW5Y2qunDDHnPWw.jpeg",
                        "isPro": false,
                        "fullname": "Matthias Minderer",
                        "user": "mjlm",
                        "type": "user"
                    },
                    "name": "Matthias Minderer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:40:35.142Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede11",
                    "user": {
                        "_id": "65986c7fbf533e3c0dd00d83",
                        "avatarUrl": "/avatars/d038ad9e50002ab4ef99e34d4ba369e7.svg",
                        "isPro": false,
                        "fullname": "Anthony Sherbondy",
                        "user": "asherbondy",
                        "type": "user"
                    },
                    "name": "Anthony Sherbondy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:40:29.132Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede12",
                    "user": {
                        "_id": "6525e3d136f98a576aa3d2a8",
                        "avatarUrl": "/avatars/b5a12dd73ff05ae38c4d60d685db7c08.svg",
                        "isPro": false,
                        "fullname": "ShangbangLong",
                        "user": "Shangbang",
                        "type": "user"
                    },
                    "name": "Shangbang Long",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:40:23.703Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede13",
                    "name": "Siyang Qin",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede14",
                    "name": "Reeve Ingle",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede15",
                    "user": {
                        "_id": "626a9284783d5891f45beb53",
                        "avatarUrl": "/avatars/8737662babc5d42cafba6087ab33e716.svg",
                        "isPro": false,
                        "fullname": "Emanuele Bugliarello",
                        "user": "e-bug",
                        "type": "user"
                    },
                    "name": "Emanuele Bugliarello",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:40:04.842Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede16",
                    "name": "Sahar Kazemzadeh",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede17",
                    "user": {
                        "_id": "6639adab8eb8c9c62ac3fb15",
                        "avatarUrl": "/avatars/83133b04922143be1d8a1fb71fb2938f.svg",
                        "isPro": false,
                        "fullname": "Thomas Mesnard",
                        "user": "thomasmesnard",
                        "type": "user"
                    },
                    "name": "Thomas Mesnard",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:39:55.694Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede18",
                    "user": {
                        "_id": "630545da20668afe24860235",
                        "avatarUrl": "/avatars/5d82be2e7412bff1af15cc5eafa60b7d.svg",
                        "isPro": false,
                        "fullname": "Ibrahim Alabdulmohsin",
                        "user": "ibomohsin",
                        "type": "user"
                    },
                    "name": "Ibrahim Alabdulmohsin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:39:49.864Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede19",
                    "user": {
                        "_id": "642d334ff65714b4585f2de4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642d334ff65714b4585f2de4/gxBynq5KyoUP0VlAQD3-w.jpeg",
                        "isPro": false,
                        "fullname": "Lucas Beyer",
                        "user": "giffmana",
                        "type": "user"
                    },
                    "name": "Lucas Beyer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:39:44.061Z",
                    "hidden": false
                },
                {
                    "_id": "675159fd74b66f2e014ede1a",
                    "user": {
                        "_id": "65dcd90082bddd501f68174b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/M2bc9PyKeFs1cCXjTfGGq.jpeg",
                        "isPro": false,
                        "fullname": "Xiaohua Zhai",
                        "user": "xiaohuazhai",
                        "type": "user"
                    },
                    "name": "Xiaohua Zhai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:39:18.732Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T18:50:42.000Z",
            "title": "PaliGemma 2: A Family of Versatile VLMs for Transfer",
            "summary": "PaliGemma 2 is an upgrade of the PaliGemma open Vision-Language Model (VLM)\nbased on the Gemma 2 family of language models. We combine the SigLIP-So400m\nvision encoder that was also used by PaliGemma with the whole range of Gemma 2\nmodels, from the 2B one all the way up to the 27B model. We train these models\nat three resolutions (224px, 448px, and 896px) in multiple stages to equip them\nwith broad knowledge for transfer via fine-tuning. The resulting family of base\nmodels covering different model sizes and resolutions allows us to investigate\nfactors impacting transfer performance (such as learning rate) and to analyze\nthe interplay between the type of task, model size, and resolution. We further\nincrease the number and breadth of transfer tasks beyond the scope of PaliGemma\nincluding different OCR-related tasks such as table structure recognition,\nmolecular structure recognition, music score recognition, as well as long\nfine-grained captioning and radiography report generation, on which PaliGemma 2\nobtains state-of-the-art results.",
            "upvotes": 34,
            "discussionId": "675159fe74b66f2e014ede63"
        },
        "publishedAt": "2024-12-05T04:34:15.968Z",
        "title": "PaliGemma 2: A Family of Versatile VLMs for Transfer",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03555.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6032802e1f993496bc14d9e3",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6032802e1f993496bc14d9e3/w6hr-DEQot4VVkoyRIBiy.png",
            "fullname": "Omar Sanseviero",
            "name": "osanseviero",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2894
        }
    },
    {
        "paper": {
            "id": "2412.03552",
            "authors": [
                {
                    "_id": "675118447679a2657e4d1369",
                    "user": {
                        "_id": "65367c40061949598892dbdc",
                        "avatarUrl": "/avatars/4baf27263841471cbd5f629a8b99424d.svg",
                        "isPro": false,
                        "fullname": "Jing Tan",
                        "user": "jingtan",
                        "type": "user"
                    },
                    "name": "Jing Tan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T09:33:59.672Z",
                    "hidden": false
                },
                {
                    "_id": "675118447679a2657e4d136a",
                    "name": "Shuai Yang",
                    "hidden": false
                },
                {
                    "_id": "675118447679a2657e4d136b",
                    "user": {
                        "_id": "62fae9328e137d7c4b896498",
                        "avatarUrl": "/avatars/1bda39dec585c099417cc9daa9f53c42.svg",
                        "isPro": false,
                        "fullname": "Tong Wu",
                        "user": "tongwu2020",
                        "type": "user"
                    },
                    "name": "Tong Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T09:33:26.828Z",
                    "hidden": false
                },
                {
                    "_id": "675118447679a2657e4d136c",
                    "user": {
                        "_id": "670749a9d827da9f37508209",
                        "avatarUrl": "/avatars/f14fc05ad405f3967b9af0bcc73d4207.svg",
                        "isPro": false,
                        "fullname": "he jingwen",
                        "user": "mimihe",
                        "type": "user"
                    },
                    "name": "Jingwen He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T09:33:19.535Z",
                    "hidden": false
                },
                {
                    "_id": "675118447679a2657e4d136d",
                    "user": {
                        "_id": "6371f83d5ffa922d638ef486",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6371f83d5ffa922d638ef486/UzWl3xhVvtol3Rz1mjQ9t.jpeg",
                        "isPro": false,
                        "fullname": "Yuwei Guo",
                        "user": "guoyww",
                        "type": "user"
                    },
                    "name": "Yuwei Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T09:33:06.811Z",
                    "hidden": false
                },
                {
                    "_id": "675118447679a2657e4d136e",
                    "user": {
                        "_id": "62ab1ac1d48b4d8b048a3473",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
                        "isPro": false,
                        "fullname": "Ziwei Liu",
                        "user": "liuziwei7",
                        "type": "user"
                    },
                    "name": "Ziwei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T09:32:44.270Z",
                    "hidden": false
                },
                {
                    "_id": "675118447679a2657e4d136f",
                    "user": {
                        "_id": "636317ed80c1a705a6eff396",
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T09:32:38.520Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T18:50:08.000Z",
            "title": "Imagine360: Immersive 360 Video Generation from Perspective Anchor",
            "summary": "360^circ videos offer a hyper-immersive experience that allows the viewers\nto explore a dynamic scene from full 360 degrees. To achieve more user-friendly\nand personalized content creation in 360^circ video format, we seek to lift\nstandard perspective videos into 360^circ equirectangular videos. To this\nend, we introduce Imagine360, the first perspective-to-360^circ video\ngeneration framework that creates high-quality 360^circ videos with rich and\ndiverse motion patterns from video anchors. Imagine360 learns fine-grained\nspherical visual and motion patterns from limited 360^circ video data with\nseveral key designs. 1) Firstly we adopt the dual-branch design, including a\nperspective and a panorama video denoising branch to provide local and global\nconstraints for 360^circ video generation, with motion module and spatial\nLoRA layers fine-tuned on extended web 360^circ videos. 2) Additionally, an\nantipodal mask is devised to capture long-range motion dependencies, enhancing\nthe reversed camera motion between antipodal pixels across hemispheres. 3) To\nhandle diverse perspective video inputs, we propose elevation-aware designs\nthat adapt to varying video masking due to changing elevations across frames.\nExtensive experiments show Imagine360 achieves superior graphics quality and\nmotion coherence among state-of-the-art 360^circ video generation methods.\nWe believe Imagine360 holds promise for advancing personalized, immersive\n360^circ video creation.",
            "upvotes": 23,
            "discussionId": "6751184a7679a2657e4d15b0"
        },
        "publishedAt": "2024-12-04T22:43:06.280Z",
        "title": "Imagine360: Immersive 360 Video Generation from Perspective Anchor",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03552.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "65367c40061949598892dbdc",
            "avatarUrl": "/avatars/4baf27263841471cbd5f629a8b99424d.svg",
            "fullname": "Jing Tan",
            "name": "jingtan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.03515",
            "authors": [
                {
                    "_id": "675115a116e6038a2ac71a80",
                    "user": {
                        "_id": "63943c882b9483beb473ec25",
                        "avatarUrl": "/avatars/abd2aae43e68c34770159c15a01c8297.svg",
                        "isPro": false,
                        "fullname": "Shengyuan Zhang",
                        "user": "SYZhang0805",
                        "type": "user"
                    },
                    "name": "Shengyuan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:25:31.664Z",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a81",
                    "name": "An Zhao",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a82",
                    "name": "Ling Yang",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a83",
                    "name": "Zejian Li",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a84",
                    "user": {
                        "_id": "66d1fb162e0412fa2aa4ffb0",
                        "avatarUrl": "/avatars/20620dd03d388f0262124f0c3523080d.svg",
                        "isPro": false,
                        "fullname": "Chenye Meng",
                        "user": "mengcy",
                        "type": "user"
                    },
                    "name": "Chenye Meng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:25:41.733Z",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a85",
                    "user": {
                        "_id": "61384b860317b0a5c10877d3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1631080954171-61384b860317b0a5c10877d3.jpeg",
                        "isPro": false,
                        "fullname": "Haoran Xu",
                        "user": "haoranxu",
                        "type": "user"
                    },
                    "name": "Haoran Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T09:44:09.643Z",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a86",
                    "name": "Tianrun Chen",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a87",
                    "name": "AnYang Wei",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a88",
                    "name": "Perry Pengyun GU",
                    "hidden": false
                },
                {
                    "_id": "675115a116e6038a2ac71a89",
                    "user": {
                        "_id": "662a5c0649e03000ed1adab4",
                        "avatarUrl": "/avatars/961e4b9bf923923fcd871672d156f50c.svg",
                        "isPro": false,
                        "fullname": "Lingyun Sun",
                        "user": "slysun",
                        "type": "user"
                    },
                    "name": "Lingyun Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T09:34:14.648Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T17:57:25.000Z",
            "title": "Distilling Diffusion Models to Efficient 3D LiDAR Scene Completion",
            "summary": "Diffusion models have been applied to 3D LiDAR scene completion due to their\nstrong training stability and high completion quality. However, the slow\nsampling speed limits the practical application of diffusion-based scene\ncompletion models since autonomous vehicles require an efficient perception of\nsurrounding environments. This paper proposes a novel distillation method\ntailored for 3D LiDAR scene completion models, dubbed ScoreLiDAR,\nwhich achieves efficient yet high-quality scene completion. ScoreLiDAR enables\nthe distilled model to sample in significantly fewer steps after distillation.\nTo improve completion quality, we also introduce a novel Structural\nLoss, which encourages the distilled model to capture the geometric structure\nof the 3D LiDAR scene. The loss contains a scene-wise term constraining the\nholistic structure and a point-wise term constraining the key landmark points\nand their relative configuration. Extensive experiments demonstrate that\nScoreLiDAR significantly accelerates the completion time from 30.55 to 5.37\nseconds per frame (>5times) on SemanticKITTI and achieves superior\nperformance compared to state-of-the-art 3D LiDAR scene completion models. Our\ncode is publicly available at https://github.com/happyw1nd/ScoreLiDAR.",
            "upvotes": 21,
            "discussionId": "675115a516e6038a2ac71c0c"
        },
        "publishedAt": "2024-12-04T21:56:58.562Z",
        "title": "Distilling Diffusion Models to Efficient 3D LiDAR Scene Completion",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03515.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63943c882b9483beb473ec25",
            "avatarUrl": "/avatars/abd2aae43e68c34770159c15a01c8297.svg",
            "fullname": "Shengyuan Zhang",
            "name": "SYZhang0805",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2412.03069",
            "authors": [
                {
                    "_id": "6751173f4af3ce83f1c4304b",
                    "user": {
                        "_id": "64b796079ebb7e6c7ddcdabf",
                        "avatarUrl": "/avatars/51af43cab078705b8745b4f942f542e5.svg",
                        "isPro": false,
                        "fullname": "Liao Qu",
                        "user": "leo1117",
                        "type": "user"
                    },
                    "name": "Liao Qu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:18:17.156Z",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c4304c",
                    "user": {
                        "_id": "636241c6b64a56694266509f",
                        "avatarUrl": "/avatars/90bf6156b649b78db13f08d0770951ad.svg",
                        "isPro": false,
                        "fullname": "zhanghuichao",
                        "user": "liqingzju",
                        "type": "user"
                    },
                    "name": "Huichao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:30:59.799Z",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c4304d",
                    "name": "Yiheng Liu",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c4304e",
                    "user": {
                        "_id": "63058fb180bc5e03dad44526",
                        "avatarUrl": "/avatars/1ce11be2c93a2165c4114ab1f45a2dd1.svg",
                        "isPro": false,
                        "fullname": "Xu Wang",
                        "user": "xuwang",
                        "type": "user"
                    },
                    "name": "Xu Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:30:29.060Z",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c4304f",
                    "name": "Yi Jiang",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c43050",
                    "user": {
                        "_id": "64898022658cf96af857bbae",
                        "avatarUrl": "/avatars/6d6904ec9f1fee8b4b5d6009723cf271.svg",
                        "isPro": false,
                        "fullname": "yiminggao",
                        "user": "gaozong",
                        "type": "user"
                    },
                    "name": "Yiming Gao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:30:21.929Z",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c43051",
                    "name": "Hu Ye",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c43052",
                    "name": "Daniel K. Du",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c43053",
                    "user": {
                        "_id": "661a80af3557013b638061d5",
                        "avatarUrl": "/avatars/4c551aeb223e257a5fc45b5b6c7ded49.svg",
                        "isPro": false,
                        "fullname": "Zehuan Yuan",
                        "user": "sweetrabor",
                        "type": "user"
                    },
                    "name": "Zehuan Yuan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:29:52.065Z",
                    "hidden": false
                },
                {
                    "_id": "6751173f4af3ce83f1c43054",
                    "name": "Xinglong Wu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T06:46:55.000Z",
            "title": "TokenFlow: Unified Image Tokenizer for Multimodal Understanding and\n  Generation",
            "summary": "We present TokenFlow, a novel unified image tokenizer that bridges the\nlong-standing gap between multimodal understanding and generation. Prior\nresearch attempt to employ a single reconstruction-targeted Vector Quantization\n(VQ) encoder for unifying these two tasks. We observe that understanding and\ngeneration require fundamentally different granularities of visual information.\nThis leads to a critical trade-off, particularly compromising performance in\nmultimodal understanding tasks. TokenFlow addresses this challenge through an\ninnovative dual-codebook architecture that decouples semantic and pixel-level\nfeature learning while maintaining their alignment via a shared mapping\nmechanism. This design enables direct access to both high-level semantic\nrepresentations crucial for understanding tasks and fine-grained visual\nfeatures essential for generation through shared indices. Our extensive\nexperiments demonstrate TokenFlow's superiority across multiple dimensions.\nLeveraging TokenFlow, we demonstrate for the first time that discrete visual\ninput can surpass LLaVA-1.5 13B in understanding performance, achieving a 7.2\\%\naverage improvement. For image reconstruction, we achieve a strong FID score of\n0.63 at 384*384 resolution. Moreover, TokenFlow establishes state-of-the-art\nperformance in autoregressive image generation with a GenEval score of 0.55 at\n256*256 resolution, achieving comparable results to SDXL.",
            "upvotes": 16,
            "discussionId": "675117464af3ce83f1c4368b"
        },
        "publishedAt": "2024-12-04T22:05:33.523Z",
        "title": "TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03069.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64b796079ebb7e6c7ddcdabf",
            "avatarUrl": "/avatars/51af43cab078705b8745b4f942f542e5.svg",
            "fullname": "Liao Qu",
            "name": "leo1117",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.03517",
            "authors": [
                {
                    "_id": "675136f914bae121c8dcd5dc",
                    "user": {
                        "_id": "66837d3c48edefb453b0640a",
                        "avatarUrl": "/avatars/b16385eaa612578728e2c6460a76b38f.svg",
                        "isPro": true,
                        "fullname": "Lingen Li",
                        "user": "l-li",
                        "type": "user"
                    },
                    "name": "Lingen Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:18:08.139Z",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5dd",
                    "user": {
                        "_id": "658409ceca19ccf6d9989add",
                        "avatarUrl": "/avatars/3ac1dbd25e52435185babdeb3da28875.svg",
                        "isPro": false,
                        "fullname": "Zhaoyang Zhang",
                        "user": "ZyZcuhk",
                        "type": "user"
                    },
                    "name": "Zhaoyang Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:18:10.618Z",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5de",
                    "user": {
                        "_id": "6362801380c1a705a6ea54ac",
                        "avatarUrl": "/avatars/041ad5abf9be42e336938f51ebb8746c.svg",
                        "isPro": false,
                        "fullname": "Yaowei Li",
                        "user": "Yw22",
                        "type": "user"
                    },
                    "name": "Yaowei Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:26:02.632Z",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5df",
                    "user": {
                        "_id": "62c695829db11473f08af1cd",
                        "avatarUrl": "/avatars/cacb54077892a44aef81454dc107df4f.svg",
                        "isPro": false,
                        "fullname": "Jiale Xu",
                        "user": "bluestyle97",
                        "type": "user"
                    },
                    "name": "Jiale Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:26:54.054Z",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5e0",
                    "name": "Xiaoyu Li",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5e1",
                    "name": "Wenbo Hu",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5e2",
                    "user": {
                        "_id": "66558938dcd4405a55873ac2",
                        "avatarUrl": "/avatars/dedeb4c6c9e424a48d934a78d759402b.svg",
                        "isPro": false,
                        "fullname": "Weihao Cheng",
                        "user": "Chengwh",
                        "type": "user"
                    },
                    "name": "Weihao Cheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:28:26.648Z",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5e3",
                    "user": {
                        "_id": "647e8118770c299e56fc2bc8",
                        "avatarUrl": "/avatars/adf80f3473dda42450148789ae5c208f.svg",
                        "isPro": false,
                        "fullname": "Jinwei Gu",
                        "user": "jwgu",
                        "type": "user"
                    },
                    "name": "Jinwei Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:28:32.438Z",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5e4",
                    "name": "Tianfan Xue",
                    "hidden": false
                },
                {
                    "_id": "675136f914bae121c8dcd5e5",
                    "user": {
                        "_id": "63ca3ddc04c979828310bfcb",
                        "avatarUrl": "/avatars/615e0d8622950b4408b40d550f02a894.svg",
                        "isPro": false,
                        "fullname": "Ying Shan",
                        "user": "yshan2u",
                        "type": "user"
                    },
                    "name": "Ying Shan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:28:56.917Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T17:58:03.000Z",
            "title": "NVComposer: Boosting Generative Novel View Synthesis with Multiple\n  Sparse and Unposed Images",
            "summary": "Recent advancements in generative models have significantly improved novel\nview synthesis (NVS) from multi-view data. However, existing methods depend on\nexternal multi-view alignment processes, such as explicit pose estimation or\npre-reconstruction, which limits their flexibility and accessibility,\nespecially when alignment is unstable due to insufficient overlap or occlusions\nbetween views. In this paper, we propose NVComposer, a novel approach that\neliminates the need for explicit external alignment. NVComposer enables the\ngenerative model to implicitly infer spatial and geometric relationships\nbetween multiple conditional views by introducing two key components: 1) an\nimage-pose dual-stream diffusion model that simultaneously generates target\nnovel views and condition camera poses, and 2) a geometry-aware feature\nalignment module that distills geometric priors from dense stereo models during\ntraining. Extensive experiments demonstrate that NVComposer achieves\nstate-of-the-art performance in generative multi-view NVS tasks, removing the\nreliance on external alignment and thus improving model accessibility. Our\napproach shows substantial improvements in synthesis quality as the number of\nunposed input views increases, highlighting its potential for more flexible and\naccessible generative NVS systems.",
            "upvotes": 13,
            "discussionId": "6751370014bae121c8dcd817"
        },
        "publishedAt": "2024-12-05T01:08:43.396Z",
        "title": "NVComposer: Boosting Generative Novel View Synthesis with Multiple Sparse and Unposed Images",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03517.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "658409ceca19ccf6d9989add",
            "avatarUrl": "/avatars/3ac1dbd25e52435185babdeb3da28875.svg",
            "fullname": "Zhaoyang Zhang",
            "name": "ZyZcuhk",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        }
    },
    {
        "paper": {
            "id": "2412.03205",
            "authors": [
                {
                    "_id": "675156f747111c6a7bcbbdac",
                    "user": {
                        "_id": "6338929107f5708a1aca1390",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6338929107f5708a1aca1390/Bq_1CDfE8rb7SHTRE8CUU.png",
                        "isPro": false,
                        "fullname": "Konstantin Chernyshev ",
                        "user": "k4black",
                        "type": "user"
                    },
                    "name": "Konstantin Chernyshev",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T14:29:22.375Z",
                    "hidden": false
                },
                {
                    "_id": "675156f747111c6a7bcbbdad",
                    "user": {
                        "_id": "650238063e61bc019201e3e2",
                        "avatarUrl": "/avatars/5268b67a116dc24f2b0228c3d87c7cd5.svg",
                        "isPro": false,
                        "fullname": "Vitaliy Polshkov",
                        "user": "cogwheelhead",
                        "type": "user"
                    },
                    "name": "Vitaliy Polshkov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T12:13:59.577Z",
                    "hidden": false
                },
                {
                    "_id": "675156f747111c6a7bcbbdae",
                    "name": "Ekaterina Artemova",
                    "hidden": false
                },
                {
                    "_id": "675156f747111c6a7bcbbdaf",
                    "name": "Alex Myasnikov",
                    "hidden": false
                },
                {
                    "_id": "675156f747111c6a7bcbbdb0",
                    "name": "Vlad Stepanov",
                    "hidden": false
                },
                {
                    "_id": "675156f747111c6a7bcbbdb1",
                    "name": "Alexei Miasnikov",
                    "hidden": false
                },
                {
                    "_id": "675156f747111c6a7bcbbdb2",
                    "user": {
                        "_id": "63ef69f4f338cc3b7774422b",
                        "avatarUrl": "/avatars/3975dca73d0941898f637d16e3115872.svg",
                        "isPro": false,
                        "fullname": "Sergei Tilga",
                        "user": "tilgasergey",
                        "type": "user"
                    },
                    "name": "Sergei Tilga",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T12:22:24.344Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T10:44:50.000Z",
            "title": "U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills\n  in LLMs",
            "summary": "The current evaluation of mathematical skills in LLMs is limited, as existing\nbenchmarks are either relatively small, primarily focus on elementary and\nhigh-school problems, or lack diversity in topics. Additionally, the inclusion\nof visual elements in tasks remains largely under-explored.\n  To address these gaps, we introduce U-MATH, a novel benchmark of 1,100\nunpublished open-ended university-level problems sourced from teaching\nmaterials. It is balanced across six core subjects, with 20% of multimodal\nproblems. Given the open-ended nature of U-MATH problems, we employ an LLM to\njudge the correctness of generated solutions. To this end, we release\nmu-MATH, a dataset to evaluate the LLMs' capabilities in judging solutions.\n  The evaluation of general domain, math-specific, and multimodal LLMs\nhighlights the challenges presented by U-MATH. Our findings reveal that LLMs\nachieve a maximum accuracy of only 63% on text-based tasks, with even lower 45%\non visual problems. The solution assessment proves challenging for LLMs, with\nthe best LLM judge having an F1-score of 80% on mu-MATH.",
            "upvotes": 12,
            "discussionId": "675156f947111c6a7bcbbe21"
        },
        "publishedAt": "2024-12-05T08:28:46.801Z",
        "title": "U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in LLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03205.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "650238063e61bc019201e3e2",
            "avatarUrl": "/avatars/5268b67a116dc24f2b0228c3d87c7cd5.svg",
            "fullname": "Vitaliy Polshkov",
            "name": "cogwheelhead",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.00493",
            "authors": [
                {
                    "_id": "675112f1d5d2963818c49068",
                    "user": {
                        "_id": "646e2fcaf813cfe153f1af6c",
                        "avatarUrl": "/avatars/2f87d0e5c071000990da29cd744bc03d.svg",
                        "isPro": false,
                        "fullname": "Duo Zheng",
                        "user": "zd11024",
                        "type": "user"
                    },
                    "name": "Duo Zheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:18:28.356Z",
                    "hidden": false
                },
                {
                    "_id": "675112f1d5d2963818c49069",
                    "user": {
                        "_id": "65204fdf377bffdc59602a8d",
                        "avatarUrl": "/avatars/02d200f856f03696b183fd0b59e9f909.svg",
                        "isPro": false,
                        "fullname": "Shijia Huang",
                        "user": "slvjul",
                        "type": "user"
                    },
                    "name": "Shijia Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:41:36.198Z",
                    "hidden": false
                },
                {
                    "_id": "675112f1d5d2963818c4906a",
                    "user": {
                        "_id": "6497272b6401266eb6752b89",
                        "avatarUrl": "/avatars/d94a011660f4cad5344756027840dc30.svg",
                        "isPro": false,
                        "fullname": "Liwei Wang",
                        "user": "asdfg80",
                        "type": "user"
                    },
                    "name": "Liwei Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:41:42.748Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-30T14:28:53.000Z",
            "title": "Video-3D LLM: Learning Position-Aware Video Representation for 3D Scene\n  Understanding",
            "summary": "The rapid advancement of Multimodal Large Language Models (MLLMs) has\nsignificantly impacted various multimodal tasks. However, these models face\nchallenges in tasks that require spatial understanding within 3D environments.\nEfforts to enhance MLLMs, such as incorporating point cloud features, have been\nmade, yet a considerable gap remains between the models' learned\nrepresentations and the inherent complexity of 3D scenes. This discrepancy\nlargely stems from the training of MLLMs on predominantly 2D data, which\nrestricts their effectiveness in comprehending 3D spaces. To address this\nissue, in this paper, we propose a novel generalist model, i.e., Video-3D LLM,\nfor 3D scene understanding. By treating 3D scenes as dynamic videos and\nincorporating 3D position encoding into these representations, our Video-3D LLM\naligns video representations with real-world spatial contexts more accurately.\nAdditionally, we have implemented a maximum coverage sampling technique to\noptimize the balance between computational costs and performance efficiency.\nExtensive experiments demonstrate that our model achieves state-of-the-art\nperformance on several 3D scene understanding benchmarks, including ScanRefer,\nMulti3DRefer, Scan2Cap, ScanQA, and SQA3D.",
            "upvotes": 12,
            "discussionId": "675112f2d5d2963818c4909a"
        },
        "publishedAt": "2024-12-05T04:20:35.674Z",
        "title": "Video-3D LLM: Learning Position-Aware Video Representation for 3D Scene Understanding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.00493.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "646e2fcaf813cfe153f1af6c",
            "avatarUrl": "/avatars/2f87d0e5c071000990da29cd744bc03d.svg",
            "fullname": "Duo Zheng",
            "name": "zd11024",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2411.19103",
            "authors": [
                {
                    "_id": "674d157b8c28f1a8d0858ac9",
                    "user": {
                        "_id": "6683b00267d2ccf03aaf8c4d",
                        "avatarUrl": "/avatars/958363fbd2af4768a5242cf828a1dc1f.svg",
                        "isPro": false,
                        "fullname": "jeong ho jun",
                        "user": "hojunssss",
                        "type": "user"
                    },
                    "name": "Jeongho Ju",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:42:08.052Z",
                    "hidden": false
                },
                {
                    "_id": "674d157b8c28f1a8d0858aca",
                    "name": "Daeyoung Kim",
                    "hidden": false
                },
                {
                    "_id": "674d157b8c28f1a8d0858acb",
                    "name": "SunYoung Park",
                    "hidden": false
                },
                {
                    "_id": "674d157b8c28f1a8d0858acc",
                    "user": {
                        "_id": "672af72944096b60a368116e",
                        "avatarUrl": "/avatars/dd6aa4b6f6efa771a357e7de0803ae9b.svg",
                        "isPro": false,
                        "fullname": "kimyoungjune",
                        "user": "kimyoungjune",
                        "type": "user"
                    },
                    "name": "Youngjune Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:29:03.858Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-28T12:38:42.000Z",
            "title": "VARCO-VISION: Expanding Frontiers in Korean Vision-Language Models",
            "summary": "In this paper, we introduce an open-source Korean-English vision-language\nmodel (VLM), VARCO-VISION. We incorporate a step-by-step training strategy that\nallows a model learn both linguistic and visual information while preserving\nthe backbone model's knowledge. Our model demonstrates outstanding performance\nin diverse settings requiring bilingual image-text understanding and generation\nabilities compared to models of similar size. VARCO-VISION is also capable of\ngrounding, referring, and OCR, expanding its usage and potential applications\nfor real-world scenarios. In addition to the model, we release five Korean\nevaluation datasets, including four closed-set and one openset benchmarks. We\nanticipate that our milestone will broaden the opportunities for AI researchers\naiming to train VLMs. VARCO-VISION is available at\nhttps://huggingface.co/NCSOFT/VARCO-VISION-14B.",
            "upvotes": 11,
            "discussionId": "674d157e8c28f1a8d0858c19"
        },
        "publishedAt": "2024-12-05T05:11:03.435Z",
        "title": "VARCO-VISION: Expanding Frontiers in Korean Vision-Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19103.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "672af72944096b60a368116e",
            "avatarUrl": "/avatars/dd6aa4b6f6efa771a357e7de0803ae9b.svg",
            "fullname": "kimyoungjune",
            "name": "kimyoungjune",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.03558",
            "authors": [
                {
                    "_id": "67511976753718a53ff7fdfb",
                    "user": {
                        "_id": "6375d136dee28348a9c63cbf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6375d136dee28348a9c63cbf/gK465HBrQWIOZ-qtHb-Vh.jpeg",
                        "isPro": false,
                        "fullname": "zehuan-huang",
                        "user": "huanngzh",
                        "type": "user"
                    },
                    "name": "Zehuan Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:18:15.519Z",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fdfc",
                    "user": {
                        "_id": "6346aaa3f06b237ba4e297b0",
                        "avatarUrl": "/avatars/5acb986e993eab1461200f3e9d99d022.svg",
                        "isPro": false,
                        "fullname": "Yuan-Chen Guo",
                        "user": "bennyguo",
                        "type": "user"
                    },
                    "name": "Yuan-Chen Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:45:34.099Z",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fdfd",
                    "user": {
                        "_id": "674d7d6fe3908280620d1ac4",
                        "avatarUrl": "/avatars/29157f5a208937655c3f5e5f2ac23c6a.svg",
                        "isPro": false,
                        "fullname": "Xingqiao_An",
                        "user": "XingqiaoAn",
                        "type": "user"
                    },
                    "name": "Xingqiao An",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:45:39.396Z",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fdfe",
                    "user": {
                        "_id": "64b4eecf2fc8324fcb63b404",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b4eecf2fc8324fcb63b404/zGYqYVB4-o-GBMybJ8CDA.png",
                        "isPro": false,
                        "fullname": "Yunhan Yang",
                        "user": "yhyang-myron",
                        "type": "user"
                    },
                    "name": "Yunhan Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:45:45.545Z",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fdff",
                    "name": "Yangguang Li",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fe00",
                    "user": {
                        "_id": "644dbf6453ad80c6593bf748",
                        "avatarUrl": "/avatars/0e170cf2aa8d7f0f3f83e36f06f023f8.svg",
                        "isPro": false,
                        "fullname": "Zixin Zou",
                        "user": "zouzx",
                        "type": "user"
                    },
                    "name": "Zi-Xin Zou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:46:03.490Z",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fe01",
                    "name": "Ding Liang",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fe02",
                    "user": {
                        "_id": "65d5ec74cd05bc1eaa125040",
                        "avatarUrl": "/avatars/2de1b1539a86452c2c89570eeb02f5ab.svg",
                        "isPro": false,
                        "fullname": "Xihui Liu",
                        "user": "XihuiLiu",
                        "type": "user"
                    },
                    "name": "Xihui Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:46:12.847Z",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fe03",
                    "user": {
                        "_id": "638066faf022c8a5803f7eb8",
                        "avatarUrl": "/avatars/4cfd699c3f6c5461b12b7dc5e3fe183d.svg",
                        "isPro": false,
                        "fullname": "Yanpei Cao",
                        "user": "pookiefoof",
                        "type": "user"
                    },
                    "name": "Yan-Pei Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:46:20.698Z",
                    "hidden": false
                },
                {
                    "_id": "67511976753718a53ff7fe04",
                    "name": "Lu Sheng",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T18:52:40.000Z",
            "title": "MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation",
            "summary": "This paper introduces MIDI, a novel paradigm for compositional 3D scene\ngeneration from a single image. Unlike existing methods that rely on\nreconstruction or retrieval techniques or recent approaches that employ\nmulti-stage object-by-object generation, MIDI extends pre-trained image-to-3D\nobject generation models to multi-instance diffusion models, enabling the\nsimultaneous generation of multiple 3D instances with accurate spatial\nrelationships and high generalizability. At its core, MIDI incorporates a novel\nmulti-instance attention mechanism, that effectively captures inter-object\ninteractions and spatial coherence directly within the generation process,\nwithout the need for complex multi-step processes. The method utilizes partial\nobject images and global scene context as inputs, directly modeling object\ncompletion during 3D generation. During training, we effectively supervise the\ninteractions between 3D instances using a limited amount of scene-level data,\nwhile incorporating single-object data for regularization, thereby maintaining\nthe pre-trained generalization ability. MIDI demonstrates state-of-the-art\nperformance in image-to-scene generation, validated through evaluations on\nsynthetic data, real-world scene data, and stylized scene images generated by\ntext-to-image diffusion models.",
            "upvotes": 10,
            "discussionId": "67511978753718a53ff7fe9d"
        },
        "publishedAt": "2024-12-04T22:11:17.014Z",
        "title": "MIDI: Multi-Instance Diffusion for Single Image to 3D Scene Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03558.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6375d136dee28348a9c63cbf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6375d136dee28348a9c63cbf/gK465HBrQWIOZ-qtHb-Vh.jpeg",
            "fullname": "zehuan-huang",
            "name": "huanngzh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 8
        }
    },
    {
        "paper": {
            "id": "2412.02030",
            "authors": [
                {
                    "_id": "674fb49742a92dddf7d64f3b",
                    "user": {
                        "_id": "64d0eb731ed6649d70afb136",
                        "avatarUrl": "/avatars/4c591c86c575c82760126c39af5a02b4.svg",
                        "isPro": true,
                        "fullname": "Chen Dar-Yen",
                        "user": "ChenDY",
                        "type": "user"
                    },
                    "name": "Dar-Yen Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-04T09:45:49.922Z",
                    "hidden": false
                },
                {
                    "_id": "674fb49742a92dddf7d64f3c",
                    "user": {
                        "_id": "638c81fa61eb51017518fa31",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/f0eCrzBrxz7Y9n25WkZ2v.png",
                        "isPro": false,
                        "fullname": "Hmrishav Bandyopadhyay",
                        "user": "Hmrishav",
                        "type": "user"
                    },
                    "name": "Hmrishav Bandyopadhyay",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:24:14.918Z",
                    "hidden": false
                },
                {
                    "_id": "674fb49742a92dddf7d64f3d",
                    "user": {
                        "_id": "66d60c6d956fdcaeb676d7cf",
                        "avatarUrl": "/avatars/c81e3a17e94892e6448f293ccadd667a.svg",
                        "isPro": false,
                        "fullname": "Kaizo240",
                        "user": "Kaizou",
                        "type": "user"
                    },
                    "name": "Kai Zou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:24:23.664Z",
                    "hidden": false
                },
                {
                    "_id": "674fb49742a92dddf7d64f3e",
                    "user": {
                        "_id": "671f999400458be2e849a7b9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/SdJZS9l4DDODEA0ls8Kb5.png",
                        "isPro": false,
                        "fullname": "Yizhe Song",
                        "user": "songyizhe",
                        "type": "user"
                    },
                    "name": "Yi-Zhe Song",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:24:33.078Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-02T23:20:35.000Z",
            "title": "NitroFusion: High-Fidelity Single-Step Diffusion through Dynamic\n  Adversarial Training",
            "summary": "We introduce NitroFusion, a fundamentally different approach to single-step\ndiffusion that achieves high-quality generation through a dynamic adversarial\nframework. While one-step methods offer dramatic speed advantages, they\ntypically suffer from quality degradation compared to their multi-step\ncounterparts. Just as a panel of art critics provides comprehensive feedback by\nspecializing in different aspects like composition, color, and technique, our\napproach maintains a large pool of specialized discriminator heads that\ncollectively guide the generation process. Each discriminator group develops\nexpertise in specific quality aspects at different noise levels, providing\ndiverse feedback that enables high-fidelity one-step generation. Our framework\ncombines: (i) a dynamic discriminator pool with specialized discriminator\ngroups to improve generation quality, (ii) strategic refresh mechanisms to\nprevent discriminator overfitting, and (iii) global-local discriminator heads\nfor multi-scale quality assessment, and unconditional/conditional training for\nbalanced generation. Additionally, our framework uniquely supports flexible\ndeployment through bottom-up refinement, allowing users to dynamically choose\nbetween 1-4 denoising steps with the same model for direct quality-speed\ntrade-offs. Through comprehensive experiments, we demonstrate that NitroFusion\nsignificantly outperforms existing single-step methods across multiple\nevaluation metrics, particularly excelling in preserving fine details and\nglobal consistency.",
            "upvotes": 9,
            "discussionId": "674fb49a42a92dddf7d65054"
        },
        "publishedAt": "2024-12-05T06:54:54.451Z",
        "title": "NitroFusion: High-Fidelity Single-Step Diffusion through Dynamic Adversarial Training",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64d0eb731ed6649d70afb136/5Yhsm2Gcty0S946Rpn3s2.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.02030.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "64d0eb731ed6649d70afb136",
            "avatarUrl": "/avatars/4c591c86c575c82760126c39af5a02b4.svg",
            "fullname": "Chen Dar-Yen",
            "name": "ChenDY",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2412.03439",
            "authors": [
                {
                    "_id": "67516be84af3ce83f1e7dc67",
                    "user": {
                        "_id": "63a1c8d63c003e409311e3c3",
                        "avatarUrl": "/avatars/c6cd546874abd5ee68ed88eff5ee1aa8.svg",
                        "isPro": false,
                        "fullname": "Nick Stracke",
                        "user": "kliyer",
                        "type": "user"
                    },
                    "name": "Nick Stracke",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:44:40.411Z",
                    "hidden": false
                },
                {
                    "_id": "67516be84af3ce83f1e7dc68",
                    "user": {
                        "_id": "6471c12a0c2b5fdaf1f07c45",
                        "avatarUrl": "/avatars/6783067212d24d1e716a8b4c64df61b4.svg",
                        "isPro": false,
                        "fullname": "Stefan Baumann",
                        "user": "stefan-baumann",
                        "type": "user"
                    },
                    "name": "Stefan Andreas Baumann",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:45:04.279Z",
                    "hidden": false
                },
                {
                    "_id": "67516be84af3ce83f1e7dc69",
                    "user": {
                        "_id": "65ae67bcbff3ae9f331c846a",
                        "avatarUrl": "/avatars/6f9572fbfdba105638112386cdc346fa.svg",
                        "isPro": false,
                        "fullname": "Kolja Bauer",
                        "user": "kolja-b",
                        "type": "user"
                    },
                    "name": "Kolja Bauer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:45:11.300Z",
                    "hidden": false
                },
                {
                    "_id": "67516be84af3ce83f1e7dc6a",
                    "user": {
                        "_id": "623dd9817d2f5b63ac1b73df",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1648220555715-623dd9817d2f5b63ac1b73df.jpeg",
                        "isPro": false,
                        "fullname": "Frank Fundel",
                        "user": "FrankFundel",
                        "type": "user"
                    },
                    "name": "Frank Fundel",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:45:17.457Z",
                    "hidden": false
                },
                {
                    "_id": "67516be84af3ce83f1e7dc6b",
                    "name": "BjÃ¶rn Ommer",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T16:29:04.000Z",
            "title": "CleanDIFT: Diffusion Features without Noise",
            "summary": "Internal features from large-scale pre-trained diffusion models have recently\nbeen established as powerful semantic descriptors for a wide range of\ndownstream tasks. Works that use these features generally need to add noise to\nimages before passing them through the model to obtain the semantic features,\nas the models do not offer the most useful features when given images with\nlittle to no noise. We show that this noise has a critical impact on the\nusefulness of these features that cannot be remedied by ensembling with\ndifferent random noises. We address this issue by introducing a lightweight,\nunsupervised fine-tuning method that enables diffusion backbones to provide\nhigh-quality, noise-free semantic features. We show that these features readily\noutperform previous diffusion features by a wide margin in a wide variety of\nextraction setups and downstream tasks, offering better performance than even\nensemble-based methods at a fraction of the cost.",
            "upvotes": 9,
            "discussionId": "67516bed4af3ce83f1e7de3c"
        },
        "publishedAt": "2024-12-05T04:03:50.350Z",
        "title": "CleanDIFT: Diffusion Features without Noise",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03439.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6471c12a0c2b5fdaf1f07c45",
            "avatarUrl": "/avatars/6783067212d24d1e716a8b4c64df61b4.svg",
            "fullname": "Stefan Baumann",
            "name": "stefan-baumann",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        }
    },
    {
        "paper": {
            "id": "2412.03085",
            "authors": [
                {
                    "_id": "67511c893da4637b2ec180c7",
                    "name": "Shuai Tan",
                    "hidden": false
                },
                {
                    "_id": "67511c893da4637b2ec180c8",
                    "user": {
                        "_id": "644fcbea4f7316588267dc80",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644fcbea4f7316588267dc80/w8-2Gkaw9BN9VzppNXrTP.jpeg",
                        "isPro": false,
                        "fullname": "Biao Gong",
                        "user": "BiaoGong",
                        "type": "user"
                    },
                    "name": "Biao Gong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:18:13.242Z",
                    "hidden": false
                },
                {
                    "_id": "67511c893da4637b2ec180c9",
                    "user": {
                        "_id": "64a54e468cfaa458bd6844bf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a54e468cfaa458bd6844bf/5Gmf4tAr59GNl-2VaZDbu.png",
                        "isPro": false,
                        "fullname": "Yutong Feng",
                        "user": "yutongfeng",
                        "type": "user"
                    },
                    "name": "Yutong Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:22:46.887Z",
                    "hidden": false
                },
                {
                    "_id": "67511c893da4637b2ec180ca",
                    "user": {
                        "_id": "64252045a4f3051f54dd1d53",
                        "avatarUrl": "/avatars/0e423a3291091be3b4736a14da3ce495.svg",
                        "isPro": false,
                        "fullname": "kecheng zheng",
                        "user": "zkcys001",
                        "type": "user"
                    },
                    "name": "Kecheng Zheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:22:40.934Z",
                    "hidden": false
                },
                {
                    "_id": "67511c893da4637b2ec180cb",
                    "user": {
                        "_id": "65dd699a89a2a760d15f7d35",
                        "avatarUrl": "/avatars/e098b56c413d147d1f38cf33a4b0ecde.svg",
                        "isPro": false,
                        "fullname": "Dandan Zheng",
                        "user": "zhengdd0422",
                        "type": "user"
                    },
                    "name": "Dandan Zheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:22:30.343Z",
                    "hidden": false
                },
                {
                    "_id": "67511c893da4637b2ec180cc",
                    "user": {
                        "_id": "65688c20178ee07f040bcae8",
                        "avatarUrl": "/avatars/24d57ad55eb00af398ca3df6507af239.svg",
                        "isPro": false,
                        "fullname": "SHUWEI SHI",
                        "user": "ssw20",
                        "type": "user"
                    },
                    "name": "Shuwei Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:23:03.099Z",
                    "hidden": false
                },
                {
                    "_id": "67511c893da4637b2ec180cd",
                    "name": "Yujun Shen",
                    "hidden": false
                },
                {
                    "_id": "67511c893da4637b2ec180ce",
                    "name": "Jingdong Chen",
                    "hidden": false
                },
                {
                    "_id": "67511c893da4637b2ec180cf",
                    "name": "Ming Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T07:26:44.000Z",
            "title": "Mimir: Improving Video Diffusion Models for Precise Text Understanding",
            "summary": "Text serves as the key control signal in video generation due to its\nnarrative nature. To render text descriptions into video clips, current video\ndiffusion models borrow features from text encoders yet struggle with limited\ntext comprehension. The recent success of large language models (LLMs)\nshowcases the power of decoder-only transformers, which offers three clear\nbenefits for text-to-video (T2V) generation, namely, precise text understanding\nresulting from the superior scalability, imagination beyond the input text\nenabled by next token prediction, and flexibility to prioritize user interests\nthrough instruction tuning. Nevertheless, the feature distribution gap emerging\nfrom the two different text modeling paradigms hinders the direct use of LLMs\nin established T2V models. This work addresses this challenge with Mimir, an\nend-to-end training framework featuring a carefully tailored token fuser to\nharmonize the outputs from text encoders and LLMs. Such a design allows the T2V\nmodel to fully leverage learned video priors while capitalizing on the\ntext-related capability of LLMs. Extensive quantitative and qualitative results\ndemonstrate the effectiveness of Mimir in generating high-quality videos with\nexcellent text comprehension, especially when processing short captions and\nmanaging shifting motions. Project page:\nhttps://lucaria-academy.github.io/Mimir/",
            "upvotes": 7,
            "discussionId": "67511c8b3da4637b2ec181ae"
        },
        "publishedAt": "2024-12-04T22:23:06.545Z",
        "title": "Mimir: Improving Video Diffusion Models for Precise Text Understanding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03085.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "644fcbea4f7316588267dc80",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644fcbea4f7316588267dc80/w8-2Gkaw9BN9VzppNXrTP.jpeg",
            "fullname": "Biao Gong",
            "name": "BiaoGong",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2412.01106",
            "authors": [
                {
                    "_id": "674e94bb320a043daeafc668",
                    "user": {
                        "_id": "657d8495e50ca9a699ae7a1a",
                        "avatarUrl": "/avatars/afa2b9c30c37c1c2130cc3a2eabab19e.svg",
                        "isPro": false,
                        "fullname": "Jun Xiang",
                        "user": "xiangjun-xj",
                        "type": "user"
                    },
                    "name": "Jun Xiang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-04T09:46:23.321Z",
                    "hidden": false
                },
                {
                    "_id": "674e94bb320a043daeafc669",
                    "user": {
                        "_id": "6358a2cc1d66b442317f56c3",
                        "avatarUrl": "/avatars/119b991a9dafefce4b9217346044f7ea.svg",
                        "isPro": false,
                        "fullname": "Yudong Guo",
                        "user": "YudongGuo",
                        "type": "user"
                    },
                    "name": "Yudong Guo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T09:28:54.257Z",
                    "hidden": false
                },
                {
                    "_id": "674e94bb320a043daeafc66a",
                    "name": "Leipeng Hu",
                    "hidden": false
                },
                {
                    "_id": "674e94bb320a043daeafc66b",
                    "name": "Boyang Guo",
                    "hidden": false
                },
                {
                    "_id": "674e94bb320a043daeafc66c",
                    "name": "Yancheng Yuan",
                    "hidden": false
                },
                {
                    "_id": "674e94bb320a043daeafc66d",
                    "user": {
                        "_id": "66fec5869b33512a6125ef2f",
                        "avatarUrl": "/avatars/5e9762ab35de5dd64ba06573fdea2ea7.svg",
                        "isPro": false,
                        "fullname": "Juyong Zhang",
                        "user": "JuyongZhang",
                        "type": "user"
                    },
                    "name": "Juyong Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T10:44:32.580Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-02T04:27:41.000Z",
            "title": "One Shot, One Talk: Whole-body Talking Avatar from a Single Image",
            "summary": "Building realistic and animatable avatars still requires minutes of\nmulti-view or monocular self-rotating videos, and most methods lack precise\ncontrol over gestures and expressions. To push this boundary, we address the\nchallenge of constructing a whole-body talking avatar from a single image. We\npropose a novel pipeline that tackles two critical issues: 1) complex dynamic\nmodeling and 2) generalization to novel gestures and expressions. To achieve\nseamless generalization, we leverage recent pose-guided image-to-video\ndiffusion models to generate imperfect video frames as pseudo-labels. To\novercome the dynamic modeling challenge posed by inconsistent and noisy\npseudo-videos, we introduce a tightly coupled 3DGS-mesh hybrid avatar\nrepresentation and apply several key regularizations to mitigate\ninconsistencies caused by imperfect labels. Extensive experiments on diverse\nsubjects demonstrate that our method enables the creation of a photorealistic,\nprecisely animatable, and expressive whole-body talking avatar from just a\nsingle image.",
            "upvotes": 7,
            "discussionId": "674e94be320a043daeafc6f2"
        },
        "publishedAt": "2024-12-04T21:59:53.689Z",
        "title": "One Shot, One Talk: Whole-body Talking Avatar from a Single Image",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/657d8495e50ca9a699ae7a1a/o8nYHXA6ddo0MCs6veeEF.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.01106.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "657d8495e50ca9a699ae7a1a",
            "avatarUrl": "/avatars/afa2b9c30c37c1c2130cc3a2eabab19e.svg",
            "fullname": "Jun Xiang",
            "name": "xiangjun-xj",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.03565",
            "authors": [
                {
                    "_id": "67519ac329945767b6c2ceeb",
                    "user": {
                        "_id": "649bce4f200e2dff194d9883",
                        "avatarUrl": "/avatars/b55a8bdc6f7e2bf9de5f26dc1d87bee3.svg",
                        "isPro": false,
                        "fullname": "Wujian Peng",
                        "user": "wjpoom",
                        "type": "user"
                    },
                    "name": "Wujian Peng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T12:22:26.413Z",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2ceec",
                    "name": "Lingchen Meng",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2ceed",
                    "name": "Yitong Chen",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2ceee",
                    "name": "Yiweng Xie",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2ceef",
                    "name": "Yang Liu",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2cef0",
                    "name": "Tao Gui",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2cef1",
                    "name": "Hang Xu",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2cef2",
                    "name": "Xipeng Qiu",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2cef3",
                    "name": "Zuxuan Wu",
                    "hidden": false
                },
                {
                    "_id": "67519ac329945767b6c2cef4",
                    "name": "Yu-Gang Jiang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T18:58:10.000Z",
            "title": "Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual\n  Prompt Instruction Tuning",
            "summary": "Large Multimodal Models (LMMs) have made significant breakthroughs with the\nadvancement of instruction tuning. However, while existing models can\nunderstand images and videos at a holistic level, they still struggle with\ninstance-level understanding that requires a more nuanced comprehension and\nalignment. Instance-level understanding is crucial, as it focuses on the\nspecific elements that we are most interested in. Excitingly, existing works\nfind that the state-of-the-art LMMs exhibit strong instance understanding\ncapabilities when provided with explicit visual cues. Motivated by this, we\nintroduce an automated annotation pipeline assisted by GPT-4o to extract\ninstance-level information from images and videos through explicit visual\nprompting for instance guidance. Building upon this pipeline, we proposed\nInst-IT, a solution to enhance LMMs in Instance understanding via explicit\nvisual prompt Instruction Tuning. Inst-IT consists of a benchmark to diagnose\nmultimodal instance-level understanding, a large-scale instruction-tuning\ndataset, and a continuous instruction-tuning training paradigm to effectively\nenhance spatial-temporal instance understanding capabilities of existing LMMs.\nExperimental results show that, with the boost of Inst-IT, our models not only\nachieve outstanding performance on Inst-IT Bench but also demonstrate\nsignificant improvements across various generic image and video understanding\nbenchmarks. This highlights that our dataset not only boosts instance-level\nunderstanding but also strengthens the overall capabilities of generic image\nand video comprehension.",
            "upvotes": 4,
            "discussionId": "67519ac629945767b6c2d01b"
        },
        "publishedAt": "2024-12-05T07:26:21.773Z",
        "title": "Inst-IT: Boosting Multimodal Instance Understanding via Explicit Visual Prompt Instruction Tuning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03565.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "649bce4f200e2dff194d9883",
            "avatarUrl": "/avatars/b55a8bdc6f7e2bf9de5f26dc1d87bee3.svg",
            "fullname": "Wujian Peng",
            "name": "wjpoom",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.03187",
            "authors": [
                {
                    "_id": "675146f4372c1020c21d2046",
                    "name": "Ziyi Yang",
                    "hidden": false
                },
                {
                    "_id": "675146f4372c1020c21d2047",
                    "user": {
                        "_id": "62ecbffd99112e99c5f7fded",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62ecbffd99112e99c5f7fded/U6iXAJbpm2vaC5qksEPiH.png",
                        "isPro": false,
                        "fullname": "Fanqi Wan",
                        "user": "Wanfq",
                        "type": "user"
                    },
                    "name": "Fanqi Wan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:23:54.907Z",
                    "hidden": false
                },
                {
                    "_id": "675146f4372c1020c21d2048",
                    "user": {
                        "_id": "62b6d20416ff90e6198301b6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656148456743-noauth.png",
                        "isPro": false,
                        "fullname": "Longguang Zhong",
                        "user": "GGLS",
                        "type": "user"
                    },
                    "name": "Longguang Zhong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:23:49.460Z",
                    "hidden": false
                },
                {
                    "_id": "675146f4372c1020c21d2049",
                    "user": {
                        "_id": "654c82ca47053d20c7986fe3",
                        "avatarUrl": "/avatars/b6560247e9d6f662d36aa1c1589bb92e.svg",
                        "isPro": false,
                        "fullname": "tianyuan shi",
                        "user": "stycoo",
                        "type": "user"
                    },
                    "name": "Tianyuan Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:23:43.208Z",
                    "hidden": false
                },
                {
                    "_id": "675146f4372c1020c21d204a",
                    "user": {
                        "_id": "63b57d75bda8d44adf2ff3ff",
                        "avatarUrl": "/avatars/8a387036758b2f7fc7d7529dea206669.svg",
                        "isPro": false,
                        "fullname": "Xiaojun Quan",
                        "user": "passerqxj",
                        "type": "user"
                    },
                    "name": "Xiaojun Quan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T12:23:35.922Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T10:15:12.000Z",
            "title": "Weighted-Reward Preference Optimization for Implicit Model Fusion",
            "summary": "While fusing heterogeneous open-source LLMs with varying architectures and\nsizes can potentially integrate the strengths of different models, existing\nfusion methods face significant challenges, such as vocabulary alignment and\nmerging distribution matrices. These procedures are not only complex but also\nprone to introducing noise and errors. In this paper, we propose an implicit\nfusion method, Weighted-Reward Preference Optimization (WRPO), which leverages\npreference optimization between the source LLMs and the target LLM to transfer\ntheir capabilities effectively. WRPO eliminates the need for vocabulary\nalignment and matrix fusion and can be efficiently scaled to accommodate\nvarious LLMs. To address distributional deviations between the source and\ntarget LLMs, WRPO introduces a progressive adaptation strategy that gradually\nshifts reliance on preferred examples from the target LLM to the source LLMs.\nExtensive experiments on the MT-Bench, AlpacaEval-2, and Arena-Hard benchmarks\ndemonstrate that WRPO consistently outperforms existing knowledge fusion\nmethods and various fine-tuning baselines. When applied to LLaMA3-8B-Instruct\nas the target model, WRPO achieves a length-controlled win rate of 55.9%\nagainst GPT-4-Preview-1106 on AlpacaEval-2 and a win rate of 46.2% against\nGPT-4-0314 on Arena-Hard. Our code is available at\nhttps://github.com/SLIT-AI/WRPO.",
            "upvotes": 4,
            "discussionId": "675146f5372c1020c21d208a"
        },
        "publishedAt": "2024-12-05T01:25:27.157Z",
        "title": "Weighted-Reward Preference Optimization for Implicit Model Fusion",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03187.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "62ecbffd99112e99c5f7fded",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62ecbffd99112e99c5f7fded/U6iXAJbpm2vaC5qksEPiH.png",
            "fullname": "Fanqi Wan",
            "name": "Wanfq",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 15
        }
    },
    {
        "paper": {
            "id": "2412.02980",
            "authors": [
                {
                    "_id": "67517cb918b3a33d49516e64",
                    "user": {
                        "_id": "6144d541fa30a4ba3ef7ef15",
                        "avatarUrl": "/avatars/eeb849eb29e249fd1b40e5c10d9bf9e5.svg",
                        "isPro": false,
                        "fullname": "Alex Havrilla",
                        "user": "Dahoas",
                        "type": "user"
                    },
                    "name": "Alex Havrilla",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:56:55.364Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e65",
                    "user": {
                        "_id": "64c04c0b5e03515457ed72a3",
                        "avatarUrl": "/avatars/dcbfca63b32a8d5c575232316c01dbe7.svg",
                        "isPro": false,
                        "fullname": "Andrew Dai",
                        "user": "PenguinPush",
                        "type": "user"
                    },
                    "name": "Andrew Dai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:56:49.264Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e66",
                    "user": {
                        "_id": "64b087aae55e77179863990d",
                        "avatarUrl": "/avatars/214f61f74636fd69b58d534993ec79d7.svg",
                        "isPro": false,
                        "fullname": "Laura O'Mahony",
                        "user": "lomahony",
                        "type": "user"
                    },
                    "name": "Laura O'Mahony",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:56:42.538Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e67",
                    "name": "Koen Oostermeijer",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e68",
                    "name": "Vera Zisler",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e69",
                    "user": {
                        "_id": "611a7ec4289467cafea62d13",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/611a7ec4289467cafea62d13/pck-0fmPQkoU7yzh6-WoL.jpeg",
                        "isPro": false,
                        "fullname": "Alon Albalak",
                        "user": "alon-albalak",
                        "type": "user"
                    },
                    "name": "Alon Albalak",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:56:28.639Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e6a",
                    "name": "Fabrizio Milo",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e6b",
                    "user": {
                        "_id": "65007a96ea5699b59a9bb432",
                        "avatarUrl": "/avatars/4549f5964b007de189c45a77daf10075.svg",
                        "isPro": false,
                        "fullname": "Sharath Raparthy",
                        "user": "sharathraparthy",
                        "type": "user"
                    },
                    "name": "Sharath Chandra Raparthy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:56:17.096Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e6c",
                    "user": {
                        "_id": "63e6a880f2e9a8f22c5a1630",
                        "avatarUrl": "/avatars/53b57690fe052ce6882bbfc87b11567c.svg",
                        "isPro": false,
                        "fullname": "Kanishk Gandhi",
                        "user": "obiwan96",
                        "type": "user"
                    },
                    "name": "Kanishk Gandhi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:56:05.575Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e6d",
                    "user": {
                        "_id": "6321b5f0909ac44b57244ca4",
                        "avatarUrl": "/avatars/ca4ceac5e2ae3d085718f6f551a2eeed.svg",
                        "isPro": false,
                        "fullname": "Baber Abbasi",
                        "user": "baber",
                        "type": "user"
                    },
                    "name": "Baber Abbasi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:55:59.377Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e6e",
                    "user": {
                        "_id": "65c19db45dd83d8613ec9375",
                        "avatarUrl": "/avatars/7732cb1aa9395af5dbc2252d6f4fb327.svg",
                        "isPro": false,
                        "fullname": "Duy Phung",
                        "user": "duycan2000",
                        "type": "user"
                    },
                    "name": "Duy Phung",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:55:49.562Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e6f",
                    "user": {
                        "_id": "62c0bb2143d4858f8221d300",
                        "avatarUrl": "/avatars/cb0e57d87428471e9ed4f1f239d758fa.svg",
                        "isPro": false,
                        "fullname": "Maia Iyer",
                        "user": "maia-iyer",
                        "type": "user"
                    },
                    "name": "Maia Iyer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:55:42.408Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e70",
                    "user": {
                        "_id": "650b012800ee18535fd228dc",
                        "avatarUrl": "/avatars/bd018922d407755494aac51f007a41be.svg",
                        "isPro": false,
                        "fullname": "Dakota Mahan",
                        "user": "stable-dakota-mahan",
                        "type": "user"
                    },
                    "name": "Dakota Mahan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:55:35.422Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e71",
                    "user": {
                        "_id": "6504bbf6ffc738079c44d329",
                        "avatarUrl": "/avatars/de64e25303d31e68186c9e2242c61c98.svg",
                        "isPro": false,
                        "fullname": "Chase Blagden",
                        "user": "bchase",
                        "type": "user"
                    },
                    "name": "Chase Blagden",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:55:28.702Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e72",
                    "user": {
                        "_id": "625d6ed9c4086370158824eb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/625d6ed9c4086370158824eb/KG_Plv-2rcydKzVf-9AAj.jpeg",
                        "isPro": false,
                        "fullname": "Srishti Gureja",
                        "user": "srishti-hf1110",
                        "type": "user"
                    },
                    "name": "Srishti Gureja",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:55:22.416Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e73",
                    "user": {
                        "_id": "62645f88c39850dc093d6105",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1650745211725-noauth.png",
                        "isPro": false,
                        "fullname": "Mohammed Hamdy",
                        "user": "mmhamdy",
                        "type": "user"
                    },
                    "name": "Mohammed Hamdy",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T10:20:26.645Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e74",
                    "user": {
                        "_id": "62e221dfcb1f164f2cb8a66b",
                        "avatarUrl": "/avatars/06f05622e232304d3f0b8c291f3263be.svg",
                        "isPro": true,
                        "fullname": "Wen-Ding Li",
                        "user": "xu3kev",
                        "type": "user"
                    },
                    "name": "Wen-Ding Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:55:07.568Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e75",
                    "user": {
                        "_id": "60d233db3125968c17ac8895",
                        "avatarUrl": "/avatars/d9f07657759978f8d56d8cb4726ff9f4.svg",
                        "isPro": false,
                        "fullname": "Giovanni Paolini",
                        "user": "giove",
                        "type": "user"
                    },
                    "name": "Giovanni Paolini",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:54:57.474Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e76",
                    "user": {
                        "_id": "5f04beab4ec31d33a72116d4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594146435878-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Pawan Sasanka Ammanamanchi",
                        "user": "paws",
                        "type": "user"
                    },
                    "name": "Pawan Sasanka Ammanamanchi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:54:48.477Z",
                    "hidden": false
                },
                {
                    "_id": "67517cb918b3a33d49516e77",
                    "user": {
                        "_id": "6514b7fde1273c28705142cc",
                        "avatarUrl": "/avatars/072bf14abd8ef17d9393338a20157cc2.svg",
                        "isPro": false,
                        "fullname": "Elliot Meyerson",
                        "user": "ekmeyerson",
                        "type": "user"
                    },
                    "name": "Elliot Meyerson",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-05T14:54:40.770Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T02:47:45.000Z",
            "title": "Surveying the Effects of Quality, Diversity, and Complexity in Synthetic\n  Data From Large Language Models",
            "summary": "Synthetic data generation with Large Language Models is a promising paradigm\nfor augmenting natural data over a nearly infinite range of tasks. Given this\nvariety, direct comparisons among synthetic data generation algorithms are\nscarce, making it difficult to understand where improvement comes from and what\nbottlenecks exist. We propose to evaluate algorithms via the makeup of\nsynthetic data generated by each algorithm in terms of data quality, diversity,\nand complexity. We choose these three characteristics for their significance in\nopen-ended processes and the impact each has on the capabilities of downstream\nmodels. We find quality to be essential for in-distribution model\ngeneralization, diversity to be essential for out-of-distribution\ngeneralization, and complexity to be beneficial for both. Further, we emphasize\nthe existence of Quality-Diversity trade-offs in training data and the\ndownstream effects on model performance. We then examine the effect of various\ncomponents in the synthetic data pipeline on each data characteristic. This\nexamination allows us to taxonomize and compare synthetic data generation\nalgorithms through the components they utilize and the resulting effects on\ndata QDC composition. This analysis extends into a discussion on the importance\nof balancing QDC in synthetic data for efficient reinforcement learning and\nself-improvement algorithms. Analogous to the QD trade-offs in training data,\noften there exist trade-offs between model output quality and output diversity\nwhich impact the composition of synthetic data. We observe that many models are\ncurrently evaluated and optimized only for output quality, thereby limiting\noutput diversity and the potential for self-improvement. We argue that\nbalancing these trade-offs is essential to the development of future\nself-improvement algorithms and highlight a number of works making progress in\nthis direction.",
            "upvotes": 3,
            "discussionId": "67517cc318b3a33d49517135"
        },
        "publishedAt": "2024-12-05T08:58:10.898Z",
        "title": "Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.02980.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6144d541fa30a4ba3ef7ef15",
            "avatarUrl": "/avatars/eeb849eb29e249fd1b40e5c10d9bf9e5.svg",
            "fullname": "Alex Havrilla",
            "name": "Dahoas",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 64
        }
    },
    {
        "paper": {
            "id": "2412.00177",
            "authors": [
                {
                    "_id": "6751af55cee25c032a044d06",
                    "user": {
                        "_id": "654b92bebe11400417aecff9",
                        "avatarUrl": "/avatars/b3e442dedb29544256b352e059cc829b.svg",
                        "isPro": true,
                        "fullname": "Xiaoyan",
                        "user": "xyxingx",
                        "type": "user"
                    },
                    "name": "Xiaoyan Xing",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-05T14:29:05.624Z",
                    "hidden": false
                },
                {
                    "_id": "6751af55cee25c032a044d07",
                    "name": "Konrad Groh",
                    "hidden": false
                },
                {
                    "_id": "6751af55cee25c032a044d08",
                    "name": "Sezer Karaoglu",
                    "hidden": false
                },
                {
                    "_id": "6751af55cee25c032a044d09",
                    "name": "Theo Gevers",
                    "hidden": false
                },
                {
                    "_id": "6751af55cee25c032a044d0a",
                    "name": "Anand Bhattad",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-29T18:59:11.000Z",
            "title": "LumiNet: Latent Intrinsics Meets Diffusion Models for Indoor Scene\n  Relighting",
            "summary": "We introduce LumiNet, a novel architecture that leverages generative models\nand latent intrinsic representations for effective lighting transfer. Given a\nsource image and a target lighting image, LumiNet synthesizes a relit version\nof the source scene that captures the target's lighting. Our approach makes two\nkey contributions: a data curation strategy from the StyleGAN-based relighting\nmodel for our training, and a modified diffusion-based ControlNet that\nprocesses both latent intrinsic properties from the source image and latent\nextrinsic properties from the target image. We further improve lighting\ntransfer through a learned adaptor (MLP) that injects the target's latent\nextrinsic properties via cross-attention and fine-tuning.\n  Unlike traditional ControlNet, which generates images with conditional maps\nfrom a single scene, LumiNet processes latent representations from two\ndifferent images - preserving geometry and albedo from the source while\ntransferring lighting characteristics from the target. Experiments demonstrate\nthat our method successfully transfers complex lighting phenomena including\nspecular highlights and indirect illumination across scenes with varying\nspatial layouts and materials, outperforming existing approaches on challenging\nindoor scenes using only images as input.",
            "upvotes": 1,
            "discussionId": "6751af56cee25c032a044db1"
        },
        "publishedAt": "2024-12-05T10:06:30.035Z",
        "title": "LumiNet: Latent Intrinsics Meets Diffusion Models for Indoor Scene Relighting",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.00177.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "654b92bebe11400417aecff9",
            "avatarUrl": "/avatars/b3e442dedb29544256b352e059cc829b.svg",
            "fullname": "Xiaoyan",
            "name": "xyxingx",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false
        }
    }
]