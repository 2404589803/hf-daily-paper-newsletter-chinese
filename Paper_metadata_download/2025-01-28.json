[
  {
    "paper": {
      "id": "2501.15368",
      "authors": [
        {
          "_id": "67986c6822990ae89bb71fb9",
          "name": "Yadong Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fba",
          "name": "Jun Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbb",
          "name": "Tao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbc",
          "name": "Tao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbd",
          "name": "Song Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbe",
          "name": "Tianpeng Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fbf",
          "name": "Zehuan Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc0",
          "name": "Lijun Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc1",
          "name": "Lingfeng Ming",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc2",
          "name": "Guosheng Dong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc3",
          "name": "Da Pan",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc4",
          "name": "Chong Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc5",
          "name": "Yuanbo Fang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc6",
          "name": "Dongdong Kuang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc7",
          "name": "Mingrui Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc8",
          "name": "Chenglin Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fc9",
          "name": "Youwei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fca",
          "name": "Hongyu Guo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcb",
          "name": "Fengyu Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcc",
          "name": "Yuran Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcd",
          "name": "Bowen Ding",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fce",
          "name": "Wei Song",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fcf",
          "name": "Xu Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd0",
          "name": "Yuqi Huo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd1",
          "name": "Zheng Liang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd2",
          "name": "Shusen Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd3",
          "name": "Xin Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd4",
          "name": "Shuai Zhao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd5",
          "name": "Linchu Xiong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd6",
          "name": "Yozhen Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd7",
          "name": "Jiahui Ye",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd8",
          "name": "Wenhao Lu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fd9",
          "name": "Bowen Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fda",
          "name": "Yan Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdb",
          "name": "Yaqi Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdc",
          "name": "Xin Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdd",
          "name": "Lei Su",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fde",
          "name": "Hongda Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fdf",
          "name": "Fuzhong Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe0",
          "name": "Xuezhen Dong",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe1",
          "name": "Na Nie",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe2",
          "name": "Zhiying Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe3",
          "name": "Bin Xiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe4",
          "name": "Ting Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe5",
          "name": "Shunya Dang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe6",
          "name": "Ping Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe7",
          "name": "Yijia Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe8",
          "name": "Jincheng Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fe9",
          "name": "Jinjie Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fea",
          "name": "Xionghai Lin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71feb",
          "name": "Zhi Ma",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fec",
          "name": "Kegeng Wu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fed",
          "name": "Jia li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fee",
          "name": "Aiyuan Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fef",
          "name": "Hui Liu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff0",
          "name": "Jianqiang Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff1",
          "name": "Xiaoxi Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff2",
          "name": "Guangwei Ai",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff3",
          "name": "Wentao Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff4",
          "name": "Yicong Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff5",
          "name": "Xiaoqin Huang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff6",
          "name": "Kun Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff7",
          "name": "Wenjing Luo",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff8",
          "name": "Yifei Duan",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ff9",
          "name": "Lingling Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffa",
          "name": "Ran Xiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffb",
          "name": "Zhe Su",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffc",
          "name": "Jiani Pu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffd",
          "name": "Dian Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71ffe",
          "name": "Xu Jia",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb71fff",
          "name": "Tianyu Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72000",
          "name": "Mengyu Ai",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72001",
          "name": "Mang Wang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72002",
          "name": "Yujing Qiao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72003",
          "name": "Lei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72004",
          "name": "Yanjun Shen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72005",
          "name": "Fan Yang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72006",
          "name": "Miao Zhen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72007",
          "name": "Yijie Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72008",
          "name": "Mingyang Chen",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72009",
          "name": "Fei Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200a",
          "name": "Chenzheng Zhu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200b",
          "name": "Keer Lu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200c",
          "name": "Yaqi Zhao",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200d",
          "name": "Hao Liang",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200e",
          "name": "Youquan Li",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb7200f",
          "name": "Yanzhao Qin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72010",
          "name": "Linzhuang Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72011",
          "name": "Jianhua Xu",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72012",
          "name": "Haoze Sun",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72013",
          "name": "Mingan Lin",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72014",
          "name": "Zenan Zhou",
          "hidden": false
        },
        {
          "_id": "67986c6822990ae89bb72015",
          "name": "Weipeng Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T02:19:03.000Z",
      "title": "Baichuan-Omni-1.5 Technical Report",
      "summary": "We introduce Baichuan-Omni-1.5, an omni-modal model that not only has\nomni-modal understanding capabilities but also provides end-to-end audio\ngeneration capabilities. To achieve fluent and high-quality interaction across\nmodalities without compromising the capabilities of any modality, we\nprioritized optimizing three key aspects. First, we establish a comprehensive\ndata cleaning and synthesis pipeline for multimodal data, obtaining about 500B\nhigh-quality data (text, audio, and vision). Second, an audio-tokenizer\n(Baichuan-Audio-Tokenizer) has been designed to capture both semantic and\nacoustic information from audio, enabling seamless integration and enhanced\ncompatibility with MLLM. Lastly, we designed a multi-stage training strategy\nthat progressively integrates multimodal alignment and multitask fine-tuning,\nensuring effective synergy across all modalities. Baichuan-Omni-1.5 leads\ncontemporary models (including GPT4o-mini and MiniCPM-o 2.6) in terms of\ncomprehensive omni-modal capabilities. Notably, it achieves results comparable\nto leading models such as Qwen2-VL-72B across various multimodal medical\nbenchmarks.",
      "upvotes": 12,
      "discussionId": "67986c6b22990ae89bb720aa"
    },
    "publishedAt": "2025-01-28T00:34:49.721Z",
    "title": "Baichuan-Omni-1.5 Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15368.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5827
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15383",
      "authors": [
        {
          "_id": "67986c83b5e71350993d28eb",
          "name": "An Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ec",
          "name": "Bowen Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ed",
          "name": "Chengyuan Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ee",
          "name": "Dayiheng Liu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ef",
          "name": "Fei Huang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f0",
          "name": "Haoyan Huang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f1",
          "name": "Jiandong Jiang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f2",
          "name": "Jianhong Tu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f3",
          "name": "Jianwei Zhang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f4",
          "name": "Jingren Zhou",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f5",
          "name": "Junyang Lin",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f6",
          "name": "Kai Dang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f7",
          "name": "Kexin Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f8",
          "name": "Le Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28f9",
          "name": "Mei Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fa",
          "name": "Minmin Sun",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fb",
          "name": "Qin Zhu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fc",
          "name": "Rui Men",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fd",
          "name": "Tao He",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28fe",
          "name": "Weijia Xu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d28ff",
          "name": "Wenbiao Yin",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2900",
          "name": "Wenyuan Yu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2901",
          "name": "Xiafei Qiu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2902",
          "name": "Xingzhang Ren",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2903",
          "name": "Xinlong Yang",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2904",
          "name": "Yong Li",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2905",
          "name": "Zhiying Xu",
          "hidden": false
        },
        {
          "_id": "67986c83b5e71350993d2906",
          "name": "Zipeng Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T03:47:25.000Z",
      "title": "Qwen2.5-1M Technical Report",
      "summary": "We introduce Qwen2.5-1M, a series of models that extend the context length to\n1 million tokens. Compared to the previous 128K version, the Qwen2.5-1M series\nhave significantly enhanced long-context capabilities through long-context\npre-training and post-training. Key techniques such as long data synthesis,\nprogressive pre-training, and multi-stage supervised fine-tuning are employed\nto effectively enhance long-context performance while reducing training costs.\n  To promote the use of long-context models among a broader user base, we\npresent and open-source our inference framework. This framework includes a\nlength extrapolation method that can expand the model context lengths by at\nleast four times, or even more, without additional training. To reduce\ninference costs, we implement a sparse attention method along with chunked\nprefill optimization for deployment scenarios and a sparsity refinement method\nto improve precision. Additionally, we detail our optimizations in the\ninference engine, including kernel optimization, pipeline parallelism, and\nscheduling optimization, which significantly enhance overall inference\nperformance. By leveraging our inference framework, the Qwen2.5-1M models\nachieve a remarkable 3x to 7x prefill speedup in scenarios with 1 million\ntokens of context. This framework provides an efficient and powerful solution\nfor developing applications that require long-context processing using\nopen-source models.\n  The Qwen2.5-1M series currently includes the open-source models\nQwen2.5-7B-Instruct-1M and Qwen2.5-14B-Instruct-1M, as well as the API-accessed\nmodel Qwen2.5-Turbo. Evaluations show that Qwen2.5-1M models have been greatly\nimproved in long-context tasks without compromising performance in\nshort-context scenarios. Specifically, the Qwen2.5-14B-Instruct-1M model\nsignificantly outperforms GPT-4o-mini in long-context tasks and supports\ncontexts eight times longer.",
      "upvotes": 4,
      "discussionId": "67986c84b5e71350993d2974"
    },
    "publishedAt": "2025-01-28T00:35:46.871Z",
    "title": "Qwen2.5-1M Technical Report",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15383.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5827
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.15369",
      "authors": [
        {
          "_id": "6798706dabdc35456a92212d",
          "name": "Chuanyang Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-26T02:34:58.000Z",
      "title": "iFormer: Integrating ConvNet and Transformer for Mobile Application",
      "summary": "We present a new family of mobile hybrid vision networks, called iFormer,\nwith a focus on optimizing latency and accuracy on mobile applications. iFormer\neffectively integrates the fast local representation capacity of convolution\nwith the efficient global modeling ability of self-attention. The local\ninteractions are derived from transforming a standard convolutional network,\ni.e., ConvNeXt, to design a more lightweight mobile network. Our newly\nintroduced mobile modulation attention removes memory-intensive operations in\nMHA and employs an efficient modulation mechanism to boost dynamic global\nrepresentational capacity. We conduct comprehensive experiments demonstrating\nthat iFormer outperforms existing lightweight networks across various tasks.\nNotably, iFormer achieves an impressive Top-1 accuracy of 80.4\\% on ImageNet-1k\nwith a latency of only 1.10 ms on an iPhone 13, surpassing the recently\nproposed MobileNetV4 under similar latency constraints. Additionally, our\nmethod shows significant improvements in downstream tasks, including COCO\nobject detection, instance segmentation, and ADE20k semantic segmentation,\nwhile still maintaining low latency on mobile devices for high-resolution\ninputs in these scenarios.",
      "upvotes": 1,
      "discussionId": "6798706eabdc35456a92215a"
    },
    "publishedAt": "2025-01-28T00:51:51.263Z",
    "title": "iFormer: Integrating ConvNet and Transformer for Mobile Application",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.15369.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5827
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16295",
      "authors": [
        {
          "_id": "67986cd6bdc99911a989b0a5",
          "name": "Weixin Liang",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a6",
          "name": "Junhong Shen",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a7",
          "name": "Genghan Zhang",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a8",
          "name": "Ning Dong",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0a9",
          "name": "Luke Zettlemoyer",
          "hidden": false
        },
        {
          "_id": "67986cd6bdc99911a989b0aa",
          "name": "Lili Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T18:35:05.000Z",
      "title": "Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with\n  Modality-Aware Sparsity",
      "summary": "State Space Models (SSMs) have emerged as efficient alternatives to\nTransformers for sequential modeling, but their inability to leverage\nmodality-specific features limits their performance in multi-modal pretraining.\nHere, we propose Mixture-of-Mamba, a novel SSM architecture that introduces\nmodality-aware sparsity through modality-specific parameterization of the Mamba\nblock. Building on Mixture-of-Transformers (W. Liang et al. arXiv:2411.04996;\n2024), we extend the benefits of modality-aware sparsity to SSMs while\npreserving their computational efficiency. We evaluate Mixture-of-Mamba across\nthree multi-modal pretraining settings: Transfusion (interleaved text and\ncontinuous image tokens with diffusion loss), Chameleon (interleaved text and\ndiscrete image tokens), and an extended three-modality framework incorporating\nspeech. Mixture-of-Mamba consistently reaches the same loss values at earlier\ntraining steps with significantly reduced computational costs. In the\nTransfusion setting, Mixture-of-Mamba achieves equivalent image loss using only\n34.76% of the training FLOPs at the 1.4B scale. In the Chameleon setting,\nMixture-of-Mamba reaches similar image loss with just 42.50% of the FLOPs at\nthe 1.4B scale, and similar text loss with just 65.40% of the FLOPs. In the\nthree-modality setting, MoM matches speech loss at 24.80% of the FLOPs at the\n1.4B scale. Our ablation study highlights the synergistic effects of decoupling\nprojection components, where joint decoupling yields greater gains than\nindividual modifications. These results establish modality-aware sparsity as a\nversatile and effective design principle, extending its impact from\nTransformers to SSMs and setting new benchmarks in multi-modal pretraining. Our\ncode can be accessed at https://github.com/Weixin-Liang/Mixture-of-Mamba",
      "upvotes": 1,
      "discussionId": "67986cd7bdc99911a989b0ea"
    },
    "publishedAt": "2025-01-28T00:36:31.841Z",
    "title": "Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16295.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5827
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.16142",
      "authors": [
        {
          "_id": "67986cbc7dbf69e4e38539b7",
          "name": "Scott Fujimoto",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539b8",
          "name": "Pierluca D'Oro",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539b9",
          "name": "Amy Zhang",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539ba",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67986cbc7dbf69e4e38539bb",
          "name": "Michael Rabbat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-27T15:36:37.000Z",
      "title": "Towards General-Purpose Model-Free Reinforcement Learning",
      "summary": "Reinforcement learning (RL) promises a framework for near-universal\nproblem-solving. In practice however, RL algorithms are often tailored to\nspecific benchmarks, relying on carefully tuned hyperparameters and algorithmic\nchoices. Recently, powerful model-based RL methods have shown impressive\ngeneral results across benchmarks but come at the cost of increased complexity\nand slow run times, limiting their broader applicability. In this paper, we\nattempt to find a unifying model-free deep RL algorithm that can address a\ndiverse class of domains and problem settings. To achieve this, we leverage\nmodel-based representations that approximately linearize the value function,\ntaking advantage of the denser task objectives used by model-based RL while\navoiding the costs associated with planning or simulated trajectories. We\nevaluate our algorithm, MR.Q, on a variety of common RL benchmarks with a\nsingle set of hyperparameters and show a competitive performance against\ndomain-specific and general baselines, providing a concrete step towards\nbuilding general-purpose model-free deep RL algorithms.",
      "upvotes": 1,
      "discussionId": "67986cbf7dbf69e4e3853a89"
    },
    "publishedAt": "2025-01-28T00:36:09.186Z",
    "title": "Towards General-Purpose Model-Free Reinforcement Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.16142.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5827
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.14912",
      "authors": [
        {
          "_id": "67986d764fccd4b95149db0b",
          "name": "Juan Ramirez",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0c",
          "name": "Ignacio Hounie",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0d",
          "name": "Juan Elenter",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0e",
          "name": "Jose Gallego-Posada",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db0f",
          "name": "Meraj Hashemizadeh",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db10",
          "name": "Alejandro Ribeiro",
          "hidden": false
        },
        {
          "_id": "67986d764fccd4b95149db11",
          "name": "Simon Lacoste-Julien",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-24T20:39:38.000Z",
      "title": "Feasible Learning",
      "summary": "We introduce Feasible Learning (FL), a sample-centric learning paradigm where\nmodels are trained by solving a feasibility problem that bounds the loss for\neach training sample. In contrast to the ubiquitous Empirical Risk Minimization\n(ERM) framework, which optimizes for average performance, FL demands\nsatisfactory performance on every individual data point. Since any model that\nmeets the prescribed performance threshold is a valid FL solution, the choice\nof optimization algorithm and its dynamics play a crucial role in shaping the\nproperties of the resulting solutions. In particular, we study a primal-dual\napproach which dynamically re-weights the importance of each sample during\ntraining. To address the challenge of setting a meaningful threshold in\npractice, we introduce a relaxation of FL that incorporates slack variables of\nminimal norm. Our empirical analysis, spanning image classification, age\nregression, and preference optimization in large language models, demonstrates\nthat models trained via FL can learn from data while displaying improved tail\nbehavior compared to ERM, with only a marginal impact on average performance.",
      "upvotes": 0,
      "discussionId": "67986d784fccd4b95149db6b"
    },
    "publishedAt": "2025-01-28T00:39:11.423Z",
    "title": "Feasible Learning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14912.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5827
    },
    "isAuthorParticipating": false
  }
]