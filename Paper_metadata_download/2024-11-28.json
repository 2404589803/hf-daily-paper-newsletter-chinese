[
    {
        "paper": {
            "id": "2411.17949",
            "authors": [
                {
                    "_id": "6747cff9cf8e0c077f37d066",
                    "user": {
                        "_id": "63021630a35b21bd8a53305a",
                        "avatarUrl": "/avatars/7a7e8b39749eda61e57d8a1908726558.svg",
                        "isPro": true,
                        "fullname": "Gu Yuchao",
                        "user": "guyuchao",
                        "type": "user"
                    },
                    "name": "Yuchao Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T09:54:59.262Z",
                    "hidden": false
                },
                {
                    "_id": "6747cff9cf8e0c077f37d067",
                    "name": "Yipin Zhou",
                    "hidden": false
                },
                {
                    "_id": "6747cff9cf8e0c077f37d068",
                    "user": {
                        "_id": "63b8c5ec3d5ccb207f57f03a",
                        "avatarUrl": "/avatars/070f535e946b5cadb82f61e5ca0a90be.svg",
                        "isPro": false,
                        "fullname": "Yunfan Ye",
                        "user": "365sleep",
                        "type": "user"
                    },
                    "name": "Yunfan Ye",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T09:55:39.519Z",
                    "hidden": false
                },
                {
                    "_id": "6747cff9cf8e0c077f37d069",
                    "user": {
                        "_id": "5f7919d5f1e7ef6e919a1f55",
                        "avatarUrl": "/avatars/fb747fb43b65ccdfb08d7bf71525f92f.svg",
                        "isPro": false,
                        "fullname": "Yixin Nie",
                        "user": "ynie",
                        "type": "user"
                    },
                    "name": "Yixin Nie",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:47.282Z",
                    "hidden": false
                },
                {
                    "_id": "6747cff9cf8e0c077f37d06a",
                    "name": "Licheng Yu",
                    "hidden": false
                },
                {
                    "_id": "6747cff9cf8e0c077f37d06b",
                    "user": {
                        "_id": "64c163ecd9bdb0d64d58f716",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64c163ecd9bdb0d64d58f716/ln8536t4XH4ZUYxdSmlId.png",
                        "isPro": false,
                        "fullname": "Pingchuan Ma",
                        "user": "pcma",
                        "type": "user"
                    },
                    "name": "Pingchuan Ma",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:45.738Z",
                    "hidden": false
                },
                {
                    "_id": "6747cff9cf8e0c077f37d06c",
                    "user": {
                        "_id": "64440be5af034cdfd69ca3a7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg",
                        "isPro": false,
                        "fullname": "Qinghong Lin",
                        "user": "KevinQHLin",
                        "type": "user"
                    },
                    "name": "Kevin Qinghong Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T09:54:20.686Z",
                    "hidden": false
                },
                {
                    "_id": "6747cff9cf8e0c077f37d06d",
                    "user": {
                        "_id": "661ab3da2b14565c7acccf5c",
                        "avatarUrl": "/avatars/fa4fc03664803e02aede4d4c3d50b393.svg",
                        "isPro": false,
                        "fullname": "Mike Zheng Shou",
                        "user": "AnalMom",
                        "type": "user"
                    },
                    "name": "Mike Zheng Shou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T09:54:09.470Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T00:10:27.000Z",
            "title": "ROICtrl: Boosting Instance Control for Visual Generation",
            "summary": "Natural language often struggles to accurately associate positional and\nattribute information with multiple instances, which limits current text-based\nvisual generation models to simpler compositions featuring only a few dominant\ninstances. To address this limitation, this work enhances diffusion models by\nintroducing regional instance control, where each instance is governed by a\nbounding box paired with a free-form caption. Previous methods in this area\ntypically rely on implicit position encoding or explicit attention masks to\nseparate regions of interest (ROIs), resulting in either inaccurate coordinate\ninjection or large computational overhead. Inspired by ROI-Align in object\ndetection, we introduce a complementary operation called ROI-Unpool. Together,\nROI-Align and ROI-Unpool enable explicit, efficient, and accurate ROI\nmanipulation on high-resolution feature maps for visual generation. Building on\nROI-Unpool, we propose ROICtrl, an adapter for pretrained diffusion models that\nenables precise regional instance control. ROICtrl is compatible with\ncommunity-finetuned diffusion models, as well as with existing spatial-based\nadd-ons (\\eg, ControlNet, T2I-Adapter) and embedding-based add-ons (\\eg,\nIP-Adapter, ED-LoRA), extending their applications to multi-instance\ngeneration. Experiments show that ROICtrl achieves superior performance in\nregional instance control while significantly reducing computational costs.",
            "upvotes": 64,
            "discussionId": "6747cffccf8e0c077f37d227"
        },
        "publishedAt": "2024-11-28T00:46:30.961Z",
        "title": "ROICtrl: Boosting Instance Control for Visual Generation",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63021630a35b21bd8a53305a/ZhZspnGDLH-jWYBKe6IwV.png",
            "https://cdn-uploads.huggingface.co/production/uploads/63021630a35b21bd8a53305a/iE7aWN5T1eUgKvN9kQqlm.png",
            "https://cdn-uploads.huggingface.co/production/uploads/63021630a35b21bd8a53305a/nmRHUs2Duh4iqw1-kD_yY.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17949.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/7a7e8b39749eda61e57d8a1908726558.svg",
            "fullname": "Gu Yuchao",
            "name": "guyuchao",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 4
        }
    },
    {
        "paper": {
            "id": "2411.18613",
            "authors": [
                {
                    "_id": "6747e4ce2e5e8d6c8522f6f7",
                    "user": {
                        "_id": "63823d59a18d1ca09653aa21",
                        "avatarUrl": "/avatars/151e1ca46627abdd99c27945ea2fa441.svg",
                        "isPro": false,
                        "fullname": "Rundi Wu",
                        "user": "rundi",
                        "type": "user"
                    },
                    "name": "Rundi Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:38.809Z",
                    "hidden": false
                },
                {
                    "_id": "6747e4ce2e5e8d6c8522f6f8",
                    "name": "Ruiqi Gao",
                    "hidden": false
                },
                {
                    "_id": "6747e4ce2e5e8d6c8522f6f9",
                    "user": {
                        "_id": "63213768d2d45f315183abc3",
                        "avatarUrl": "/avatars/521f52f430b73e514afb06e3a9d6779d.svg",
                        "isPro": false,
                        "fullname": "Ben Poole",
                        "user": "doinkda",
                        "type": "user"
                    },
                    "name": "Ben Poole",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:35:38.276Z",
                    "hidden": false
                },
                {
                    "_id": "6747e4ce2e5e8d6c8522f6fa",
                    "user": {
                        "_id": "656a76839dcedd16d5d4ed49",
                        "avatarUrl": "/avatars/81e4a17f9af8c990dc13bf1a7bb4efbd.svg",
                        "isPro": false,
                        "fullname": "Alex Trevithick",
                        "user": "atrevithick",
                        "type": "user"
                    },
                    "name": "Alex Trevithick",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:35:32.163Z",
                    "hidden": false
                },
                {
                    "_id": "6747e4ce2e5e8d6c8522f6fb",
                    "name": "Changxi Zheng",
                    "hidden": false
                },
                {
                    "_id": "6747e4ce2e5e8d6c8522f6fc",
                    "name": "Jonathan T. Barron",
                    "hidden": false
                },
                {
                    "_id": "6747e4ce2e5e8d6c8522f6fd",
                    "user": {
                        "_id": "62f6e2792e53c2efd33faa92",
                        "avatarUrl": "/avatars/85d94b4022577747b8d2d10a82c2f3c7.svg",
                        "isPro": false,
                        "fullname": "Aleksander Holynski",
                        "user": "holynski",
                        "type": "user"
                    },
                    "name": "Aleksander Holynski",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:35:58.104Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T18:57:16.000Z",
            "title": "CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models",
            "summary": "We present CAT4D, a method for creating 4D (dynamic 3D) scenes from monocular\nvideo. CAT4D leverages a multi-view video diffusion model trained on a diverse\ncombination of datasets to enable novel view synthesis at any specified camera\nposes and timestamps. Combined with a novel sampling approach, this model can\ntransform a single monocular video into a multi-view video, enabling robust 4D\nreconstruction via optimization of a deformable 3D Gaussian representation. We\ndemonstrate competitive performance on novel view synthesis and dynamic scene\nreconstruction benchmarks, and highlight the creative capabilities for 4D scene\ngeneration from real or generated videos. See our project page for results and\ninteractive demos: cat-4d.github.io.",
            "upvotes": 21,
            "discussionId": "6747e4d42e5e8d6c8522f99d"
        },
        "publishedAt": "2024-11-28T02:15:52.741Z",
        "title": "CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18613.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5250
        }
    },
    {
        "paper": {
            "id": "2411.17188",
            "authors": [
                {
                    "_id": "67467ee679406f42a1466a07",
                    "user": {
                        "_id": "643be8879f5d314db2d9ed23",
                        "avatarUrl": "/avatars/64e9bb2c4e10fbe03e2b81afedf40865.svg",
                        "isPro": false,
                        "fullname": "Chen Dongping",
                        "user": "shuaishuaicdp",
                        "type": "user"
                    },
                    "name": "Dongping Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-27T22:20:26.369Z",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a08",
                    "user": {
                        "_id": "65a135df18b7d7c225737173",
                        "avatarUrl": "/avatars/a186f776011bb62c54fd73e787ff8415.svg",
                        "isPro": false,
                        "fullname": "Ruoxi Chen",
                        "user": "Dipsy0830",
                        "type": "user"
                    },
                    "name": "Ruoxi Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:39:29.970Z",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a09",
                    "name": "Shu Pu",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a0a",
                    "user": {
                        "_id": "6695ca27bcd81f395ec16e6d",
                        "avatarUrl": "/avatars/6f70cd2fe6d8316dfcf555b3d8cf706c.svg",
                        "isPro": false,
                        "fullname": "Zhaoyi LIU",
                        "user": "lzy8465",
                        "type": "user"
                    },
                    "name": "Zhaoyi Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:39:43.179Z",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a0b",
                    "name": "Yanru Wu",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a0c",
                    "name": "Caixi Chen",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a0d",
                    "user": {
                        "_id": "6326723c21c98f83d6ad128e",
                        "avatarUrl": "/avatars/6c208ff815c037d0a6a2ada3198e7fd4.svg",
                        "isPro": false,
                        "fullname": "Benlin Liu",
                        "user": "Tim666",
                        "type": "user"
                    },
                    "name": "Benlin Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:39:59.992Z",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a0e",
                    "name": "Yue Huang",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a0f",
                    "name": "Yao Wan",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a10",
                    "name": "Pan Zhou",
                    "hidden": false
                },
                {
                    "_id": "67467ee679406f42a1466a11",
                    "user": {
                        "_id": "66429868ab89e3a3a85668b0",
                        "avatarUrl": "/avatars/170e0daa454838deee2bf946f7118651.svg",
                        "isPro": false,
                        "fullname": "Ranjay Krishna",
                        "user": "ranjaykrishna",
                        "type": "user"
                    },
                    "name": "Ranjay Krishna",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:39:19.626Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-26T07:55:57.000Z",
            "title": "Interleaved Scene Graph for Interleaved Text-and-Image Generation\n  Assessment",
            "summary": "Many real-world user queries (e.g. \"How do to make egg fried rice?\") could\nbenefit from systems capable of generating responses with both textual steps\nwith accompanying images, similar to a cookbook. Models designed to generate\ninterleaved text and images face challenges in ensuring consistency within and\nacross these modalities. To address these challenges, we present ISG, a\ncomprehensive evaluation framework for interleaved text-and-image generation.\nISG leverages a scene graph structure to capture relationships between text and\nimage blocks, evaluating responses on four levels of granularity: holistic,\nstructural, block-level, and image-specific. This multi-tiered evaluation\nallows for a nuanced assessment of consistency, coherence, and accuracy, and\nprovides interpretable question-answer feedback. In conjunction with ISG, we\nintroduce a benchmark, ISG-Bench, encompassing 1,150 samples across 8\ncategories and 21 subcategories. This benchmark dataset includes complex\nlanguage-vision dependencies and golden answers to evaluate models effectively\non vision-centric tasks such as style transfer, a challenging area for current\nmodels. Using ISG-Bench, we demonstrate that recent unified vision-language\nmodels perform poorly on generating interleaved content. While compositional\napproaches that combine separate language and image models show a 111%\nimprovement over unified models at the holistic level, their performance\nremains suboptimal at both block and image levels. To facilitate future work,\nwe develop ISG-Agent, a baseline agent employing a \"plan-execute-refine\"\npipeline to invoke tools, achieving a 122% performance improvement.",
            "upvotes": 18,
            "discussionId": "67467ee879406f42a1466b08"
        },
        "publishedAt": "2024-11-28T00:57:52.642Z",
        "title": "Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17188.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/64e9bb2c4e10fbe03e2b81afedf40865.svg",
            "fullname": "Chen Dongping",
            "name": "shuaishuaicdp",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        }
    },
    {
        "paper": {
            "id": "2411.17945",
            "authors": [
                {
                    "_id": "6747c9cfae9bfb99e7596c3f",
                    "name": "Sankalp Sinha",
                    "hidden": false
                },
                {
                    "_id": "6747c9cfae9bfb99e7596c40",
                    "user": {
                        "_id": "65e07fb40d364b871d406648",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65e07fb40d364b871d406648/rrSqE8-7xmIzFfwvC_VPV.jpeg",
                        "isPro": false,
                        "fullname": "Mohammad Sadil Khan",
                        "user": "SadilKhan",
                        "type": "user"
                    },
                    "name": "Mohammad Sadil Khan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T10:35:09.219Z",
                    "hidden": false
                },
                {
                    "_id": "6747c9cfae9bfb99e7596c41",
                    "user": {
                        "_id": "6623d8266046dd4b8575906f",
                        "avatarUrl": "/avatars/0ca98a2b24f598ce02bf23ddbc6a7ecf.svg",
                        "isPro": false,
                        "fullname": "Muhammad Usama",
                        "user": "MUsama100",
                        "type": "user"
                    },
                    "name": "Muhammad Usama",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T12:29:26.415Z",
                    "hidden": false
                },
                {
                    "_id": "6747c9cfae9bfb99e7596c42",
                    "user": {
                        "_id": "66576f6e644a2dd7f2f93d68",
                        "avatarUrl": "/avatars/7da4c7bc2299b4216ffc0aa65cef0a26.svg",
                        "isPro": false,
                        "fullname": "Shino Sam",
                        "user": "alootikki",
                        "type": "user"
                    },
                    "name": "Shino Sam",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:41:32.383Z",
                    "hidden": false
                },
                {
                    "_id": "6747c9cfae9bfb99e7596c43",
                    "name": "Didier Stricker",
                    "hidden": false
                },
                {
                    "_id": "6747c9cfae9bfb99e7596c44",
                    "user": {
                        "_id": "65a11c41712e1321d051617b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/pWfZoI9PnErCKOf5XFiN1.jpeg",
                        "isPro": false,
                        "fullname": "Sk Aziz Ali",
                        "user": "saali14",
                        "type": "user"
                    },
                    "name": "Sk Aziz Ali",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:41:17.052Z",
                    "hidden": false
                },
                {
                    "_id": "6747c9cfae9bfb99e7596c45",
                    "user": {
                        "_id": "663b5392e6257fa86a26e8ef",
                        "avatarUrl": "/avatars/5a94f3ea7b0bd60264c35643de5423a0.svg",
                        "isPro": true,
                        "fullname": "Muhammad Zeshan Afzal",
                        "user": "mzafzal",
                        "type": "user"
                    },
                    "name": "Muhammad Zeshan Afzal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:40:52.954Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-26T23:39:43.000Z",
            "title": "MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D\n  Content Creation",
            "summary": "Generating high-fidelity 3D content from text prompts remains a significant\nchallenge in computer vision due to the limited size, diversity, and annotation\ndepth of the existing datasets. To address this, we introduce MARVEL-40M+, an\nextensive dataset with 40 million text annotations for over 8.9 million 3D\nassets aggregated from seven major 3D datasets. Our contribution is a novel\nmulti-stage annotation pipeline that integrates open-source pretrained\nmulti-view VLMs and LLMs to automatically produce multi-level descriptions,\nranging from detailed (150-200 words) to concise semantic tags (10-20 words).\nThis structure supports both fine-grained 3D reconstruction and rapid\nprototyping. Furthermore, we incorporate human metadata from source datasets\ninto our annotation pipeline to add domain-specific information in our\nannotation and reduce VLM hallucinations. Additionally, we develop MARVEL-FX3D,\na two-stage text-to-3D pipeline. We fine-tune Stable Diffusion with our\nannotations and use a pretrained image-to-3D network to generate 3D textured\nmeshes within 15s. Extensive evaluations show that MARVEL-40M+ significantly\noutperforms existing datasets in annotation quality and linguistic diversity,\nachieving win rates of 72.41% by GPT-4 and 73.40% by human evaluators.",
            "upvotes": 17,
            "discussionId": "6747c9d5ae9bfb99e7596d5c"
        },
        "publishedAt": "2024-11-28T00:16:04.498Z",
        "title": "MARVEL-40M+: Multi-Level Visual Elaboration for High-Fidelity Text-to-3D Content Creation",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/65e07fb40d364b871d406648/_TLTZPDLYtFfa2TDoCN6k.png",
            "https://cdn-uploads.huggingface.co/production/uploads/65e07fb40d364b871d406648/XlunuW_DLVlMyQr3wjsDw.png",
            "https://cdn-uploads.huggingface.co/production/uploads/65e07fb40d364b871d406648/TobEXTblX-nOL1whi7619.png",
            "https://cdn-uploads.huggingface.co/production/uploads/65e07fb40d364b871d406648/op_IdY_Qbyvv-BYQwAIUZ.png",
            "https://cdn-uploads.huggingface.co/production/uploads/65e07fb40d364b871d406648/4pVt0PCnlcoAwobz7M3EA.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17945.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65e07fb40d364b871d406648/rrSqE8-7xmIzFfwvC_VPV.jpeg",
            "fullname": "Mohammad Sadil Khan",
            "name": "SadilKhan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2411.18279",
            "authors": [
                {
                    "_id": "674803e9833196ed1932d215",
                    "user": {
                        "_id": "654dbac9938fbf1e696be8aa",
                        "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
                        "isPro": false,
                        "fullname": "Chaoyun Zhang",
                        "user": "vyokky",
                        "type": "user"
                    },
                    "name": "Chaoyun Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:42:30.670Z",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d216",
                    "user": {
                        "_id": "62c6df026a092eda1f1ab6e5",
                        "avatarUrl": "/avatars/d58fff1a157b189ce2617889ef5f6e2f.svg",
                        "isPro": false,
                        "fullname": "Shilin He",
                        "user": "shilhe",
                        "type": "user"
                    },
                    "name": "Shilin He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:42:36.575Z",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d217",
                    "name": "Jiaxu Qian",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d218",
                    "user": {
                        "_id": "61cd553d3dd34ba1985e075b",
                        "avatarUrl": "/avatars/5c39e4ac0892decc3af8e08109469196.svg",
                        "isPro": false,
                        "fullname": "Bowen Li",
                        "user": "bowenli",
                        "type": "user"
                    },
                    "name": "Bowen Li",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-11-28T05:47:23.418Z",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d219",
                    "user": {
                        "_id": "666933c97bf97e24f7b5266e",
                        "avatarUrl": "/avatars/283961b37d463a386b08ad33dacca0f4.svg",
                        "isPro": false,
                        "fullname": "Liqun Li",
                        "user": "liqul",
                        "type": "user"
                    },
                    "name": "Liqun Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:23.018Z",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d21a",
                    "name": "Si Qin",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d21b",
                    "name": "Yu Kang",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d21c",
                    "user": {
                        "_id": "653b52098abd634b83f4fd38",
                        "avatarUrl": "/avatars/c9c5023b030e94c1b1abfb7a1c1dfaf3.svg",
                        "isPro": false,
                        "fullname": "MingHua Ma",
                        "user": "Gezelligheid520",
                        "type": "user"
                    },
                    "name": "Minghua Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:42:51.136Z",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d21d",
                    "user": {
                        "_id": "652fc9f39bc50a6c0e435224",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/652fc9f39bc50a6c0e435224/70OBVDHHBsxG2giJ-E3_1.jpeg",
                        "isPro": false,
                        "fullname": "Lin Qingwei",
                        "user": "Eliblo1969",
                        "type": "user"
                    },
                    "name": "Qingwei Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:43:11.603Z",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d21e",
                    "name": "Saravan Rajmohan",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d21f",
                    "user": {
                        "_id": "66473d2c7abe6ad66e81a3dd",
                        "avatarUrl": "/avatars/82f40244806c06ffeaa1c4265e9725ea.svg",
                        "isPro": false,
                        "fullname": "ZHANGDONGMEI",
                        "user": "ZDM6426",
                        "type": "user"
                    },
                    "name": "Dongmei Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:43:30.415Z",
                    "hidden": false
                },
                {
                    "_id": "674803e9833196ed1932d220",
                    "name": "Qi Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T12:13:39.000Z",
            "title": "Large Language Model-Brained GUI Agents: A Survey",
            "summary": "GUIs have long been central to human-computer interaction, providing an\nintuitive and visually-driven way to access and interact with digital systems.\nThe advent of LLMs, particularly multimodal models, has ushered in a new era of\nGUI automation. They have demonstrated exceptional capabilities in natural\nlanguage understanding, code generation, and visual processing. This has paved\nthe way for a new generation of LLM-brained GUI agents capable of interpreting\ncomplex GUI elements and autonomously executing actions based on natural\nlanguage instructions. These agents represent a paradigm shift, enabling users\nto perform intricate, multi-step tasks through simple conversational commands.\nTheir applications span across web navigation, mobile app interactions, and\ndesktop automation, offering a transformative user experience that\nrevolutionizes how individuals interact with software. This emerging field is\nrapidly advancing, with significant progress in both research and industry.\n  To provide a structured understanding of this trend, this paper presents a\ncomprehensive survey of LLM-brained GUI agents, exploring their historical\nevolution, core components, and advanced techniques. We address research\nquestions such as existing GUI agent frameworks, the collection and utilization\nof data for training specialized GUI agents, the development of large action\nmodels tailored for GUI tasks, and the evaluation metrics and benchmarks\nnecessary to assess their effectiveness. Additionally, we examine emerging\napplications powered by these agents. Through a detailed analysis, this survey\nidentifies key research gaps and outlines a roadmap for future advancements in\nthe field. By consolidating foundational knowledge and state-of-the-art\ndevelopments, this work aims to guide both researchers and practitioners in\novercoming challenges and unlocking the full potential of LLM-brained GUI\nagents.",
            "upvotes": 13,
            "discussionId": "674803eb833196ed1932d29f"
        },
        "publishedAt": "2024-11-28T04:17:44.489Z",
        "title": "Large Language Model-Brained GUI Agents: A Survey",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18279.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
            "fullname": "Chaoyun Zhang",
            "name": "vyokky",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2411.17786",
            "authors": [
                {
                    "_id": "6748216e80aebd7436f21d92",
                    "user": {
                        "_id": "6515ac7f60757b8c8f6b8d31",
                        "avatarUrl": "/avatars/ed033f30f9f78ed68da976e6d01af0ea.svg",
                        "isPro": false,
                        "fullname": "Emanuele Aiello",
                        "user": "Ema97x",
                        "type": "user"
                    },
                    "name": "Emanuele Aiello",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:32:51.961Z",
                    "hidden": false
                },
                {
                    "_id": "6748216e80aebd7436f21d93",
                    "user": {
                        "_id": "646f1879c261dc4133830dd6",
                        "avatarUrl": "/avatars/f4134a8fb171f93c098a43f1c7a94eb6.svg",
                        "isPro": false,
                        "fullname": "Umberto Michieli",
                        "user": "u-michieli",
                        "type": "user"
                    },
                    "name": "Umberto Michieli",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:32:31.539Z",
                    "hidden": false
                },
                {
                    "_id": "6748216e80aebd7436f21d94",
                    "name": "Diego Valsesia",
                    "hidden": false
                },
                {
                    "_id": "6748216e80aebd7436f21d95",
                    "user": {
                        "_id": "65bced24c63d6a8d7f400b8b",
                        "avatarUrl": "/avatars/91212d7f39eba91158d7a0d0c823bc45.svg",
                        "isPro": false,
                        "fullname": "Mete Ozay",
                        "user": "mosams",
                        "type": "user"
                    },
                    "name": "Mete Ozay",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:32:12.229Z",
                    "hidden": false
                },
                {
                    "_id": "6748216e80aebd7436f21d96",
                    "user": {
                        "_id": "65e58cd65df8e81bed738067",
                        "avatarUrl": "/avatars/dd6eb8f9d2e0ae2c43727b9fe884f6e1.svg",
                        "isPro": false,
                        "fullname": "Enrico Magli",
                        "user": "emagli",
                        "type": "user"
                    },
                    "name": "Enrico Magli",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:32:06.161Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-26T15:03:14.000Z",
            "title": "DreamCache: Finetuning-Free Lightweight Personalized Image Generation\n  via Feature Caching",
            "summary": "Personalized image generation requires text-to-image generative models that\ncapture the core features of a reference subject to allow for controlled\ngeneration across different contexts. Existing methods face challenges due to\ncomplex training requirements, high inference costs, limited flexibility, or a\ncombination of these issues. In this paper, we introduce DreamCache, a scalable\napproach for efficient and high-quality personalized image generation. By\ncaching a small number of reference image features from a subset of layers and\na single timestep of the pretrained diffusion denoiser, DreamCache enables\ndynamic modulation of the generated image features through lightweight, trained\nconditioning adapters. DreamCache achieves state-of-the-art image and text\nalignment, utilizing an order of magnitude fewer extra parameters, and is both\nmore computationally effective and versatile than existing models.",
            "upvotes": 9,
            "discussionId": "6748217580aebd7436f220b5"
        },
        "publishedAt": "2024-11-28T06:24:42.337Z",
        "title": "DreamCache: Finetuning-Free Lightweight Personalized Image Generation via Feature Caching",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17786.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/ed033f30f9f78ed68da976e6d01af0ea.svg",
            "fullname": "Emanuele Aiello",
            "name": "Ema97x",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.17787",
            "authors": [
                {
                    "_id": "6747d429cd2486b8b0e1fb24",
                    "user": {
                        "_id": "65811eeaa2284a018e51f1ba",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dH8UZj6Kk5HJkI1DItCNm.jpeg",
                        "isPro": false,
                        "fullname": "Zigeng Chen",
                        "user": "Zigeng",
                        "type": "user"
                    },
                    "name": "Zigeng Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:44.162Z",
                    "hidden": false
                },
                {
                    "_id": "6747d429cd2486b8b0e1fb25",
                    "user": {
                        "_id": "64396ebc21221ac7411852b3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64396ebc21221ac7411852b3/SR0dC8N0bdj9tZFxYPpSf.jpeg",
                        "isPro": false,
                        "fullname": "Xinyin Ma",
                        "user": "horseee",
                        "type": "user"
                    },
                    "name": "Xinyin Ma",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:42.545Z",
                    "hidden": false
                },
                {
                    "_id": "6747d429cd2486b8b0e1fb26",
                    "name": "Gongfan Fang",
                    "hidden": false
                },
                {
                    "_id": "6747d429cd2486b8b0e1fb27",
                    "name": "Xinchao Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-26T15:13:15.000Z",
            "title": "Collaborative Decoding Makes Visual Auto-Regressive Modeling Efficient",
            "summary": "In the rapidly advancing field of image generation, Visual Auto-Regressive\n(VAR) modeling has garnered considerable attention for its innovative\nnext-scale prediction approach. This paradigm offers substantial improvements\nin efficiency, scalability, and zero-shot generalization. Yet, the inherently\ncoarse-to-fine nature of VAR introduces a prolonged token sequence, leading to\nprohibitive memory consumption and computational redundancies. To address these\nbottlenecks, we propose Collaborative Decoding (CoDe), a novel efficient\ndecoding strategy tailored for the VAR framework. CoDe capitalizes on two\ncritical observations: the substantially reduced parameter demands at larger\nscales and the exclusive generation patterns across different scales. Based on\nthese insights, we partition the multi-scale inference process into a seamless\ncollaboration between a large model and a small model. The large model serves\nas the 'drafter', specializing in generating low-frequency content at smaller\nscales, while the smaller model serves as the 'refiner', solely focusing on\npredicting high-frequency details at larger scales. This collaboration yields\nremarkable efficiency with minimal impact on quality: CoDe achieves a 1.7x\nspeedup, slashes memory usage by around 50%, and preserves image quality with\nonly a negligible FID increase from 1.95 to 1.98. When drafting steps are\nfurther decreased, CoDe can achieve an impressive 2.9x acceleration ratio,\nreaching 41 images/s at 256x256 resolution on a single NVIDIA 4090 GPU, while\npreserving a commendable FID of 2.27. The code is available at\nhttps://github.com/czg1225/CoDe",
            "upvotes": 9,
            "discussionId": "6747d42bcd2486b8b0e1fc13"
        },
        "publishedAt": "2024-11-28T01:00:45.833Z",
        "title": "Collaborative Decoding Makes Visual Auto-Regressive Modeling Efficient",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17787.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dH8UZj6Kk5HJkI1DItCNm.jpeg",
            "fullname": "Zigeng Chen",
            "name": "Zigeng",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 5
        }
    },
    {
        "paper": {
            "id": "2411.17440",
            "authors": [
                {
                    "_id": "674698d29c25e8cefac0250f",
                    "user": {
                        "_id": "63468720dd6d90d82ccf3450",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
                        "isPro": false,
                        "fullname": "YSH",
                        "user": "BestWishYsh",
                        "type": "user"
                    },
                    "name": "Shenghai Yuan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:50.317Z",
                    "hidden": false
                },
                {
                    "_id": "674698d29c25e8cefac02510",
                    "user": {
                        "_id": "63f37af60be81bdc5d92eebb",
                        "avatarUrl": "/avatars/b8dfdff4ab36988ec9a8643e82a3d2db.svg",
                        "isPro": false,
                        "fullname": "Huang",
                        "user": "Jinfa",
                        "type": "user"
                    },
                    "name": "Jinfa Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:36:16.287Z",
                    "hidden": false
                },
                {
                    "_id": "674698d29c25e8cefac02511",
                    "user": {
                        "_id": "6524370de0823fbfef8abf4b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/yOW16YDRam2qXpu3-4_RM.jpeg",
                        "isPro": false,
                        "fullname": "hexianyi",
                        "user": "hexianyi",
                        "type": "user"
                    },
                    "name": "Xianyi He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:36:06.803Z",
                    "hidden": false
                },
                {
                    "_id": "674698d29c25e8cefac02512",
                    "name": "Yunyuan Ge",
                    "hidden": false
                },
                {
                    "_id": "674698d29c25e8cefac02513",
                    "name": "Yujun Shi",
                    "hidden": false
                },
                {
                    "_id": "674698d29c25e8cefac02514",
                    "user": {
                        "_id": "65c0588569429d85dc594a85",
                        "avatarUrl": "/avatars/822203d982519b999247a53235e30c39.svg",
                        "isPro": false,
                        "fullname": "liuhan",
                        "user": "LiuhanChen",
                        "type": "user"
                    },
                    "name": "Liuhan Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:35:39.975Z",
                    "hidden": false
                },
                {
                    "_id": "674698d29c25e8cefac02515",
                    "name": "Jiebo Luo",
                    "hidden": false
                },
                {
                    "_id": "674698d29c25e8cefac02516",
                    "name": "Li Yuan",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-26T13:58:24.000Z",
            "title": "Identity-Preserving Text-to-Video Generation by Frequency Decomposition",
            "summary": "Identity-preserving text-to-video (IPT2V) generation aims to create\nhigh-fidelity videos with consistent human identity. It is an important task in\nvideo generation but remains an open problem for generative models. This paper\npushes the technical frontier of IPT2V in two directions that have not been\nresolved in literature: (1) A tuning-free pipeline without tedious case-by-case\nfinetuning, and (2) A frequency-aware heuristic identity-preserving DiT-based\ncontrol scheme. We propose ConsisID, a tuning-free DiT-based controllable IPT2V\nmodel to keep human identity consistent in the generated video. Inspired by\nprior findings in frequency analysis of diffusion transformers, it employs\nidentity-control signals in the frequency domain, where facial features can be\ndecomposed into low-frequency global features and high-frequency intrinsic\nfeatures. First, from a low-frequency perspective, we introduce a global facial\nextractor, which encodes reference images and facial key points into a latent\nspace, generating features enriched with low-frequency information. These\nfeatures are then integrated into shallow layers of the network to alleviate\ntraining challenges associated with DiT. Second, from a high-frequency\nperspective, we design a local facial extractor to capture high-frequency\ndetails and inject them into transformer blocks, enhancing the model's ability\nto preserve fine-grained features. We propose a hierarchical training strategy\nto leverage frequency information for identity preservation, transforming a\nvanilla pre-trained video generation model into an IPT2V model. Extensive\nexperiments demonstrate that our frequency-aware heuristic scheme provides an\noptimal control solution for DiT-based models. Thanks to this scheme, our\nConsisID generates high-quality, identity-preserving videos, making strides\ntowards more effective IPT2V.",
            "upvotes": 9,
            "discussionId": "674698d69c25e8cefac02743"
        },
        "publishedAt": "2024-11-28T00:43:37.847Z",
        "title": "Identity-Preserving Text-to-Video Generation by Frequency Decomposition",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17440.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
            "fullname": "YSH",
            "name": "BestWishYsh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 15
        }
    },
    {
        "paper": {
            "id": "2411.15139",
            "authors": [
                {
                    "_id": "6747e0c3e2d14d26680251b1",
                    "user": {
                        "_id": "6577073fc2bf55b1f6bafb49",
                        "avatarUrl": "/avatars/58803398b1a918b7570db17893e65122.svg",
                        "isPro": false,
                        "fullname": "liao",
                        "user": "LegendBC",
                        "type": "user"
                    },
                    "name": "Bencheng Liao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:40.481Z",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251b2",
                    "user": {
                        "_id": "64c1c9d595181d492cd90531",
                        "avatarUrl": "/avatars/b686706e661f22f0472ef716838946ea.svg",
                        "isPro": false,
                        "fullname": "Shaoyu Chen",
                        "user": "csy71",
                        "type": "user"
                    },
                    "name": "Shaoyu Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:45:55.020Z",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251b3",
                    "name": "Haoran Yin",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251b4",
                    "user": {
                        "_id": "6505b82fa61b2c010ee14c7b",
                        "avatarUrl": "/avatars/a092795b5fdd566c072fe05b20732b23.svg",
                        "isPro": false,
                        "fullname": "Bo JIANG",
                        "user": "bojiang-bentoml",
                        "type": "user"
                    },
                    "name": "Bo Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:46:16.062Z",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251b5",
                    "name": "Cheng Wang",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251b6",
                    "name": "Sixu Yan",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251b7",
                    "name": "Xinbang Zhang",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251b8",
                    "name": "Xiangyu Li",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251b9",
                    "name": "Ying Zhang",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251ba",
                    "name": "Qian Zhang",
                    "hidden": false
                },
                {
                    "_id": "6747e0c3e2d14d26680251bb",
                    "user": {
                        "_id": "62600de6d47e3dbae32ce1ce",
                        "avatarUrl": "/avatars/a536417cfec6e10ac415091bd1829426.svg",
                        "isPro": false,
                        "fullname": "Xinggang Wang",
                        "user": "xinggangw",
                        "type": "user"
                    },
                    "name": "Xinggang Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T10:43:58.649Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-22T18:59:47.000Z",
            "title": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous\n  Driving",
            "summary": "Recently, the diffusion model has emerged as a powerful generative technique\nfor robotic policy learning, capable of modeling multi-mode action\ndistributions. Leveraging its capability for end-to-end autonomous driving is a\npromising direction. However, the numerous denoising steps in the robotic\ndiffusion policy and the more dynamic, open-world nature of traffic scenes pose\nsubstantial challenges for generating diverse driving actions at a real-time\nspeed. To address these challenges, we propose a novel truncated diffusion\npolicy that incorporates prior multi-mode anchors and truncates the diffusion\nschedule, enabling the model to learn denoising from anchored Gaussian\ndistribution to the multi-mode driving action distribution. Additionally, we\ndesign an efficient cascade diffusion decoder for enhanced interaction with\nconditional scene context. The proposed model, DiffusionDrive, demonstrates\n10times reduction in denoising steps compared to vanilla diffusion policy,\ndelivering superior diversity and quality in just 2 steps. On the\nplanning-oriented NAVSIM dataset, with the aligned ResNet-34 backbone,\nDiffusionDrive achieves 88.1 PDMS without bells and whistles, setting a new\nrecord, while running at a real-time speed of 45 FPS on an NVIDIA 4090.\nQualitative results on challenging scenarios further confirm that\nDiffusionDrive can robustly generate diverse plausible driving actions. Code\nand model will be available at https://github.com/hustvl/DiffusionDrive.",
            "upvotes": 8,
            "discussionId": "6747e0c5e2d14d26680253cc"
        },
        "publishedAt": "2024-11-28T01:50:28.889Z",
        "title": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6577073fc2bf55b1f6bafb49/ucZ4p0V2eDNg9DjatxTY7.png",
            "https://cdn-uploads.huggingface.co/production/uploads/6577073fc2bf55b1f6bafb49/8JOynhcDlvCzgpw9EhPsy.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.15139.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/58803398b1a918b7570db17893e65122.svg",
            "fullname": "liao",
            "name": "LegendBC",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2411.14974",
            "authors": [
                {
                    "_id": "67486212d54ac635d1e18fef",
                    "name": "Jan Held",
                    "hidden": false
                },
                {
                    "_id": "67486212d54ac635d1e18ff0",
                    "name": "Renaud Vandeghen",
                    "hidden": false
                },
                {
                    "_id": "67486212d54ac635d1e18ff1",
                    "name": "Abdullah Hamdi",
                    "hidden": false
                },
                {
                    "_id": "67486212d54ac635d1e18ff2",
                    "name": "Adrien Deliege",
                    "hidden": false
                },
                {
                    "_id": "67486212d54ac635d1e18ff3",
                    "name": "Anthony Cioppa",
                    "hidden": false
                },
                {
                    "_id": "67486212d54ac635d1e18ff4",
                    "name": "Silvio Giancola",
                    "hidden": false
                },
                {
                    "_id": "67486212d54ac635d1e18ff5",
                    "name": "Andrea Vedaldi",
                    "hidden": false
                },
                {
                    "_id": "67486212d54ac635d1e18ff6",
                    "name": "Bernard Ghanem",
                    "hidden": false
                },
                {
                    "_id": "67486212d54ac635d1e18ff7",
                    "name": "Marc Van Droogenbroeck",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-22T14:31:39.000Z",
            "title": "3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes",
            "summary": "Recent advances in radiance field reconstruction, such as 3D Gaussian\nSplatting (3DGS), have achieved high-quality novel view synthesis and fast\nrendering by representing scenes with compositions of Gaussian primitives.\nHowever, 3D Gaussians present several limitations for scene reconstruction.\nAccurately capturing hard edges is challenging without significantly increasing\nthe number of Gaussians, creating a large memory footprint. Moreover, they\nstruggle to represent flat surfaces, as they are diffused in space. Without\nhand-crafted regularizers, they tend to disperse irregularly around the actual\nsurface. To circumvent these issues, we introduce a novel method, named 3D\nConvex Splatting (3DCS), which leverages 3D smooth convexes as primitives for\nmodeling geometrically-meaningful radiance fields from multi-view images.\nSmooth convex shapes offer greater flexibility than Gaussians, allowing for a\nbetter representation of 3D scenes with hard edges and dense volumes using\nfewer primitives. Powered by our efficient CUDA-based rasterizer, 3DCS achieves\nsuperior performance over 3DGS on benchmarks such as Mip-NeRF360, Tanks and\nTemples, and Deep Blending. Specifically, our method attains an improvement of\nup to 0.81 in PSNR and 0.026 in LPIPS compared to 3DGS while maintaining high\nrendering speeds and reducing the number of required primitives. Our results\nhighlight the potential of 3D Convex Splatting to become the new standard for\nhigh-quality scene reconstruction and novel view synthesis. Project page:\nconvexsplatting.github.io.",
            "upvotes": 6,
            "discussionId": "67486219d54ac635d1e191bf"
        },
        "publishedAt": "2024-11-28T11:02:02.607Z",
        "title": "3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62fe3442e9061c0170d06e0b/UvX55U92py-vsRNBQzmk-.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.14974.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660827186084-62fe3442e9061c0170d06e0b.png",
            "fullname": "Abdullah Hamdi",
            "name": "ajhamdi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2411.18197",
            "authors": [
                {
                    "_id": "6747ff92d3cce579b6e34efa",
                    "user": {
                        "_id": "65fba7bd0b78c48c9e39e0f1",
                        "avatarUrl": "/avatars/ca432ead932cb7c641f9375b9653ad0d.svg",
                        "isPro": false,
                        "fullname": "Jason Guo",
                        "user": "jasongzy",
                        "type": "user"
                    },
                    "name": "Zhiyang Guo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:24.694Z",
                    "hidden": false
                },
                {
                    "_id": "6747ff92d3cce579b6e34efb",
                    "user": {
                        "_id": "6321fdcc6b1992383fa3e405",
                        "avatarUrl": "/avatars/69a010d43c78f46cb5d0e4a5dd3ef9f1.svg",
                        "isPro": false,
                        "fullname": "Jinxu Xiang",
                        "user": "PhantomXJX",
                        "type": "user"
                    },
                    "name": "Jinxu Xiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:27:46.277Z",
                    "hidden": false
                },
                {
                    "_id": "6747ff92d3cce579b6e34efc",
                    "user": {
                        "_id": "65f9ba6a1e5b57dc4f831e38",
                        "avatarUrl": "/avatars/941aa0e217837f4532cbc37a6580c62c.svg",
                        "isPro": false,
                        "fullname": "Kai Ma",
                        "user": "KaiMa-endeavour",
                        "type": "user"
                    },
                    "name": "Kai Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:27:53.098Z",
                    "hidden": false
                },
                {
                    "_id": "6747ff92d3cce579b6e34efd",
                    "name": "Wengang Zhou",
                    "hidden": false
                },
                {
                    "_id": "6747ff92d3cce579b6e34efe",
                    "name": "Houqiang Li",
                    "hidden": false
                },
                {
                    "_id": "6747ff92d3cce579b6e34eff",
                    "name": "Ran Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T10:18:06.000Z",
            "title": "Make-It-Animatable: An Efficient Framework for Authoring Animation-Ready\n  3D Characters",
            "summary": "3D characters are essential to modern creative industries, but making them\nanimatable often demands extensive manual work in tasks like rigging and\nskinning. Existing automatic rigging tools face several limitations, including\nthe necessity for manual annotations, rigid skeleton topologies, and limited\ngeneralization across diverse shapes and poses. An alternative approach is to\ngenerate animatable avatars pre-bound to a rigged template mesh. However, this\nmethod often lacks flexibility and is typically limited to realistic human\nshapes. To address these issues, we present Make-It-Animatable, a novel\ndata-driven method to make any 3D humanoid model ready for character animation\nin less than one second, regardless of its shapes and poses. Our unified\nframework generates high-quality blend weights, bones, and pose\ntransformations. By incorporating a particle-based shape autoencoder, our\napproach supports various 3D representations, including meshes and 3D Gaussian\nsplats. Additionally, we employ a coarse-to-fine representation and a\nstructure-aware modeling strategy to ensure both accuracy and robustness, even\nfor characters with non-standard skeleton structures. We conducted extensive\nexperiments to validate our framework's effectiveness. Compared to existing\nmethods, our approach demonstrates significant improvements in both quality and\nspeed.",
            "upvotes": 6,
            "discussionId": "6747ff94d3cce579b6e34f37"
        },
        "publishedAt": "2024-11-28T05:15:13.795Z",
        "title": "Make-It-Animatable: An Efficient Framework for Authoring Animation-Ready 3D Characters",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18197.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5250
        }
    },
    {
        "paper": {
            "id": "2411.17769",
            "authors": [
                {
                    "_id": "67480fd786d0329c44dcdfa0",
                    "user": {
                        "_id": "64a7780d87cbd4dc73fd1889",
                        "avatarUrl": "/avatars/d680cdc58d69ef0f5091cbc122f3383b.svg",
                        "isPro": false,
                        "fullname": "HOU XINYU",
                        "user": "itsmag11",
                        "type": "user"
                    },
                    "name": "Xinyu Hou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:36:46.015Z",
                    "hidden": false
                },
                {
                    "_id": "67480fd786d0329c44dcdfa1",
                    "user": {
                        "_id": "630ad0dd2ff113e0fb31c6b0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1671174653229-630ad0dd2ff113e0fb31c6b0.jpeg",
                        "isPro": false,
                        "fullname": "Zongsheng Yue",
                        "user": "OAOA",
                        "type": "user"
                    },
                    "name": "Zongsheng Yue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:37:04.861Z",
                    "hidden": false
                },
                {
                    "_id": "67480fd786d0329c44dcdfa2",
                    "name": "Xiaoming Li",
                    "hidden": false
                },
                {
                    "_id": "67480fd786d0329c44dcdfa3",
                    "user": {
                        "_id": "67459d997a49660f7f62452f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/X25yTdxC_hcLVxpx4voZo.png",
                        "isPro": false,
                        "fullname": "Chen Change Loy",
                        "user": "cavanloy",
                        "type": "user"
                    },
                    "name": "Chen Change Loy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:36:53.340Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-26T08:23:16.000Z",
            "title": "Omegance: A Single Parameter for Various Granularities in\n  Diffusion-Based Synthesis",
            "summary": "In this work, we introduce a single parameter omega, to effectively\ncontrol granularity in diffusion-based synthesis. This parameter is\nincorporated during the denoising steps of the diffusion model's reverse\nprocess. Our approach does not require model retraining, architectural\nmodifications, or additional computational overhead during inference, yet\nenables precise control over the level of details in the generated outputs.\nMoreover, spatial masks or denoising schedules with varying omega values can\nbe applied to achieve region-specific or timestep-specific granularity control.\nPrior knowledge of image composition from control signals or reference images\nfurther facilitates the creation of precise omega masks for granularity\ncontrol on specific objects. To highlight the parameter's role in controlling\nsubtle detail variations, the technique is named Omegance, combining \"omega\"\nand \"nuance\". Our method demonstrates impressive performance across various\nimage and video synthesis tasks and is adaptable to advanced diffusion models.\nThe code is available at https://github.com/itsmag11/Omegance.",
            "upvotes": 5,
            "discussionId": "67480fda86d0329c44dce061"
        },
        "publishedAt": "2024-11-28T05:08:32.279Z",
        "title": "Omegance: A Single Parameter for Various Granularities in Diffusion-Based Synthesis",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17769.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5250
        }
    },
    {
        "paper": {
            "id": "2411.18363",
            "authors": [
                {
                    "_id": "674805864fedd3964253eadf",
                    "name": "Qing Jiang",
                    "hidden": false
                },
                {
                    "_id": "674805864fedd3964253eae0",
                    "name": "Gen luo",
                    "hidden": false
                },
                {
                    "_id": "674805864fedd3964253eae1",
                    "user": {
                        "_id": "64672f4aa9b4610868a0407e",
                        "avatarUrl": "/avatars/2e964e7edd2d1ebaa2b8597992090925.svg",
                        "isPro": false,
                        "fullname": "Yuqin Yang",
                        "user": "CRIS-Yang",
                        "type": "user"
                    },
                    "name": "Yuqin Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T13:12:28.350Z",
                    "hidden": false
                },
                {
                    "_id": "674805864fedd3964253eae2",
                    "name": "Yuda Xiong",
                    "hidden": false
                },
                {
                    "_id": "674805864fedd3964253eae3",
                    "name": "Yihao Chen",
                    "hidden": false
                },
                {
                    "_id": "674805864fedd3964253eae4",
                    "user": {
                        "_id": "669f0abdc13da2bbe268c5c3",
                        "avatarUrl": "/avatars/87961bfd01c53c420ae13133d643f22c.svg",
                        "isPro": false,
                        "fullname": "Zhaoyang Zeng",
                        "user": "zengzhaoyang",
                        "type": "user"
                    },
                    "name": "Zhaoyang Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:29:31.995Z",
                    "hidden": false
                },
                {
                    "_id": "674805864fedd3964253eae5",
                    "name": "Tianhe Ren",
                    "hidden": false
                },
                {
                    "_id": "674805864fedd3964253eae6",
                    "name": "Lei Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T14:11:10.000Z",
            "title": "ChatRex: Taming Multimodal LLM for Joint Perception and Understanding",
            "summary": "Perception and understanding are two pillars of computer vision. While\nmultimodal large language models (MLLM) have demonstrated remarkable visual\nunderstanding capabilities, they arguably lack accurate perception abilities,\ne.g. the stage-of-the-art model Qwen2-VL only achieves a 43.9 recall rate on\nthe COCO dataset, limiting many tasks requiring the combination of perception\nand understanding. In this work, we aim to bridge this perception gap from both\nmodel designing and data development perspectives. We first introduce ChatRex,\nan MLLM with a decoupled perception design. Instead of having the LLM directly\npredict box coordinates, we feed the output boxes from a universal proposal\nnetwork into the LLM, allowing it to output the corresponding box indices to\nrepresent its detection results, turning the regression task into a\nretrieval-based task that LLM handles more proficiently. From the data\nperspective, we build a fully automated data engine and construct the\nRexverse-2M dataset which possesses multiple granularities to support the joint\ntraining of perception and understanding. After standard two-stage training,\nChatRex demonstrates strong perception capabilities while preserving multimodal\nunderstanding performance. The combination of these two capabilities\nsimultaneously unlocks many attractive applications, demonstrating the\ncomplementary roles of both perception and understanding in MLLM. Code is\navailable at https://github.com/IDEA-Research/ChatRex.",
            "upvotes": 5,
            "discussionId": "674805884fedd3964253eb87"
        },
        "publishedAt": "2024-11-28T04:27:00.128Z",
        "title": "ChatRex: Taming Multimodal LLM for Joint Perception and Understanding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18363.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647f46b6838ac3601fc89852/N5cr1MFEtgKLJ4sVAhS04.jpeg",
            "fullname": "Qing Jiang",
            "name": "Mountchicken",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 9
        }
    },
    {
        "paper": {
            "id": "2411.16781",
            "authors": [
                {
                    "_id": "674713a34295e90fc523ab3d",
                    "user": {
                        "_id": "66afcc9b3cbe4ea9a4b57df6",
                        "avatarUrl": "/avatars/add1c3cdfbb9c1013820761057a6a643.svg",
                        "isPro": false,
                        "fullname": "Li YiHeng",
                        "user": "LiyiGang",
                        "type": "user"
                    },
                    "name": "Yiheng Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-27T22:19:41.408Z",
                    "hidden": false
                },
                {
                    "_id": "674713a34295e90fc523ab3e",
                    "user": {
                        "_id": "64f1e1badd92641727444364",
                        "avatarUrl": "/avatars/a2e9331b456694ff5f955281416e33d9.svg",
                        "isPro": false,
                        "fullname": "ruibing hou",
                        "user": "flow2023",
                        "type": "user"
                    },
                    "name": "Ruibing Hou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:37:17.826Z",
                    "hidden": false
                },
                {
                    "_id": "674713a34295e90fc523ab3f",
                    "name": "Hong Chang",
                    "hidden": false
                },
                {
                    "_id": "674713a34295e90fc523ab40",
                    "name": "Shiguang Shan",
                    "hidden": false
                },
                {
                    "_id": "674713a34295e90fc523ab41",
                    "user": {
                        "_id": "670f0d33c9504aac1179cd3c",
                        "avatarUrl": "/avatars/a593778043e9dca533cfb89e03ce57f9.svg",
                        "isPro": false,
                        "fullname": "xilin chen",
                        "user": "Heylon",
                        "type": "user"
                    },
                    "name": "Xilin Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T11:37:38.181Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-25T08:06:30.000Z",
            "title": "UniPose: A Unified Multimodal Framework for Human Pose Comprehension,\n  Generation and Editing",
            "summary": "Human pose plays a crucial role in the digital age. While recent works have\nachieved impressive progress in understanding and generating human poses, they\noften support only a single modality of control signals and operate in\nisolation, limiting their application in real-world scenarios. This paper\npresents UniPose, a framework employing Large Language Models (LLMs) to\ncomprehend, generate, and edit human poses across various modalities, including\nimages, text, and 3D SMPL poses. Specifically, we apply a pose tokenizer to\nconvert 3D poses into discrete pose tokens, enabling seamless integration into\nthe LLM within a unified vocabulary. To further enhance the fine-grained pose\nperception capabilities, we facilitate UniPose with a mixture of visual\nencoders, among them a pose-specific visual encoder. Benefiting from a unified\nlearning strategy, UniPose effectively transfers knowledge across different\npose-relevant tasks, adapts to unseen tasks, and exhibits extended\ncapabilities. This work serves as the first attempt at building a\ngeneral-purpose framework for pose comprehension, generation, and editing.\nExtensive experiments highlight UniPose's competitive and even superior\nperformance across various pose-relevant tasks.",
            "upvotes": 4,
            "discussionId": "674713a44295e90fc523ab91"
        },
        "publishedAt": "2024-11-28T03:30:27.379Z",
        "title": "UniPose: A Unified Multimodal Framework for Human Pose Comprehension, Generation and Editing",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.16781.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/add1c3cdfbb9c1013820761057a6a643.svg",
            "fullname": "Li YiHeng",
            "name": "LiyiGang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.18462",
            "authors": [
                {
                    "_id": "6747d5adfc7953b90c88935d",
                    "user": {
                        "_id": "6430bdd8cd31d174a9f900fb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/Y9SPnRfpKSbYc7MhNdP-H.jpeg",
                        "isPro": false,
                        "fullname": "Ziyin Zhang",
                        "user": "Geralt-Targaryen",
                        "type": "user"
                    },
                    "name": "Ziyin Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T12:19:43.515Z",
                    "hidden": false
                },
                {
                    "_id": "6747d5adfc7953b90c88935e",
                    "user": {
                        "_id": "660399710f1fc2f16de18072",
                        "avatarUrl": "/avatars/c22a749cc45db693c2d9ea877c7cace4.svg",
                        "isPro": false,
                        "fullname": "Jiahao Xu",
                        "user": "Jiahao004",
                        "type": "user"
                    },
                    "name": "Jiahao Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:20:57.716Z",
                    "hidden": false
                },
                {
                    "_id": "6747d5adfc7953b90c88935f",
                    "name": "Tian Liang",
                    "hidden": false
                },
                {
                    "_id": "6747d5adfc7953b90c889360",
                    "name": "Xingyu Chen",
                    "hidden": false
                },
                {
                    "_id": "6747d5adfc7953b90c889361",
                    "user": {
                        "_id": "638439ca834d3558a398d035",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669609868550-noauth.png",
                        "isPro": false,
                        "fullname": "Zhiwei He",
                        "user": "zwhe99",
                        "type": "user"
                    },
                    "name": "Zhiwei He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:21:46.167Z",
                    "hidden": false
                },
                {
                    "_id": "6747d5adfc7953b90c889362",
                    "name": "Rui Wang",
                    "hidden": false
                },
                {
                    "_id": "6747d5adfc7953b90c889363",
                    "user": {
                        "_id": "67485743561b1e6f9579389f",
                        "avatarUrl": "/avatars/8a4cc63bd7be388010bc329bb74582a1.svg",
                        "isPro": false,
                        "fullname": "Zhaopeng Tu",
                        "user": "zptu",
                        "type": "user"
                    },
                    "name": "Zhaopeng Tu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T11:44:05.551Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T15:53:17.000Z",
            "title": "Draft Model Knows When to Stop: A Self-Verification Length Policy for\n  Speculative Decoding",
            "summary": "Speculative Decoding (SD) has become an important technique in accelerating\nthe inference speed of large language models. Conventional SD methods employ a\nfixed draft length, which ignores the token generation difficulty across tasks.\nConsequently, in this paper, we address such an issue and introduce SVIP - a\ndifficulty-aware dynamic draft length policy for speculative decoding systems.\nBased on a theoretical lower bound of draft token acceptance rate and its\ninference-time approximation, SVIP adaptively determines the lengths of draft\nsequences based on the entropy of each draft token distribution. Experimental\nresults on mainstream SD benchmarks and frameworks demonstrate the superior\nperformance of SVIP, achieving up to 20\\% walltime speedup on SpecBench over\nbaseline SD methods and 60\\% speedup on MT-Bench for long-form generation of up\nto 8K tokens. Moreover, SVIP is totally training-free and compatible with any\nexisting SD methods that generate draft tokens autoregressively. Experimental\nresults also show that SVIP yields consistent walltime improvement on top of\nGliDe & CaPE and EAGLE-2.",
            "upvotes": 4,
            "discussionId": "6747d5aefc7953b90c889381"
        },
        "publishedAt": "2024-11-28T01:04:04.834Z",
        "title": "Draft Model Knows When to Stop: A Self-Verification Length Policy for Speculative Decoding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18462.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/Y9SPnRfpKSbYc7MhNdP-H.jpeg",
            "fullname": "Ziyin Zhang",
            "name": "Geralt-Targaryen",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.17991",
            "authors": [
                {
                    "_id": "6747ea29d59bc71f133e8d0a",
                    "user": {
                        "_id": "643672220b2c0d86d0b0f639",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643672220b2c0d86d0b0f639/8nqZku8HxsSL_zR3XJPqK.png",
                        "isPro": false,
                        "fullname": "Yueqian Wang",
                        "user": "wangyueqian",
                        "type": "user"
                    },
                    "name": "Yueqian Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:22:04.153Z",
                    "hidden": false
                },
                {
                    "_id": "6747ea29d59bc71f133e8d0b",
                    "name": "Xiaojun Meng",
                    "hidden": false
                },
                {
                    "_id": "6747ea29d59bc71f133e8d0c",
                    "user": {
                        "_id": "60b9e6837946aff342f734ae",
                        "avatarUrl": "/avatars/a711a6aa35757dfd7b78b26098a964fc.svg",
                        "isPro": false,
                        "fullname": "Yuxuan Wang",
                        "user": "ColorfulAI",
                        "type": "user"
                    },
                    "name": "Yuxuan Wang",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-11-28T07:16:32.123Z",
                    "hidden": false
                },
                {
                    "_id": "6747ea29d59bc71f133e8d0d",
                    "user": {
                        "_id": "64d245829db917d3f0a256d2",
                        "avatarUrl": "/avatars/f7821992daa8d3a587b45b2ecbc4304e.svg",
                        "isPro": false,
                        "fullname": "jianxin liang",
                        "user": "ljx2000",
                        "type": "user"
                    },
                    "name": "Jianxin Liang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:22:17.700Z",
                    "hidden": false
                },
                {
                    "_id": "6747ea29d59bc71f133e8d0e",
                    "user": {
                        "_id": "6348ad7826a24bfaf4ae7924",
                        "avatarUrl": "/avatars/6af4ebc10cf6dffa18efc859144da841.svg",
                        "isPro": false,
                        "fullname": "Wei JianSheng",
                        "user": "jiansheng80",
                        "type": "user"
                    },
                    "name": "Jiansheng Wei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:22:30.128Z",
                    "hidden": false
                },
                {
                    "_id": "6747ea29d59bc71f133e8d0f",
                    "name": "Huishuai Zhang",
                    "hidden": false
                },
                {
                    "_id": "6747ea29d59bc71f133e8d10",
                    "user": {
                        "_id": "66389190596ff1c3447cb88b",
                        "avatarUrl": "/avatars/e1eabfa6892810a830d8a42c1b5ee928.svg",
                        "isPro": false,
                        "fullname": "zhao dongyang",
                        "user": "yang2016",
                        "type": "user"
                    },
                    "name": "Dongyan Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:22:53.269Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T02:15:34.000Z",
            "title": "VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video\n  Comprehension with Video-Text Duet Interaction Format",
            "summary": "Recent researches on video large language models (VideoLLM) predominantly\nfocus on model architectures and training datasets, leaving the interaction\nformat between the user and the model under-explored. In existing works, users\noften interact with VideoLLMs by using the entire video and a query as input,\nafter which the model generates a response. This interaction format constrains\nthe application of VideoLLMs in scenarios such as live-streaming comprehension\nwhere videos do not end and responses are required in a real-time manner, and\nalso results in unsatisfactory performance on time-sensitive tasks that\nrequires localizing video segments. In this paper, we focus on a video-text\nduet interaction format. This interaction format is characterized by the\ncontinuous playback of the video, and both the user and the model can insert\ntheir text messages at any position during the video playback. When a text\nmessage ends, the video continues to play, akin to the alternative of two\nperformers in a duet. We construct MMDuetIT, a video-text training dataset\ndesigned to adapt VideoLLMs to video-text duet interaction format. We also\nintroduce the Multi-Answer Grounded Video Question Answering (MAGQA) task to\nbenchmark the real-time response ability of VideoLLMs. Trained on MMDuetIT,\nMMDuet demonstrates that adopting the video-text duet interaction format\nenables the model to achieve significant improvements in various time-sensitive\ntasks (76% CIDEr on YouCook2 dense video captioning, 90\\% mAP on QVHighlights\nhighlight detection and 25% R@0.5 on Charades-STA temporal video grounding)\nwith minimal training efforts, and also enable VideoLLMs to reply in a\nreal-time manner as the video plays. Code, data and demo are available at:\nhttps://github.com/yellow-binary-tree/MMDuet.",
            "upvotes": 3,
            "discussionId": "6747ea2bd59bc71f133e8d69"
        },
        "publishedAt": "2024-11-28T08:18:04.897Z",
        "title": "VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video Comprehension with Video-Text Duet Interaction Format",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17991.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/a711a6aa35757dfd7b78b26098a964fc.svg",
            "fullname": "Yuxuan Wang",
            "name": "ColorfulAI",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        }
    },
    {
        "paper": {
            "id": "2411.18412",
            "authors": [
                {
                    "_id": "67483446e4a6e7b8a5223991",
                    "user": {
                        "_id": "6479b418bfaa9e96b850959b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6479b418bfaa9e96b850959b/qQSSgCK2M8ATutL6H0Yvv.jpeg",
                        "isPro": false,
                        "fullname": "David Serrano Lozano",
                        "user": "davidserra9",
                        "type": "user"
                    },
                    "name": "David Serrano-Lozano",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:29:39.301Z",
                    "hidden": false
                },
                {
                    "_id": "67483446e4a6e7b8a5223992",
                    "name": "Luis Herranz",
                    "hidden": false
                },
                {
                    "_id": "67483446e4a6e7b8a5223993",
                    "name": "Shaolin Su",
                    "hidden": false
                },
                {
                    "_id": "67483446e4a6e7b8a5223994",
                    "name": "Javier Vazquez-Corral",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T14:58:08.000Z",
            "title": "Adaptive Blind All-in-One Image Restoration",
            "summary": "Blind all-in-one image restoration models aim to recover a high-quality image\nfrom an input degraded with unknown distortions. However, these models require\nall the possible degradation types to be defined during the training stage\nwhile showing limited generalization to unseen degradations, which limits their\npractical application in complex cases. In this paper, we propose a simple but\neffective adaptive blind all-in-one restoration (ABAIR) model, which can\naddress multiple degradations, generalizes well to unseen degradations, and\nefficiently incorporate new degradations by training a small fraction of\nparameters. First, we train our baseline model on a large dataset of natural\nimages with multiple synthetic degradations, augmented with a segmentation head\nto estimate per-pixel degradation types, resulting in a powerful backbone able\nto generalize to a wide range of degradations. Second, we adapt our baseline\nmodel to varying image restoration tasks using independent low-rank adapters.\nThird, we learn to adaptively combine adapters to versatile images via a\nflexible and lightweight degradation estimator. Our model is both powerful in\nhandling specific distortions and flexible in adapting to complex tasks, it not\nonly outperforms the state-of-the-art by a large margin on five- and three-task\nIR setups, but also shows improved generalization to unseen degradations and\nalso composite distortions.",
            "upvotes": 3,
            "discussionId": "67483449e4a6e7b8a5223a84"
        },
        "publishedAt": "2024-11-28T07:49:36.446Z",
        "title": "Adaptive Blind All-in-One Image Restoration",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6479b418bfaa9e96b850959b/6HqUqDLI2-CZMQaOFfeuM.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/6479b418bfaa9e96b850959b/9Yqrsm7TfO1msTuzxUrpO.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/6479b418bfaa9e96b850959b/LlSn92yLbhr0CVeZzzO13.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18412.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6479b418bfaa9e96b850959b/qQSSgCK2M8ATutL6H0Yvv.jpeg",
            "fullname": "David Serrano Lozano",
            "name": "davidserra9",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.15872",
            "authors": [
                {
                    "_id": "6746df9e92de61cf7ce4271f",
                    "user": {
                        "_id": "62676a94dacab364889bb36c",
                        "avatarUrl": "/avatars/0ead41b44957eb30564ea685ed22781a.svg",
                        "isPro": false,
                        "fullname": "SARIM HASHMI",
                        "user": "Sarim-Hash",
                        "type": "user"
                    },
                    "name": "Sarim Hashmi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-27T22:19:50.065Z",
                    "hidden": false
                },
                {
                    "_id": "6746df9e92de61cf7ce42720",
                    "user": {
                        "_id": "664a56468d50b4b0ef2bde91",
                        "avatarUrl": "/avatars/292c750d5fa9ce711b59e29e9d4dde42.svg",
                        "isPro": false,
                        "fullname": "juan lugo",
                        "user": "jlugopul",
                        "type": "user"
                    },
                    "name": "Juan Lugo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:29:10.569Z",
                    "hidden": false
                },
                {
                    "_id": "6746df9e92de61cf7ce42721",
                    "user": {
                        "_id": "66f7e7a78d215c6331aabee2",
                        "avatarUrl": "/avatars/f5a8e4894d889cf4c55ec4913381504b.svg",
                        "isPro": false,
                        "fullname": "Abdelrahman Amr El Sayed",
                        "user": "pythn",
                        "type": "user"
                    },
                    "name": "Abdelrahman Elsayed",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-27T22:19:48.340Z",
                    "hidden": false
                },
                {
                    "_id": "6746df9e92de61cf7ce42722",
                    "name": "Dinesh Saggurthi",
                    "hidden": false
                },
                {
                    "_id": "6746df9e92de61cf7ce42723",
                    "user": {
                        "_id": "670a9e9d92e1f8429b4dff14",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/FqzdtSimXHTZEgSKYxRPA.png",
                        "isPro": false,
                        "fullname": "Mohammed Elseiagy",
                        "user": "MohammedElseiagy",
                        "type": "user"
                    },
                    "name": "Mohammed Elseiagy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:29:01.617Z",
                    "hidden": false
                },
                {
                    "_id": "6746df9e92de61cf7ce42724",
                    "user": {
                        "_id": "66882837e6d7dbf169121357",
                        "avatarUrl": "/avatars/5086bbc7061c3f5e8871a360bc6fdc2b.svg",
                        "isPro": false,
                        "fullname": "Alikhan Nurkamal",
                        "user": "alikhann03",
                        "type": "user"
                    },
                    "name": "Alikhan Nurkamal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:28:56.167Z",
                    "hidden": false
                },
                {
                    "_id": "6746df9e92de61cf7ce42725",
                    "name": "Jaskaran Walia",
                    "hidden": false
                },
                {
                    "_id": "6746df9e92de61cf7ce42726",
                    "user": {
                        "_id": "66dfd6c4d892eca5d80f5f5a",
                        "avatarUrl": "/avatars/f0341aae051104e99fb3bf61551c06d6.svg",
                        "isPro": false,
                        "fullname": "Fadillah Adamsyah Maani",
                        "user": "adamsyah",
                        "type": "user"
                    },
                    "name": "Fadillah Adamsyah Maani",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:28:45.028Z",
                    "hidden": false
                },
                {
                    "_id": "6746df9e92de61cf7ce42727",
                    "user": {
                        "_id": "665532d6dcd4405a556a4677",
                        "avatarUrl": "/avatars/11a842cde456da06eb29adc18119a795.svg",
                        "isPro": false,
                        "fullname": "Mohammad Yaqub Bin Sheikh Mahmoud",
                        "user": "shxljit",
                        "type": "user"
                    },
                    "name": "Mohammad Yaqub",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-11-28T12:28:38.400Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-24T15:19:19.000Z",
            "title": "Optimizing Brain Tumor Segmentation with MedNeXt: BraTS 2024 SSA and\n  Pediatrics",
            "summary": "Identifying key pathological features in brain MRIs is crucial for the\nlong-term survival of glioma patients. However, manual segmentation is\ntime-consuming, requiring expert intervention and is susceptible to human\nerror. Therefore, significant research has been devoted to developing machine\nlearning methods that can accurately segment tumors in 3D multimodal brain MRI\nscans. Despite their progress, state-of-the-art models are often limited by the\ndata they are trained on, raising concerns about their reliability when applied\nto diverse populations that may introduce distribution shifts. Such shifts can\nstem from lower quality MRI technology (e.g., in sub-Saharan Africa) or\nvariations in patient demographics (e.g., children). The BraTS-2024 challenge\nprovides a platform to address these issues. This study presents our\nmethodology for segmenting tumors in the BraTS-2024 SSA and Pediatric Tumors\ntasks using MedNeXt, comprehensive model ensembling, and thorough\npostprocessing. Our approach demonstrated strong performance on the unseen\nvalidation set, achieving an average Dice Similarity Coefficient (DSC) of 0.896\non the BraTS-2024 SSA dataset and an average DSC of 0.830 on the BraTS\nPediatric Tumor dataset. Additionally, our method achieved an average Hausdorff\nDistance (HD95) of 14.682 on the BraTS-2024 SSA dataset and an average HD95 of\n37.508 on the BraTS Pediatric dataset. Our GitHub repository can be accessed\nhere: Project Repository :\nhttps://github.com/python-arch/BioMbz-Optimizing-Brain-Tumor-Segmentation-with-MedNeXt-BraTS-2024-SSA-and-Pediatrics",
            "upvotes": 3,
            "discussionId": "6746dfa092de61cf7ce427e3"
        },
        "publishedAt": "2024-11-28T03:19:12.118Z",
        "title": "Optimizing Brain Tumor Segmentation with MedNeXt: BraTS 2024 SSA and Pediatrics",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.15872.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/0ead41b44957eb30564ea685ed22781a.svg",
            "fullname": "SARIM HASHMI",
            "name": "Sarim-Hash",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.18104",
            "authors": [
                {
                    "_id": "6747f2f69c24d74b09c17158",
                    "user": {
                        "_id": "647bf082aba7062fe5c51ca9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/p4lY9IjHiWZETKmFq1mtU.jpeg",
                        "isPro": false,
                        "fullname": "Yifan Zhang",
                        "user": "yifAI",
                        "type": "user"
                    },
                    "name": "Yifan Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T09:19:31.227Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T07:32:56.000Z",
            "title": "Training and Evaluating Language Models with Template-based Data\n  Generation",
            "summary": "The rapid advancement of large language models (LLMs) such as GPT-3, PaLM,\nand Llama has significantly transformed natural language processing, showcasing\nremarkable capabilities in understanding and generating language. However,\nthese models often struggle with tasks requiring complex reasoning,\nparticularly in mathematical problem-solving, due in part to the scarcity of\nlarge-scale, high-quality, domain-specific datasets necessary for training\nsophisticated reasoning abilities. To address this limitation, we introduce\nTemplate-based Data Generation (TDG), a novel approach that leverages LLMs\n(GPT-4) to automatically generate parameterized meta-templates, which are then\nused to synthesize a vast array of high-quality problems and solutions.\nLeveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset\ncomprising over 7 million synthetically generated grade school math\nproblems--each accompanied by code-based and natural language solutions--with\nthe potential to generate an effectively unlimited number more. This dataset\nalleviates the scarcity of large-scale mathematical datasets and serves as a\nvaluable resource for pre-training, fine-tuning, and evaluating LLMs in\nmathematical reasoning. Our method not only enables the generation of virtually\ninfinite data but also elevates data augmentation to a new level by using GPT-4\nfor meta-template generation, ensuring diverse and high-quality problem\nstructures. The TemplateMath Part I: TemplateGSM dataset is publicly available\nat https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available\nat https://github.com/iiis-ai/TemplateMath.",
            "upvotes": 1,
            "discussionId": "6747f2f79c24d74b09c1717a"
        },
        "publishedAt": "2024-11-28T03:07:00.278Z",
        "title": "Training and Evaluating Language Models with Template-based Data Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18104.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/p4lY9IjHiWZETKmFq1mtU.jpeg",
            "fullname": "Yifan Zhang",
            "name": "yifAI",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 7
        }
    },
    {
        "paper": {
            "id": "2411.17698",
            "authors": [
                {
                    "_id": "6748776100cf30c297e7d286",
                    "user": {
                        "_id": "6542bf99899592bf11847315",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6542bf99899592bf11847315/ll0tyrWbbymrhYKOZxRHX.jpeg",
                        "isPro": false,
                        "fullname": "Ziyang Chen",
                        "user": "czyang",
                        "type": "user"
                    },
                    "name": "Ziyang Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-11-28T16:05:44.842Z",
                    "hidden": false
                },
                {
                    "_id": "6748776100cf30c297e7d287",
                    "name": "Prem Seetharaman",
                    "hidden": false
                },
                {
                    "_id": "6748776100cf30c297e7d288",
                    "name": "Bryan Russell",
                    "hidden": false
                },
                {
                    "_id": "6748776100cf30c297e7d289",
                    "name": "Oriol Nieto",
                    "hidden": false
                },
                {
                    "_id": "6748776100cf30c297e7d28a",
                    "name": "David Bourgin",
                    "hidden": false
                },
                {
                    "_id": "6748776100cf30c297e7d28b",
                    "name": "Andrew Owens",
                    "hidden": false
                },
                {
                    "_id": "6748776100cf30c297e7d28c",
                    "name": "Justin Salamon",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-26T18:59:58.000Z",
            "title": "Video-Guided Foley Sound Generation with Multimodal Controls",
            "summary": "Generating sound effects for videos often requires creating artistic sound\neffects that diverge significantly from real-life sources and flexible control\nin the sound design. To address this problem, we introduce MultiFoley, a model\ndesigned for video-guided sound generation that supports multimodal\nconditioning through text, audio, and video. Given a silent video and a text\nprompt, MultiFoley allows users to create clean sounds (e.g., skateboard wheels\nspinning without wind noise) or more whimsical sounds (e.g., making a lion's\nroar sound like a cat's meow). MultiFoley also allows users to choose reference\naudio from sound effects (SFX) libraries or partial videos for conditioning. A\nkey novelty of our model lies in its joint training on both internet video\ndatasets with low-quality audio and professional SFX recordings, enabling\nhigh-quality, full-bandwidth (48kHz) audio generation. Through automated\nevaluations and human studies, we demonstrate that MultiFoley successfully\ngenerates synchronized high-quality sounds across varied conditional inputs and\noutperforms existing methods. Please see our project page for video results:\nhttps://ificl.github.io/MultiFoley/",
            "upvotes": 0,
            "discussionId": "6748776300cf30c297e7d301"
        },
        "publishedAt": "2024-11-28T12:31:36.320Z",
        "title": "Video-Guided Foley Sound Generation with Multimodal Controls",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.17698.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6542bf99899592bf11847315/ll0tyrWbbymrhYKOZxRHX.jpeg",
            "fullname": "Ziyang Chen",
            "name": "czyang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    }
]