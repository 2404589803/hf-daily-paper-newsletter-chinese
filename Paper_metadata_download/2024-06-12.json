[
    {
        "paper": {
            "id": "2406.07550",
            "authors": [
                {
                    "_id": "666902d603e3c114f0651c3a",
                    "user": {
                        "avatarUrl": "/avatars/54419bb6e6ee788aba10cd64cd921204.svg",
                        "isPro": false,
                        "fullname": "Qihang Yu",
                        "user": "yucornetto",
                        "type": "user"
                    },
                    "name": "Qihang Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T07:52:29.465Z",
                    "hidden": false
                },
                {
                    "_id": "666902d603e3c114f0651c3b",
                    "name": "Mark Weber",
                    "hidden": false
                },
                {
                    "_id": "666902d603e3c114f0651c3c",
                    "user": {
                        "avatarUrl": "/avatars/8f7bde1c44d8e665a29ee08ce7fedfa4.svg",
                        "isPro": false,
                        "fullname": "Xueqing Deng",
                        "user": "xdeng77",
                        "type": "user"
                    },
                    "name": "Xueqing Deng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T07:53:04.811Z",
                    "hidden": false
                },
                {
                    "_id": "666902d603e3c114f0651c3d",
                    "user": {
                        "avatarUrl": "/avatars/5419f8d6d4d36fa5ac83e30667b9fd99.svg",
                        "isPro": false,
                        "fullname": "Xiaohui Shen",
                        "user": "XiaohuiShen",
                        "type": "user"
                    },
                    "name": "Xiaohui Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T07:53:11.344Z",
                    "hidden": false
                },
                {
                    "_id": "666902d603e3c114f0651c3e",
                    "name": "Daniel Cremers",
                    "hidden": false
                },
                {
                    "_id": "666902d603e3c114f0651c3f",
                    "name": "Liang-Chieh Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-11T17:59:56.000Z",
            "title": "An Image is Worth 32 Tokens for Reconstruction and Generation",
            "summary": "Recent advancements in generative models have highlighted the crucial role of\nimage tokenization in the efficient synthesis of high-resolution images.\nTokenization, which transforms images into latent representations, reduces\ncomputational demands compared to directly processing pixels and enhances the\neffectiveness and efficiency of the generation process. Prior methods, such as\nVQGAN, typically utilize 2D latent grids with fixed downsampling factors.\nHowever, these 2D tokenizations face challenges in managing the inherent\nredundancies present in images, where adjacent regions frequently display\nsimilarities. To overcome this issue, we introduce Transformer-based\n1-Dimensional Tokenizer (TiTok), an innovative approach that tokenizes images\ninto 1D latent sequences. TiTok provides a more compact latent representation,\nyielding substantially more efficient and effective representations than\nconventional techniques. For example, a 256 x 256 x 3 image can be reduced to\njust 32 discrete tokens, a significant reduction from the 256 or 1024 tokens\nobtained by prior methods. Despite its compact nature, TiTok achieves\ncompetitive performance to state-of-the-art approaches. Specifically, using the\nsame generator framework, TiTok attains 1.97 gFID, outperforming MaskGIT\nbaseline significantly by 4.21 at ImageNet 256 x 256 benchmark. The advantages\nof TiTok become even more significant when it comes to higher resolution. At\nImageNet 512 x 512 benchmark, TiTok not only outperforms state-of-the-art\ndiffusion model DiT-XL/2 (gFID 2.74 vs. 3.04), but also reduces the image\ntokens by 64x, leading to 410x faster generation process. Our best-performing\nvariant can significantly surpasses DiT-XL/2 (gFID 2.13 vs. 3.04) while still\ngenerating high-quality samples 74x faster.",
            "upvotes": 23
        },
        "publishedAt": "2024-06-12T02:08:15.299Z",
        "title": "An Image is Worth 32 Tokens for Reconstruction and Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.07550.png",
        "numComments": 4
    },
    {
        "paper": {
            "id": "2406.07547",
            "authors": [
                {
                    "_id": "6669102952faf47d18f0e07e",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644a1b6401e18bf93a6f45c1/P0i_CgCrIzOS2tYRlxoE9.png",
                        "isPro": false,
                        "fullname": "xichen",
                        "user": "xichenhku",
                        "type": "user"
                    },
                    "name": "Xi Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T07:29:29.878Z",
                    "hidden": false
                },
                {
                    "_id": "6669102952faf47d18f0e07f",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a54e468cfaa458bd6844bf/5Gmf4tAr59GNl-2VaZDbu.png",
                        "isPro": false,
                        "fullname": "Yutong Feng",
                        "user": "yutongfeng",
                        "type": "user"
                    },
                    "name": "Yutong Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T07:47:03.236Z",
                    "hidden": false
                },
                {
                    "_id": "6669102952faf47d18f0e080",
                    "user": {
                        "avatarUrl": "/avatars/0eed14a8929682f182e474f3693fc442.svg",
                        "isPro": false,
                        "fullname": "Chenmengting",
                        "user": "MengTingChen",
                        "type": "user"
                    },
                    "name": "Mengting Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T07:47:46.418Z",
                    "hidden": false
                },
                {
                    "_id": "6669102952faf47d18f0e081",
                    "user": {
                        "avatarUrl": "/avatars/7182aa41dd4c7f74f7b566506543d33a.svg",
                        "isPro": false,
                        "fullname": "Yiyang Wang",
                        "user": "dwyy",
                        "type": "user"
                    },
                    "name": "Yiyang Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T07:47:53.032Z",
                    "hidden": false
                },
                {
                    "_id": "6669102952faf47d18f0e082",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6424ffce46d202ad3d918a67/gmYmOA072fP_5cJLc9Qs4.jpeg",
                        "isPro": false,
                        "fullname": "Shilong Zhang",
                        "user": "shilongz",
                        "type": "user"
                    },
                    "name": "Shilong Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T07:47:59.760Z",
                    "hidden": false
                },
                {
                    "_id": "6669102952faf47d18f0e083",
                    "user": {
                        "avatarUrl": "/avatars/3e281e547e1697e1c06805e7e63f3918.svg",
                        "isPro": false,
                        "fullname": "Yu Liu",
                        "user": "YuLiu",
                        "type": "user"
                    },
                    "name": "Yu Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T07:48:29.016Z",
                    "hidden": false
                },
                {
                    "_id": "6669102952faf47d18f0e084",
                    "name": "Yujun Shen",
                    "hidden": false
                },
                {
                    "_id": "6669102952faf47d18f0e085",
                    "name": "Hengshuang Zhao",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-11T17:59:51.000Z",
            "title": "Zero-shot Image Editing with Reference Imitation",
            "summary": "Image editing serves as a practical yet challenging task considering the\ndiverse demands from users, where one of the hardest parts is to precisely\ndescribe how the edited image should look like. In this work, we present a new\nform of editing, termed imitative editing, to help users exercise their\ncreativity more conveniently. Concretely, to edit an image region of interest,\nusers are free to directly draw inspiration from some in-the-wild references\n(e.g., some relative pictures come across online), without having to cope with\nthe fit between the reference and the source. Such a design requires the system\nto automatically figure out what to expect from the reference to perform the\nediting. For this purpose, we propose a generative training framework, dubbed\nMimicBrush, which randomly selects two frames from a video clip, masks some\nregions of one frame, and learns to recover the masked regions using the\ninformation from the other frame. That way, our model, developed from a\ndiffusion prior, is able to capture the semantic correspondence between\nseparate images in a self-supervised manner. We experimentally show the\neffectiveness of our method under various test cases as well as its superiority\nover existing alternatives. We also construct a benchmark to facilitate further\nresearch.",
            "upvotes": 21
        },
        "publishedAt": "2024-06-12T01:34:11.443Z",
        "title": "Zero-shot Image Editing with Reference Imitation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.07547.png",
        "numComments": 1
    },
    {
        "paper": {
            "id": "2406.07436",
            "authors": [
                {
                    "_id": "666913357acc6e95a98c8012",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ba096e760936217a3ad2e2/aNQK83Jg5PsBkY0UDg-RA.jpeg",
                        "isPro": false,
                        "fullname": "Linzheng Chai",
                        "user": "Challenging666",
                        "type": "user"
                    },
                    "name": "Linzheng Chai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T07:29:09.991Z",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8013",
                    "name": "Shukai Liu",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8014",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8015",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/lOeHK9Bvt3IXcB7Urx6jZ.jpeg",
                        "isPro": false,
                        "fullname": "Yuwei Yin",
                        "user": "yuweiyin",
                        "type": "user"
                    },
                    "name": "Yuwei Yin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T07:29:19.814Z",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8016",
                    "name": "Ke Jin",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8017",
                    "name": "Jiaheng Liu",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8018",
                    "name": "Tao Sun",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8019",
                    "user": {
                        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                        "isPro": false,
                        "fullname": "Ge Zhang",
                        "user": "zhangysk",
                        "type": "user"
                    },
                    "name": "Ge Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T07:29:04.533Z",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c801a",
                    "name": "Changyu Ren",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c801b",
                    "name": "Hongcheng Guo",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c801c",
                    "name": "Zekun Wang",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c801d",
                    "name": "Boyang Wang",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c801e",
                    "name": "Xianjie Wu",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c801f",
                    "name": "Bing Wang",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8020",
                    "name": "Tongliang Li",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8021",
                    "name": "Liqun Yang",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8022",
                    "name": "Sufeng Duan",
                    "hidden": false
                },
                {
                    "_id": "666913357acc6e95a98c8023",
                    "name": "Zhoujun Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-11T16:45:17.000Z",
            "title": "McEval: Massively Multilingual Code Evaluation",
            "summary": "Code large language models (LLMs) have shown remarkable advances in code\nunderstanding, completion, and generation tasks. Programming benchmarks,\ncomprised of a selection of code challenges and corresponding test cases, serve\nas a standard to evaluate the capability of different LLMs in such tasks.\nHowever, most existing benchmarks primarily focus on Python and are still\nrestricted to a limited number of languages, where other languages are\ntranslated from the Python samples (e.g. MultiPL-E) degrading the data\ndiversity. To further facilitate the research of code LLMs, we propose a\nmassively multilingual code benchmark covering 40 programming languages\n(McEval) with 16K test samples, which substantially pushes the limits of code\nLLMs in multilingual scenarios. The benchmark contains challenging code\ncompletion, understanding, and generation evaluation tasks with finely curated\nmassively multilingual instruction corpora McEval-Instruct. In addition, we\nintroduce an effective multilingual coder mCoder trained on McEval-Instruct to\nsupport multilingual programming language generation. Extensive experimental\nresults on McEval show that there is still a difficult journey between\nopen-source models and closed-source LLMs (e.g. GPT-series models) in numerous\nlanguages. The instruction corpora, evaluation benchmark, and leaderboard are\navailable at https://mceval.github.io/.",
            "upvotes": 11
        },
        "publishedAt": "2024-06-12T15:24:10.934Z",
        "title": "McEval: Massively Multilingual Code Evaluation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.07436.png",
        "numComments": 1
    },
    {
        "paper": {
            "id": "2406.07496",
            "authors": [
                {
                    "_id": "66691326f77c35410da184cb",
                    "user": {
                        "avatarUrl": "/avatars/9c91c33a0744eae1454e242d51295fbc.svg",
                        "isPro": false,
                        "fullname": "Mert",
                        "user": "merty",
                        "type": "user"
                    },
                    "name": "Mert Yuksekgonul",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-06-12T03:36:00.974Z",
                    "hidden": false
                },
                {
                    "_id": "66691326f77c35410da184cc",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1625214886903-603f7c7af84ebe399f1c85cf.jpeg",
                        "isPro": false,
                        "fullname": "Federico Bianchi",
                        "user": "vinid",
                        "type": "user"
                    },
                    "name": "Federico Bianchi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T07:29:22.065Z",
                    "hidden": false
                },
                {
                    "_id": "66691326f77c35410da184cd",
                    "name": "Joseph Boen",
                    "hidden": false
                },
                {
                    "_id": "66691326f77c35410da184ce",
                    "user": {
                        "avatarUrl": "/avatars/ced64fdde8bf43c69b8c20dfe81d732c.svg",
                        "isPro": false,
                        "fullname": "Sheng Liu",
                        "user": "JeremyHide",
                        "type": "user"
                    },
                    "name": "Sheng Liu",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-12T03:16:55.258Z",
                    "hidden": false
                },
                {
                    "_id": "66691326f77c35410da184cf",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/634b90db3a0cd2d498640479/hsM58SlJHK_PnLN2f2esf.jpeg",
                        "isPro": false,
                        "fullname": "Zhi Huang",
                        "user": "zhihuang",
                        "type": "user"
                    },
                    "name": "Zhi Huang",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-06-12T03:17:24.193Z",
                    "hidden": false
                },
                {
                    "_id": "66691326f77c35410da184d0",
                    "name": "Carlos Guestrin",
                    "hidden": false
                },
                {
                    "_id": "66691326f77c35410da184d1",
                    "user": {
                        "avatarUrl": "/avatars/7647f99abdcca4251fcac7783b6fcc8d.svg",
                        "isPro": false,
                        "fullname": "zou",
                        "user": "jameszou707",
                        "type": "user"
                    },
                    "name": "James Zou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:10:54.616Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-11T17:32:21.000Z",
            "title": "TextGrad: Automatic \"Differentiation\" via Text",
            "summary": "AI is undergoing a paradigm shift, with breakthroughs achieved by systems\norchestrating multiple large language models (LLMs) and other complex\ncomponents. As a result, developing principled and automated optimization\nmethods for compound AI systems is one of the most important new challenges.\nNeural networks faced a similar challenge in its early days until\nbackpropagation and automatic differentiation transformed the field by making\noptimization turn-key. Inspired by this, we introduce TextGrad, a powerful\nframework performing automatic ``differentiation'' via text. TextGrad\nbackpropagates textual feedback provided by LLMs to improve individual\ncomponents of a compound AI system. In our framework, LLMs provide rich,\ngeneral, natural language suggestions to optimize variables in computation\ngraphs, ranging from code snippets to molecular structures. TextGrad follows\nPyTorch's syntax and abstraction and is flexible and easy-to-use. It works\nout-of-the-box for a variety of tasks, where the users only provide the\nobjective function without tuning components or prompts of the framework. We\nshowcase TextGrad's effectiveness and generality across a diverse range of\napplications, from question answering and molecule optimization to radiotherapy\ntreatment planning. Without modifying the framework, TextGrad improves the\nzero-shot accuracy of GPT-4o in Google-Proof Question Answering from 51% to\n55%, yields 20% relative performance gain in optimizing LeetCode-Hard\ncoding problem solutions, improves prompts for reasoning, designs new druglike\nsmall molecules with desirable in silico binding, and designs radiation\noncology treatment plans with high specificity. TextGrad lays a foundation to\naccelerate the development of the next-generation of AI systems.",
            "upvotes": 11
        },
        "publishedAt": "2024-06-12T01:46:55.285Z",
        "title": "TextGrad: Automatic \"Differentiation\" via Text",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.07496.png",
        "numComments": 0
    },
    {
        "paper": {
            "id": "2406.06563",
            "authors": [
                {
                    "_id": "666919d303e3c114f06b8f15",
                    "user": {
                        "avatarUrl": "/avatars/07efea204d172e2844dbacc418131da2.svg",
                        "isPro": false,
                        "fullname": "Wei Tianwen",
                        "user": "weitianwen",
                        "type": "user"
                    },
                    "name": "Tianwen Wei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T09:14:32.771Z",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f16",
                    "name": "Bo Zhu",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f17",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64996ce2ed09df36eaf236ea/wIr1j2zkAezXfpsczTjq_.jpeg",
                        "isPro": false,
                        "fullname": "zhaoliang",
                        "user": "zhao1iang",
                        "type": "user"
                    },
                    "name": "Liang Zhao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T09:21:14.969Z",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f18",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64535b71bcbd25618f7655da/vDc8nrYQd4rpYgXLWOuIx.jpeg",
                        "isPro": false,
                        "fullname": "cheng cheng",
                        "user": "chengtbf",
                        "type": "user"
                    },
                    "name": "Cheng Cheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T09:21:16.941Z",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f19",
                    "name": "Biye Li",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f1a",
                    "name": "Weiwei Lü",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f1b",
                    "user": {
                        "avatarUrl": "/avatars/84b6209914cb83af7cfce2ffb337d7bd.svg",
                        "isPro": false,
                        "fullname": "CPFLAME",
                        "user": "CPFLAME",
                        "type": "user"
                    },
                    "name": "Peng Cheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T09:24:00.021Z",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f1c",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64235adf23b98d5ee6e9ca85/m_7uwLaAkTXyt3qB2pPLA.png",
                        "isPro": false,
                        "fullname": "Jianhao Zhang",
                        "user": "Heerozh",
                        "type": "user"
                    },
                    "name": "Jianhao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T09:24:18.827Z",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f1d",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63647823a1503c61efd4fbcb/fOn74vqVyvR4nCP_5sxQK.png",
                        "isPro": false,
                        "fullname": "Yi Wang",
                        "user": "BBuf",
                        "type": "user"
                    },
                    "name": "Xiaoyu Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T11:50:52.655Z",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f1e",
                    "user": {
                        "avatarUrl": "/avatars/c35acce69f244ec0833dffd53eedf6a3.svg",
                        "isPro": false,
                        "fullname": "Liang Zeng",
                        "user": "zengliangcs",
                        "type": "user"
                    },
                    "name": "Liang Zeng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T09:31:25.323Z",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f1f",
                    "user": {
                        "avatarUrl": "/avatars/39ebc8efc124d1b05274be54f212123c.svg",
                        "isPro": false,
                        "fullname": "Wangxiaokun",
                        "user": "Wswxk",
                        "type": "user"
                    },
                    "name": "Xiaokun Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T09:23:50.654Z",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f20",
                    "name": "Yutuan Ma",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f21",
                    "name": "Rui Hu",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f22",
                    "name": "Shuicheng Yan",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f23",
                    "name": "Han Fang",
                    "hidden": false
                },
                {
                    "_id": "666919d303e3c114f06b8f24",
                    "name": "Yahui Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-03T03:58:41.000Z",
            "title": "Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts\n  Language Models",
            "summary": "In this technical report, we introduce the training methodologies implemented\nin the development of Skywork-MoE, a high-performance mixture-of-experts (MoE)\nlarge language model (LLM) with 146 billion parameters and 16 experts. It is\ninitialized from the pre-existing dense checkpoints of our Skywork-13B model.\nWe explore the comparative effectiveness of upcycling versus training from\nscratch initializations. Our findings suggest that the choice between these two\napproaches should consider both the performance of the existing dense\ncheckpoints and the MoE training budget. We highlight two innovative\ntechniques: gating logit normalization, which improves expert diversification,\nand adaptive auxiliary loss coefficients, allowing for layer-specific\nadjustment of auxiliary loss coefficients. Our experimental results validate\nthe effectiveness of these methods. Leveraging these techniques and insights,\nwe trained our upcycled Skywork-MoE on a condensed subset of our SkyPile\ncorpus. The evaluation results demonstrate that our model delivers strong\nperformance across a wide range of benchmarks.",
            "upvotes": 10
        },
        "publishedAt": "2024-06-12T02:15:25.476Z",
        "title": "Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.06563.png",
        "numComments": 8
    },
    {
        "paper": {
            "id": "2406.06608",
            "authors": [
                {
                    "_id": "666919794cecc4ae5b0c6275",
                    "user": {
                        "avatarUrl": "/avatars/96743c43bdbfc595052de45be2c8e20f.svg",
                        "isPro": false,
                        "fullname": "Sander Schulhoff",
                        "user": "Trigaten",
                        "type": "user"
                    },
                    "name": "Sander Schulhoff",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:52:25.789Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6276",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/xbcwDQr5cOHOrQhzxpqup.jpeg",
                        "isPro": false,
                        "fullname": "michael ilie",
                        "user": "skdrx",
                        "type": "user"
                    },
                    "name": "Michael Ilie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:52:31.530Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6277",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a3f93fe2b7740fe2a94c86/ZiaPqiVqXI2ANIyWQY_hT.png",
                        "isPro": false,
                        "fullname": "Nishant Balepur",
                        "user": "nbalepur",
                        "type": "user"
                    },
                    "name": "Nishant Balepur",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:52:37.490Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6278",
                    "user": {
                        "avatarUrl": "/avatars/a7e8aa568cbdcb8da0b6e9a5f19b3863.svg",
                        "isPro": false,
                        "fullname": "Konstantine Kahadze",
                        "user": "kkahadze",
                        "type": "user"
                    },
                    "name": "Konstantine Kahadze",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:52:43.886Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6279",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/wYkbvoSoVg2w749e1hB0j.jpeg",
                        "isPro": false,
                        "fullname": "Amanda Liu",
                        "user": "Amandaliu",
                        "type": "user"
                    },
                    "name": "Amanda Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:52:52.791Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c627a",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1631895645405-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Chenglei Si",
                        "user": "CLS",
                        "type": "user"
                    },
                    "name": "Chenglei Si",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:52:58.277Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c627b",
                    "user": {
                        "avatarUrl": "/avatars/b052b3f50822a4a8f3f86ceea4bffa8e.svg",
                        "isPro": false,
                        "fullname": "Yinheng Li",
                        "user": "Inhenn",
                        "type": "user"
                    },
                    "name": "Yinheng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:53:03.704Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c627c",
                    "name": "Aayush Gupta",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c627d",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61327740e6d0da50f81a7ff1/GnG53du342odZBmlqR5rF.png",
                        "isPro": false,
                        "fullname": "HyoJung Han",
                        "user": "h-j-han",
                        "type": "user"
                    },
                    "name": "HyoJung Han",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:55:45.157Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c627e",
                    "user": {
                        "avatarUrl": "/avatars/9521cc38e7e8367e207dd9c23a7d508c.svg",
                        "isPro": false,
                        "fullname": "Sevien Schulhoff",
                        "user": "solarwaffles",
                        "type": "user"
                    },
                    "name": "Sevien Schulhoff",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:55:52.307Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c627f",
                    "user": {
                        "avatarUrl": "/avatars/1efcdc9dff98f526094932038208af10.svg",
                        "isPro": false,
                        "fullname": "Pranav Dulepet",
                        "user": "pdulepet",
                        "type": "user"
                    },
                    "name": "Pranav Sandeep Dulepet",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:56:03.144Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6280",
                    "user": {
                        "avatarUrl": "/avatars/b197a81505a4aad543fc425c12b3428b.svg",
                        "isPro": false,
                        "fullname": "Saurav Vidyadhara",
                        "user": "Saurav15",
                        "type": "user"
                    },
                    "name": "Saurav Vidyadhara",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:56:13.118Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6281",
                    "user": {
                        "avatarUrl": "/avatars/282043419d74f77f48f174472afb2650.svg",
                        "isPro": false,
                        "fullname": "Dayeon Ki",
                        "user": "zoeyki",
                        "type": "user"
                    },
                    "name": "Dayeon Ki",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:56:20.696Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6282",
                    "user": {
                        "avatarUrl": "/avatars/e696f5cfa0215867cb4149e8904fbf5f.svg",
                        "isPro": false,
                        "fullname": "Sweta Agrawal",
                        "user": "swetaagrawal",
                        "type": "user"
                    },
                    "name": "Sweta Agrawal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:56:27.138Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6283",
                    "name": "Chau Pham",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6284",
                    "user": {
                        "avatarUrl": "/avatars/b8fb749b209bb029cd3fcd15663c85d8.svg",
                        "isPro": false,
                        "fullname": "Gerson Kroiz",
                        "user": "gkroiz",
                        "type": "user"
                    },
                    "name": "Gerson Kroiz",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:56:58.535Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6285",
                    "name": "Feileen Li",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6286",
                    "user": {
                        "avatarUrl": "/avatars/b5a67b869574d9289c72a00e7b65ca96.svg",
                        "isPro": false,
                        "fullname": "Hudson Tao",
                        "user": "hudssntao",
                        "type": "user"
                    },
                    "name": "Hudson Tao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:57:17.731Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6287",
                    "user": {
                        "avatarUrl": "/avatars/07f6073460b949f454e55ae6aa340ab2.svg",
                        "isPro": false,
                        "fullname": "Ashay Srivastava",
                        "user": "ashay-sriv",
                        "type": "user"
                    },
                    "name": "Ashay Srivastava",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:57:23.736Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6288",
                    "name": "Hevander Da Costa",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6289",
                    "name": "Saloni Gupta",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c628a",
                    "user": {
                        "avatarUrl": "/avatars/967e9a170a0b8279e8c22ea9ce79b162.svg",
                        "isPro": false,
                        "fullname": "megan rogers",
                        "user": "hook444",
                        "type": "user"
                    },
                    "name": "Megan L. Rogers",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:57:53.970Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c628b",
                    "name": "Inna Goncearenco",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c628c",
                    "name": "Giuseppe Sarli",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c628d",
                    "name": "Igor Galynker",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c628e",
                    "name": "Denis Peskoff",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c628f",
                    "name": "Marine Carpuat",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6290",
                    "name": "Jules White",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6291",
                    "user": {
                        "avatarUrl": "/avatars/b833d972ebceb00f188d2fb308dd30e2.svg",
                        "isPro": false,
                        "fullname": "Shyamal Anadkat",
                        "user": "shyamal",
                        "type": "user"
                    },
                    "name": "Shyamal Anadkat",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:58:22.087Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6292",
                    "user": {
                        "avatarUrl": "/avatars/5746d6bf2fa25c5e53c5b33f6a9b52f7.svg",
                        "isPro": false,
                        "fullname": "Alexander Hoyle",
                        "user": "hoyle",
                        "type": "user"
                    },
                    "name": "Alexander Hoyle",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:58:29.399Z",
                    "hidden": false
                },
                {
                    "_id": "666919794cecc4ae5b0c6293",
                    "name": "Philip Resnik",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-06T18:10:11.000Z",
            "title": "The Prompt Report: A Systematic Survey of Prompting Techniques",
            "summary": "Generative Artificial Intelligence (GenAI) systems are being increasingly\ndeployed across all parts of industry and research settings. Developers and end\nusers interact with these systems through the use of prompting or prompt\nengineering. While prompting is a widespread and highly researched concept,\nthere exists conflicting terminology and a poor ontological understanding of\nwhat constitutes a prompt due to the area's nascency. This paper establishes a\nstructured understanding of prompts, by assembling a taxonomy of prompting\ntechniques and analyzing their use. We present a comprehensive vocabulary of 33\nvocabulary terms, a taxonomy of 58 text-only prompting techniques, and 40\ntechniques for other modalities. We further present a meta-analysis of the\nentire literature on natural language prefix-prompting.",
            "upvotes": 9
        },
        "publishedAt": "2024-06-12T02:13:54.423Z",
        "title": "The Prompt Report: A Systematic Survey of Prompting Techniques",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.06608.png",
        "numComments": 0
    },
    {
        "paper": {
            "id": "2406.06592",
            "authors": [
                {
                    "_id": "6669064673d2031011583c57",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/bNp7XtXqPQoauh7CU5B7b.jpeg",
                        "isPro": false,
                        "fullname": "Liangchen Luo",
                        "user": "luolc",
                        "type": "user"
                    },
                    "name": "Liangchen Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:13:24.860Z",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c58",
                    "name": "Yinxiao Liu",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c59",
                    "name": "Rosanne Liu",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c5a",
                    "user": {
                        "avatarUrl": "/avatars/66b61203f2a6fd07f9026ba97f9e8c5d.svg",
                        "isPro": false,
                        "fullname": "Samrat Phatale",
                        "user": "samratph",
                        "type": "user"
                    },
                    "name": "Samrat Phatale",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:14:15.496Z",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c5b",
                    "user": {
                        "avatarUrl": "/avatars/f6a0def91074fd079a4a341083c5a0d3.svg",
                        "isPro": false,
                        "fullname": "Harsh Lara",
                        "user": "harrylingua",
                        "type": "user"
                    },
                    "name": "Harsh Lara",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:14:21.193Z",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c5c",
                    "user": {
                        "avatarUrl": "/avatars/d8df470349aa976741604921cb408440.svg",
                        "isPro": false,
                        "fullname": "Yunxuan Li",
                        "user": "eric008",
                        "type": "user"
                    },
                    "name": "Yunxuan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:14:32.711Z",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c5d",
                    "name": "Lei Shu",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c5e",
                    "name": "Yun Zhu",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c5f",
                    "name": "Lei Meng",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c60",
                    "user": {
                        "avatarUrl": "/avatars/64ad33b67c10e3cb7b9b07744d108d8c.svg",
                        "isPro": false,
                        "fullname": "Jiao Sun",
                        "user": "sunjiao123sun",
                        "type": "user"
                    },
                    "name": "Jiao Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:15:08.371Z",
                    "hidden": false
                },
                {
                    "_id": "6669064673d2031011583c61",
                    "user": {
                        "avatarUrl": "/avatars/10baa6536793b397c05028011d4ffcdc.svg",
                        "isPro": false,
                        "fullname": "Abhinav Rastogi",
                        "user": "abhirast",
                        "type": "user"
                    },
                    "name": "Abhinav Rastogi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:15:35.463Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-05T19:25:40.000Z",
            "title": "Improve Mathematical Reasoning in Language Models by Automated Process\n  Supervision",
            "summary": "Complex multi-step reasoning tasks, such as solving mathematical problems or\ngenerating code, remain a significant hurdle for even the most advanced large\nlanguage models (LLMs). Verifying LLM outputs with an Outcome Reward Model\n(ORM) is a standard inference-time technique aimed at enhancing the reasoning\nperformance of LLMs. However, this still proves insufficient for reasoning\ntasks with a lengthy or multi-hop reasoning chain, where the intermediate\noutcomes are neither properly rewarded nor penalized. Process supervision\naddresses this limitation by assigning intermediate rewards during the\nreasoning process. To date, the methods used to collect process supervision\ndata have relied on either human annotation or per-step Monte Carlo estimation,\nboth prohibitively expensive to scale, thus hindering the broad application of\nthis technique. In response to this challenge, we propose a novel\ndivide-and-conquer style Monte Carlo Tree Search (MCTS) algorithm named\nOmegaPRM for the efficient collection of high-quality process\nsupervision data. This algorithm swiftly identifies the first error in the\nChain of Thought (CoT) with binary search and balances the positive and\nnegative examples, thereby ensuring both efficiency and quality. As a result,\nwe are able to collect over 1.5 million process supervision annotations to\ntrain a Process Reward Model (PRM). Utilizing this fully automated process\nsupervision alongside the weighted self-consistency algorithm, we have enhanced\nthe instruction tuned Gemini Pro model's math reasoning performance, achieving\na 69.4\\% success rate on the MATH benchmark, a 36\\% relative improvement from\nthe 51\\% base model performance. Additionally, the entire process operates\nwithout any human intervention, making our method both financially and\ncomputationally cost-effective compared to existing methods.",
            "upvotes": 7
        },
        "publishedAt": "2024-06-12T00:51:59.750Z",
        "title": "Improve Mathematical Reasoning in Language Models by Automated Process Supervision",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.06592.png",
        "numComments": 0
    },
    {
        "paper": {
            "id": "2406.06911",
            "authors": [
                {
                    "_id": "666915f90a19d52d441b7730",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/dH8UZj6Kk5HJkI1DItCNm.jpeg",
                        "isPro": false,
                        "fullname": "Zigeng Chen",
                        "user": "Zigeng",
                        "type": "user"
                    },
                    "name": "Zigeng Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T09:31:30.267Z",
                    "hidden": false
                },
                {
                    "_id": "666915f90a19d52d441b7731",
                    "user": {
                        "avatarUrl": "/avatars/ed8024a79a6e8126496c3ea7fd2db338.svg",
                        "isPro": false,
                        "fullname": "Xinyin Ma",
                        "user": "horseee",
                        "type": "user"
                    },
                    "name": "Xinyin Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T09:31:36.686Z",
                    "hidden": false
                },
                {
                    "_id": "666915f90a19d52d441b7732",
                    "user": {
                        "avatarUrl": "/avatars/752e9d86018e7d33ad8bcd741203fd86.svg",
                        "isPro": false,
                        "fullname": "Gongfan Fang",
                        "user": "Vinnnf",
                        "type": "user"
                    },
                    "name": "Gongfan Fang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T09:31:43.353Z",
                    "hidden": false
                },
                {
                    "_id": "666915f90a19d52d441b7733",
                    "user": {
                        "avatarUrl": "/avatars/fd3f8a844b391be6c1ac2ea89b228f5a.svg",
                        "isPro": false,
                        "fullname": "Tan Zhen Xiong",
                        "user": "ZhenXiong",
                        "type": "user"
                    },
                    "name": "Zhenxiong Tan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T09:31:52.919Z",
                    "hidden": false
                },
                {
                    "_id": "666915f90a19d52d441b7734",
                    "user": {
                        "avatarUrl": "/avatars/9d5b1bb2a41928e08176b703935133ab.svg",
                        "isPro": false,
                        "fullname": "Wangxinchao",
                        "user": "wxcTest",
                        "type": "user"
                    },
                    "name": "Xinchao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T09:32:05.522Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-11T03:09:37.000Z",
            "title": "AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising",
            "summary": "Diffusion models have garnered significant interest from the community for\ntheir great generative ability across various applications. However, their\ntypical multi-step sequential-denoising nature gives rise to high cumulative\nlatency, thereby precluding the possibilities of parallel computation. To\naddress this, we introduce AsyncDiff, a universal and plug-and-play\nacceleration scheme that enables model parallelism across multiple devices. Our\napproach divides the cumbersome noise prediction model into multiple\ncomponents, assigning each to a different device. To break the dependency chain\nbetween these components, it transforms the conventional sequential denoising\ninto an asynchronous process by exploiting the high similarity between hidden\nstates in consecutive diffusion steps. Consequently, each component is\nfacilitated to compute in parallel on separate devices. The proposed strategy\nsignificantly reduces inference latency while minimally impacting the\ngenerative quality. Specifically, for the Stable Diffusion v2.1, AsyncDiff\nachieves a 2.7x speedup with negligible degradation and a 4.0x speedup with\nonly a slight reduction of 0.38 in CLIP Score, on four NVIDIA A5000 GPUs. Our\nexperiments also demonstrate that AsyncDiff can be readily applied to video\ndiffusion models with encouraging performances. The code is available at\nhttps://github.com/czg1225/AsyncDiff.",
            "upvotes": 6
        },
        "publishedAt": "2024-06-12T01:59:01.182Z",
        "title": "AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.06911.png",
        "numComments": 1
    },
    {
        "paper": {
            "id": "2406.07472",
            "authors": [
                {
                    "_id": "6669056f61588d66710d13ba",
                    "name": "Heng Yu",
                    "hidden": false
                },
                {
                    "_id": "6669056f61588d66710d13bb",
                    "user": {
                        "avatarUrl": "/avatars/d4730f70a6f1cb51266862c7a8d54f77.svg",
                        "isPro": false,
                        "fullname": "Chaoyang Wang",
                        "user": "cwang9",
                        "type": "user"
                    },
                    "name": "Chaoyang Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:17:01.607Z",
                    "hidden": false
                },
                {
                    "_id": "6669056f61588d66710d13bc",
                    "user": {
                        "avatarUrl": "/avatars/6973b4c959ef8bb72c40c611d384a78a.svg",
                        "isPro": false,
                        "fullname": "peiye zhuang",
                        "user": "Kelest",
                        "type": "user"
                    },
                    "name": "Peiye Zhuang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:17:07.735Z",
                    "hidden": false
                },
                {
                    "_id": "6669056f61588d66710d13bd",
                    "user": {
                        "avatarUrl": "/avatars/3b089a25a87c2e83c6b23ccb5d2dc73e.svg",
                        "isPro": false,
                        "fullname": "Willi Menapace",
                        "user": "willi-menapace",
                        "type": "user"
                    },
                    "name": "Willi Menapace",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:17:14.379Z",
                    "hidden": false
                },
                {
                    "_id": "6669056f61588d66710d13be",
                    "user": {
                        "avatarUrl": "/avatars/76f933cd549f10e5e2db379de235d304.svg",
                        "isPro": false,
                        "fullname": "Aliaksandr Siarohin",
                        "user": "aliaksandr-siarohin",
                        "type": "user"
                    },
                    "name": "Aliaksandr Siarohin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:17:23.361Z",
                    "hidden": false
                },
                {
                    "_id": "6669056f61588d66710d13bf",
                    "user": {
                        "avatarUrl": "/avatars/c73c5870039611ab9162daad46a1ba20.svg",
                        "isPro": false,
                        "fullname": "junli cao",
                        "user": "jlcao2",
                        "type": "user"
                    },
                    "name": "Junli Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:17:29.415Z",
                    "hidden": false
                },
                {
                    "_id": "6669056f61588d66710d13c0",
                    "user": {
                        "avatarUrl": "/avatars/698d98d8b42c478a3d7584b93c6dbcc2.svg",
                        "isPro": false,
                        "fullname": "Laszlo Jeni",
                        "user": "laszlo-ai",
                        "type": "user"
                    },
                    "name": "Laszlo A Jeni",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:17:39.866Z",
                    "hidden": false
                },
                {
                    "_id": "6669056f61588d66710d13c1",
                    "name": "Sergey Tulyakov",
                    "hidden": false
                },
                {
                    "_id": "6669056f61588d66710d13c2",
                    "user": {
                        "avatarUrl": "/avatars/1cb94deadc288d07c571c9289085548c.svg",
                        "isPro": false,
                        "fullname": "Hsin-Ying Lee",
                        "user": "james371507",
                        "type": "user"
                    },
                    "name": "Hsin-Ying Lee",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:17:54.621Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-11T17:19:26.000Z",
            "title": "4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion\n  Models",
            "summary": "Existing dynamic scene generation methods mostly rely on distilling knowledge\nfrom pre-trained 3D generative models, which are typically fine-tuned on\nsynthetic object datasets. As a result, the generated scenes are often\nobject-centric and lack photorealism. To address these limitations, we\nintroduce a novel pipeline designed for photorealistic text-to-4D scene\ngeneration, discarding the dependency on multi-view generative models and\ninstead fully utilizing video generative models trained on diverse real-world\ndatasets. Our method begins by generating a reference video using the video\ngeneration model. We then learn the canonical 3D representation of the video\nusing a freeze-time video, delicately generated from the reference video. To\nhandle inconsistencies in the freeze-time video, we jointly learn a per-frame\ndeformation to model these imperfections. We then learn the temporal\ndeformation based on the canonical representation to capture dynamic\ninteractions in the reference video. The pipeline facilitates the generation of\ndynamic scenes with enhanced photorealism and structural integrity, viewable\nfrom multiple perspectives, thereby setting a new standard in 4D scene\ngeneration.",
            "upvotes": 6
        },
        "publishedAt": "2024-06-12T00:48:26.926Z",
        "title": "4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.07472.png",
        "numComments": 2
    },
    {
        "paper": {
            "id": "2406.06612",
            "authors": [
                {
                    "_id": "66691ba8c4ef4175fb26ee97",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60796959c59d9e1697fa2324/wxnDm-p3YgB95NV2p4LGF.png",
                        "isPro": false,
                        "fullname": "Rishit Dagli",
                        "user": "rishitdagli",
                        "type": "user"
                    },
                    "name": "Rishit Dagli",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:41:00.397Z",
                    "hidden": false
                },
                {
                    "_id": "66691ba8c4ef4175fb26ee98",
                    "name": "Shivesh Prakash",
                    "hidden": false
                },
                {
                    "_id": "66691ba8c4ef4175fb26ee99",
                    "name": "Robert Wu",
                    "hidden": false
                },
                {
                    "_id": "66691ba8c4ef4175fb26ee9a",
                    "user": {
                        "avatarUrl": "/avatars/e1fb69477fc5f1a5356b7cb66d65bcde.svg",
                        "isPro": false,
                        "fullname": "Houman Khosravani",
                        "user": "houmank",
                        "type": "user"
                    },
                    "name": "Houman Khosravani",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:41:26.500Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-06T22:55:01.000Z",
            "title": "SEE-2-SOUND: Zero-Shot Spatial Environment-to-Spatial Sound",
            "summary": "Generating combined visual and auditory sensory experiences is critical for\nthe consumption of immersive content. Recent advances in neural generative\nmodels have enabled the creation of high-resolution content across multiple\nmodalities such as images, text, speech, and videos. Despite these successes,\nthere remains a significant gap in the generation of high-quality spatial audio\nthat complements generated visual content. Furthermore, current audio\ngeneration models excel in either generating natural audio or speech or music\nbut fall short in integrating spatial audio cues necessary for immersive\nexperiences. In this work, we introduce SEE-2-SOUND, a zero-shot approach that\ndecomposes the task into (1) identifying visual regions of interest; (2)\nlocating these elements in 3D space; (3) generating mono-audio for each; and\n(4) integrating them into spatial audio. Using our framework, we demonstrate\ncompelling results for generating spatial audio for high-quality videos,\nimages, and dynamic images from the internet, as well as media generated by\nlearned approaches.",
            "upvotes": 5
        },
        "publishedAt": "2024-06-12T02:23:13.231Z",
        "title": "SEE-2-SOUND: Zero-Shot Spatial Environment-to-Spatial Sound",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.06612.png",
        "numComments": 0
    },
    {
        "paper": {
            "id": "2406.07394",
            "authors": [
                {
                    "_id": "666917ff2bd3135cc34128a6",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64bce15bafd1e46c5504ad38/bQFX1iFbXEBXcQvUNL811.png",
                        "isPro": false,
                        "fullname": "Di Zhang",
                        "user": "qq8933",
                        "type": "user"
                    },
                    "name": "Di Zhang",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-12T03:37:35.692Z",
                    "hidden": false
                },
                {
                    "_id": "666917ff2bd3135cc34128a7",
                    "name": "Jiatong Li",
                    "hidden": false
                },
                {
                    "_id": "666917ff2bd3135cc34128a8",
                    "name": "Xiaoshui Huang",
                    "hidden": false
                },
                {
                    "_id": "666917ff2bd3135cc34128a9",
                    "user": {
                        "avatarUrl": "/avatars/6817dbfe903675721fd227058b0a91ac.svg",
                        "isPro": false,
                        "fullname": "Dongzhan Zhou",
                        "user": "schrodingers-tiger",
                        "type": "user"
                    },
                    "name": "Dongzhan Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:33:20.574Z",
                    "hidden": false
                },
                {
                    "_id": "666917ff2bd3135cc34128aa",
                    "user": {
                        "avatarUrl": "/avatars/9b4b4556ffd8de215dc37b02366d781b.svg",
                        "isPro": false,
                        "fullname": "Yuqiang Li",
                        "user": "yuqiangli",
                        "type": "user"
                    },
                    "name": "Yuqiang Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:34:18.015Z",
                    "hidden": false
                },
                {
                    "_id": "666917ff2bd3135cc34128ab",
                    "name": "Wanli Ouyang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-11T16:01:07.000Z",
            "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo\n  Tree Self-refine with LLaMa-3 8B",
            "summary": "This paper introduces the MCT Self-Refine (MCTSr) algorithm, an innovative\nintegration of Large Language Models (LLMs) with Monte Carlo Tree Search\n(MCTS), designed to enhance performance in complex mathematical reasoning\ntasks. Addressing the challenges of accuracy and reliability in LLMs,\nparticularly in strategic and mathematical reasoning, MCTSr leverages\nsystematic exploration and heuristic self-refine mechanisms to improve\ndecision-making frameworks within LLMs. The algorithm constructs a Monte Carlo\nsearch tree through iterative processes of Selection, self-refine,\nself-evaluation, and Backpropagation, utilizing an improved Upper Confidence\nBound (UCB) formula to optimize the exploration-exploitation balance. Extensive\nexperiments demonstrate MCTSr's efficacy in solving Olympiad-level mathematical\nproblems, significantly improving success rates across multiple datasets,\nincluding GSM8K, GSM Hard, MATH, and Olympiad-level benchmarks, including Math\nOdyssey, AIME, and OlympiadBench. The study advances the application of LLMs in\ncomplex reasoning tasks and sets a foundation for future AI integration,\nenhancing decision-making accuracy and reliability in LLM-driven applications.",
            "upvotes": 5
        },
        "publishedAt": "2024-06-12T02:07:35.724Z",
        "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.07394.png",
        "numComments": 0
    },
    {
        "paper": {
            "id": "2406.07524",
            "authors": [
                {
                    "_id": "66690f02aa74814619caee13",
                    "user": {
                        "avatarUrl": "/avatars/74c48e1ace77fd8c2138040bd2a18756.svg",
                        "isPro": false,
                        "fullname": "Subham Sekhar Sahoo",
                        "user": "subbham",
                        "type": "user"
                    },
                    "name": "Subham Sekhar Sahoo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:36:17.388Z",
                    "hidden": false
                },
                {
                    "_id": "66690f02aa74814619caee14",
                    "user": {
                        "avatarUrl": "/avatars/64a99f756e7b5e15463c8265f3cc35c7.svg",
                        "isPro": false,
                        "fullname": "Marianne Arriola",
                        "user": "marriola",
                        "type": "user"
                    },
                    "name": "Marianne Arriola",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:36:23.171Z",
                    "hidden": false
                },
                {
                    "_id": "66690f02aa74814619caee15",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6418e5e722270b3ccf15dfef/ZiammTpL9FVMuE7DN8n5B.jpeg",
                        "isPro": false,
                        "fullname": "Yair Schiff",
                        "user": "yairschiff",
                        "type": "user"
                    },
                    "name": "Yair Schiff",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:36:28.591Z",
                    "hidden": false
                },
                {
                    "_id": "66690f02aa74814619caee16",
                    "user": {
                        "avatarUrl": "/avatars/9353c064ef8ccac84d0397411d38fa90.svg",
                        "isPro": false,
                        "fullname": "Aaron Gokaslan",
                        "user": "Skylion007",
                        "type": "user"
                    },
                    "name": "Aaron Gokaslan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-12T07:29:31.761Z",
                    "hidden": false
                },
                {
                    "_id": "66690f02aa74814619caee17",
                    "user": {
                        "avatarUrl": "/avatars/5261c6223571955260f7720ff88a8d67.svg",
                        "isPro": false,
                        "fullname": "Edgar Marroquin",
                        "user": "emarro",
                        "type": "user"
                    },
                    "name": "Edgar Marroquin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:36:41.104Z",
                    "hidden": false
                },
                {
                    "_id": "66690f02aa74814619caee18",
                    "user": {
                        "avatarUrl": "/avatars/1e8005eca079748365e7243a5d100fe9.svg",
                        "isPro": false,
                        "fullname": "Justin T Chiu",
                        "user": "justintchiu",
                        "type": "user"
                    },
                    "name": "Justin T Chiu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:36:46.781Z",
                    "hidden": false
                },
                {
                    "_id": "66690f02aa74814619caee19",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1668440123408-noauth.png",
                        "isPro": false,
                        "fullname": "Alex Rush",
                        "user": "OfficialAL33900",
                        "type": "user"
                    },
                    "name": "Alexander Rush",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:36:58.268Z",
                    "hidden": false
                },
                {
                    "_id": "66690f02aa74814619caee1a",
                    "user": {
                        "avatarUrl": "/avatars/3213d2e8a433a207dfb96a35f0f52a92.svg",
                        "isPro": false,
                        "fullname": "Volodymyr Kuleshov",
                        "user": "kuleshov",
                        "type": "user"
                    },
                    "name": "Volodymyr Kuleshov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:37:04.642Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-11T17:51:40.000Z",
            "title": "Simple and Effective Masked Diffusion Language Models",
            "summary": "While diffusion models excel at generating high-quality images, prior work\nreports a significant performance gap between diffusion and autoregressive (AR)\nmethods in language modeling. In this work, we show that simple masked discrete\ndiffusion is more performant than previously thought. We apply an effective\ntraining recipe that improves the performance of masked diffusion models and\nderive a simplified, Rao-Blackwellized objective that results in additional\nimprovements. Our objective has a simple form -- it is a mixture of classical\nmasked language modeling losses -- and can be used to train encoder-only\nlanguage models that admit efficient samplers, including ones that can generate\narbitrary lengths of text semi-autoregressively like a traditional language\nmodel. On language modeling benchmarks, a range of masked diffusion models\ntrained with modern engineering practices achieves a new state-of-the-art among\ndiffusion models, and approaches AR perplexity. We release our code at:\nhttps://github.com/kuleshov-group/mdlm",
            "upvotes": 3
        },
        "publishedAt": "2024-06-12T01:29:15.761Z",
        "title": "Simple and Effective Masked Diffusion Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.07524.png",
        "numComments": 2
    },
    {
        "paper": {
            "id": "2406.06573",
            "authors": [
                {
                    "_id": "666919ea2de144452f920f45",
                    "user": {
                        "avatarUrl": "/avatars/1087a75f7dbfd65b4d18d369d38eb5be.svg",
                        "isPro": false,
                        "fullname": "Robert Osazuwa Ness",
                        "user": "osazuwa",
                        "type": "user"
                    },
                    "name": "Robert Osazuwa Ness",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:47:27.299Z",
                    "hidden": false
                },
                {
                    "_id": "666919ea2de144452f920f46",
                    "user": {
                        "avatarUrl": "/avatars/17f727f8e7e7322a2af571d664ddff65.svg",
                        "isPro": false,
                        "fullname": "Katie Matton",
                        "user": "kmatton",
                        "type": "user"
                    },
                    "name": "Katie Matton",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:47:33.622Z",
                    "hidden": false
                },
                {
                    "_id": "666919ea2de144452f920f47",
                    "user": {
                        "avatarUrl": "/avatars/79db890fc8615700d9df05b264f3ca86.svg",
                        "isPro": false,
                        "fullname": "Hayden Helm",
                        "user": "hshelm",
                        "type": "user"
                    },
                    "name": "Hayden Helm",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:47:39.133Z",
                    "hidden": false
                },
                {
                    "_id": "666919ea2de144452f920f48",
                    "name": "Sheng Zhang",
                    "hidden": false
                },
                {
                    "_id": "666919ea2de144452f920f49",
                    "name": "Junaid Bajwa",
                    "hidden": false
                },
                {
                    "_id": "666919ea2de144452f920f4a",
                    "name": "Carey E. Priebe",
                    "hidden": false
                },
                {
                    "_id": "666919ea2de144452f920f4b",
                    "user": {
                        "avatarUrl": "/avatars/377045263dca803819289394da719ac9.svg",
                        "isPro": false,
                        "fullname": "Eric Horvitz",
                        "user": "skaviouz",
                        "type": "user"
                    },
                    "name": "Eric Horvitz",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-12T08:48:21.339Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-03T18:15:56.000Z",
            "title": "MedFuzz: Exploring the Robustness of Large Language Models in Medical\n  Question Answering",
            "summary": "Large language models (LLM) have achieved impressive performance on medical\nquestion-answering benchmarks. However, high benchmark accuracy does not imply\nthat the performance generalizes to real-world clinical settings. Medical\nquestion-answering benchmarks rely on assumptions consistent with quantifying\nLLM performance but that may not hold in the open world of the clinic. Yet LLMs\nlearn broad knowledge that can help the LLM generalize to practical conditions\nregardless of unrealistic assumptions in celebrated benchmarks. We seek to\nquantify how well LLM medical question-answering benchmark performance\ngeneralizes when benchmark assumptions are violated. Specifically, we present\nan adversarial method that we call MedFuzz (for medical fuzzing). MedFuzz\nattempts to modify benchmark questions in ways aimed at confounding the LLM. We\ndemonstrate the approach by targeting strong assumptions about patient\ncharacteristics presented in the MedQA benchmark. Successful \"attacks\" modify a\nbenchmark item in ways that would be unlikely to fool a medical expert but\nnonetheless \"trick\" the LLM into changing from a correct to an incorrect\nanswer. Further, we present a permutation test technique that can ensure a\nsuccessful attack is statistically significant. We show how to use performance\non a \"MedFuzzed\" benchmark, as well as individual successful attacks. The\nmethods show promise at providing insights into the ability of an LLM to\noperate robustly in more realistic settings.",
            "upvotes": 2
        },
        "publishedAt": "2024-06-12T02:15:47.399Z",
        "title": "MedFuzz: Exploring the Robustness of Large Language Models in Medical Question Answering",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.06573.png",
        "numComments": 0
    },
    {
        "paper": {
            "id": "2406.05629",
            "authors": [
                {
                    "_id": "6669c2e9832c8542889e1e20",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1658512237806-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Mark Hamilton",
                        "user": "mhamilton723",
                        "type": "user"
                    },
                    "name": "Mark Hamilton",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-12T15:46:51.541Z",
                    "hidden": false
                },
                {
                    "_id": "6669c2e9832c8542889e1e21",
                    "name": "Andrew Zisserman",
                    "hidden": false
                },
                {
                    "_id": "6669c2e9832c8542889e1e22",
                    "name": "John R. Hershey",
                    "hidden": false
                },
                {
                    "_id": "6669c2e9832c8542889e1e23",
                    "name": "William T. Freeman",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-09T03:38:21.000Z",
            "title": "Separating the \"Chirp\" from the \"Chat\": Self-supervised Visual Grounding\n  of Sound and Language",
            "summary": "We present DenseAV, a novel dual encoder grounding architecture that learns\nhigh-resolution, semantically meaningful, and audio-visually aligned features\nsolely through watching videos. We show that DenseAV can discover the\n``meaning'' of words and the ``location'' of sounds without explicit\nlocalization supervision. Furthermore, it automatically discovers and\ndistinguishes between these two types of associations without supervision. We\nshow that DenseAV's localization abilities arise from a new multi-head feature\naggregation operator that directly compares dense image and audio\nrepresentations for contrastive learning. In contrast, many other systems that\nlearn ``global'' audio and video representations cannot localize words and\nsound. Finally, we contribute two new datasets to improve the evaluation of AV\nrepresentations through speech and sound prompted semantic segmentation. On\nthese and other datasets we show DenseAV dramatically outperforms the prior art\non speech and sound prompted semantic segmentation. DenseAV outperforms the\nprevious state-of-the-art, ImageBind, on cross-modal retrieval using fewer than\nhalf of the parameters. Project Page:\nhttps://aka.ms/denseav{https://aka.ms/denseav}",
            "upvotes": 1
        },
        "publishedAt": "2024-06-12T14:27:50.408Z",
        "title": "Separating the \"Chirp\" from the \"Chat\": Self-supervised Visual Grounding of Sound and Language",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62dae3734398e21bf7f53443/XwhYauVo770ji3fIdotWk.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.05629.png",
        "numComments": 1
    }
]