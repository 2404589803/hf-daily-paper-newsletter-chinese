[
  {
    "paper": {
      "id": "2511.06221",
      "authors": [
        {
          "_id": "6912a1c7a644ba07c499c6e1",
          "user": {
            "_id": "67486775ed2e4d9e50fc9117",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67486775ed2e4d9e50fc9117/WrCtPqY9X67ASbkUeloDF.jpeg",
            "isPro": false,
            "fullname": "Sen Xu",
            "user": "SenXbjtu",
            "type": "user"
          },
          "name": "Sen Xu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:44:27.021Z",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6e2",
          "user": {
            "_id": "6406991ec3ab325efa9b6732",
            "avatarUrl": "/avatars/5ba29d9e25820c1172b5a98b078e416f.svg",
            "isPro": false,
            "fullname": "DenseHub",
            "user": "YiZhouDenseHub",
            "type": "user"
          },
          "name": "Yi Zhou",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:44:32.245Z",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6e3",
          "name": "Wei Wang",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6e4",
          "name": "Jixin Min",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6e5",
          "user": {
            "_id": "64d1faaa1ed6649d70d1fa2f",
            "avatarUrl": "/avatars/388ba18df077eaa8e16a89e59bf852fa.svg",
            "isPro": false,
            "fullname": "YinZhiBin",
            "user": "YinZhiBin",
            "type": "user"
          },
          "name": "Zhibin Yin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:44:34.446Z",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6e6",
          "name": "Yingwei Dai",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6e7",
          "name": "Shixi Liu",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6e8",
          "name": "Lianyu Pang",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6e9",
          "name": "Yirong Chen",
          "hidden": false
        },
        {
          "_id": "6912a1c7a644ba07c499c6ea",
          "user": {
            "_id": "668b5090101353874ced73d0",
            "avatarUrl": "/avatars/b2ec34a321890140e97ddd69884132a8.svg",
            "isPro": false,
            "fullname": "junlin zhang",
            "user": "junlinzhang",
            "type": "user"
          },
          "name": "Junlin Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:44:24.601Z",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/6406991ec3ab325efa9b6732/4yVJjn-Y2UONHvzebYMkU.png"
      ],
      "publishedAt": "2025-11-09T04:37:36.000Z",
      "submittedOnDailyAt": "2025-11-12T00:53:44.764Z",
      "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model\n  Reasoning Ability in VibeThinker-1.5B",
      "submittedOnDailyBy": {
        "_id": "6406991ec3ab325efa9b6732",
        "avatarUrl": "/avatars/5ba29d9e25820c1172b5a98b078e416f.svg",
        "isPro": false,
        "fullname": "DenseHub",
        "user": "YiZhouDenseHub",
        "type": "user"
      },
      "summary": "Challenging the prevailing consensus that small models inherently lack robust\nreasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense\nmodel developed via our Spectrum-to-Signal Principle (SSP). This challenges the\nprevailing approach of scaling model parameters to enhance capabilities, as\nseen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework\nfirst employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a\nbroad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL)\nto amplify the correct signal. With a total training cost of only $7,800,\nVibeThinker-1.5B demonstrates superior reasoning capabilities compared to\nclosed-source models like Magistral Medium and Claude Opus 4, and performs on\npar with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses\nthe 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8),\nAIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial\nimprovement over its base model (6.7, 4.3, and 0.6, respectively). On\nLiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its\nbase model's 0.0. These findings demonstrate that small models can achieve\nreasoning capabilities comparable to large models, drastically reducing\ntraining and inference costs and thereby democratizing advanced AI research.",
      "upvotes": 35,
      "discussionId": "6912a1c7a644ba07c499c6eb",
      "projectPage": "https://github.com/WeiboAI/VibeThinker",
      "githubRepo": "https://github.com/WeiboAI/VibeThinker",
      "ai_summary": "VibeThinker-1.5B, a 1.5B-parameter model using the Spectrum-to-Signal Principle, achieves superior reasoning capabilities compared to larger models at a significantly lower cost.",
      "ai_keywords": [
        "Spectrum-to-Signal Principle",
        "Two-Stage Diversity-Exploring Distillation",
        "MaxEnt-Guided Policy Optimization",
        "VibeThinker-1.5B",
        "DeepSeek R1",
        "Kimi k2",
        "Magistral Medium",
        "Claude Opus 4",
        "GPT OSS-20B Medium",
        "AIME24",
        "AIME25",
        "HMMT25",
        "LiveCodeBench V6"
      ],
      "githubStars": 19,
      "organization": {
        "_id": "68c8059479c43cfa50f36156",
        "name": "WeiboAI",
        "fullname": "WeiboAI",
        "avatar": "https://cdn-uploads.huggingface.co/production/uploads/64d1faaa1ed6649d70d1fa2f/lZVm6Yuiif9cdr5KsnfZr.png"
      }
    },
    "publishedAt": "2025-11-08T23:37:36.000Z",
    "title": "Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model\n  Reasoning Ability in VibeThinker-1.5B",
    "summary": "Challenging the prevailing consensus that small models inherently lack robust\nreasoning, this report introduces VibeThinker-1.5B, a 1.5B-parameter dense\nmodel developed via our Spectrum-to-Signal Principle (SSP). This challenges the\nprevailing approach of scaling model parameters to enhance capabilities, as\nseen in models like DeepSeek R1 (671B) and Kimi k2 (>1T). The SSP framework\nfirst employs a Two-Stage Diversity-Exploring Distillation (SFT) to generate a\nbroad spectrum of solutions, followed by MaxEnt-Guided Policy Optimization (RL)\nto amplify the correct signal. With a total training cost of only $7,800,\nVibeThinker-1.5B demonstrates superior reasoning capabilities compared to\nclosed-source models like Magistral Medium and Claude Opus 4, and performs on\npar with open-source models like GPT OSS-20B Medium. Remarkably, it surpasses\nthe 400x larger DeepSeek R1 on three math benchmarks: AIME24 (80.3 vs. 79.8),\nAIME25 (74.4 vs. 70.0), and HMMT25 (50.4 vs. 41.7). This is a substantial\nimprovement over its base model (6.7, 4.3, and 0.6, respectively). On\nLiveCodeBench V6, it scores 51.1, outperforming Magistral Medium's 50.3 and its\nbase model's 0.0. These findings demonstrate that small models can achieve\nreasoning capabilities comparable to large models, drastically reducing\ntraining and inference costs and thereby democratizing advanced AI research.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6406991ec3ab325efa9b6732/4yVJjn-Y2UONHvzebYMkU.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.06221.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "6406991ec3ab325efa9b6732",
      "avatarUrl": "/avatars/5ba29d9e25820c1172b5a98b078e416f.svg",
      "fullname": "DenseHub",
      "name": "YiZhouDenseHub",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "organization": {
      "_id": "68c8059479c43cfa50f36156",
      "name": "WeiboAI",
      "fullname": "WeiboAI",
      "avatar": "https://cdn-uploads.huggingface.co/production/uploads/64d1faaa1ed6649d70d1fa2f/lZVm6Yuiif9cdr5KsnfZr.png"
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2511.08319",
      "authors": [
        {
          "_id": "691416b6ac231a572657202a",
          "name": "Soyeong Jeong",
          "hidden": false
        },
        {
          "_id": "691416b6ac231a572657202b",
          "name": "Aparna Elangovan",
          "hidden": false
        },
        {
          "_id": "691416b6ac231a572657202c",
          "name": "Emine Yilmaz",
          "hidden": false
        },
        {
          "_id": "691416b6ac231a572657202d",
          "name": "Oleg Rokhlenko",
          "hidden": false
        }
      ],
      "publishedAt": "2025-11-11T14:48:34.000Z",
      "submittedOnDailyAt": "2025-11-12T02:44:47.353Z",
      "title": "Adaptive Multi-Agent Response Refinement in Conversational Systems",
      "submittedOnDailyBy": {
        "_id": "64e5a1cd4c20016ec9020ec8",
        "avatarUrl": "/avatars/d7ffe7fbbe39c0a013375357457c57b3.svg",
        "isPro": false,
        "fullname": "Soyeong",
        "user": "starsuzi",
        "type": "user"
      },
      "summary": "Large Language Models (LLMs) have demonstrated remarkable success in conversational systems by generating human-like responses. However, they can fall short, especially when required to account for personalization or specific knowledge. In real-life settings, it is impractical to rely on users to detect these errors and request a new response. One way to address this problem is to refine the response before returning it to the user. While existing approaches focus on refining responses within a single LLM, this method struggles to consider diverse aspects needed for effective conversations. In this work, we propose refining responses through a multi-agent framework, where each agent is assigned a specific role for each aspect. We focus on three key aspects crucial to conversational quality: factuality, personalization, and coherence. Each agent is responsible for reviewing and refining one of these aspects, and their feedback is then merged to improve the overall response. To enhance collaboration among them, we introduce a dynamic communication strategy. Instead of following a fixed sequence of agents, our approach adaptively selects and coordinates the most relevant agents based on the specific requirements of each query. We validate our framework on challenging conversational datasets, demonstrating that ours significantly outperforms relevant baselines, particularly in tasks involving knowledge or user's persona, or both.",
      "upvotes": 27,
      "discussionId": "691416b6ac231a572657202e",
      "ai_summary": "A multi-agent framework refines conversational responses by addressing factuality, personalization, and coherence, outperforming single-agent methods on challenging datasets.",
      "ai_keywords": [
        "Large Language Models",
        "conversational systems",
        "multi-agent framework",
        "factuality",
        "personalization",
        "coherence",
        "dynamic communication strategy"
      ],
      "organization": {
        "_id": "5ffdfbadbba2ae614d771970",
        "name": "amazon",
        "fullname": "Amazon",
        "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66f19ed428ae41c20c470792/8y7msN6A6W82LdQhQd85a.png"
      }
    },
    "publishedAt": "2025-11-11T09:48:34.000Z",
    "title": "Adaptive Multi-Agent Response Refinement in Conversational Systems",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable success in conversational systems by generating human-like responses. However, they can fall short, especially when required to account for personalization or specific knowledge. In real-life settings, it is impractical to rely on users to detect these errors and request a new response. One way to address this problem is to refine the response before returning it to the user. While existing approaches focus on refining responses within a single LLM, this method struggles to consider diverse aspects needed for effective conversations. In this work, we propose refining responses through a multi-agent framework, where each agent is assigned a specific role for each aspect. We focus on three key aspects crucial to conversational quality: factuality, personalization, and coherence. Each agent is responsible for reviewing and refining one of these aspects, and their feedback is then merged to improve the overall response. To enhance collaboration among them, we introduce a dynamic communication strategy. Instead of following a fixed sequence of agents, our approach adaptively selects and coordinates the most relevant agents based on the specific requirements of each query. We validate our framework on challenging conversational datasets, demonstrating that ours significantly outperforms relevant baselines, particularly in tasks involving knowledge or user's persona, or both.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.08319.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e5a1cd4c20016ec9020ec8",
      "avatarUrl": "/avatars/d7ffe7fbbe39c0a013375357457c57b3.svg",
      "fullname": "Soyeong",
      "name": "starsuzi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 17
    },
    "organization": {
      "_id": "5ffdfbadbba2ae614d771970",
      "name": "amazon",
      "fullname": "Amazon",
      "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66f19ed428ae41c20c470792/8y7msN6A6W82LdQhQd85a.png"
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2511.07332",
      "authors": [
        {
          "_id": "6912b70ea644ba07c499c752",
          "user": {
            "_id": "62e98e784fa4bc6de6c0f65b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e98e784fa4bc6de6c0f65b/V8M3vr8yC4d5x4o2MfIhX.jpeg",
            "isPro": false,
            "fullname": "Aarash Feizi",
            "user": "aarashfeizi",
            "type": "user"
          },
          "name": "Aarash Feizi",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:44:00.927Z",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c753",
          "name": "Shravan Nayak",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c754",
          "user": {
            "_id": "636865b8cca0a0a962c21f3f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Mja7cpws4gb2Jmdj_foPA.png",
            "isPro": false,
            "fullname": "Xiangru (Edward) Jian",
            "user": "HideOnBush",
            "type": "user"
          },
          "name": "Xiangru Jian",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:44:03.406Z",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c755",
          "user": {
            "_id": "64440be5af034cdfd69ca3a7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg",
            "isPro": false,
            "fullname": "Qinghong (Kevin) Lin",
            "user": "KevinQHLin",
            "type": "user"
          },
          "name": "Kevin Qinghong Lin",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:44:05.862Z",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c756",
          "name": "Kaixin Li",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c757",
          "user": {
            "_id": "60edf5e03203a5daf7d3912e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60edf5e03203a5daf7d3912e/fq1AzGutKI_qojhevc03P.jpeg",
            "isPro": false,
            "fullname": "Rabiul Awal",
            "user": "rabiulawal",
            "type": "user"
          },
          "name": "Rabiul Awal",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:43:58.411Z",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c758",
          "user": {
            "_id": "5fa9ff3ea13e063b8b2b60cb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633380224986-5fa9ff3ea13e063b8b2b60cb.jpeg",
            "isPro": false,
            "fullname": "Xing Han Lù",
            "user": "xhluca",
            "type": "user"
          },
          "name": "Xing Han Lù",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:43:50.993Z",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c759",
          "user": {
            "_id": "6478f30ea68454566353ef95",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6478f30ea68454566353ef95/hX5NiVPyQbK8TIBKnT4J1.jpeg",
            "isPro": false,
            "fullname": "Johan Samir Obando Ceron",
            "user": "johanobandoc",
            "type": "user"
          },
          "name": "Johan Obando-Ceron",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:43:55.983Z",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c75a",
          "name": "Juan A. Rodriguez",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c75b",
          "name": "Nicolas Chapados",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c75c",
          "name": "David Vazquez",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c75d",
          "name": "Adriana Romero-Soriano",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c75e",
          "name": "Reihaneh Rabbany",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c75f",
          "name": "Perouz Taslakian",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c760",
          "name": "Christopher Pal",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c761",
          "name": "Spandana Gella",
          "hidden": false
        },
        {
          "_id": "6912b70ea644ba07c499c762",
          "name": "Sai Rajeswar",
          "hidden": false
        }
      ],
      "publishedAt": "2025-11-10T17:35:21.000Z",
      "submittedOnDailyAt": "2025-11-12T01:32:27.759Z",
      "title": "Grounding Computer Use Agents on Human Demonstrations",
      "submittedOnDailyBy": {
        "_id": "62e98e784fa4bc6de6c0f65b",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e98e784fa4bc6de6c0f65b/V8M3vr8yC4d5x4o2MfIhX.jpeg",
        "isPro": false,
        "fullname": "Aarash Feizi",
        "user": "aarashfeizi",
        "type": "user"
      },
      "summary": "Building reliable computer-use agents requires grounding: accurately\nconnecting natural language instructions to the correct on-screen elements.\nWhile large datasets exist for web and mobile interactions, high-quality\nresources for desktop environments are limited. To address this gap, we\nintroduce GroundCUA, a large-scale desktop grounding dataset built from expert\nhuman demonstrations. It covers 87 applications across 12 categories and\nincludes 56K screenshots, with every on-screen element carefully annotated for\na total of over 3.56M human-verified annotations. From these demonstrations, we\ngenerate diverse instructions that capture a wide range of real-world tasks,\nproviding high-quality data for model training. Using GroundCUA, we develop the\nGroundNext family of models that map instructions to their target UI elements.\nAt both 3B and 7B scales, GroundNext achieves state-of-the-art results across\nfive benchmarks using supervised fine-tuning, while requiring less than\none-tenth the training data of prior work. Reinforcement learning post-training\nfurther improves performance, and when evaluated in an agentic setting on the\nOSWorld benchmark using o3 as planner, GroundNext attains comparable or\nsuperior results to models trained with substantially more data,. These results\ndemonstrate the critical role of high-quality, expert-driven datasets in\nadvancing general-purpose computer-use agents.",
      "upvotes": 18,
      "discussionId": "6912b70fa644ba07c499c763",
      "projectPage": "https://groundcua.github.io/",
      "githubRepo": "https://github.com/ServiceNow/GroundCUA/",
      "ai_summary": "GroundCUA, a large-scale desktop grounding dataset, enables the development of GroundNext models that achieve state-of-the-art performance in mapping instructions to UI elements with less training data.",
      "ai_keywords": [
        "grounding",
        "natural language instructions",
        "on-screen elements",
        "desktop environments",
        "GroundCUA",
        "expert human demonstrations",
        "screenshots",
        "human-verified annotations",
        "GroundNext",
        "supervised fine-tuning",
        "reinforcement learning",
        "OSWorld benchmark",
        "o3 planner"
      ],
      "githubStars": 15,
      "organization": {
        "_id": "633497b475bed993246ff763",
        "name": "ServiceNow",
        "fullname": "ServiceNow",
        "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1664391313869-62f6691f329d4d014d1b4087.png"
      }
    },
    "publishedAt": "2025-11-10T12:35:21.000Z",
    "title": "Grounding Computer Use Agents on Human Demonstrations",
    "summary": "Building reliable computer-use agents requires grounding: accurately\nconnecting natural language instructions to the correct on-screen elements.\nWhile large datasets exist for web and mobile interactions, high-quality\nresources for desktop environments are limited. To address this gap, we\nintroduce GroundCUA, a large-scale desktop grounding dataset built from expert\nhuman demonstrations. It covers 87 applications across 12 categories and\nincludes 56K screenshots, with every on-screen element carefully annotated for\na total of over 3.56M human-verified annotations. From these demonstrations, we\ngenerate diverse instructions that capture a wide range of real-world tasks,\nproviding high-quality data for model training. Using GroundCUA, we develop the\nGroundNext family of models that map instructions to their target UI elements.\nAt both 3B and 7B scales, GroundNext achieves state-of-the-art results across\nfive benchmarks using supervised fine-tuning, while requiring less than\none-tenth the training data of prior work. Reinforcement learning post-training\nfurther improves performance, and when evaluated in an agentic setting on the\nOSWorld benchmark using o3 as planner, GroundNext attains comparable or\nsuperior results to models trained with substantially more data,. These results\ndemonstrate the critical role of high-quality, expert-driven datasets in\nadvancing general-purpose computer-use agents.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.07332.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "62e98e784fa4bc6de6c0f65b",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e98e784fa4bc6de6c0f65b/V8M3vr8yC4d5x4o2MfIhX.jpeg",
      "fullname": "Aarash Feizi",
      "name": "aarashfeizi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "organization": {
      "_id": "633497b475bed993246ff763",
      "name": "ServiceNow",
      "fullname": "ServiceNow",
      "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1664391313869-62f6691f329d4d014d1b4087.png"
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2511.05664",
      "authors": [
        {
          "_id": "6912e1b6a644ba07c499c82d",
          "name": "Seo Hyun Kim",
          "hidden": false
        },
        {
          "_id": "6912e1b6a644ba07c499c82e",
          "name": "Sunwoo Hong",
          "hidden": false
        },
        {
          "_id": "6912e1b6a644ba07c499c82f",
          "name": "Hojung Jung",
          "hidden": false
        },
        {
          "_id": "6912e1b6a644ba07c499c830",
          "name": "Youngrok Park",
          "hidden": false
        },
        {
          "_id": "6912e1b6a644ba07c499c831",
          "name": "Se-Young Yun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-11-07T19:05:36.000Z",
      "submittedOnDailyAt": "2025-11-12T03:18:40.045Z",
      "title": "KLASS: KL-Guided Fast Inference in Masked Diffusion Models",
      "submittedOnDailyBy": {
        "_id": "62e167813eb0730f6217c95e",
        "avatarUrl": "/avatars/95a18009f725832646643d6169c2bc08.svg",
        "isPro": false,
        "fullname": "Seo Hyun Kim",
        "user": "shkim0116",
        "type": "user"
      },
      "summary": "Masked diffusion models have demonstrated competitive results on various\ntasks including language generation. However, due to its iterative refinement\nprocess, the inference is often bottlenecked by slow and static sampling speed.\nTo overcome this problem, we introduce `KL-Adaptive Stability Sampling'\n(KLASS), a fast yet effective sampling method that exploits token-level KL\ndivergence to identify stable, high-confidence predictions. By unmasking\nmultiple tokens in each iteration without any additional model training, our\napproach speeds up generation significantly while maintaining sample quality.\nOn reasoning benchmarks, KLASS achieves up to 2.78times wall-clock speedups\nwhile improving performance over standard greedy decoding, attaining\nstate-of-the-art results among diffusion-based samplers. We further validate\nKLASS across diverse domains, including text, image, and molecular generation,\nshowing its effectiveness as a broadly applicable sampler across different\nmodels.",
      "upvotes": 14,
      "discussionId": "6912e1b6a644ba07c499c832",
      "githubRepo": "https://github.com/shkim0116/KLASS",
      "ai_summary": "KL-Adaptive Stability Sampling (KLASS) accelerates diffusion-based generation by identifying stable predictions, achieving significant speedups and quality improvements across various domains.",
      "ai_keywords": [
        "masked diffusion models",
        "language generation",
        "KL divergence",
        "token-level",
        "sampling speed",
        "greedy decoding",
        "text generation",
        "image generation",
        "molecular generation"
      ],
      "githubStars": 3,
      "organization": {
        "_id": "6475760c33192631bad2bb38",
        "name": "kaist-ai",
        "fullname": "KAIST AI",
        "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6469949654873f0043b09c22/aaZFiyXe1qR-Dmy_xq67m.png"
      }
    },
    "publishedAt": "2025-11-07T14:05:36.000Z",
    "title": "KLASS: KL-Guided Fast Inference in Masked Diffusion Models",
    "summary": "Masked diffusion models have demonstrated competitive results on various\ntasks including language generation. However, due to its iterative refinement\nprocess, the inference is often bottlenecked by slow and static sampling speed.\nTo overcome this problem, we introduce `KL-Adaptive Stability Sampling'\n(KLASS), a fast yet effective sampling method that exploits token-level KL\ndivergence to identify stable, high-confidence predictions. By unmasking\nmultiple tokens in each iteration without any additional model training, our\napproach speeds up generation significantly while maintaining sample quality.\nOn reasoning benchmarks, KLASS achieves up to 2.78times wall-clock speedups\nwhile improving performance over standard greedy decoding, attaining\nstate-of-the-art results among diffusion-based samplers. We further validate\nKLASS across diverse domains, including text, image, and molecular generation,\nshowing its effectiveness as a broadly applicable sampler across different\nmodels.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.05664.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62e167813eb0730f6217c95e",
      "avatarUrl": "/avatars/95a18009f725832646643d6169c2bc08.svg",
      "fullname": "Seo Hyun Kim",
      "name": "shkim0116",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "organization": {
      "_id": "6475760c33192631bad2bb38",
      "name": "kaist-ai",
      "fullname": "KAIST AI",
      "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6469949654873f0043b09c22/aaZFiyXe1qR-Dmy_xq67m.png"
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2511.06281",
      "authors": [
        {
          "_id": "6912a658a644ba07c499c6f5",
          "name": "Zefeng He",
          "hidden": false
        },
        {
          "_id": "6912a658a644ba07c499c6f6",
          "name": "Xiaoye Qu",
          "hidden": false
        },
        {
          "_id": "6912a658a644ba07c499c6f7",
          "name": "Yafu Li",
          "hidden": false
        },
        {
          "_id": "6912a658a644ba07c499c6f8",
          "name": "Siyuan Huang",
          "hidden": false
        },
        {
          "_id": "6912a658a644ba07c499c6f9",
          "name": "Daizong Liu",
          "hidden": false
        },
        {
          "_id": "6912a658a644ba07c499c6fa",
          "name": "Yu Cheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-11-09T08:36:40.000Z",
      "submittedOnDailyAt": "2025-11-12T00:47:54.808Z",
      "title": "VideoSSR: Video Self-Supervised Reinforcement Learning",
      "submittedOnDailyBy": {
        "_id": "64cb54da1af278541d663708",
        "avatarUrl": "/avatars/c44507cc92bb2e83154bad31b90ce6dd.svg",
        "isPro": false,
        "fullname": "Xiaoye Qu",
        "user": "Xiaoye08",
        "type": "user"
      },
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has substantially\nadvanced the video understanding capabilities of Multimodal Large Language\nModels (MLLMs). However, the rapid progress of MLLMs is outpacing the\ncomplexity of existing video datasets, while the manual annotation of new,\nhigh-quality data remains prohibitively expensive. This work investigates a\npivotal question: Can the rich, intrinsic information within videos be\nharnessed to self-generate high-quality, verifiable training data? To\ninvestigate this, we introduce three self-supervised pretext tasks: Anomaly\nGrounding, Object Counting, and Temporal Jigsaw. We construct the Video\nIntrinsic Understanding Benchmark (VIUBench) to validate their difficulty,\nrevealing that current state-of-the-art MLLMs struggle significantly on these\ntasks. Building upon these pretext tasks, we develop the VideoSSR-30K dataset\nand propose VideoSSR, a novel video self-supervised reinforcement learning\nframework for RLVR. Extensive experiments across 17 benchmarks, spanning four\nmajor video domains (General Video QA, Long Video QA, Temporal Grounding, and\nComplex Reasoning), demonstrate that VideoSSR consistently enhances model\nperformance, yielding an average improvement of over 5\\%. These results\nestablish VideoSSR as a potent foundational framework for developing more\nadvanced video understanding in MLLMs. The code is available at\nhttps://github.com/lcqysl/VideoSSR.",
      "upvotes": 11,
      "discussionId": "6912a659a644ba07c499c6fb",
      "projectPage": "https://github.com/lcqysl/VideoSSR",
      "githubRepo": "https://github.com/lcqysl/VideoSSR",
      "ai_summary": "A novel video self-supervised reinforcement learning framework, VideoSSR, enhances MLLM performance across various video understanding tasks by leveraging intrinsic video information.",
      "ai_keywords": [
        "Reinforcement Learning with Verifiable Rewards",
        "Multimodal Large Language Models",
        "self-supervised pretext tasks",
        "Anomaly Grounding",
        "Object Counting",
        "Temporal Jigsaw",
        "Video Intrinsic Understanding Benchmark",
        "VideoSSR-30K dataset",
        "VideoSSR",
        "General Video QA",
        "Long Video QA",
        "Temporal Grounding",
        "Complex Reasoning"
      ],
      "githubStars": 14,
      "organization": {
        "_id": "6747ee5decec679eafb90450",
        "name": "ShanghaiAiLab",
        "fullname": "shanghai ailab "
      }
    },
    "publishedAt": "2025-11-09T03:36:40.000Z",
    "title": "VideoSSR: Video Self-Supervised Reinforcement Learning",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has substantially\nadvanced the video understanding capabilities of Multimodal Large Language\nModels (MLLMs). However, the rapid progress of MLLMs is outpacing the\ncomplexity of existing video datasets, while the manual annotation of new,\nhigh-quality data remains prohibitively expensive. This work investigates a\npivotal question: Can the rich, intrinsic information within videos be\nharnessed to self-generate high-quality, verifiable training data? To\ninvestigate this, we introduce three self-supervised pretext tasks: Anomaly\nGrounding, Object Counting, and Temporal Jigsaw. We construct the Video\nIntrinsic Understanding Benchmark (VIUBench) to validate their difficulty,\nrevealing that current state-of-the-art MLLMs struggle significantly on these\ntasks. Building upon these pretext tasks, we develop the VideoSSR-30K dataset\nand propose VideoSSR, a novel video self-supervised reinforcement learning\nframework for RLVR. Extensive experiments across 17 benchmarks, spanning four\nmajor video domains (General Video QA, Long Video QA, Temporal Grounding, and\nComplex Reasoning), demonstrate that VideoSSR consistently enhances model\nperformance, yielding an average improvement of over 5\\%. These results\nestablish VideoSSR as a potent foundational framework for developing more\nadvanced video understanding in MLLMs. The code is available at\nhttps://github.com/lcqysl/VideoSSR.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.06281.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64cb54da1af278541d663708",
      "avatarUrl": "/avatars/c44507cc92bb2e83154bad31b90ce6dd.svg",
      "fullname": "Xiaoye Qu",
      "name": "Xiaoye08",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 7
    },
    "organization": {
      "_id": "6747ee5decec679eafb90450",
      "name": "ShanghaiAiLab",
      "fullname": "shanghai ailab "
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2511.08567",
      "authors": [
        {
          "_id": "6914114aac231a572657201a",
          "name": "Hanqing Zhu",
          "hidden": false
        },
        {
          "_id": "6914114aac231a572657201b",
          "name": "Zhenyu Zhang",
          "hidden": false
        },
        {
          "_id": "6914114aac231a572657201c",
          "name": "Hanxian Huang",
          "hidden": false
        },
        {
          "_id": "6914114aac231a572657201d",
          "name": "DiJia Su",
          "hidden": false
        },
        {
          "_id": "6914114aac231a572657201e",
          "name": "Zechun Liu",
          "hidden": false
        },
        {
          "_id": "6914114aac231a572657201f",
          "name": "Jiawei Zhao",
          "hidden": false
        },
        {
          "_id": "6914114aac231a5726572020",
          "name": "Igor Fedorov",
          "hidden": false
        },
        {
          "_id": "6914114aac231a5726572021",
          "name": "Hamed Pirsiavash",
          "hidden": false
        },
        {
          "_id": "6914114aac231a5726572022",
          "name": "Zhizhou Sha",
          "hidden": false
        },
        {
          "_id": "6914114aac231a5726572023",
          "name": "Jinwon Lee",
          "hidden": false
        },
        {
          "_id": "6914114aac231a5726572024",
          "name": "David Z. Pan",
          "hidden": false
        },
        {
          "_id": "6914114aac231a5726572025",
          "name": "Zhangyang Wang",
          "hidden": false
        },
        {
          "_id": "6914114aac231a5726572026",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "6914114aac231a5726572027",
          "name": "Kai Sheng Tai",
          "hidden": false
        }
      ],
      "publishedAt": "2025-11-11T18:49:45.000Z",
      "submittedOnDailyAt": "2025-11-12T03:56:19.786Z",
      "title": "The Path Not Taken: RLVR Provably Learns Off the Principals",
      "submittedOnDailyBy": {
        "_id": "64adab87692be9d12f81957d",
        "avatarUrl": "/avatars/dbb738c8e78769513d8d699e62d6e49b.svg",
        "isPro": false,
        "fullname": "Hanqing Zhu",
        "user": "hanqing666",
        "type": "user"
      },
      "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) reliably improves the reasoning performance of large language models, yet it appears to modify only a small fraction of parameters. We revisit this paradox and show that sparsity is a surface artifact of a model-conditioned optimization bias: for a fixed pretrained model, updates consistently localize to preferred parameter regions, highly consistent across runs and largely invariant to datasets and RL recipes. We mechanistically explain these dynamics with a Three-Gate Theory: Gate I (KL Anchor) imposes a KL-constrained update; Gate II (Model Geometry) steers the step off principal directions into low-curvature, spectrum-preserving subspaces; and Gate III (Precision) hides micro-updates in non-preferred regions, making the off-principal bias appear as sparsity. We then validate this theory and, for the first time, provide a parameter-level characterization of RLVR's learning dynamics: RLVR learns off principal directions in weight space, achieving gains via minimal spectral drift, reduced principal-subspace rotation, and off-principal update alignment. In contrast, SFT targets principal weights, distorts the spectrum, and even lags RLVR.\n  Together, these results provide the first parameter-space account of RLVR's training dynamics, revealing clear regularities in how parameters evolve. Crucially, we show that RL operates in a distinct optimization regime from SFT, so directly adapting SFT-era parameter-efficient fine-tuning (PEFT) methods can be flawed, as evidenced by our case studies on advanced sparse fine-tuning and LoRA variants. We hope this work charts a path toward a white-box understanding of RLVR and the design of geometry-aware, RLVR-native learning algorithms, rather than repurposed SFT-era heuristics.",
      "upvotes": 2,
      "discussionId": "6914114aac231a5726572028",
      "ai_summary": "Reinforcement Learning with Verifiable Rewards (RLVR) improves large language models by modifying a small fraction of parameters through a mechanism involving KL-constrained updates, steering into low-curvature subspaces, and hiding updates in non-preferred regions, differing from supervised fine-tuning methods.",
      "ai_keywords": [
        "Reinforcement Learning with Verifiable Rewards",
        "RLVR",
        "KL-constrained update",
        "low-curvature subspaces",
        "parameter-level characterization",
        "learning dynamics",
        "principal directions",
        "weight space",
        "spectral drift",
        "principal-subspace rotation",
        "off-principal update alignment",
        "supervised fine-tuning",
        "parameter-efficient fine-tuning",
        "PEFT",
        "sparse fine-tuning",
        "LoRA"
      ],
      "organization": {
        "_id": "5e63d8713071d5be688861b8",
        "name": "facebook",
        "fullname": "AI at Meta",
        "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1592839207516-noauth.png"
      }
    },
    "publishedAt": "2025-11-11T13:49:45.000Z",
    "title": "The Path Not Taken: RLVR Provably Learns Off the Principals",
    "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) reliably improves the reasoning performance of large language models, yet it appears to modify only a small fraction of parameters. We revisit this paradox and show that sparsity is a surface artifact of a model-conditioned optimization bias: for a fixed pretrained model, updates consistently localize to preferred parameter regions, highly consistent across runs and largely invariant to datasets and RL recipes. We mechanistically explain these dynamics with a Three-Gate Theory: Gate I (KL Anchor) imposes a KL-constrained update; Gate II (Model Geometry) steers the step off principal directions into low-curvature, spectrum-preserving subspaces; and Gate III (Precision) hides micro-updates in non-preferred regions, making the off-principal bias appear as sparsity. We then validate this theory and, for the first time, provide a parameter-level characterization of RLVR's learning dynamics: RLVR learns off principal directions in weight space, achieving gains via minimal spectral drift, reduced principal-subspace rotation, and off-principal update alignment. In contrast, SFT targets principal weights, distorts the spectrum, and even lags RLVR.\n  Together, these results provide the first parameter-space account of RLVR's training dynamics, revealing clear regularities in how parameters evolve. Crucially, we show that RL operates in a distinct optimization regime from SFT, so directly adapting SFT-era parameter-efficient fine-tuning (PEFT) methods can be flawed, as evidenced by our case studies on advanced sparse fine-tuning and LoRA variants. We hope this work charts a path toward a white-box understanding of RLVR and the design of geometry-aware, RLVR-native learning algorithms, rather than repurposed SFT-era heuristics.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.08567.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64adab87692be9d12f81957d",
      "avatarUrl": "/avatars/dbb738c8e78769513d8d699e62d6e49b.svg",
      "fullname": "Hanqing Zhu",
      "name": "hanqing666",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "organization": {
      "_id": "5e63d8713071d5be688861b8",
      "name": "facebook",
      "fullname": "AI at Meta",
      "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1592839207516-noauth.png"
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2511.07080",
      "authors": [
        {
          "_id": "6912c6cba644ba07c499c7dd",
          "user": {
            "_id": "65276c7911a8a521c91bc10f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
            "isPro": false,
            "fullname": "Khalil Hennara",
            "user": "Hennara",
            "type": "user"
          },
          "name": "Khalil Hennara",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-11-11T19:43:31.158Z",
          "hidden": false
        },
        {
          "_id": "6912c6cba644ba07c499c7de",
          "name": "Ahmad Bastati",
          "hidden": false
        },
        {
          "_id": "6912c6cba644ba07c499c7df",
          "name": "Muhammad Hreden",
          "hidden": false
        },
        {
          "_id": "6912c6cba644ba07c499c7e0",
          "name": "Mohamed Motasim Hamed",
          "hidden": false
        },
        {
          "_id": "6912c6cba644ba07c499c7e1",
          "name": "Zeina Aldallal",
          "hidden": false
        },
        {
          "_id": "6912c6cba644ba07c499c7e2",
          "name": "Sara Chrouf",
          "hidden": false
        },
        {
          "_id": "6912c6cba644ba07c499c7e3",
          "name": "Safwan AlModhayan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-11-10T13:10:31.000Z",
      "submittedOnDailyAt": "2025-11-12T04:46:28.866Z",
      "title": "Wasm: A Pipeline for Constructing Structured Arabic Interleaved\n  Multimodal Corpora",
      "submittedOnDailyBy": {
        "_id": "65276c7911a8a521c91bc10f",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
        "isPro": false,
        "fullname": "Khalil Hennara",
        "user": "Hennara",
        "type": "user"
      },
      "summary": "The performance of large language models (LLMs) and large multimodal models\n(LMMs) depends heavily on the quality and scale of their pre-training datasets.\nRecent research shows that large multimodal models trained on natural documents\nwhere images and text are interleaved outperform those trained only on\nimage-text pairs across a wide range of benchmarks, leveraging advanced pre-\ntrained models to enforce semantic alignment, image-sequence consistency, and\ntextual coherence. For Arabic, however, the lack of high-quality multimodal\ndatasets that preserve document structure has limited progress. In this paper,\nwe present our pipeline Wasm for processing the Common Crawl dataset to create\na new Arabic multimodal dataset that uniquely provides markdown output. Unlike\nexisting Arabic corpora that focus solely on text extraction, our approach\npreserves the structural integrity of web content while maintaining flexibility\nfor both text-only and multimodal pre-training scenarios. We provide a\ncomprehensive comparative analysis of our data processing pipeline against\nthose used for major existing datasets, highlighting the convergences in\nfiltering strategies and justifying our specific design choices. To support\nfuture research, we publicly release a representative dataset dump along with\nthe multimodal processing pipeline for Arabic.",
      "upvotes": 2,
      "discussionId": "6912c6cba644ba07c499c7e4",
      "ai_summary": "A pipeline for processing the Common Crawl dataset to create a new Arabic multimodal dataset that preserves document structure and supports both text-only and multimodal pre-training.",
      "ai_keywords": [
        "large language models",
        "large multimodal models",
        "pre-training datasets",
        "natural documents",
        "semantic alignment",
        "image-sequence consistency",
        "textual coherence",
        "Arabic",
        "multimodal datasets",
        "markdown output",
        "web content",
        "data processing pipeline",
        "comparative analysis",
        "dataset dump"
      ]
    },
    "publishedAt": "2025-11-10T08:10:31.000Z",
    "title": "Wasm: A Pipeline for Constructing Structured Arabic Interleaved\n  Multimodal Corpora",
    "summary": "The performance of large language models (LLMs) and large multimodal models\n(LMMs) depends heavily on the quality and scale of their pre-training datasets.\nRecent research shows that large multimodal models trained on natural documents\nwhere images and text are interleaved outperform those trained only on\nimage-text pairs across a wide range of benchmarks, leveraging advanced pre-\ntrained models to enforce semantic alignment, image-sequence consistency, and\ntextual coherence. For Arabic, however, the lack of high-quality multimodal\ndatasets that preserve document structure has limited progress. In this paper,\nwe present our pipeline Wasm for processing the Common Crawl dataset to create\na new Arabic multimodal dataset that uniquely provides markdown output. Unlike\nexisting Arabic corpora that focus solely on text extraction, our approach\npreserves the structural integrity of web content while maintaining flexibility\nfor both text-only and multimodal pre-training scenarios. We provide a\ncomprehensive comparative analysis of our data processing pipeline against\nthose used for major existing datasets, highlighting the convergences in\nfiltering strategies and justifying our specific design choices. To support\nfuture research, we publicly release a representative dataset dump along with\nthe multimodal processing pipeline for Arabic.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.07080.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65276c7911a8a521c91bc10f",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65276c7911a8a521c91bc10f/39dbuUtqQTJERTJ_WkxSh.jpeg",
      "fullname": "Khalil Hennara",
      "name": "Hennara",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 21
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2511.06428",
      "authors": [
        {
          "_id": "69140e95ac231a5726572014",
          "name": "Samuel Ferino",
          "hidden": false
        },
        {
          "_id": "69140e95ac231a5726572015",
          "name": "Rashina Hoda",
          "hidden": false
        },
        {
          "_id": "69140e95ac231a5726572016",
          "name": "John Grundy",
          "hidden": false
        },
        {
          "_id": "69140e95ac231a5726572017",
          "name": "Christoph Treude",
          "hidden": false
        }
      ],
      "publishedAt": "2025-11-09T15:49:55.000Z",
      "submittedOnDailyAt": "2025-11-12T02:06:36.224Z",
      "title": "Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective",
      "submittedOnDailyBy": {
        "_id": "665be0100a6a819676f073d3",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/665be0100a6a819676f073d3/moAmuTzDuYu45ti2Ob9wR.png",
        "isPro": false,
        "fullname": "Samuel Ferino",
        "user": "samuellucas97",
        "type": "user"
      },
      "summary": "Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.",
      "upvotes": 1,
      "discussionId": "69140e95ac231a5726572018",
      "ai_summary": "LLMs impact software development by offering benefits like maintaining workflow and fostering entrepreneurship, but also pose risks to developers' well-being and reputation; best practices for adoption are identified.",
      "ai_keywords": [
        ""
      ]
    },
    "publishedAt": "2025-11-09T10:49:55.000Z",
    "title": "Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective",
    "summary": "Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2511.06428.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "665be0100a6a819676f073d3",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/665be0100a6a819676f073d3/moAmuTzDuYu45ti2Ob9wR.png",
      "fullname": "Samuel Ferino",
      "name": "samuellucas97",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  }
]