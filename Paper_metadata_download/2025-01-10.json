[
    "{'paper': {'id': '2501.05441', 'authors': [{'_id': '6780827489ff720d2e028eb8', 'user': {'_id': '656988c35958c68e3180961e', 'avatarUrl': '/avatars/7e7916a9c9d2502774dd7727c1a03049.svg', 'isPro': False, 'fullname': 'Yiwen Huang', 'user': 'Eva1209', 'type': 'user'}, 'name': 'Yiwen Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:25:22.968Z', 'hidden': False}, {'_id': '6780827489ff720d2e028eb9', 'user': {'_id': '620573d0522e40b4a18d8763', 'avatarUrl': '/avatars/9353c064ef8ccac84d0397411d38fa90.svg', 'isPro': False, 'fullname': 'Aaron Gokaslan', 'user': 'Skylion007', 'type': 'user'}, 'name': 'Aaron Gokaslan', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:25:29.960Z', 'hidden': False}, {'_id': '6780827489ff720d2e028eba', 'user': {'_id': '640ea1c43c82bd463ee80e19', 'avatarUrl': '/avatars/3213d2e8a433a207dfb96a35f0f52a92.svg', 'isPro': False, 'fullname': 'Volodymyr Kuleshov', 'user': 'kuleshov', 'type': 'user'}, 'name': 'Volodymyr Kuleshov', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:25:37.188Z', 'hidden': False}, {'_id': '6780827489ff720d2e028ebb', 'user': {'_id': '6581b07b4466994ea8491941', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6581b07b4466994ea8491941/dsKpoHwnyTqCaSRMV3evn.png', 'isPro': False, 'fullname': 'James Tompkin', 'user': 'jamestompkin', 'type': 'user'}, 'name': 'James Tompkin', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:25:45.080Z', 'hidden': False}], 'publishedAt': '2025-01-09T18:53:06.000Z', 'title': 'The GAN is dead; long live the GAN! A Modern GAN Baseline', 'summary': 'There is a widely-spread claim that GANs are difficult to train, and GAN\\narchitectures in the literature are littered with empirical tricks. We provide\\nevidence against this claim and build a modern GAN baseline in a more\\nprincipled manner. First, we derive a well-behaved regularized relativistic GAN\\nloss that addresses issues of mode dropping and non-convergence that were\\npreviously tackled via a bag of ad-hoc tricks. We analyze our loss\\nmathematically and prove that it admits local convergence guarantees, unlike\\nmost existing relativistic losses. Second, our new loss allows us to discard\\nall ad-hoc tricks and replace outdated backbones used in common GANs with\\nmodern architectures. Using StyleGAN2 as an example, we present a roadmap of\\nsimplification and modernization that results in a new minimalist baseline --\\nR3GAN. Despite being simple, our approach surpasses StyleGAN2 on FFHQ,\\nImageNet, CIFAR, and Stacked MNIST datasets, and compares favorably against\\nstate-of-the-art GANs and diffusion models.', 'upvotes': 27, 'discussionId': '6780827a89ff720d2e029207'}, 'publishedAt': '2025-01-09T22:24:36.430Z', 'title': 'The GAN is dead; long live the GAN! A Modern GAN Baseline', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/620573d0522e40b4a18d8763/IMeKij7GEtgCHE6EY-6Uj.png', 'https://cdn-uploads.huggingface.co/production/uploads/620573d0522e40b4a18d8763/1YdVsIOzNIJ3Sn_AkbouR.png', 'https://cdn-uploads.huggingface.co/production/uploads/620573d0522e40b4a18d8763/7N325Hb7KAqJWXaobBPv6.png'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05441.png', 'numComments': 3, 'submittedBy': {'_id': '620573d0522e40b4a18d8763', 'avatarUrl': '/avatars/9353c064ef8ccac84d0397411d38fa90.svg', 'fullname': 'Aaron Gokaslan', 'name': 'Skylion007', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 20}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.05453', 'authors': [{'_id': '67809ce9063dd44ffb1de7a7', 'user': {'_id': '63895b3a43d8b0797a0d0406', 'avatarUrl': '/avatars/04d9952dff70f85d4e481ec80ae818cb.svg', 'isPro': False, 'fullname': 'Jathushan Rajasegaran', 'user': 'brjathu', 'type': 'user'}, 'name': 'Jathushan Rajasegaran', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:22:39.142Z', 'hidden': False}, {'_id': '67809ce9063dd44ffb1de7a8', 'name': 'Ilija Radosavovic', 'hidden': False}, {'_id': '67809ce9063dd44ffb1de7a9', 'user': {'_id': '667f3f8c5595354e745a1eb8', 'avatarUrl': '/avatars/7bdf766b61709e318c86795b2f48d424.svg', 'isPro': False, 'fullname': 'Rahul Ravishankar', 'user': 'rravishankar', 'type': 'user'}, 'name': 'Rahul Ravishankar', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:23:24.331Z', 'hidden': False}, {'_id': '67809ce9063dd44ffb1de7aa', 'user': {'_id': '62f6942205ca68c0e0ff7b97', 'avatarUrl': '/avatars/b0600de531b4c88f4aa7c30c5ceb06e1.svg', 'isPro': False, 'fullname': 'Yossi Gandelsman', 'user': 'yossig', 'type': 'user'}, 'name': 'Yossi Gandelsman', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:23:33.999Z', 'hidden': False}, {'_id': '67809ce9063dd44ffb1de7ab', 'name': 'Christoph Feichtenhofer', 'hidden': False}, {'_id': '67809ce9063dd44ffb1de7ac', 'user': {'_id': '65369a95605a07338de78ab0', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/sGFjOjLT2akN-sn5beVWL.jpeg', 'isPro': False, 'fullname': 'Jitendra Malik ', 'user': 'jitendra1995', 'type': 'user'}, 'name': 'Jitendra Malik', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:24:49.391Z', 'hidden': False}], 'publishedAt': '2025-01-09T18:59:58.000Z', 'title': 'An Empirical Study of Autoregressive Pre-training from Videos', 'summary': 'We empirically study autoregressive pre-training from videos. To perform our\\nstudy, we construct a series of autoregressive video models, called Toto. We\\ntreat videos as sequences of visual tokens and train transformer models to\\nautoregressively predict future tokens. Our models are pre-trained on a diverse\\ndataset of videos and images comprising over 1 trillion visual tokens. We\\nexplore different architectural, training, and inference design choices. We\\nevaluate the learned visual representations on a range of downstream tasks\\nincluding image recognition, video classification, object tracking, and\\nrobotics. Our results demonstrate that, despite minimal inductive biases,\\nautoregressive pre-training leads to competitive performance across all\\nbenchmarks. Finally, we find that scaling our video models results in similar\\nscaling curves to those seen in language models, albeit with a different rate.\\nMore details at https://brjathu.github.io/toto/', 'upvotes': 17, 'discussionId': '67809ced063dd44ffb1de947'}, 'publishedAt': '2025-01-09T23:07:34.793Z', 'title': 'An Empirical Study of Autoregressive Pre-training from Videos', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05453.png', 'numComments': 2, 'submittedBy': {'_id': '63895b3a43d8b0797a0d0406', 'avatarUrl': '/avatars/04d9952dff70f85d4e481ec80ae818cb.svg', 'fullname': 'Jathushan Rajasegaran', 'name': 'brjathu', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 4}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04003', 'authors': [{'_id': '6780c27b7a8cd9c2c506a074', 'user': {'_id': '67097d0c02d531812edad345', 'avatarUrl': '/avatars/b3a48c0f7c8e37bcfb0749007cd25608.svg', 'isPro': False, 'fullname': 'Shaoyuan Xie', 'user': 'shaoyuanxie', 'type': 'user'}, 'name': 'Shaoyuan Xie', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:34:11.760Z', 'hidden': False}, {'_id': '6780c27b7a8cd9c2c506a075', 'user': {'_id': '62df78222d89ce551ce0f71d', 'avatarUrl': '/avatars/89fba294cff2d2f941d121c1923e4c76.svg', 'isPro': False, 'fullname': 'Lingdong Kong', 'user': 'ldkong', 'type': 'user'}, 'name': 'Lingdong Kong', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-10T08:20:30.948Z', 'hidden': False}, {'_id': '6780c27b7a8cd9c2c506a076', 'user': {'_id': '652965773a416e1f2173443b', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/652965773a416e1f2173443b/y9MB8YgHzbwCXAc4EI9T3.jpeg', 'isPro': False, 'fullname': 'Yuhao Dong', 'user': 'THUdyh', 'type': 'user'}, 'name': 'Yuhao Dong', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:34:17.783Z', 'hidden': False}, {'_id': '6780c27b7a8cd9c2c506a077', 'user': {'_id': '65bcaa3f88b6228542e9caa3', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/65bcaa3f88b6228542e9caa3/DcaY3Ioic6lKfd8Rk3A1D.jpeg', 'isPro': False, 'fullname': 'Sima', 'user': 'Chonghao', 'type': 'user'}, 'name': 'Chonghao Sima', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:34:27.775Z', 'hidden': False}, {'_id': '6780c27b7a8cd9c2c506a078', 'user': {'_id': '64e8505321540e1da3226b54', 'avatarUrl': '/avatars/18958b8406d1ce492b54c1c839f18c54.svg', 'isPro': False, 'fullname': 'Wenwei Zhang', 'user': 'ZwwWayne', 'type': 'user'}, 'name': 'Wenwei Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:34:33.723Z', 'hidden': False}, {'_id': '6780c27b7a8cd9c2c506a079', 'name': 'Qi Alfred Chen', 'hidden': False}, {'_id': '6780c27b7a8cd9c2c506a07a', 'user': {'_id': '62ab1ac1d48b4d8b048a3473', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png', 'isPro': False, 'fullname': 'Ziwei Liu', 'user': 'liuziwei7', 'type': 'user'}, 'name': 'Ziwei Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:35:28.051Z', 'hidden': False}, {'_id': '6780c27b7a8cd9c2c506a07b', 'name': 'Liang Pan', 'hidden': False}], 'publishedAt': '2025-01-07T18:59:55.000Z', 'title': 'Are VLMs Ready for Autonomous Driving? An Empirical Study from the\\n  Reliability, Data, and Metric Perspectives', 'summary': \"Recent advancements in Vision-Language Models (VLMs) have sparked interest in\\ntheir use for autonomous driving, particularly in generating interpretable\\ndriving decisions through natural language. However, the assumption that VLMs\\ninherently provide visually grounded, reliable, and interpretable explanations\\nfor driving remains largely unexamined. To address this gap, we introduce\\nDriveBench, a benchmark dataset designed to evaluate VLM reliability across 17\\nsettings (clean, corrupted, and text-only inputs), encompassing 19,200 frames,\\n20,498 question-answer pairs, three question types, four mainstream driving\\ntasks, and a total of 12 popular VLMs. Our findings reveal that VLMs often\\ngenerate plausible responses derived from general knowledge or textual cues\\nrather than true visual grounding, especially under degraded or missing visual\\ninputs. This behavior, concealed by dataset imbalances and insufficient\\nevaluation metrics, poses significant risks in safety-critical scenarios like\\nautonomous driving. We further observe that VLMs struggle with multi-modal\\nreasoning and display heightened sensitivity to input corruptions, leading to\\ninconsistencies in performance. To address these challenges, we propose refined\\nevaluation metrics that prioritize robust visual grounding and multi-modal\\nunderstanding. Additionally, we highlight the potential of leveraging VLMs'\\nawareness of corruptions to enhance their reliability, offering a roadmap for\\ndeveloping more trustworthy and interpretable decision-making systems in\\nreal-world autonomous driving contexts. The benchmark toolkit is publicly\\naccessible.\", 'upvotes': 10, 'discussionId': '6780c27d7a8cd9c2c506a10d'}, 'publishedAt': '2025-01-10T01:47:59.692Z', 'title': 'Are VLMs Ready for Autonomous Driving? An Empirical Study from the Reliability, Data, and Metric Perspectives', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04003.png', 'numComments': 2, 'submittedBy': {'_id': '62df78222d89ce551ce0f71d', 'avatarUrl': '/avatars/89fba294cff2d2f941d121c1923e4c76.svg', 'fullname': 'Lingdong Kong', 'name': 'ldkong', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 3}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.05032', 'authors': [{'_id': '6780bd677a8cd9c2c5053b7d', 'user': {'_id': '6468ce47e134d050a58aa89c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6468ce47e134d050a58aa89c/ApFcPlOzgI6Cjr0SYPpk6.png', 'isPro': False, 'fullname': 'Yağız Çalık', 'user': 'Weyaxi', 'type': 'user'}, 'name': 'Ethem Yağız Çalık', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-10T06:28:04.751Z', 'hidden': False}, {'_id': '6780bd677a8cd9c2c5053b7e', 'user': {'_id': '63da3d7ae697e5898cb86854', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1675246771355-noauth.jpeg', 'isPro': False, 'fullname': 'Talha Rüzgar Akkuş', 'user': 'Q-bert', 'type': 'user'}, 'name': 'Talha Rüzgar Akkuş', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-10T06:28:32.323Z', 'hidden': False}], 'publishedAt': '2025-01-09T07:44:06.000Z', 'title': 'Enhancing Human-Like Responses in Large Language Models', 'summary': 'This paper explores the advancements in making large language models (LLMs)\\nmore human-like. We focus on techniques that enhance natural language\\nunderstanding, conversational coherence, and emotional intelligence in AI\\nsystems. The study evaluates various approaches, including fine-tuning with\\ndiverse datasets, incorporating psychological principles, and designing models\\nthat better mimic human reasoning patterns. Our findings demonstrate that these\\nenhancements not only improve user interactions but also open new possibilities\\nfor AI applications across different domains. Future work will address the\\nethical implications and potential biases introduced by these human-like\\nattributes.', 'upvotes': 8, 'discussionId': '6780bd687a8cd9c2c5053bc1'}, 'publishedAt': '2025-01-10T11:13:57.890Z', 'title': 'Enhancing Human-Like Responses in Large Language Models', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/6468ce47e134d050a58aa89c/pa99XH3DHuWsxGVaCIJGK.png'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05032.png', 'numComments': 2, 'submittedBy': {'_id': '6468ce47e134d050a58aa89c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6468ce47e134d050a58aa89c/ApFcPlOzgI6Cjr0SYPpk6.png', 'fullname': 'Yağız Çalık', 'name': 'Weyaxi', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 280}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.05122', 'authors': [{'_id': '6780ce57c759e70936ba6da5', 'user': {'_id': '613f291fe5a812eff913808e', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/613f291fe5a812eff913808e/aQUoRv6tllC2j-jg6meUt.jpeg', 'isPro': False, 'fullname': 'Gregor Geigle', 'user': 'Gregor', 'type': 'user'}, 'name': 'Gregor Geigle', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T13:35:02.224Z', 'hidden': False}, {'_id': '6780ce57c759e70936ba6da6', 'name': 'Florian Schneider', 'hidden': False}, {'_id': '6780ce57c759e70936ba6da7', 'name': 'Carolin Holtermann', 'hidden': False}, {'_id': '6780ce57c759e70936ba6da8', 'name': 'Chris Biemann', 'hidden': False}, {'_id': '6780ce57c759e70936ba6da9', 'name': 'Radu Timofte', 'hidden': False}, {'_id': '6780ce57c759e70936ba6daa', 'name': 'Anne Lauscher', 'hidden': False}, {'_id': '6780ce57c759e70936ba6dab', 'name': 'Goran Glavaš', 'hidden': False}], 'publishedAt': '2025-01-09T10:26:14.000Z', 'title': 'Centurio: On Drivers of Multilingual Ability of Large Vision-Language\\n  Model', 'summary': 'Most Large Vision-Language Models (LVLMs) to date are trained predominantly\\non English data, which makes them struggle to understand non-English input and\\nfail to generate output in the desired target language. Existing efforts\\nmitigate these issues by adding multilingual training data, but do so in a\\nlargely ad-hoc manner, lacking insight into how different training mixes tip\\nthe scale for different groups of languages. In this work, we present a\\ncomprehensive investigation into the training strategies for massively\\nmultilingual LVLMs. First, we conduct a series of multi-stage experiments\\nspanning 13 downstream vision-language tasks and 43 languages, systematically\\nexamining: (1) the number of training languages that can be included without\\ndegrading English performance and (2) optimal language distributions of\\npre-training as well as (3) instruction-tuning data. Further, we (4)\\ninvestigate how to improve multilingual text-in-image understanding, and\\nintroduce a new benchmark for the task. Surprisingly, our analysis reveals that\\none can (i) include as many as 100 training languages simultaneously (ii) with\\nas little as 25-50\\\\% of non-English data, to greatly improve multilingual\\nperformance while retaining strong English performance. We further find that\\n(iii) including non-English OCR data in pre-training and instruction-tuning is\\nparamount for improving multilingual text-in-image understanding. Finally, we\\nput all our findings together and train Centurio, a 100-language LVLM, offering\\nstate-of-the-art performance in an evaluation covering 14 tasks and 56\\nlanguages.', 'upvotes': 5, 'discussionId': '6780ce5ac759e70936ba6e7b'}, 'publishedAt': '2025-01-10T06:37:36.233Z', 'title': 'Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05122.png', 'numComments': 2, 'submittedBy': {'_id': '613f291fe5a812eff913808e', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/613f291fe5a812eff913808e/aQUoRv6tllC2j-jg6meUt.jpeg', 'fullname': 'Gregor Geigle', 'name': 'Gregor', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 2}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04377', 'authors': [{'_id': '6780a7fdaf887f31d643cb55', 'user': {'_id': '6600cb94e95908a2a60f3abd', 'avatarUrl': '/avatars/82cdb1ef4ab4caacfa8d9f4c4f538222.svg', 'isPro': False, 'fullname': 'keyekun', 'user': 'keyekun', 'type': 'user'}, 'name': 'Yekun Ke', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:26:56.992Z', 'hidden': False}, {'_id': '6780a7fdaf887f31d643cb56', 'name': 'Xiaoyu Li', 'hidden': False}, {'_id': '6780a7fdaf887f31d643cb57', 'name': 'Yingyu Liang', 'hidden': False}, {'_id': '6780a7fdaf887f31d643cb58', 'user': {'_id': '6335604ea01bd734f72316b0', 'avatarUrl': '/avatars/4c6611dabd492106ffb2e82fd680d983.svg', 'isPro': False, 'fullname': 'Zhizhou Sha', 'user': 'JamesSand', 'type': 'user'}, 'name': 'Zhizhou Sha', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:26:20.704Z', 'hidden': False}, {'_id': '6780a7fdaf887f31d643cb59', 'user': {'_id': '64b769d7fa7eabaae5fb7f2f', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/64b769d7fa7eabaae5fb7f2f/AbxVphanApZDfj3cOI1tb.jpeg', 'isPro': False, 'fullname': 'Zhenmei Shi', 'user': 'Zhenmei', 'type': 'user'}, 'name': 'Zhenmei Shi', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:26:12.739Z', 'hidden': False}, {'_id': '6780a7fdaf887f31d643cb5a', 'name': 'Zhao Song', 'hidden': False}], 'publishedAt': '2025-01-08T09:34:15.000Z', 'title': 'On Computational Limits and Provably Efficient Criteria of Visual\\n  Autoregressive Models: A Fine-Grained Complexity Analysis', 'summary': 'Recently, Visual Autoregressive (VAR) Models introduced a\\ngroundbreaking advancement in the field of image generation, offering a\\nscalable approach through a coarse-to-fine \"next-scale prediction\" paradigm.\\nHowever, the state-of-the-art algorithm of VAR models in [Tian,\\nJiang, Yuan, Peng and Wang, NeurIPS 2024] takes O(n^4) time, which is\\ncomputationally inefficient. In this work, we analyze the computational limits\\nand efficiency criteria of VAR Models through a fine-grained\\ncomplexity lens. Our key contribution is identifying the conditions under which\\nVAR computations can achieve sub-quadratic time complexity.\\nSpecifically, we establish a critical threshold for the norm of input matrices\\nused in VAR attention mechanisms. Above this threshold, assuming the\\nStrong Exponential Time Hypothesis (SETH) from fine-grained\\ncomplexity theory, a sub-quartic time algorithm for VAR models is\\nimpossible. To substantiate our theoretical findings, we present efficient\\nconstructions leveraging low-rank approximations that align with the derived\\ncriteria. This work initiates the study of the computational efficiency of the\\nVAR model from a theoretical perspective. Our technique will shed\\nlight on advancing scalable and efficient image generation in VAR\\nframeworks.', 'upvotes': 5, 'discussionId': '6780a7feaf887f31d643cb83'}, 'publishedAt': '2025-01-09T23:55:24.698Z', 'title': 'On Computational Limits and Provably Efficient Criteria of Visual Autoregressive Models: A Fine-Grained Complexity Analysis', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04377.png', 'numComments': 2, 'submittedBy': {'_id': '6335604ea01bd734f72316b0', 'avatarUrl': '/avatars/4c6611dabd492106ffb2e82fd680d983.svg', 'fullname': 'Zhizhou Sha', 'name': 'JamesSand', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 3}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.03489', 'authors': [{'_id': '678047e05e9a7b1c28c857be', 'user': {'_id': '670ec3f6db1a6bcfe832e0a6', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/-mZNLeLJoXzkwPgYO38lF.png', 'isPro': False, 'fullname': 'Nandan Kumar Jha', 'user': 'nandan523', 'type': 'user'}, 'name': 'Nandan Kumar Jha', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T08:36:07.110Z', 'hidden': False}, {'_id': '678047e05e9a7b1c28c857bf', 'name': 'Brandon Reagen', 'hidden': False}], 'publishedAt': '2025-01-07T03:17:47.000Z', 'title': 'Entropy-Guided Attention for Private LLMs', 'summary': \"The pervasiveness of proprietary language models has raised critical privacy\\nconcerns, necessitating advancements in private inference (PI), where\\ncomputations are performed directly on encrypted data without revealing users'\\nsensitive information. While PI offers a promising solution, its practical\\ndeployment is hindered by substantial communication and latency overheads,\\nprimarily stemming from nonlinear operations. To address this, we introduce an\\ninformation-theoretic framework to characterize the role of nonlinearities in\\ndecoder-only language models, laying a principled foundation for optimizing\\ntransformer-architectures tailored to the demands of PI.\\n  By leveraging Shannon's entropy as a quantitative measure, we uncover the\\npreviously unexplored dual significance of nonlinearities: beyond ensuring\\ntraining stability, they are crucial for maintaining attention head diversity.\\nSpecifically, we find that their removal triggers two critical failure modes:\\n{\\\\em entropy collapse} in deeper layers that destabilizes training, and {\\\\em\\nentropic overload} in earlier layers that leads to under-utilization of\\nMulti-Head Attention's (MHA) representational capacity.\\n  We propose an entropy-guided attention mechanism paired with a novel entropy\\nregularization technique to mitigate entropic overload. Additionally, we\\nexplore PI-friendly alternatives to layer normalization for preventing entropy\\ncollapse and stabilizing the training of LLMs with reduced-nonlinearities. Our\\nstudy bridges the gap between information theory and architectural design,\\nestablishing entropy dynamics as a principled guide for developing efficient PI\\narchitectures. The code and implementation are available at\\nhttps://github.com/Nandan91/entropy-guided-attention-llm{entropy-guided-llm}.\", 'upvotes': 5, 'discussionId': '678047e15e9a7b1c28c8580f'}, 'publishedAt': '2025-01-09T23:35:15.366Z', 'title': 'Entropy-Guided Attention for Private LLMs', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.03489.png', 'numComments': 4, 'submittedBy': {'_id': '670ec3f6db1a6bcfe832e0a6', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/-mZNLeLJoXzkwPgYO38lF.png', 'fullname': 'Nandan Kumar Jha', 'name': 'nandan523', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.05040', 'authors': [{'_id': '6780943c53cd2d16be1e9aae', 'user': {'_id': '62d00ff8dd7bdfc5e5c553c6', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62d00ff8dd7bdfc5e5c553c6/u9Be7K16IS2Hc5OqKctEA.jpeg', 'isPro': False, 'fullname': 'chengxing xie', 'user': 'yitianlian', 'type': 'user'}, 'name': 'Chengxing Xie', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-10T03:32:24.510Z', 'hidden': False}, {'_id': '6780943c53cd2d16be1e9aaf', 'user': {'_id': '61cd553d3dd34ba1985e075b', 'avatarUrl': '/avatars/5c39e4ac0892decc3af8e08109469196.svg', 'isPro': False, 'fullname': 'Bowen Li', 'user': 'bowenli', 'type': 'user'}, 'name': 'Bowen Li', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-10T09:31:08.408Z', 'hidden': False}, {'_id': '6780943c53cd2d16be1e9ab0', 'user': {'_id': '65570843c4865c852d541688', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/AEGlyozNi3YGSbdcJLmOL.jpeg', 'isPro': False, 'fullname': 'Chang Gao', 'user': 'changgy', 'type': 'user'}, 'name': 'Chang Gao', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T16:10:27.384Z', 'hidden': False}, {'_id': '6780943c53cd2d16be1e9ab1', 'name': 'He Du', 'hidden': False}, {'_id': '6780943c53cd2d16be1e9ab2', 'name': 'Wai Lam', 'hidden': False}, {'_id': '6780943c53cd2d16be1e9ab3', 'name': 'Difan Zou', 'hidden': False}, {'_id': '6780943c53cd2d16be1e9ab4', 'name': 'Kai Chen', 'hidden': False}], 'publishedAt': '2025-01-09T07:54:24.000Z', 'title': 'SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub\\n  Issue Resolution', 'summary': 'Large Language Models (LLMs) have demonstrated remarkable proficiency across\\na variety of complex tasks. One significant application of LLMs is in tackling\\nsoftware engineering challenges, particularly in resolving real-world tasks on\\nGitHub by fixing code based on the issues reported by the users. However, many\\ncurrent approaches rely on proprietary LLMs, which limits reproducibility,\\naccessibility, and transparency. The critical components of LLMs for addressing\\nsoftware engineering issues and how their capabilities can be effectively\\nenhanced remain unclear. To address these challenges, we introduce SWE-Fixer, a\\nnovel open-source LLM designed to effectively and efficiently resolve GitHub\\nissues. SWE-Fixer comprises two essential modules: a code file retrieval module\\nand a code editing module. The retrieval module employs BM25 along with a\\nlightweight LLM model to achieve coarse-to-fine file retrieval. Subsequently,\\nthe code editing module utilizes the other LLM model to generate patches for\\nthe identified files. Then, to mitigate the lack of publicly available\\ndatasets, we compile an extensive dataset that includes 110K GitHub issues\\nalong with their corresponding patches, and train the two modules of SWE-Fixer\\nseparately. We assess our approach on the SWE-Bench Lite and Verified\\nbenchmarks, achieving state-of-the-art performance among open-source models\\nwith scores of 23.3% and 30.2%, respectively. These outcomes highlight the\\nefficacy of our approach. We will make our model, dataset, and code publicly\\navailable at https://github.com/InternLM/SWE-Fixer.', 'upvotes': 4, 'discussionId': '6780944053cd2d16be1e9c10'}, 'publishedAt': '2025-01-10T10:39:32.270Z', 'title': 'SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05040.png', 'numComments': 2, 'submittedBy': {'_id': '62d00ff8dd7bdfc5e5c553c6', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62d00ff8dd7bdfc5e5c553c6/u9Be7K16IS2Hc5OqKctEA.jpeg', 'fullname': 'chengxing xie', 'name': 'yitianlian', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04828', 'authors': [{'_id': '6780c9488299cfc4289f3e32', 'user': {'_id': '676e79527f6800a084e0c579', 'avatarUrl': '/avatars/088b9f76d2882985c5b5656a6230c2c1.svg', 'isPro': False, 'fullname': 'Saziye Betül Özates', 'user': 'sbozates', 'type': 'user'}, 'name': 'Şaziye Betül Özateş', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T10:58:00.713Z', 'hidden': False}, {'_id': '6780c9488299cfc4289f3e33', 'user': {'_id': '663a2ad20301bc198ed03ec0', 'avatarUrl': '/avatars/7a8c7b40ac3933085ad2ccdc033a70cc.svg', 'isPro': False, 'fullname': 'Tarık Emre Tıraş', 'user': 'temretiras', 'type': 'user'}, 'name': 'Tarık Emre Tıraş', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-10T08:20:23.780Z', 'hidden': False}, {'_id': '6780c9488299cfc4289f3e34', 'name': 'Ece Elif Adak', 'hidden': False}, {'_id': '6780c9488299cfc4289f3e35', 'name': 'Berat Doğan', 'hidden': False}, {'_id': '6780c9488299cfc4289f3e36', 'user': {'_id': '66816ea081998a6a08eb6606', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/66816ea081998a6a08eb6606/MWkJMVLxaQC7eS_ff1WMD.png', 'isPro': False, 'fullname': 'Fatih Burak Karagöz', 'user': 'fatihburakkaragoz', 'type': 'user'}, 'name': 'Fatih Burak Karagöz', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T11:01:15.324Z', 'hidden': False}, {'_id': '6780c9488299cfc4289f3e37', 'user': {'_id': '655b99be973f30a0a579f9f8', 'avatarUrl': '/avatars/657b4d6204edda6c1a1a2fa037a88c6e.svg', 'isPro': False, 'fullname': 'Efe Genç', 'user': 'tcTHEBESTMAN', 'type': 'user'}, 'name': 'Efe Eren Genç', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-10T11:01:27.195Z', 'hidden': False}, {'_id': '6780c9488299cfc4289f3e38', 'name': 'Esma F. Bilgin Taşdemir', 'hidden': False}], 'publishedAt': '2025-01-08T20:29:00.000Z', 'title': 'Building Foundations for Natural Language Processing of Historical\\n  Turkish: Resources and Models', 'summary': 'This paper introduces foundational resources and models for natural language\\nprocessing (NLP) of historical Turkish, a domain that has remained\\nunderexplored in computational linguistics. We present the first named entity\\nrecognition (NER) dataset, HisTR and the first Universal Dependencies treebank,\\nOTA-BOUN for a historical form of the Turkish language along with\\ntransformer-based models trained using these datasets for named entity\\nrecognition, dependency parsing, and part-of-speech tagging tasks.\\nAdditionally, we introduce Ottoman Text Corpus (OTC), a clean corpus of\\ntransliterated historical Turkish texts that spans a wide range of historical\\nperiods. Our experimental results show significant improvements in the\\ncomputational analysis of historical Turkish, achieving promising results in\\ntasks that require understanding of historical linguistic structures. They also\\nhighlight existing challenges, such as domain adaptation and language\\nvariations across time periods. All of the presented resources and models are\\nmade available at https://huggingface.co/bucolin to serve as a benchmark for\\nfuture progress in historical Turkish NLP.', 'upvotes': 3, 'discussionId': '6780c9498299cfc4289f3e78'}, 'publishedAt': '2025-01-10T05:33:06.168Z', 'title': 'Building Foundations for Natural Language Processing of Historical Turkish: Resources and Models', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/5e6a3d4ea9afd5125d9ec064/D52AtEF4DHULixVWrFgut.png'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04828.png', 'numComments': 2, 'submittedBy': {'_id': '5e6a3d4ea9afd5125d9ec064', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1584020801691-noauth.jpeg', 'fullname': 'Stefan Schweter', 'name': 'stefan-it', 'type': 'user', 'isPro': True, 'isHf': False, 'isMod': False, 'followerCount': 1995}, 'isAuthorParticipating': False}"
]