[
    {
        "paper": {
            "id": "2410.01215",
            "authors": [
                {
                    "_id": "66fe140c7d722f0879868725",
                    "user": {
                        "_id": "645b0c3ec35da9c7afd95421",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645b0c3ec35da9c7afd95421/QuzictLB9OU_nvq1ovoFF.png",
                        "isPro": false,
                        "fullname": "Yuling",
                        "user": "YerbaPage",
                        "type": "user"
                    },
                    "name": "Yuling Shi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-03T08:31:20.232Z",
                    "hidden": false
                },
                {
                    "_id": "66fe140c7d722f0879868726",
                    "name": "Songsong Wang",
                    "hidden": false
                },
                {
                    "_id": "66fe140c7d722f0879868727",
                    "name": "Chengcheng Wan",
                    "hidden": false
                },
                {
                    "_id": "66fe140c7d722f0879868728",
                    "name": "Xiaodong Gu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T03:57:21.000Z",
            "title": "From Code to Correctness: Closing the Last Mile of Code Generation with\n  Hierarchical Debugging",
            "summary": "While large language models have made significant strides in code generation,\nthe pass rate of the generated code is bottlenecked on subtle errors, often\nrequiring human intervention to pass tests, especially for complex problems.\nExisting LLM-based debugging systems treat generated programs as monolithic\nunits, failing to address bugs at multiple levels of granularity, from\nlow-level syntax errors to high-level algorithmic flaws. In this paper, we\nintroduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger\nby isolating, identifying, and resolving bugs at various levels of granularity.\nMGDebugger decomposes problematic code into a hierarchical tree structure of\nsubfunctions, with each level representing a particular granularity of error.\nDuring debugging, it analyzes each subfunction and iteratively resolves bugs in\na bottom-up manner. To effectively test each subfunction, we propose an\nLLM-simulated Python executor, which traces code execution and tracks important\nvariable states to pinpoint errors accurately. Extensive experiments\ndemonstrate that MGDebugger outperforms existing debugging systems, achieving\nan 18.9% improvement in accuracy over seed generations in HumanEval and a 97.6%\nrepair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes\nbugs across different categories and difficulty levels, demonstrating its\nrobustness and effectiveness.",
            "upvotes": 16,
            "discussionId": "66fe140d7d722f0879868788"
        },
        "publishedAt": "2024-10-03T02:20:13.644Z",
        "title": "From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01215.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645b0c3ec35da9c7afd95421/QuzictLB9OU_nvq1ovoFF.png",
            "fullname": "Yuling",
            "name": "YerbaPage",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01744",
            "authors": [
                {
                    "_id": "66fe1c9f81382f012c968fbe",
                    "name": "Mengzhao Jia",
                    "hidden": false
                },
                {
                    "_id": "66fe1c9f81382f012c968fbf",
                    "user": {
                        "_id": "5feab3a28a3201f8e554c969",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660795228685-5feab3a28a3201f8e554c969.png",
                        "isPro": false,
                        "fullname": "Wenhao Yu",
                        "user": "wyu1",
                        "type": "user"
                    },
                    "name": "Wenhao Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:46:36.047Z",
                    "hidden": false
                },
                {
                    "_id": "66fe1c9f81382f012c968fc0",
                    "user": {
                        "_id": "64ae4f6280f308a395fd7c19",
                        "avatarUrl": "/avatars/5f1330f8187cd5e66aa517303659f110.svg",
                        "isPro": false,
                        "fullname": "Kaixin Ma",
                        "user": "kaixinm",
                        "type": "user"
                    },
                    "name": "Kaixin Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:46:55.518Z",
                    "hidden": false
                },
                {
                    "_id": "66fe1c9f81382f012c968fc1",
                    "name": "Tianqing Fang",
                    "hidden": false
                },
                {
                    "_id": "66fe1c9f81382f012c968fc2",
                    "name": "Zhihan Zhang",
                    "hidden": false
                },
                {
                    "_id": "66fe1c9f81382f012c968fc3",
                    "name": "Siru Ouyang",
                    "hidden": false
                },
                {
                    "_id": "66fe1c9f81382f012c968fc4",
                    "name": "Hongming Zhang",
                    "hidden": false
                },
                {
                    "_id": "66fe1c9f81382f012c968fc5",
                    "name": "Meng Jiang",
                    "hidden": false
                },
                {
                    "_id": "66fe1c9f81382f012c968fc6",
                    "name": "Dong Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T16:55:01.000Z",
            "title": "LEOPARD : A Vision Language Model For Text-Rich Multi-Image Tasks",
            "summary": "Text-rich images, where text serves as the central visual element guiding the\noverall understanding, are prevalent in real-world applications, such as\npresentation slides, scanned documents, and webpage snapshots. Tasks involving\nmultiple text-rich images are especially challenging, as they require not only\nunderstanding the content of individual images but reasoning about\ninter-relationships and logical flows across multiple visual inputs. Despite\nthe importance of these scenarios, current multimodal large language models\n(MLLMs) struggle to handle such tasks due to two key challenges: (1) the\nscarcity of high-quality instruction tuning datasets for text-rich multi-image\nscenarios, and (2) the difficulty in balancing image resolution with visual\nfeature sequence length. To address these challenges, we propose \\OurMethod, a\nMLLM designed specifically for handling vision-language tasks involving\nmultiple text-rich images. First, we curated about one million high-quality\nmultimodal instruction-tuning data, tailored to text-rich, multi-image\nscenarios. Second, we developed an adaptive high-resolution multi-image\nencoding module to dynamically optimize the allocation of visual sequence\nlength based on the original aspect ratios and resolutions of the input images.\nExperiments across a wide range of benchmarks demonstrate our model's superior\ncapabilities in text-rich, multi-image evaluations and competitive performance\nin general domain evaluations.",
            "upvotes": 13,
            "discussionId": "66fe1ca081382f012c96906f"
        },
        "publishedAt": "2024-10-03T02:55:21.948Z",
        "title": "LEOPARD : A Vision Language Model For Text-Rich Multi-Image Tasks",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01744.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660795228685-5feab3a28a3201f8e554c969.png",
            "fullname": "Wenhao Yu",
            "name": "wyu1",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.20059",
            "authors": [
                {
                    "_id": "66fd33a20cde4879f9ab4654",
                    "user": {
                        "_id": "65fa95405355a52c784633fc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65fa95405355a52c784633fc/rSfBUHPa7eSAsLd8DuOq4.png",
                        "isPro": false,
                        "fullname": "Hippolyte Gisserot-Boukhlef",
                        "user": "hgissbkh",
                        "type": "user"
                    },
                    "name": "Hippolyte Gisserot-Boukhlef",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-02T12:44:47.000Z",
                    "hidden": false
                },
                {
                    "_id": "66fd33a20cde4879f9ab4655",
                    "name": "Ricardo Rei",
                    "hidden": false
                },
                {
                    "_id": "66fd33a20cde4879f9ab4656",
                    "user": {
                        "_id": "66f2d6a684a241caac8e16dc",
                        "avatarUrl": "/avatars/81acb87c2b07bea938251b40a2139911.svg",
                        "isPro": false,
                        "fullname": "Emmanuel Malherbe",
                        "user": "emmanuelmalherbe",
                        "type": "user"
                    },
                    "name": "Emmanuel Malherbe",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:53:40.295Z",
                    "hidden": false
                },
                {
                    "_id": "66fd33a20cde4879f9ab4657",
                    "user": {
                        "_id": "61efea03a57920a251ec19b8",
                        "avatarUrl": "/avatars/f47c8e3cb17a2bf7d43f2c152bb86885.svg",
                        "isPro": false,
                        "fullname": "Celine Hudelot",
                        "user": "CelineH",
                        "type": "user"
                    },
                    "name": "CÃ©line Hudelot",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:53:47.051Z",
                    "hidden": false
                },
                {
                    "_id": "66fd33a20cde4879f9ab4658",
                    "user": {
                        "_id": "644a900e3a619fe72b14af0f",
                        "avatarUrl": "/avatars/e2d5dac3d92757ed48e37e126a3464a3.svg",
                        "isPro": false,
                        "fullname": "Colombo",
                        "user": "PierreColombo",
                        "type": "user"
                    },
                    "name": "Pierre Colombo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:53:53.386Z",
                    "hidden": false
                },
                {
                    "_id": "66fd33a20cde4879f9ab4659",
                    "user": {
                        "_id": "61f06c8ba57920a251ec1a5c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61f06c8ba57920a251ec1a5c/TmmSN9xWm1noLeAtsUSRk.jpeg",
                        "isPro": false,
                        "fullname": "Nuno Guerreiro",
                        "user": "nunonmg",
                        "type": "user"
                    },
                    "name": "Nuno M. Guerreiro",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:54:03.564Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-30T08:01:44.000Z",
            "title": "Is Preference Alignment Always the Best Option to Enhance LLM-Based\n  Translation? An Empirical Analysis",
            "summary": "Neural metrics for machine translation (MT) evaluation have become\nincreasingly prominent due to their superior correlation with human judgments\ncompared to traditional lexical metrics. Researchers have therefore utilized\nneural metrics through quality-informed decoding strategies, achieving better\nresults than likelihood-based methods. With the rise of Large Language Models\n(LLMs), preference-based alignment techniques have gained attention for their\npotential to enhance translation quality by optimizing model weights directly\non preferences induced by quality estimators. This study focuses on Contrastive\nPreference Optimization (CPO) and conducts extensive experiments to evaluate\nthe impact of preference-based alignment on translation quality. Our findings\nindicate that while CPO consistently outperforms Supervised Fine-Tuning (SFT)\non high-quality data with regard to the alignment metric, it may lead to\ninstability across downstream evaluation metrics, particularly between neural\nand lexical ones. Additionally, we demonstrate that relying solely on the base\nmodel for generating candidate translations achieves performance comparable to\nusing multiple external systems, while ensuring better consistency across\ndownstream metrics.",
            "upvotes": 12,
            "discussionId": "66fd33a30cde4879f9ab46ad"
        },
        "publishedAt": "2024-10-03T06:30:16.351Z",
        "title": "Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.20059.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65fa95405355a52c784633fc/rSfBUHPa7eSAsLd8DuOq4.png",
            "fullname": "Hippolyte Gisserot-Boukhlef",
            "name": "hgissbkh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01044",
            "authors": [
                {
                    "_id": "66fe079fe9e5b5c3e49e309e",
                    "user": {
                        "_id": "63eba2774dcaaf087638e3d6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676386919413-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Jiang",
                        "user": "Dongwei",
                        "type": "user"
                    },
                    "name": "Dongwei Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:15:24.379Z",
                    "hidden": false
                },
                {
                    "_id": "66fe079fe9e5b5c3e49e309f",
                    "name": "Guoxuan Wang",
                    "hidden": false
                },
                {
                    "_id": "66fe079fe9e5b5c3e49e30a0",
                    "user": {
                        "_id": "642f742270daaa6e7209a2c8",
                        "avatarUrl": "/avatars/746fb840c220329f69a17905ea519322.svg",
                        "isPro": false,
                        "fullname": "Yining Lu",
                        "user": "ylu610",
                        "type": "user"
                    },
                    "name": "Yining Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:22:30.977Z",
                    "hidden": false
                },
                {
                    "_id": "66fe079fe9e5b5c3e49e30a1",
                    "name": "Andrew Wang",
                    "hidden": false
                },
                {
                    "_id": "66fe079fe9e5b5c3e49e30a2",
                    "name": "Jingyu Zhang",
                    "hidden": false
                },
                {
                    "_id": "66fe079fe9e5b5c3e49e30a3",
                    "user": {
                        "_id": "66240a576046dd4b8586a604",
                        "avatarUrl": "/avatars/6b4c5fbdaafd6f42d8f4581d0f48d2c0.svg",
                        "isPro": false,
                        "fullname": "Chuyu Liu",
                        "user": "ChuyuLiu",
                        "type": "user"
                    },
                    "name": "Chuyu Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:20:21.699Z",
                    "hidden": false
                },
                {
                    "_id": "66fe079fe9e5b5c3e49e30a4",
                    "name": "Benjamin Van Durme",
                    "hidden": false
                },
                {
                    "_id": "66fe079fe9e5b5c3e49e30a5",
                    "user": {
                        "_id": "5f6540c65e78cc6b0ed3199d",
                        "avatarUrl": "/avatars/0280d4df417855965a0964d22766c012.svg",
                        "isPro": false,
                        "fullname": "Daniel Khashabi",
                        "user": "danyaljj",
                        "type": "user"
                    },
                    "name": "Daniel Khashabi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:20:05.299Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-01T20:05:51.000Z",
            "title": "RATIONALYST: Pre-training Process-Supervision for Improving Reasoning",
            "summary": "The reasoning steps generated by LLMs might be incomplete, as they mimic\nlogical leaps common in everyday communication found in their pre-training\ndata: underlying rationales are frequently left implicit (unstated). To address\nthis challenge, we introduce RATIONALYST, a model for process-supervision of\nreasoning based on pre-training on a vast collection of rationale annotations\nextracted from unlabeled data. We extract 79k rationales from web-scale\nunlabelled dataset (the Pile) and a combination of reasoning datasets with\nminimal human intervention. This web-scale pre-training for reasoning allows\nRATIONALYST to consistently generalize across diverse reasoning tasks,\nincluding mathematical, commonsense, scientific, and logical reasoning.\nFine-tuned from LLaMa-3-8B, RATIONALYST improves the accuracy of reasoning by\nan average of 3.9% on 7 representative reasoning benchmarks. It also\ndemonstrates superior performance compared to significantly larger verifiers\nlike GPT-4 and similarly sized models fine-tuned on matching training sets.",
            "upvotes": 11,
            "discussionId": "66fe07a2e9e5b5c3e49e3170"
        },
        "publishedAt": "2024-10-03T01:26:20.838Z",
        "title": "RATIONALYST: Pre-training Process-Supervision for Improving Reasoning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01044.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676386919413-noauth.jpeg",
            "fullname": "Jiang",
            "name": "Dongwei",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01748",
            "authors": [
                {
                    "_id": "66fe4d83b7c3b3c0f298f78b",
                    "user": {
                        "_id": "62e447e9640206c5d21e5ff6",
                        "avatarUrl": "/avatars/42d8247c2ffa98a4c6255ce84051f1b9.svg",
                        "isPro": false,
                        "fullname": "Arian Hosseini",
                        "user": "arianhosseini",
                        "type": "user"
                    },
                    "name": "Arian Hosseini",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-03T07:53:39.980Z",
                    "hidden": false
                },
                {
                    "_id": "66fe4d83b7c3b3c0f298f78c",
                    "name": "Alessandro Sordoni",
                    "hidden": false
                },
                {
                    "_id": "66fe4d83b7c3b3c0f298f78d",
                    "name": "Daniel Toyama",
                    "hidden": false
                },
                {
                    "_id": "66fe4d83b7c3b3c0f298f78e",
                    "name": "Aaron Courville",
                    "hidden": false
                },
                {
                    "_id": "66fe4d83b7c3b3c0f298f78f",
                    "user": {
                        "_id": "647875e37b370854241b89a8",
                        "avatarUrl": "/avatars/fd25f7e5960e4e132b9ee689f114820b.svg",
                        "isPro": false,
                        "fullname": "Rishabh Agarwal",
                        "user": "agarwl",
                        "type": "user"
                    },
                    "name": "Rishabh Agarwal",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-03T07:53:39.980Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T17:01:10.000Z",
            "title": "Not All LLM Reasoners Are Created Equal",
            "summary": "We study the depth of grade-school math (GSM) problem-solving capabilities of\nLLMs. To this end, we evaluate their performance on pairs of existing math word\nproblems together so that the answer to the second problem depends on correctly\nanswering the first problem. Our findings reveal a significant reasoning gap in\nmost LLMs, that is performance difference between solving the compositional\npairs and solving each question independently. This gap is more pronounced in\nsmaller, more cost-efficient, and math-specialized models. Moreover,\ninstruction-tuning recipes and code generation have varying effects across LLM\nsizes, while finetuning on GSM can lead to task overfitting. Our analysis\nindicates that large reasoning gaps are not because of test-set leakage, but\ndue to distraction from additional context and poor second-hop reasoning.\nOverall, LLMs exhibit systematic differences in their reasoning abilities,\ndespite what their performance on standard benchmarks indicates.",
            "upvotes": 10,
            "discussionId": "66fe4d83b7c3b3c0f298f7da"
        },
        "publishedAt": "2024-10-03T07:04:21.698Z",
        "title": "Not All LLM Reasoners Are Created Equal",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01748.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/669dbd709a4bf63e08f1ddc2/aV10ZJPPzH5LbnHFZNqc7.png",
            "fullname": "Yi Cui",
            "name": "onekq",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01731",
            "authors": [
                {
                    "_id": "66fe0d6064acd6a2de1864b8",
                    "user": {
                        "_id": "627c1360f19c5eb46d55ba05",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1652712871747-627c1360f19c5eb46d55ba05.jpeg",
                        "isPro": false,
                        "fullname": "Rinon Gal",
                        "user": "rinong",
                        "type": "user"
                    },
                    "name": "Rinon Gal",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-03T09:14:20.320Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0d6064acd6a2de1864b9",
                    "user": {
                        "_id": "610b89ccf5098560ee5fa698",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1628156505064-610b89ccf5098560ee5fa698.jpeg",
                        "isPro": false,
                        "fullname": "Adi Haviv",
                        "user": "adihaviv",
                        "type": "user"
                    },
                    "name": "Adi Haviv",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:52:49.297Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0d6064acd6a2de1864ba",
                    "user": {
                        "_id": "6310c1e0e87051f3e3e3bcc1",
                        "avatarUrl": "/avatars/61b24a2eace7da0e27fbc4369a046051.svg",
                        "isPro": false,
                        "fullname": "Yuval Alaluf",
                        "user": "yuvalalaluf",
                        "type": "user"
                    },
                    "name": "Yuval Alaluf",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:52:41.386Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0d6064acd6a2de1864bb",
                    "name": "Amit H. Bermano",
                    "hidden": false
                },
                {
                    "_id": "66fe0d6064acd6a2de1864bc",
                    "user": {
                        "_id": "628507161949ebcae8e24ec3",
                        "avatarUrl": "/avatars/008ecb3daa4c8187b5f339f1176b3c39.svg",
                        "isPro": false,
                        "fullname": "Daniel Cohen-Or",
                        "user": "cohenor",
                        "type": "user"
                    },
                    "name": "Daniel Cohen-Or",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:52:28.974Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0d6064acd6a2de1864bd",
                    "user": {
                        "_id": "6493393f357b252af72196c5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6493393f357b252af72196c5/EWSy18XRcMRa_4XMM3Fu-.jpeg",
                        "isPro": false,
                        "fullname": "Gal Chechik",
                        "user": "galchechik",
                        "type": "user"
                    },
                    "name": "Gal Chechik",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:52:23.222Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T16:43:24.000Z",
            "title": "ComfyGen: Prompt-Adaptive Workflows for Text-to-Image Generation",
            "summary": "The practical use of text-to-image generation has evolved from simple,\nmonolithic models to complex workflows that combine multiple specialized\ncomponents. While workflow-based approaches can lead to improved image quality,\ncrafting effective workflows requires significant expertise, owing to the large\nnumber of available components, their complex inter-dependence, and their\ndependence on the generation prompt. Here, we introduce the novel task of\nprompt-adaptive workflow generation, where the goal is to automatically tailor\na workflow to each user prompt. We propose two LLM-based approaches to tackle\nthis task: a tuning-based method that learns from user-preference data, and a\ntraining-free method that uses the LLM to select existing flows. Both\napproaches lead to improved image quality when compared to monolithic models or\ngeneric, prompt-independent workflows. Our work shows that prompt-dependent\nflow prediction offers a new pathway to improving text-to-image generation\nquality, complementing existing research directions in the field.",
            "upvotes": 10,
            "discussionId": "66fe0d6464acd6a2de1866e9"
        },
        "publishedAt": "2024-10-03T01:50:07.270Z",
        "title": "ComfyGen: Prompt-Adaptive Workflows for Text-to-Image Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01731.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01769",
            "authors": [
                {
                    "_id": "66fe2719cbfd008a80789765",
                    "user": {
                        "_id": "650390d0c549d0b61839ca13",
                        "avatarUrl": "/avatars/64037f862985cddb55dac682d82093ab.svg",
                        "isPro": false,
                        "fullname": "Zhenting Qi",
                        "user": "zhenting",
                        "type": "user"
                    },
                    "name": "Zhenting Qi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-03T15:01:56.628Z",
                    "hidden": false
                },
                {
                    "_id": "66fe2719cbfd008a80789766",
                    "user": {
                        "_id": "62bc495016897fa76cdcda18",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656506661693-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Hongyin Luo",
                        "user": "luohy",
                        "type": "user"
                    },
                    "name": "Hongyin Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:02:01.424Z",
                    "hidden": false
                },
                {
                    "_id": "66fe2719cbfd008a80789767",
                    "user": {
                        "_id": "66e1080a26e1efe7d7f0f431",
                        "avatarUrl": "/avatars/1e229ff545461a719589d8f1b6196eb0.svg",
                        "isPro": false,
                        "fullname": "Xuliang Huang",
                        "user": "Xulianghuang",
                        "type": "user"
                    },
                    "name": "Xuliang Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:02:22.898Z",
                    "hidden": false
                },
                {
                    "_id": "66fe2719cbfd008a80789768",
                    "user": {
                        "_id": "63af25605fe9db73f67a0fb7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63af25605fe9db73f67a0fb7/mcQHbTdJVxi2GdHzRB9ad.jpeg",
                        "isPro": false,
                        "fullname": "Zhuokai Zhao",
                        "user": "zhuokai",
                        "type": "user"
                    },
                    "name": "Zhuokai Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:02:30.772Z",
                    "hidden": false
                },
                {
                    "_id": "66fe2719cbfd008a80789769",
                    "user": {
                        "_id": "65e53fdf00680b19bc6fc834",
                        "avatarUrl": "/avatars/44bb6406ec2ffb2534b25237cb0dc5d8.svg",
                        "isPro": false,
                        "fullname": "Yibo Jiang",
                        "user": "Nrain",
                        "type": "user"
                    },
                    "name": "Yibo Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:02:37.313Z",
                    "hidden": false
                },
                {
                    "_id": "66fe2719cbfd008a8078976a",
                    "user": {
                        "_id": "64c2e1f785f7034e2eefd8dc",
                        "avatarUrl": "/avatars/5f0affc5dfde833431494621d5fb3037.svg",
                        "isPro": false,
                        "fullname": "Xiangjun Fan",
                        "user": "maxtiktok",
                        "type": "user"
                    },
                    "name": "Xiangjun Fan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:02:45.309Z",
                    "hidden": false
                },
                {
                    "_id": "66fe2719cbfd008a8078976b",
                    "name": "Himabindu Lakkaraju",
                    "hidden": false
                },
                {
                    "_id": "66fe2719cbfd008a8078976c",
                    "user": {
                        "_id": "62a793d33e101ec156cc58c4",
                        "avatarUrl": "/avatars/d3607cdb2cac1b2a3011d7441e6ea321.svg",
                        "isPro": false,
                        "fullname": "James Glass",
                        "user": "OmegaLittleBob",
                        "type": "user"
                    },
                    "name": "James Glass",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:02:58.664Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T17:25:37.000Z",
            "title": "Quantifying Generalization Complexity for Large Language Models",
            "summary": "While large language models (LLMs) have shown exceptional capabilities in\nunderstanding complex queries and performing sophisticated tasks, their\ngeneralization abilities are often deeply entangled with memorization,\nnecessitating more precise evaluation. To address this challenge, we introduce\nScylla, a dynamic evaluation framework that quantitatively measures the\ngeneralization abilities of LLMs. Scylla disentangles generalization from\nmemorization via assessing model performance on both in-distribution (ID) and\nout-of-distribution (OOD) data through 20 tasks across 5 levels of complexity.\nThrough extensive experiments, we uncover a non-monotonic relationship between\ntask complexity and the performance gap between ID and OOD data, which we term\nthe generalization valley. Specifically, this phenomenon reveals a critical\nthreshold - referred to as critical complexity - where reliance on\nnon-generalizable behavior peaks, indicating the upper bound of LLMs'\ngeneralization capabilities. As model size increases, the critical complexity\nshifts toward higher levels of task complexity, suggesting that larger models\ncan handle more complex reasoning tasks before over-relying on memorization.\nLeveraging Scylla and the concept of critical complexity, we benchmark 28LLMs\nincluding both open-sourced models such as LLaMA and Qwen families, and\nclose-sourced models like Claude and GPT, providing a more robust evaluation\nand establishing a clearer understanding of LLMs' generalization capabilities.",
            "upvotes": 9,
            "discussionId": "66fe271acbfd008a807897b1"
        },
        "publishedAt": "2024-10-03T03:41:52.231Z",
        "title": "Quantifying Generalization Complexity for Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01769.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656506661693-noauth.jpeg",
            "fullname": "Hongyin Luo",
            "name": "luohy",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01647",
            "authors": [
                {
                    "_id": "66fe459a609fa71aa6f715e7",
                    "user": {
                        "_id": "647d893bcfca67bc50f8974f",
                        "avatarUrl": "/avatars/fab275f968b7d648dbdf8485c9279fb6.svg",
                        "isPro": false,
                        "fullname": "Yang Cao",
                        "user": "YangCaoCS",
                        "type": "user"
                    },
                    "name": "Yang Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:58:43.253Z",
                    "hidden": false
                },
                {
                    "_id": "66fe459a609fa71aa6f715e8",
                    "user": {
                        "_id": "646f4cf46b3df773a2c93fd0",
                        "avatarUrl": "/avatars/b28407fa2ef666a9c63eb6294a287436.svg",
                        "isPro": false,
                        "fullname": "Yuanliang Ju",
                        "user": "Yuanliang",
                        "type": "user"
                    },
                    "name": "Yuanliang Jv",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T08:58:10.852Z",
                    "hidden": false
                },
                {
                    "_id": "66fe459a609fa71aa6f715e9",
                    "name": "Dan Xu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T15:15:52.000Z",
            "title": "3DGS-DET: Empower 3D Gaussian Splatting with Boundary Guidance and\n  Box-Focused Sampling for 3D Object Detection",
            "summary": "Neural Radiance Fields (NeRF) are widely used for novel-view synthesis and\nhave been adapted for 3D Object Detection (3DOD), offering a promising approach\nto 3DOD through view-synthesis representation. However, NeRF faces inherent\nlimitations: (i) limited representational capacity for 3DOD due to its implicit\nnature, and (ii) slow rendering speeds. Recently, 3D Gaussian Splatting (3DGS)\nhas emerged as an explicit 3D representation that addresses these limitations.\nInspired by these advantages, this paper introduces 3DGS into 3DOD for the\nfirst time, identifying two main challenges: (i) Ambiguous spatial distribution\nof Gaussian blobs: 3DGS primarily relies on 2D pixel-level supervision,\nresulting in unclear 3D spatial distribution of Gaussian blobs and poor\ndifferentiation between objects and background, which hinders 3DOD; (ii)\nExcessive background blobs: 2D images often include numerous background pixels,\nleading to densely reconstructed 3DGS with many noisy Gaussian blobs\nrepresenting the background, negatively affecting detection. To tackle the\nchallenge (i), we leverage the fact that 3DGS reconstruction is derived from 2D\nimages, and propose an elegant and efficient solution by incorporating 2D\nBoundary Guidance to significantly enhance the spatial distribution of Gaussian\nblobs, resulting in clearer differentiation between objects and their\nbackground. To address the challenge (ii), we propose a Box-Focused Sampling\nstrategy using 2D boxes to generate object probability distribution in 3D\nspaces, allowing effective probabilistic sampling in 3D to retain more object\nblobs and reduce noisy background blobs. Benefiting from our designs, our\n3DGS-DET significantly outperforms the SOTA NeRF-based method, NeRF-Det,\nachieving improvements of +6.6 on mAP@0.25 and +8.1 on mAP@0.5 for the ScanNet\ndataset, and impressive +31.5 on mAP@0.25 for the ARKITScenes dataset.",
            "upvotes": 5,
            "discussionId": "66fe459d609fa71aa6f716a7"
        },
        "publishedAt": "2024-10-03T05:50:23.903Z",
        "title": "3DGS-DET: Empower 3D Gaussian Splatting with Boundary Guidance and Box-Focused Sampling for 3D Object Detection",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01647.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/fab275f968b7d648dbdf8485c9279fb6.svg",
            "fullname": "Yang Cao",
            "name": "YangCaoCS",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01257",
            "authors": [
                {
                    "_id": "66fe0ad03e4ef90f0175b132",
                    "user": {
                        "_id": "635865c8aff68f72ac039a4e",
                        "avatarUrl": "/avatars/3fa9bee2e9e211723fcf44bddc6110c2.svg",
                        "isPro": false,
                        "fullname": "Zhilin Wang",
                        "user": "zhilinw",
                        "type": "user"
                    },
                    "name": "Zhilin Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-03T15:27:08.582Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0ad03e4ef90f0175b133",
                    "user": {
                        "_id": "6501fe9d1671f7186dcfbc2d",
                        "avatarUrl": "/avatars/b31cf5f07ae77a8a1604e1472e59d4d8.svg",
                        "isPro": false,
                        "fullname": "Alexander Bukharin",
                        "user": "alexwb",
                        "type": "user"
                    },
                    "name": "Alexander Bukharin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:13:33.557Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0ad03e4ef90f0175b134",
                    "user": {
                        "_id": "6556379e10428134ff235afd",
                        "avatarUrl": "/avatars/ec569729870d7392e806e59a02f37d0c.svg",
                        "isPro": false,
                        "fullname": "Olivier Delalleau",
                        "user": "odelalleau",
                        "type": "user"
                    },
                    "name": "Olivier Delalleau",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:13:39.596Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0ad03e4ef90f0175b135",
                    "user": {
                        "_id": "63d2f2bc2727d7888cb9f3cd",
                        "avatarUrl": "/avatars/f26eb927e803f1ea05d8ae9abfdd2846.svg",
                        "isPro": false,
                        "fullname": "Daniel Egert",
                        "user": "trias702",
                        "type": "user"
                    },
                    "name": "Daniel Egert",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:13:52.093Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0ad03e4ef90f0175b136",
                    "user": {
                        "_id": "6635187e27cf4d1a75f27a40",
                        "avatarUrl": "/avatars/e36f11c962f52e783b4677ca5460c41e.svg",
                        "isPro": false,
                        "fullname": "Gerald Shen",
                        "user": "gshennvm",
                        "type": "user"
                    },
                    "name": "Gerald Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:14:13.742Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0ad03e4ef90f0175b137",
                    "name": "Jiaqi Zeng",
                    "hidden": false
                },
                {
                    "_id": "66fe0ad03e4ef90f0175b138",
                    "user": {
                        "_id": "622937a4acd5bef90e55c49d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649475932211-622937a4acd5bef90e55c49d.jpeg",
                        "isPro": false,
                        "fullname": "Oleksii Kuchaiev",
                        "user": "okuchaiev",
                        "type": "user"
                    },
                    "name": "Oleksii Kuchaiev",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:14:28.153Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0ad03e4ef90f0175b139",
                    "name": "Yi Dong",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T06:05:52.000Z",
            "title": "HelpSteer2-Preference: Complementing Ratings with Preferences",
            "summary": "Reward models are critical for aligning models to follow instructions, and\nare typically trained following one of two popular paradigms: Bradley-Terry\nstyle or Regression style. However, there is a lack of evidence that either\napproach is better than the other, when adequately matched for data. This is\nprimarily because these approaches require data collected in different (but\nincompatible) formats, meaning that adequately matched data is not available in\nexisting public datasets. To tackle this problem, we release preference\nannotations (designed for Bradley-Terry training) to complement existing\nratings (designed for Regression style training) in the HelpSteer2 dataset. To\nimprove data interpretability, preference annotations are accompanied with\nhuman-written justifications. Using this data, we conduct the first\nhead-to-head comparison of Bradley-Terry and Regression models when adequately\nmatched for data. Based on insights derived from such a comparison, we propose\na novel approach to combine Bradley-Terry and Regression reward modeling. A\nLlama-3.1-70B-Instruct model tuned with this approach scores 94.1 on\nRewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. We\nalso demonstrate the effectiveness of this reward model at aligning models to\nfollow instructions in RLHF. We open-source this dataset (CC-BY-4.0 license) at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2 and openly release the\ntrained Reward Model at\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward",
            "upvotes": 5,
            "discussionId": "66fe0ad13e4ef90f0175b180"
        },
        "publishedAt": "2024-10-03T01:39:11.760Z",
        "title": "HelpSteer2-Preference: Complementing Ratings with Preferences",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01257.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01036",
            "authors": [
                {
                    "_id": "66fe8ce315148a910ce929e0",
                    "name": "Marco Gaido",
                    "hidden": false
                },
                {
                    "_id": "66fe8ce315148a910ce929e1",
                    "name": "Sara Papi",
                    "hidden": false
                },
                {
                    "_id": "66fe8ce315148a910ce929e2",
                    "name": "Luisa Bentivogli",
                    "hidden": false
                },
                {
                    "_id": "66fe8ce315148a910ce929e3",
                    "user": {
                        "_id": "66fe8ee6bb54785c355d4549",
                        "avatarUrl": "/avatars/6e2a49b20e1caa6e4005411420845b72.svg",
                        "isPro": false,
                        "fullname": "Alessio Brutti",
                        "user": "AlessioBrutti",
                        "type": "user"
                    },
                    "name": "Alessio Brutti",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-03T15:01:43.727Z",
                    "hidden": false
                },
                {
                    "_id": "66fe8ce315148a910ce929e4",
                    "name": "Mauro Cettolo",
                    "hidden": false
                },
                {
                    "_id": "66fe8ce315148a910ce929e5",
                    "name": "Roberto Gretter",
                    "hidden": false
                },
                {
                    "_id": "66fe8ce315148a910ce929e6",
                    "name": "Marco Matassoni",
                    "hidden": false
                },
                {
                    "_id": "66fe8ce315148a910ce929e7",
                    "name": "Mohamed Nabih",
                    "hidden": false
                },
                {
                    "_id": "66fe8ce315148a910ce929e8",
                    "name": "Matteo Negri",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-01T19:54:10.000Z",
            "title": "MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation\n  Model Training on EU Languages",
            "summary": "The rise of foundation models (FMs), coupled with regulatory efforts\naddressing their risks and impacts, has sparked significant interest in\nopen-source models. However, existing speech FMs (SFMs) fall short of full\ncompliance with the open-source principles, even if claimed otherwise, as no\nexisting SFM has model weights, code, and training data publicly available\nunder open-source terms. In this work, we take the first step toward filling\nthis gap by focusing on the 24 official languages of the European Union (EU).\nWe collect suitable training data by surveying automatic speech recognition\ndatasets and unlabeled speech corpora under open-source compliant licenses, for\na total of 950k hours. Additionally, we release automatic transcripts for 441k\nhours of unlabeled data under the permissive CC-BY license, thereby\nfacilitating the creation of open-source SFMs for the EU languages.",
            "upvotes": 4,
            "discussionId": "66fe8ce415148a910ce92a54"
        },
        "publishedAt": "2024-10-03T11:00:01.759Z",
        "title": "MOSEL: 950,000 Hours of Speech Data for Open-Source Speech Foundation Model Training on EU Languages",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01036.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/bd2a3fb38820c828bdb1acb93b673cb4.svg",
            "fullname": "Sara Papi",
            "name": "spapi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01440",
            "authors": [
                {
                    "_id": "66fe1f1215148a910cc0df1c",
                    "user": {
                        "_id": "669fd314e43472e6109c7a88",
                        "avatarUrl": "/avatars/08f5f4dc6ebd7911348eca20352f2581.svg",
                        "isPro": false,
                        "fullname": "lijinghan",
                        "user": "ljh0104",
                        "type": "user"
                    },
                    "name": "Jinghan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:27:14.588Z",
                    "hidden": false
                },
                {
                    "_id": "66fe1f1215148a910cc0df1d",
                    "user": {
                        "_id": "62fc758172a7ab50b4b89c8c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677251053045-62fc758172a7ab50b4b89c8c.jpeg",
                        "isPro": false,
                        "fullname": "Zhicheng Sun",
                        "user": "feifeiobama",
                        "type": "user"
                    },
                    "name": "Zhicheng Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:27:01.992Z",
                    "hidden": false
                },
                {
                    "_id": "66fe1f1215148a910cc0df1e",
                    "name": "Fei Li",
                    "hidden": false
                },
                {
                    "_id": "66fe1f1215148a910cc0df1f",
                    "name": "Cao Sheng",
                    "hidden": false
                },
                {
                    "_id": "66fe1f1215148a910cc0df20",
                    "name": "Jiazhong Yu",
                    "hidden": false
                },
                {
                    "_id": "66fe1f1215148a910cc0df21",
                    "name": "Yadong Mu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T11:42:49.000Z",
            "title": "Closed-loop Long-horizon Robotic Planning via Equilibrium Sequence\n  Modeling",
            "summary": "In the endeavor to make autonomous robots take actions, task planning is a\nmajor challenge that requires translating high-level task descriptions into\nlong-horizon action sequences. Despite recent advances in language model\nagents, they remain prone to planning errors and limited in their ability to\nplan ahead. To address these limitations in robotic planning, we advocate a\nself-refining scheme that iteratively refines a draft plan until an equilibrium\nis reached. Remarkably, this process can be optimized end-to-end from an\nanalytical perspective without the need to curate additional verifiers or\nreward models, allowing us to train self-refining planners in a simple\nsupervised learning fashion. Meanwhile, a nested equilibrium sequence modeling\nprocedure is devised for efficient closed-loop planning that incorporates\nuseful feedback from the environment (or an internal world model). Our method\nis evaluated on the VirtualHome-Env benchmark, showing advanced performance\nwith better scaling for inference computation. Code is available at\nhttps://github.com/Singularity0104/equilibrium-planner.",
            "upvotes": 3,
            "discussionId": "66fe1f1315148a910cc0df60"
        },
        "publishedAt": "2024-10-03T03:05:45.856Z",
        "title": "Closed-loop Long-horizon Robotic Planning via Equilibrium Sequence Modeling",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01440.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677251053045-62fc758172a7ab50b4b89c8c.jpeg",
            "fullname": "Zhicheng Sun",
            "name": "feifeiobama",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01804",
            "authors": [
                {
                    "_id": "66fe0dc064acd6a2de188b29",
                    "name": "Alexander Mai",
                    "hidden": false
                },
                {
                    "_id": "66fe0dc064acd6a2de188b2a",
                    "user": {
                        "_id": "651ec3aee17ef6a94eefc8e7",
                        "avatarUrl": "/avatars/e90ce400ec0d2de8f9fe4365a6e07b4f.svg",
                        "isPro": false,
                        "fullname": "Peter Hedman",
                        "user": "phedman",
                        "type": "user"
                    },
                    "name": "Peter Hedman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:36:09.541Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0dc064acd6a2de188b2b",
                    "name": "George Kopanas",
                    "hidden": false
                },
                {
                    "_id": "66fe0dc064acd6a2de188b2c",
                    "user": {
                        "_id": "6315b0fc915d0b806830b424",
                        "avatarUrl": "/avatars/e25a7c8df2364c6e8024ec5c646a2889.svg",
                        "isPro": false,
                        "fullname": "Dor Verbin",
                        "user": "dorverbin",
                        "type": "user"
                    },
                    "name": "Dor Verbin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:35:44.578Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0dc064acd6a2de188b2d",
                    "name": "David Futschik",
                    "hidden": false
                },
                {
                    "_id": "66fe0dc064acd6a2de188b2e",
                    "user": {
                        "_id": "64c1a214c84cd12dd79c1530",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/CSK0AyQhXs3Izrnt9s6_l.png",
                        "isPro": false,
                        "fullname": "qiangeng xu",
                        "user": "xharlie",
                        "type": "user"
                    },
                    "name": "Qiangeng Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:35:32.367Z",
                    "hidden": false
                },
                {
                    "_id": "66fe0dc064acd6a2de188b2f",
                    "name": "Falko Kuester",
                    "hidden": false
                },
                {
                    "_id": "66fe0dc064acd6a2de188b30",
                    "name": "Jon Barron",
                    "hidden": false
                },
                {
                    "_id": "66fe0dc064acd6a2de188b31",
                    "name": "Yinda Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T17:59:09.000Z",
            "title": "EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis",
            "summary": "We present Exact Volumetric Ellipsoid Rendering (EVER), a method for\nreal-time differentiable emission-only volume rendering. Unlike recent\nrasterization based approach by 3D Gaussian Splatting (3DGS), our primitive\nbased representation allows for exact volume rendering, rather than alpha\ncompositing 3D Gaussian billboards. As such, unlike 3DGS our formulation does\nnot suffer from popping artifacts and view dependent density, but still\nachieves frame rates of sim!30 FPS at 720p on an NVIDIA RTX4090. Since our\napproach is built upon ray tracing it enables effects such as defocus blur and\ncamera distortion (e.g. such as from fisheye cameras), which are difficult to\nachieve by rasterization. We show that our method is more accurate with fewer\nblending issues than 3DGS and follow-up work on view-consistent rendering,\nespecially on the challenging large-scale scenes from the Zip-NeRF dataset\nwhere it achieves sharpest results among real-time techniques.",
            "upvotes": 3,
            "discussionId": "66fe0dc664acd6a2de188d67"
        },
        "publishedAt": "2024-10-03T01:51:45.436Z",
        "title": "EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01804.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01691",
            "authors": [
                {
                    "_id": "66fea748343c151be4f15b22",
                    "name": "Chao-Wei Huang",
                    "hidden": false
                },
                {
                    "_id": "66fea748343c151be4f15b23",
                    "name": "Yun-Nung Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T16:03:13.000Z",
            "title": "FactAlign: Long-form Factuality Alignment of Large Language Models",
            "summary": "Large language models have demonstrated significant potential as the\nnext-generation information access engines. However, their reliability is\nhindered by issues of hallucination and generating non-factual content. This is\nparticularly problematic in long-form responses, where assessing and ensuring\nfactual accuracy is complex. In this paper, we address this gap by proposing\nFactAlign, a novel alignment framework designed to enhance the factuality of\nLLMs' long-form responses while maintaining their helpfulness. We introduce\nfKTO, a fine-grained, sentence-level alignment algorithm that extends the\nKahneman-Tversky Optimization (KTO) alignment method. Leveraging recent\nadvances in automatic factuality evaluation, FactAlign utilizes fine-grained\nfactuality assessments to guide the alignment process. Our experiments on\nopen-domain prompts and information-seeking questions demonstrate that\nFactAlign significantly improves the factual accuracy of LLM responses while\nalso improving their helpfulness. Further analyses identify that FactAlign is\ncapable of training LLMs to provide more information without losing factual\nprecision, thus improving the factual F1 score. Our source code, datasets, and\ntrained models are publicly available at https://github.com/MiuLab/FactAlign",
            "upvotes": 2,
            "discussionId": "66fea748343c151be4f15b6d"
        },
        "publishedAt": "2024-10-03T12:50:05.048Z",
        "title": "FactAlign: Long-form Factuality Alignment of Large Language Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/5e060e7dcbfd036a99df0dbf/YrBEQXxP7RP-931stltr5.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01691.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5e060e7dcbfd036a99df0dbf/qJ31KnXhyP701B2vcot8Q.jpeg",
            "fullname": "Chao-Wei Huang",
            "name": "chaoweihuang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.18111",
            "authors": [
                {
                    "_id": "66f703ea91c723ca3194dcca",
                    "name": "Ye Liu",
                    "hidden": false
                },
                {
                    "_id": "66f703ea91c723ca3194dccb",
                    "name": "Zongyang Ma",
                    "hidden": false
                },
                {
                    "_id": "66f703ea91c723ca3194dccc",
                    "name": "Zhongang Qi",
                    "hidden": false
                },
                {
                    "_id": "66f703ea91c723ca3194dccd",
                    "name": "Yang Wu",
                    "hidden": false
                },
                {
                    "_id": "66f703ea91c723ca3194dcce",
                    "name": "Ying Shan",
                    "hidden": false
                },
                {
                    "_id": "66f703ea91c723ca3194dccf",
                    "name": "Chang Wen Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-26T17:53:04.000Z",
            "title": "E.T. Bench: Towards Open-Ended Event-Level Video-Language Understanding",
            "summary": "Recent advances in Video Large Language Models (Video-LLMs) have demonstrated\ntheir great potential in general-purpose video understanding. To verify the\nsignificance of these models, a number of benchmarks have been proposed to\ndiagnose their capabilities in different scenarios. However, existing\nbenchmarks merely evaluate models through video-level question-answering,\nlacking fine-grained event-level assessment and task diversity. To fill this\ngap, we introduce E.T. Bench (Event-Level & Time-Sensitive Video Understanding\nBenchmark), a large-scale and high-quality benchmark for open-ended event-level\nvideo understanding. Categorized within a 3-level task taxonomy, E.T. Bench\nencompasses 7.3K samples under 12 tasks with 7K videos (251.4h total length)\nunder 8 domains, providing comprehensive evaluations. We extensively evaluated\n8 Image-LLMs and 12 Video-LLMs on our benchmark, and the results reveal that\nstate-of-the-art models for coarse-level (video-level) understanding struggle\nto solve our fine-grained tasks, e.g., grounding event-of-interests within\nvideos, largely due to the short video context length, improper time\nrepresentations, and lack of multi-event training data. Focusing on these\nissues, we further propose a strong baseline model, E.T. Chat, together with an\ninstruction-tuning dataset E.T. Instruct 164K tailored for fine-grained\nevent-level understanding. Our simple but effective solution demonstrates\nsuperior performance in multiple scenarios.",
            "upvotes": 2,
            "discussionId": "66f703ec91c723ca3194dd41"
        },
        "publishedAt": "2024-10-03T08:16:21.851Z",
        "title": "E.T. Bench: Towards Open-Ended Event-Level Video-Language Understanding",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6250eb5c1fd03f78d0ae550f/K-EC07EwUix9zIjrRi8-M.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18111.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649470297585-noauth.jpeg",
            "fullname": "Ye Liu",
            "name": "yeliudev",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01171",
            "authors": [
                {
                    "_id": "66feb92281382f012cce3e67",
                    "name": "Bryan Li",
                    "hidden": false
                },
                {
                    "_id": "66feb92281382f012cce3e68",
                    "name": "Samar Haider",
                    "hidden": false
                },
                {
                    "_id": "66feb92281382f012cce3e69",
                    "name": "Fiona Luo",
                    "hidden": false
                },
                {
                    "_id": "66feb92281382f012cce3e6a",
                    "name": "Adwait Agashe",
                    "hidden": false
                },
                {
                    "_id": "66feb92281382f012cce3e6b",
                    "name": "Chris Callison-Burch",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T01:59:07.000Z",
            "title": "BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented\n  Generation",
            "summary": "Large language models excel at creative generation but continue to struggle\nwith the issues of hallucination and bias. While retrieval-augmented generation\n(RAG) provides a framework for grounding LLMs' responses in accurate and\nup-to-date information, it still raises the question of bias: which sources\nshould be selected for inclusion in the context? And how should their\nimportance be weighted? In this paper, we study the challenge of cross-lingual\nRAG and present a dataset to investigate the robustness of existing systems at\nanswering queries about geopolitical disputes, which exist at the intersection\nof linguistic, cultural, and political boundaries. Our dataset is sourced from\nWikipedia pages containing information relevant to the given queries and we\ninvestigate the impact of including additional context, as well as the\ncomposition of this context in terms of language and source, on an LLM's\nresponse. Our results show that existing RAG systems continue to be challenged\nby cross-lingual use cases and suffer from a lack of consistency when they are\nprovided with competing information in multiple languages. We present case\nstudies to illustrate these issues and outline steps for future research to\naddress these challenges. We make our dataset and code publicly available at\nhttps://github.com/manestay/bordIRlines.",
            "upvotes": 1,
            "discussionId": "66feb92581382f012cce3f95"
        },
        "publishedAt": "2024-10-03T14:07:00.062Z",
        "title": "BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented Generation",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/618d8e2cfc15c4a6739b17e6/JaFjb1a_BrxChUCPdL2cZ.png",
            "https://cdn-uploads.huggingface.co/production/uploads/618d8e2cfc15c4a6739b17e6/5rOu7kdH834dZoYxW4nUZ.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01171.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/3f02c0d1fad478722f180d9559ae215d.svg",
            "fullname": "Bryan Li",
            "name": "manestay",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01481",
            "authors": [
                {
                    "_id": "66feb6df001816b29e69cd78",
                    "user": {
                        "_id": "6387676c23da90491eb9fb16",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669818175965-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Kai Li",
                        "user": "JusperLee",
                        "type": "user"
                    },
                    "name": "Kai Li",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-03T15:23:13.186Z",
                    "hidden": false
                },
                {
                    "_id": "66feb6df001816b29e69cd79",
                    "name": "Wendi Sang",
                    "hidden": false
                },
                {
                    "_id": "66feb6df001816b29e69cd7a",
                    "name": "Chang Zeng",
                    "hidden": false
                },
                {
                    "_id": "66feb6df001816b29e69cd7b",
                    "name": "Runxuan Yang",
                    "hidden": false
                },
                {
                    "_id": "66feb6df001816b29e69cd7c",
                    "name": "Guo Chen",
                    "hidden": false
                },
                {
                    "_id": "66feb6df001816b29e69cd7d",
                    "name": "Xiaolin Hu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T12:33:59.000Z",
            "title": "SonicSim: A customizable simulation platform for speech processing in\n  moving sound source scenarios",
            "summary": "The systematic evaluation of speech separation and enhancement models under\nmoving sound source conditions typically requires extensive data comprising\ndiverse scenarios. However, real-world datasets often contain insufficient data\nto meet the training and evaluation requirements of models. Although synthetic\ndatasets offer a larger volume of data, their acoustic simulations lack\nrealism. Consequently, neither real-world nor synthetic datasets effectively\nfulfill practical needs. To address these issues, we introduce SonicSim, a\nsynthetic toolkit de-designed to generate highly customizable data for moving\nsound sources. SonicSim is developed based on the embodied AI simulation\nplatform, Habitat-sim, supporting multi-level adjustments, including\nscene-level, microphone-level, and source-level, thereby generating more\ndiverse synthetic data. Leveraging SonicSim, we constructed a moving sound\nsource benchmark dataset, SonicSet, using the Librispeech, the Freesound\nDataset 50k (FSD50K) and Free Music Archive (FMA), and 90 scenes from the\nMatterport3D to evaluate speech separation and enhancement models.\nAdditionally, to validate the differences between synthetic data and real-world\ndata, we randomly selected 5 hours of raw data without reverberation from the\nSonicSet validation set to record a real-world speech separation dataset, which\nwas then compared with the corresponding synthetic datasets. Similarly, we\nutilized the real-world speech enhancement dataset RealMAN to validate the\nacoustic gap between other synthetic datasets and the SonicSet dataset for\nspeech enhancement. The results indicate that the synthetic data generated by\nSonicSim can effectively generalize to real-world scenarios. Demo and code are\npublicly available at https://cslikai.cn/SonicSim/.",
            "upvotes": 1,
            "discussionId": "66feb6e1001816b29e69ce1f"
        },
        "publishedAt": "2024-10-03T13:54:50.023Z",
        "title": "SonicSim: A customizable simulation platform for speech processing in moving sound source scenarios",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01481.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669818175965-noauth.jpeg",
            "fullname": "Kai Li",
            "name": "JusperLee",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01723",
            "authors": [
                {
                    "_id": "66fe82a327821b16ec531774",
                    "name": "Yushi Huang",
                    "hidden": false
                },
                {
                    "_id": "66fe82a327821b16ec531775",
                    "name": "Zining Wang",
                    "hidden": false
                },
                {
                    "_id": "66fe82a327821b16ec531776",
                    "name": "Ruihao Gong",
                    "hidden": false
                },
                {
                    "_id": "66fe82a327821b16ec531777",
                    "name": "Jing Liu",
                    "hidden": false
                },
                {
                    "_id": "66fe82a327821b16ec531778",
                    "name": "Xinjie Zhang",
                    "hidden": false
                },
                {
                    "_id": "66fe82a327821b16ec531779",
                    "name": "Jinyang Guo",
                    "hidden": false
                },
                {
                    "_id": "66fe82a327821b16ec53177a",
                    "name": "Xianglong Liu",
                    "hidden": false
                },
                {
                    "_id": "66fe82a327821b16ec53177b",
                    "name": "Jun Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T16:34:29.000Z",
            "title": "HarmoniCa: Harmonizing Training and Inference for Better Feature Cache\n  in Diffusion Transformer Acceleration",
            "summary": "Diffusion Transformers (DiTs) have gained prominence for outstanding\nscalability and extraordinary performance in generative tasks. However, their\nconsiderable inference costs impede practical deployment. The feature cache\nmechanism, which involves storing and retrieving redundant computations across\ntimesteps, holds promise for reducing per-step inference time in diffusion\nmodels. Most existing caching methods for DiT are manually designed. Although\nthe learning-based approach attempts to optimize strategies adaptively, it\nsuffers from discrepancies between training and inference, which hampers both\nthe performance and acceleration ratio. Upon detailed analysis, we pinpoint\nthat these discrepancies primarily stem from two aspects: (1) Prior Timestep\nDisregard, where training ignores the effect of cache usage at earlier\ntimesteps, and (2) Objective Mismatch, where the training target (align\npredicted noise in each timestep) deviates from the goal of inference (generate\nthe high-quality image). To alleviate these discrepancies, we propose\nHarmoniCa, a novel method that Harmonizes training and inference with a novel\nlearning-based Caching framework built upon Step-Wise Denoising Training (SDT)\nand Image Error Proxy-Guided Objective (IEPO). Compared to the traditional\ntraining paradigm, the newly proposed SDT maintains the continuity of the\ndenoising process, enabling the model to leverage information from prior\ntimesteps during training, similar to the way it operates during inference.\nFurthermore, we design IEPO, which integrates an efficient proxy mechanism to\napproximate the final image error caused by reusing the cached feature.\nTherefore, IEPO helps balance final image quality and cache utilization,\nresolving the issue of training that only considers the impact of cache usage\non the predicted output at each timestep.",
            "upvotes": 1,
            "discussionId": "66fe82a827821b16ec5319ca"
        },
        "publishedAt": "2024-10-03T10:14:25.721Z",
        "title": "HarmoniCa: Harmonizing Training and Inference for Better Feature Cache in Diffusion Transformer Acceleration",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64b500fdf460afaefc5c64b3/F9b4PNziIm9it6H2y-mJU.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01723.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/0cb90e3fdd116e1a49209b222125c76e.svg",
            "fullname": "Yushi Huang",
            "name": "Harahan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01463",
            "authors": [
                {
                    "_id": "66fdfde460a069010d11c007",
                    "user": {
                        "_id": "668f440894dfc0ed1a7006ed",
                        "avatarUrl": "/avatars/fa0d328300b03bcbbf9b3a7532f28458.svg",
                        "isPro": false,
                        "fullname": "Pengxin Guo",
                        "user": "gpx333",
                        "type": "user"
                    },
                    "name": "Pengxin Guo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-03T08:31:28.860Z",
                    "hidden": false
                },
                {
                    "_id": "66fdfde460a069010d11c008",
                    "user": {
                        "_id": "66712ff09c609c2484ce4aa0",
                        "avatarUrl": "/avatars/717b96ddef8a4c19ce07ea1fd9e9fd66.svg",
                        "isPro": false,
                        "fullname": "Shuang Zeng",
                        "user": "stevezs",
                        "type": "user"
                    },
                    "name": "Shuang Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:31:15.344Z",
                    "hidden": false
                },
                {
                    "_id": "66fdfde460a069010d11c009",
                    "user": {
                        "_id": "656f698c80ff527c44e3c33b",
                        "avatarUrl": "/avatars/19ea552ed0bb36260ab0f6e41421f9b3.svg",
                        "isPro": false,
                        "fullname": "Yanran Wang",
                        "user": "yanranw1",
                        "type": "user"
                    },
                    "name": "Yanran Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:31:22.188Z",
                    "hidden": false
                },
                {
                    "_id": "66fdfde460a069010d11c00a",
                    "name": "Huijie Fan",
                    "hidden": false
                },
                {
                    "_id": "66fdfde460a069010d11c00b",
                    "name": "Feifei Wang",
                    "hidden": false
                },
                {
                    "_id": "66fdfde460a069010d11c00c",
                    "user": {
                        "_id": "663058bc2653ec94f4a6235f",
                        "avatarUrl": "/avatars/f55b8c3c8100d6b6d65ba61abc4fb014.svg",
                        "isPro": false,
                        "fullname": "Liangqiong Qu",
                        "user": "Liangqiong-QU",
                        "type": "user"
                    },
                    "name": "Liangqiong Qu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-03T09:32:14.110Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T12:14:36.000Z",
            "title": "Selective Aggregation for Low-Rank Adaptation in Federated Learning",
            "summary": "We investigate LoRA in federated learning through the lens of the asymmetry\nanalysis of the learned A and B matrices. In doing so, we uncover that A\nmatrices are responsible for learning general knowledge, while B matrices\nfocus on capturing client-specific knowledge. Based on this finding, we\nintroduce Federated Share-A Low-Rank Adaptation (FedSA-LoRA), which employs two\nlow-rank trainable matrices A and B to model the weight update, but only\nA matrices are shared with the server for aggregation. Moreover, we delve\ninto the relationship between the learned A and B matrices in other LoRA\nvariants, such as rsLoRA and VeRA, revealing a consistent pattern.\nConsequently, we extend our FedSA-LoRA method to these LoRA variants, resulting\nin FedSA-rsLoRA and FedSA-VeRA. In this way, we establish a general paradigm\nfor integrating LoRA with FL, offering guidance for future work on subsequent\nLoRA variants combined with FL. Extensive experimental results on natural\nlanguage understanding and generation tasks demonstrate the effectiveness of\nthe proposed method.",
            "upvotes": 1,
            "discussionId": "66fdfde460a069010d11c03f"
        },
        "publishedAt": "2024-10-03T07:20:19.087Z",
        "title": "Selective Aggregation for Low-Rank Adaptation in Federated Learning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01463.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/fa0d328300b03bcbbf9b3a7532f28458.svg",
            "fullname": "Pengxin Guo",
            "name": "gpx333",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.20325",
            "authors": [
                {
                    "_id": "66feab3f285117b16ffcc1c0",
                    "name": "Jeremy Bernstein",
                    "hidden": false
                },
                {
                    "_id": "66feab3f285117b16ffcc1c1",
                    "name": "Laker Newhouse",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-30T14:26:12.000Z",
            "title": "Old Optimizer, New Norm: An Anthology",
            "summary": "Deep learning optimizers are often motivated through a mix of convex and\napproximate second-order theory. We select three such methods -- Adam, Shampoo\nand Prodigy -- and argue that each method can instead be understood as a\nsquarely first-order method without convexity assumptions. In fact, after\nswitching off exponential moving averages, each method is equivalent to\nsteepest descent under a particular norm. By generalizing this observation, we\nchart a new design space for training algorithms. Different operator norms\nshould be assigned to different tensors based on the role that the tensor plays\nwithin the network. For example, while linear and embedding layers may have the\nsame weight space of R^{mtimes n}, these layers play different\nroles and should be assigned different norms. We hope that this idea of\ncarefully metrizing the neural architecture might lead to more stable, scalable\nand indeed faster training.",
            "upvotes": 0,
            "discussionId": "66feab3f285117b16ffcc201"
        },
        "publishedAt": "2024-10-03T13:04:12.058Z",
        "title": "Old Optimizer, New Norm: An Anthology",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.20325.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e96991b97c9f33d26bde6/-Bqs6qrmz0yCfwtB2e-6q.jpeg",
            "fullname": "Elie Bakouch",
            "name": "eliebak",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.01518",
            "authors": [
                {
                    "_id": "66fea1fbbb54785c35647ede",
                    "user": {
                        "_id": "63c0e2503bdc86f8108da51b",
                        "avatarUrl": "/avatars/7d47f11992f030b3d831e45102581d1f.svg",
                        "isPro": false,
                        "fullname": "Minsoo Kim",
                        "user": "minsoo2333",
                        "type": "user"
                    },
                    "name": "Minsoo Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-03T15:01:41.434Z",
                    "hidden": false
                },
                {
                    "_id": "66fea1fbbb54785c35647edf",
                    "name": "Kyuhong Shim",
                    "hidden": false
                },
                {
                    "_id": "66fea1fbbb54785c35647ee0",
                    "name": "Jungwook Choi",
                    "hidden": false
                },
                {
                    "_id": "66fea1fbbb54785c35647ee1",
                    "name": "Simyung Chang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-02T13:09:41.000Z",
            "title": "InfiniPot: Infinite Context Processing on Memory-Constrained LLMs",
            "summary": "Handling long input contexts remains a significant challenge for Large\nLanguage Models (LLMs), particularly in resource-constrained environments such\nas mobile devices. Our work aims to address this limitation by introducing\nInfiniPot, a novel KV cache control framework designed to enable pre-trained\nLLMs to manage extensive sequences within fixed memory constraints efficiently,\nwithout requiring additional training. InfiniPot leverages Continual Context\nDistillation (CCD), an iterative process that compresses and retains essential\ninformation through novel importance metrics, effectively maintaining critical\ndata even without access to future context. Our comprehensive evaluations\nindicate that InfiniPot significantly outperforms models trained for long\ncontexts in various NLP tasks, establishing its efficacy and versatility. This\nwork represents a substantial advancement toward making LLMs applicable to a\nbroader range of real-world scenarios.",
            "upvotes": 0,
            "discussionId": "66fea1fcbb54785c35647f32"
        },
        "publishedAt": "2024-10-03T12:25:16.990Z",
        "title": "InfiniPot: Infinite Context Processing on Memory-Constrained LLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.01518.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/7d47f11992f030b3d831e45102581d1f.svg",
            "fullname": "Minsoo Kim",
            "name": "minsoo2333",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]