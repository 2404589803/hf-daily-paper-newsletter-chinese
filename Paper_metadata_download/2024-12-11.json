[
    {
        "paper": {
            "id": "2412.05210",
            "authors": [
                {
                    "_id": "67591839a7adc43651b0d085",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d086",
                    "user": {
                        "_id": "646df403ad20c6fa4f30b7ec",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646df403ad20c6fa4f30b7ec/Q64-XMghOcBoo3itZDGYA.jpeg",
                        "isPro": false,
                        "fullname": "Jiaxi Yang",
                        "user": "jx-yang",
                        "type": "user"
                    },
                    "name": "Jiaxi Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:10:29.983Z",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d087",
                    "name": "Ke Jin",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d088",
                    "user": {
                        "_id": "64a139c098fad0c8a5a627a4",
                        "avatarUrl": "/avatars/6eb508abd827d4a4f5abb6b24155b22d.svg",
                        "isPro": false,
                        "fullname": "Yibo Miao",
                        "user": "instro",
                        "type": "user"
                    },
                    "name": "Yibo Miao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:10:18.768Z",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d089",
                    "name": "Lei Zhang",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d08a",
                    "name": "Liqun Yang",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d08b",
                    "user": {
                        "_id": "672c25ca8cfb61188128eb6f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/FJWy9Tt7UQmu9KcTOx3Rt.png",
                        "isPro": false,
                        "fullname": "Zeyu Cui",
                        "user": "misakamage",
                        "type": "user"
                    },
                    "name": "Zeyu Cui",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:09:40.232Z",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d08c",
                    "name": "Yichang Zhang",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d08d",
                    "user": {
                        "_id": "61e4c4ca1ab24785ac11ba69",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61e4c4ca1ab24785ac11ba69/1Q1zhhyGSJ9RJG9MzwxVv.jpeg",
                        "isPro": false,
                        "fullname": "Binyuan Hui",
                        "user": "huybery",
                        "type": "user"
                    },
                    "name": "Binyuan Hui",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:09:25.313Z",
                    "hidden": false
                },
                {
                    "_id": "67591839a7adc43651b0d08e",
                    "user": {
                        "_id": "620760a26e3b7210c2ff1943",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg",
                        "isPro": false,
                        "fullname": "Junyang Lin",
                        "user": "JustinLin610",
                        "type": "user"
                    },
                    "name": "Junyang Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:09:17.833Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-06T17:40:38.000Z",
            "title": "Evaluating and Aligning CodeLLMs on Human Preference",
            "summary": "Code large language models (codeLLMs) have made significant strides in code\ngeneration. Most previous code-related benchmarks, which consist of various\nprogramming exercises along with the corresponding test cases, are used as a\ncommon measure to evaluate the performance and capabilities of code LLMs.\nHowever, the current code LLMs focus on synthesizing the correct code snippet,\nignoring the alignment with human preferences, where the query should be\nsampled from the practical application scenarios and the model-generated\nresponses should satisfy the human preference. To bridge the gap between the\nmodel-generated response and human preference, we present a rigorous\nhuman-curated benchmark CodeArena to emulate the complexity and diversity of\nreal-world coding tasks, where 397 high-quality samples spanning 40 categories\nand 44 programming languages, carefully curated from user queries. Further, we\npropose a diverse synthetic instruction corpus SynCode-Instruct (nearly 20B\ntokens) by scaling instructions from the website to verify the effectiveness of\nthe large-scale synthetic instruction fine-tuning, where Qwen2.5-SynCoder\ntotally trained on synthetic instruction data can achieve top-tier performance\nof open-source code LLMs. The results find performance differences between\nexecution-based benchmarks and CodeArena. Our systematic experiments of\nCodeArena on 40+ LLMs reveal a notable performance gap between open SOTA code\nLLMs (e.g. Qwen2.5-Coder) and proprietary LLMs (e.g., OpenAI o1), underscoring\nthe importance of the human preference\nalignment.\\url{https://codearenaeval.github.io/ }",
            "upvotes": 39,
            "discussionId": "6759183aa7adc43651b0d0ec"
        },
        "publishedAt": "2024-12-11T00:03:49.859Z",
        "title": "Evaluating and Aligning CodeLLMs on Human Preference",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.05210.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "64ccb9bfead94891d12aef42",
            "avatarUrl": "/avatars/c54809d43d93d3f0766bd2555cecc4e3.svg",
            "fullname": "Yang Jian",
            "name": "CSJianYang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 9
        }
    },
    {
        "paper": {
            "id": "2412.07730",
            "authors": [
                {
                    "_id": "67590ae29500a8d4bb970a6b",
                    "name": "Zongyu Lin",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a6c",
                    "name": "Wei Liu",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a6d",
                    "name": "Chen Chen",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a6e",
                    "user": {
                        "_id": "62b6b0397523238923221df9",
                        "avatarUrl": "/avatars/77068771dd51df7519516cd502a88789.svg",
                        "isPro": false,
                        "fullname": "Jiasenlu",
                        "user": "Jiasenlu",
                        "type": "user"
                    },
                    "name": "Jiasen Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:14:42.640Z",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a6f",
                    "user": {
                        "_id": "638807bd5c2df0349f443de9",
                        "avatarUrl": "/avatars/8593af4c3b716dfe17227618873dd3f2.svg",
                        "isPro": false,
                        "fullname": "wenze",
                        "user": "wenzehu",
                        "type": "user"
                    },
                    "name": "Wenze Hu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:14:36.538Z",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a70",
                    "user": {
                        "_id": "638cb2efc8912be69c149a46",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/638cb2efc8912be69c149a46/qxMNOWoSUG525DgNPpHcK.jpeg",
                        "isPro": false,
                        "fullname": "Tsu-Jui Fu",
                        "user": "tsujuifu",
                        "type": "user"
                    },
                    "name": "Tsu-Jui Fu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:14:29.657Z",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a71",
                    "user": {
                        "_id": "6304992abad6ce7fc025a36a",
                        "avatarUrl": "/avatars/daf4c8a895336c7af45adff068e6f010.svg",
                        "isPro": false,
                        "fullname": "Jesse Allardice",
                        "user": "JesseAllardice",
                        "type": "user"
                    },
                    "name": "Jesse Allardice",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:14:23.262Z",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a72",
                    "user": {
                        "_id": "66b5295f83425904fa7a1a6a",
                        "avatarUrl": "/avatars/a35568fb933ceef7451bd88fb3d5ab17.svg",
                        "isPro": false,
                        "fullname": "Zhengfeng Lai",
                        "user": "jefflai",
                        "type": "user"
                    },
                    "name": "Zhengfeng Lai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:19:53.394Z",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a73",
                    "name": "Liangchen Song",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a74",
                    "name": "Bowen Zhang",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a75",
                    "name": "Cha Chen",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a76",
                    "name": "Yiran Fei",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a77",
                    "name": "Yifan Jiang",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a78",
                    "name": "Lezhi Li",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a79",
                    "user": {
                        "_id": "67091ab8a6ad85d9c8dade7f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/2Mr-EVQJaeMFydmhEXXBI.png",
                        "isPro": false,
                        "fullname": "Yizhou Sun",
                        "user": "HoSaiiRai",
                        "type": "user"
                    },
                    "name": "Yizhou Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:13:07.473Z",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a7a",
                    "user": {
                        "_id": "60b7b9d71b90c5d07c23fbd0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1622653364258-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Kai-Wei Chang",
                        "user": "kaiweichang",
                        "type": "user"
                    },
                    "name": "Kai-Wei Chang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:12:58.775Z",
                    "hidden": false
                },
                {
                    "_id": "67590ae29500a8d4bb970a7b",
                    "user": {
                        "_id": "64b762568c632fbca942a405",
                        "avatarUrl": "/avatars/1eb737ec169967872f1ebf5ff29f1e6b.svg",
                        "isPro": false,
                        "fullname": "Yinfei Yang",
                        "user": "yinfeiy",
                        "type": "user"
                    },
                    "name": "Yinfei Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:12:52.506Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T18:27:06.000Z",
            "title": "STIV: Scalable Text and Image Conditioned Video Generation",
            "summary": "The field of video generation has made remarkable advancements, yet there\nremains a pressing need for a clear, systematic recipe that can guide the\ndevelopment of robust and scalable models. In this work, we present a\ncomprehensive study that systematically explores the interplay of model\narchitectures, training recipes, and data curation strategies, culminating in a\nsimple and scalable text-image-conditioned video generation method, named STIV.\nOur framework integrates image condition into a Diffusion Transformer (DiT)\nthrough frame replacement, while incorporating text conditioning via a joint\nimage-text conditional classifier-free guidance. This design enables STIV to\nperform both text-to-video (T2V) and text-image-to-video (TI2V) tasks\nsimultaneously. Additionally, STIV can be easily extended to various\napplications, such as video prediction, frame interpolation, multi-view\ngeneration, and long video generation, etc. With comprehensive ablation studies\non T2I, T2V, and TI2V, STIV demonstrate strong performance, despite its simple\ndesign. An 8.7B model with 512 resolution achieves 83.1 on VBench T2V,\nsurpassing both leading open and closed-source models like CogVideoX-5B, Pika,\nKling, and Gen-3. The same-sized model also achieves a state-of-the-art result\nof 90.1 on VBench I2V task at 512 resolution. By providing a transparent and\nextensible recipe for building cutting-edge video generation models, we aim to\nempower future research and accelerate progress toward more versatile and\nreliable video generation solutions.",
            "upvotes": 29,
            "discussionId": "67590ae79500a8d4bb970b16"
        },
        "publishedAt": "2024-12-11T01:02:25.688Z",
        "title": "STIV: Scalable Text and Image Conditioned Video Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07730.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "656c2fa772c19de72367bd69",
            "avatarUrl": "/avatars/540bb3d8a2afe2ef927b80d895cae28b.svg",
            "fullname": "Alex Yang",
            "name": "yyf86",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2412.07589",
            "authors": [
                {
                    "_id": "6759025d301d7a7b7ef45ee0",
                    "user": {
                        "_id": "657a6eed1ccc3c2a5ea7b585",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/RIQIF-JJdNI0SwJEq_9z7.jpeg",
                        "isPro": true,
                        "fullname": "Jianzong Wu",
                        "user": "jianzongwu",
                        "type": "user"
                    },
                    "name": "Jianzong Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:12:40.931Z",
                    "hidden": false
                },
                {
                    "_id": "6759025d301d7a7b7ef45ee1",
                    "user": {
                        "_id": "65bce64b8467e2a3d6a450af",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65bce64b8467e2a3d6a450af/ibrJanTW44ZzD_k-HnUEh.png",
                        "isPro": false,
                        "fullname": "Chao Tang",
                        "user": "Tangc03",
                        "type": "user"
                    },
                    "name": "Chao Tang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T13:39:16.104Z",
                    "hidden": false
                },
                {
                    "_id": "6759025d301d7a7b7ef45ee2",
                    "user": {
                        "_id": "665590ac9ccb17d9670addce",
                        "avatarUrl": "/avatars/e13aa166af6c8ed9ee2fbb0add46b8dd.svg",
                        "isPro": false,
                        "fullname": "Jingbo Wang",
                        "user": "JingboWang",
                        "type": "user"
                    },
                    "name": "Jingbo Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:12:10.281Z",
                    "hidden": false
                },
                {
                    "_id": "6759025d301d7a7b7ef45ee3",
                    "user": {
                        "_id": "63d4b843df01ef426a0f79fb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676365795587-63d4b843df01ef426a0f79fb.jpeg",
                        "isPro": false,
                        "fullname": "Yanhong Zeng",
                        "user": "zengyh1900",
                        "type": "user"
                    },
                    "name": "Yanhong Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:11:44.658Z",
                    "hidden": false
                },
                {
                    "_id": "6759025d301d7a7b7ef45ee4",
                    "user": {
                        "_id": "63958b4414513eaf9029ebf1",
                        "avatarUrl": "/avatars/1f5e9b9dfcc16df8e88e3dcecfcb4e10.svg",
                        "isPro": false,
                        "fullname": "Xiangtai Li",
                        "user": "LXT",
                        "type": "user"
                    },
                    "name": "Xiangtai Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:11:39.250Z",
                    "hidden": false
                },
                {
                    "_id": "6759025d301d7a7b7ef45ee5",
                    "name": "Yunhai Tong",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T15:24:12.000Z",
            "title": "DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for\n  Customized Manga Generation",
            "summary": "Story visualization, the task of creating visual narratives from textual\ndescriptions, has seen progress with text-to-image generation models. However,\nthese models often lack effective control over character appearances and\ninteractions, particularly in multi-character scenes. To address these\nlimitations, we propose a new task: customized manga generation and\nintroduce DiffSensei, an innovative framework specifically designed\nfor generating manga with dynamic multi-character control. DiffSensei\nintegrates a diffusion-based image generator with a multimodal large language\nmodel (MLLM) that acts as a text-compatible identity adapter. Our approach\nemploys masked cross-attention to seamlessly incorporate character features,\nenabling precise layout control without direct pixel transfer. Additionally,\nthe MLLM-based adapter adjusts character features to align with panel-specific\ntext cues, allowing flexible adjustments in character expressions, poses, and\nactions. We also introduce MangaZero, a large-scale dataset tailored\nto this task, containing 43,264 manga pages and 427,147 annotated panels,\nsupporting the visualization of varied character interactions and movements\nacross sequential frames. Extensive experiments demonstrate that DiffSensei\noutperforms existing models, marking a significant advancement in manga\ngeneration by enabling text-adaptable character customization. The project page\nis https://jianzongwu.github.io/projects/diffsensei/.",
            "upvotes": 24,
            "discussionId": "67590260301d7a7b7ef45fdc"
        },
        "publishedAt": "2024-12-11T00:53:47.368Z",
        "title": "DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07589.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63958b4414513eaf9029ebf1",
            "avatarUrl": "/avatars/1f5e9b9dfcc16df8e88e3dcecfcb4e10.svg",
            "fullname": "Xiangtai Li",
            "name": "LXT",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 6
        }
    },
    {
        "paper": {
            "id": "2412.04653",
            "authors": [
                {
                    "_id": "67584aed66fd404ad4478569",
                    "user": {
                        "_id": "656a1590801ed9952f407547",
                        "avatarUrl": "/avatars/de90853b933511ab63b4b81fc8d9e1c0.svg",
                        "isPro": false,
                        "fullname": "Kasra Arabi",
                        "user": "kasraarabi",
                        "type": "user"
                    },
                    "name": "Kasra Arabi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-10T15:15:20.150Z",
                    "hidden": false
                },
                {
                    "_id": "67584aed66fd404ad447856a",
                    "user": {
                        "_id": "62f7f4efe7c1c9bf10c81465",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f7f4efe7c1c9bf10c81465/AYlOg0fkP1o4GAP-8Y3xt.jpeg",
                        "isPro": true,
                        "fullname": "Benjamin Feuer",
                        "user": "penfever",
                        "type": "user"
                    },
                    "name": "Benjamin Feuer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:15:18.300Z",
                    "hidden": false
                },
                {
                    "_id": "67584aed66fd404ad447856b",
                    "user": {
                        "_id": "637ff9cb3b36a53c22ed4c86",
                        "avatarUrl": "/avatars/3df0253a1127a5c5664850b0da09af2a.svg",
                        "isPro": false,
                        "fullname": "R. Teal Witter",
                        "user": "rtealwitter",
                        "type": "user"
                    },
                    "name": "R. Teal Witter",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:15:23.537Z",
                    "hidden": false
                },
                {
                    "_id": "67584aed66fd404ad447856c",
                    "user": {
                        "_id": "631620f6894404e25068856f",
                        "avatarUrl": "/avatars/52c30caa0ee11347f82420a14ec19996.svg",
                        "isPro": false,
                        "fullname": "Chinmay Hegde",
                        "user": "chegde",
                        "type": "user"
                    },
                    "name": "Chinmay Hegde",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:15:48.130Z",
                    "hidden": false
                },
                {
                    "_id": "67584aed66fd404ad447856d",
                    "name": "Niv Cohen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-05T22:50:42.000Z",
            "title": "Hidden in the Noise: Two-Stage Robust Watermarking for Images",
            "summary": "As the quality of image generators continues to improve, deepfakes become a\ntopic of considerable societal debate. Image watermarking allows responsible\nmodel owners to detect and label their AI-generated content, which can mitigate\nthe harm. Yet, current state-of-the-art methods in image watermarking remain\nvulnerable to forgery and removal attacks. This vulnerability occurs in part\nbecause watermarks distort the distribution of generated images,\nunintentionally revealing information about the watermarking techniques.\n  In this work, we first demonstrate a distortion-free watermarking method for\nimages, based on a diffusion model's initial noise. However, detecting the\nwatermark requires comparing the initial noise reconstructed for an image to\nall previously used initial noises. To mitigate these issues, we propose a\ntwo-stage watermarking framework for efficient detection. During generation, we\naugment the initial noise with generated Fourier patterns to embed information\nabout the group of initial noises we used. For detection, we (i) retrieve the\nrelevant group of noises, and (ii) search within the given group for an initial\nnoise that might match our image. This watermarking approach achieves\nstate-of-the-art robustness to forgery and removal against a large battery of\nattacks.",
            "upvotes": 19,
            "discussionId": "67584af266fd404ad4478647"
        },
        "publishedAt": "2024-12-10T23:59:33.541Z",
        "title": "Hidden in the Noise: Two-Stage Robust Watermarking for Images",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.04653.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "656a1590801ed9952f407547",
            "avatarUrl": "/avatars/de90853b933511ab63b4b81fc8d9e1c0.svg",
            "fullname": "Kasra Arabi",
            "name": "kasraarabi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.07674",
            "authors": [
                {
                    "_id": "67592cfa672bea990a20b0d1",
                    "user": {
                        "_id": "62fae9328e137d7c4b896498",
                        "avatarUrl": "/avatars/1bda39dec585c099417cc9daa9f53c42.svg",
                        "isPro": false,
                        "fullname": "Tong Wu",
                        "user": "tongwu2020",
                        "type": "user"
                    },
                    "name": "Tong Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:35:37.538Z",
                    "hidden": false
                },
                {
                    "_id": "67592cfa672bea990a20b0d2",
                    "user": {
                        "_id": "6555da9adcf410fd0753569c",
                        "avatarUrl": "/avatars/ac58a796bb54f334fdb475a4b75c4d27.svg",
                        "isPro": false,
                        "fullname": "Yinghao Xu",
                        "user": "justimyhxu",
                        "type": "user"
                    },
                    "name": "Yinghao Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:35:22.282Z",
                    "hidden": false
                },
                {
                    "_id": "67592cfa672bea990a20b0d3",
                    "name": "Ryan Po",
                    "hidden": false
                },
                {
                    "_id": "67592cfa672bea990a20b0d4",
                    "user": {
                        "_id": "64de20c5808492ba6e65d124",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64de20c5808492ba6e65d124/58IX_TI5vJw73qS1knw56.jpeg",
                        "isPro": false,
                        "fullname": "Zhang Mengchen",
                        "user": "Dubhe-zmc",
                        "type": "user"
                    },
                    "name": "Mengchen Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:19:34.086Z",
                    "hidden": false
                },
                {
                    "_id": "67592cfa672bea990a20b0d5",
                    "user": {
                        "_id": "64547ca006728ff79a38e7a5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64547ca006728ff79a38e7a5/xfTVQXMSfRv-IbljFpswQ.jpeg",
                        "isPro": false,
                        "fullname": "Guandao Yang",
                        "user": "guandao",
                        "type": "user"
                    },
                    "name": "Guandao Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:35:11.580Z",
                    "hidden": false
                },
                {
                    "_id": "67592cfa672bea990a20b0d6",
                    "user": {
                        "_id": "64b4eec4faa3181a5eab9c46",
                        "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
                        "isPro": true,
                        "fullname": "Jiaqi Wang",
                        "user": "myownskyW7",
                        "type": "user"
                    },
                    "name": "Jiaqi Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:19:36.146Z",
                    "hidden": false
                },
                {
                    "_id": "67592cfa672bea990a20b0d7",
                    "user": {
                        "_id": "62ab1ac1d48b4d8b048a3473",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
                        "isPro": false,
                        "fullname": "Ziwei Liu",
                        "user": "liuziwei7",
                        "type": "user"
                    },
                    "name": "Ziwei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:34:51.048Z",
                    "hidden": false
                },
                {
                    "_id": "67592cfa672bea990a20b0d8",
                    "user": {
                        "_id": "636317ed80c1a705a6eff396",
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:35:03.851Z",
                    "hidden": false
                },
                {
                    "_id": "67592cfa672bea990a20b0d9",
                    "user": {
                        "_id": "6694e583ac96ca2c17131505",
                        "avatarUrl": "/avatars/6e7a31f257e36cf301da6f879dc0a122.svg",
                        "isPro": false,
                        "fullname": "Gordon Wetzstein",
                        "user": "wetzste1",
                        "type": "user"
                    },
                    "name": "Gordon Wetzstein",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:34:57.689Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T17:02:58.000Z",
            "title": "FiVA: Fine-grained Visual Attribute Dataset for Text-to-Image Diffusion\n  Models",
            "summary": "Recent advances in text-to-image generation have enabled the creation of\nhigh-quality images with diverse applications. However, accurately describing\ndesired visual attributes can be challenging, especially for non-experts in art\nand photography. An intuitive solution involves adopting favorable attributes\nfrom the source images. Current methods attempt to distill identity and style\nfrom source images. However, \"style\" is a broad concept that includes texture,\ncolor, and artistic elements, but does not cover other important attributes\nsuch as lighting and dynamics. Additionally, a simplified \"style\" adaptation\nprevents combining multiple attributes from different sources into one\ngenerated image. In this work, we formulate a more effective approach to\ndecompose the aesthetics of a picture into specific visual attributes, allowing\nusers to apply characteristics such as lighting, texture, and dynamics from\ndifferent images. To achieve this goal, we constructed the first fine-grained\nvisual attributes dataset (FiVA) to the best of our knowledge. This FiVA\ndataset features a well-organized taxonomy for visual attributes and includes\naround 1 M high-quality generated images with visual attribute annotations.\nLeveraging this dataset, we propose a fine-grained visual attribute adaptation\nframework (FiVA-Adapter), which decouples and adapts visual attributes from one\nor more source images into a generated one. This approach enhances\nuser-friendly customization, allowing users to selectively apply desired\nattributes to create images that meet their unique preferences and specific\ncontent requirements.",
            "upvotes": 16,
            "discussionId": "67592cfd672bea990a20b1db"
        },
        "publishedAt": "2024-12-11T01:14:33.497Z",
        "title": "FiVA: Fine-grained Visual Attribute Dataset for Text-to-Image Diffusion Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64b4eec4faa3181a5eab9c46/4DpoeOvFdjgBOQXjM9Aqk.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07674.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "64b4eec4faa3181a5eab9c46",
            "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
            "fullname": "Jiaqi Wang",
            "name": "myownskyW7",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 9
        }
    },
    {
        "paper": {
            "id": "2412.07759",
            "authors": [
                {
                    "_id": "675962a407803203aef900ec",
                    "user": {
                        "_id": "63aef2cafcca84593e6682db",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672409763337-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Xiao Fu",
                        "user": "lemonaddie",
                        "type": "user"
                    },
                    "name": "Xiao Fu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T10:09:04.015Z",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900ed",
                    "name": "Xian Liu",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900ee",
                    "user": {
                        "_id": "60e272ca6c78a8c122b12127",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg",
                        "isPro": false,
                        "fullname": "Xintao Wang",
                        "user": "Xintao",
                        "type": "user"
                    },
                    "name": "Xintao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:21:32.060Z",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900ef",
                    "user": {
                        "_id": "62986ca2b58e71e2ac9b8f01",
                        "avatarUrl": "/avatars/83944db5f3dbb6f47c47c46fb2cb2849.svg",
                        "isPro": false,
                        "fullname": "Sida Peng",
                        "user": "pengsida",
                        "type": "user"
                    },
                    "name": "Sida Peng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:21:24.280Z",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900f0",
                    "user": {
                        "_id": "63401c89f81b9d101361f712",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1665146415483-63401c89f81b9d101361f712.png",
                        "isPro": false,
                        "fullname": "Richard",
                        "user": "menghanxia",
                        "type": "user"
                    },
                    "name": "Menghan Xia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:20:48.288Z",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900f1",
                    "user": {
                        "_id": "641af5fcf902cc42730b47e2",
                        "avatarUrl": "/avatars/73ac99dec226f0e814a16d2f1dbfbce8.svg",
                        "isPro": false,
                        "fullname": "Xiaoyu Shi",
                        "user": "btwbtm",
                        "type": "user"
                    },
                    "name": "Xiaoyu Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:21:17.084Z",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900f2",
                    "user": {
                        "_id": "66c15837b186e4f6a0dac80c",
                        "avatarUrl": "/avatars/a3b75d6945f1608e64a2fcff887a5024.svg",
                        "isPro": false,
                        "fullname": "Ziyang Yuan",
                        "user": "ziyangy",
                        "type": "user"
                    },
                    "name": "Ziyang Yuan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:20:31.083Z",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900f3",
                    "name": "Pengfei Wan",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900f4",
                    "user": {
                        "_id": "64bce15bafd1e46c5504ad38",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64bce15bafd1e46c5504ad38/bQFX1iFbXEBXcQvUNL811.png",
                        "isPro": false,
                        "fullname": "Di Zhang",
                        "user": "qq8933",
                        "type": "user"
                    },
                    "name": "Di Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:20:13.824Z",
                    "hidden": false
                },
                {
                    "_id": "675962a407803203aef900f5",
                    "user": {
                        "_id": "636317ed80c1a705a6eff396",
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:19:40.425Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T18:55:13.000Z",
            "title": "3DTrajMaster: Mastering 3D Trajectory for Multi-Entity Motion in Video\n  Generation",
            "summary": "This paper aims to manipulate multi-entity 3D motions in video generation.\nPrevious methods on controllable video generation primarily leverage 2D control\nsignals to manipulate object motions and have achieved remarkable synthesis\nresults. However, 2D control signals are inherently limited in expressing the\n3D nature of object motions. To overcome this problem, we introduce\n3DTrajMaster, a robust controller that regulates multi-entity dynamics in 3D\nspace, given user-desired 6DoF pose (location and rotation) sequences of\nentities. At the core of our approach is a plug-and-play 3D-motion grounded\nobject injector that fuses multiple input entities with their respective 3D\ntrajectories through a gated self-attention mechanism. In addition, we exploit\nan injector architecture to preserve the video diffusion prior, which is\ncrucial for generalization ability. To mitigate video quality degradation, we\nintroduce a domain adaptor during training and employ an annealed sampling\nstrategy during inference. To address the lack of suitable training data, we\nconstruct a 360-Motion Dataset, which first correlates collected 3D human and\nanimal assets with GPT-generated trajectory and then captures their motion with\n12 evenly-surround cameras on diverse 3D UE platforms. Extensive experiments\nshow that 3DTrajMaster sets a new state-of-the-art in both accuracy and\ngeneralization for controlling multi-entity 3D motions. Project page:\nhttp://fuxiao0719.github.io/projects/3dtrajmaster",
            "upvotes": 15,
            "discussionId": "675962ab07803203aef9035e"
        },
        "publishedAt": "2024-12-11T05:00:32.930Z",
        "title": "3DTrajMaster: Mastering 3D Trajectory for Multi-Entity Motion in Video Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07759.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63aef2cafcca84593e6682db",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672409763337-noauth.jpeg",
            "fullname": "Xiao Fu",
            "name": "lemonaddie",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 10
        }
    },
    {
        "paper": {
            "id": "2412.07774",
            "authors": [
                {
                    "_id": "675904147ab15d62b77e40e0",
                    "user": {
                        "_id": "644a1b6401e18bf93a6f45c1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644a1b6401e18bf93a6f45c1/P0i_CgCrIzOS2tYRlxoE9.png",
                        "isPro": false,
                        "fullname": "xichen",
                        "user": "xichenhku",
                        "type": "user"
                    },
                    "name": "Xi Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:19:38.341Z",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e1",
                    "name": "Zhifei Zhang",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e2",
                    "name": "He Zhang",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e3",
                    "name": "Yuqian Zhou",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e4",
                    "name": "Soo Ye Kim",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e5",
                    "name": "Qing Liu",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e6",
                    "name": "Yijun Li",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e7",
                    "user": {
                        "_id": "632d52047bad38a82f75daee",
                        "avatarUrl": "/avatars/56cc9b5dea95408a83cb80ee8c5565bf.svg",
                        "isPro": false,
                        "fullname": "Jianming Zhang",
                        "user": "jimmie33",
                        "type": "user"
                    },
                    "name": "Jianming Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:21:15.636Z",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e8",
                    "name": "Nanxuan Zhao",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40e9",
                    "name": "Yilin Wang",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40ea",
                    "name": "Hui Ding",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40eb",
                    "name": "Zhe Lin",
                    "hidden": false
                },
                {
                    "_id": "675904147ab15d62b77e40ec",
                    "name": "Hengshuang Zhao",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T18:59:55.000Z",
            "title": "UniReal: Universal Image Generation and Editing via Learning Real-world\n  Dynamics",
            "summary": "We introduce UniReal, a unified framework designed to address various image\ngeneration and editing tasks. Existing solutions often vary by tasks, yet share\nfundamental principles: preserving consistency between inputs and outputs while\ncapturing visual variations. Inspired by recent video generation models that\neffectively balance consistency and variation across frames, we propose a\nunifying approach that treats image-level tasks as discontinuous video\ngeneration. Specifically, we treat varying numbers of input and output images\nas frames, enabling seamless support for tasks such as image generation,\nediting, customization, composition, etc. Although designed for image-level\ntasks, we leverage videos as a scalable source for universal supervision.\nUniReal learns world dynamics from large-scale videos, demonstrating advanced\ncapability in handling shadows, reflections, pose variation, and object\ninteraction, while also exhibiting emergent capability for novel applications.",
            "upvotes": 15,
            "discussionId": "675904167ab15d62b77e4158"
        },
        "publishedAt": "2024-12-10T22:18:30.068Z",
        "title": "UniReal: Universal Image Generation and Editing via Learning Real-world Dynamics",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07774.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "644a1b6401e18bf93a6f45c1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644a1b6401e18bf93a6f45c1/P0i_CgCrIzOS2tYRlxoE9.png",
            "fullname": "xichen",
            "name": "xichenhku",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 39
        }
    },
    {
        "paper": {
            "id": "2412.07626",
            "authors": [
                {
                    "_id": "6758f2c55cd36ca4c1a4539b",
                    "user": {
                        "_id": "66753c556f2ac48ee625d7d1",
                        "avatarUrl": "/avatars/8f7c252675fd8a096794d12971903722.svg",
                        "isPro": false,
                        "fullname": "Linke Ouyang",
                        "user": "ouyanglinke",
                        "type": "user"
                    },
                    "name": "Linke Ouyang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:20:06.000Z",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a4539c",
                    "name": "Yuan Qu",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a4539d",
                    "name": "Hongbin Zhou",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a4539e",
                    "name": "Jiawei Zhu",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a4539f",
                    "name": "Rui Zhang",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a0",
                    "name": "Qunshu Lin",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a1",
                    "user": {
                        "_id": "63ae9ff5557befe297a76f90",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672388558183-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Bin Wang",
                        "user": "wanderkid",
                        "type": "user"
                    },
                    "name": "Bin Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:20:11.073Z",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a2",
                    "name": "Zhiyuan Zhao",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a3",
                    "name": "Man Jiang",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a4",
                    "name": "Xiaomeng Zhao",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a5",
                    "name": "Jin Shi",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a6",
                    "name": "Fan Wu",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a7",
                    "name": "Pei Chu",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a8",
                    "user": {
                        "_id": "6417d9ea8f689506e7148417",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6417d9ea8f689506e7148417/bAYcruWNw4WvmuQcGgcwC.jpeg",
                        "isPro": false,
                        "fullname": "minghao",
                        "user": "Liam-Liu",
                        "type": "user"
                    },
                    "name": "Minghao Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:20:08.296Z",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453a9",
                    "name": "Zhenxiang Li",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453aa",
                    "name": "Chao Xu",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453ab",
                    "name": "Bo Zhang",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453ac",
                    "user": {
                        "_id": "643df87f7cd64d872cb9fabd",
                        "avatarUrl": "/avatars/c53bfabcee08de448dde973915e8b31d.svg",
                        "isPro": false,
                        "fullname": "Botian Shi",
                        "user": "friskit",
                        "type": "user"
                    },
                    "name": "Botian Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:17:19.807Z",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453ad",
                    "name": "Zhongying Tu",
                    "hidden": false
                },
                {
                    "_id": "6758f2c55cd36ca4c1a453ae",
                    "user": {
                        "_id": "63f9fca8d4349b157a109eec",
                        "avatarUrl": "/avatars/fa1f2ae7972d7cde99dab178136ccbb0.svg",
                        "isPro": false,
                        "fullname": "Conghui He",
                        "user": "conghui",
                        "type": "user"
                    },
                    "name": "Conghui He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:17:05.536Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T16:05:56.000Z",
            "title": "OmniDocBench: Benchmarking Diverse PDF Document Parsing with\n  Comprehensive Annotations",
            "summary": "Document content extraction is crucial in computer vision, especially for\nmeeting the high-quality data needs of large language models (LLMs) and\nretrieval-augmented generation (RAG) technologies. However, current document\nparsing methods suffer from significant limitations in terms of diversity and\ncomprehensive evaluation. To address these challenges, we introduce\nOmniDocBench, a novel multi-source benchmark designed to advance automated\ndocument content extraction. OmniDocBench includes a meticulously curated and\nannotated high-quality evaluation dataset comprising nine diverse document\ntypes, such as academic papers, textbooks, slides, among others. Our benchmark\nprovides a flexible and comprehensive evaluation framework with 19 layout\ncategory labels and 14 attribute labels, enabling multi-level assessments\nacross entire datasets, individual modules, or specific data types. Using\nOmniDocBench, we perform an exhaustive comparative analysis of existing modular\npipelines and multimodal end-to-end methods, highlighting their limitations in\nhandling document diversity and ensuring fair evaluation. OmniDocBench\nestablishes a robust, diverse, and fair evaluation standard for the document\ncontent extraction field, offering crucial insights for future advancements and\nfostering the development of document parsing technologies. The codes and\ndataset is available in https://github.com/opendatalab/OmniDocBench.",
            "upvotes": 14,
            "discussionId": "6758f2c85cd36ca4c1a4547f"
        },
        "publishedAt": "2024-12-11T05:13:21.539Z",
        "title": "OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07626.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63ae9ff5557befe297a76f90",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672388558183-noauth.jpeg",
            "fullname": "Bin Wang",
            "name": "wanderkid",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 15
        }
    },
    {
        "paper": {
            "id": "2412.07724",
            "authors": [
                {
                    "_id": "675903756f804e05e3cf41d6",
                    "name": "Inkit Padhi",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41d7",
                    "user": {
                        "_id": "659ed39fd75c46188d7496ff",
                        "avatarUrl": "/avatars/665e4dd171f7e8c1c483cdeb02b71744.svg",
                        "isPro": false,
                        "fullname": "Manish Nagireddy",
                        "user": "mnagired",
                        "type": "user"
                    },
                    "name": "Manish Nagireddy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:39:39.816Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41d8",
                    "user": {
                        "_id": "65da497841325e422edc56e9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65da497841325e422edc56e9/yC3C3NUEQ76uqjQCk5KpY.jpeg",
                        "isPro": false,
                        "fullname": "Giandomenico Cornacchia",
                        "user": "Giandomenico",
                        "type": "user"
                    },
                    "name": "Giandomenico Cornacchia",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:19:55.714Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41d9",
                    "user": {
                        "_id": "63536559a023833e59da3458",
                        "avatarUrl": "/avatars/bcf1c4193f75bb464998a02403f1eb91.svg",
                        "isPro": false,
                        "fullname": "Subhajit Chaudhury",
                        "user": "cosmik1412",
                        "type": "user"
                    },
                    "name": "Subhajit Chaudhury",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:45:46.974Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41da",
                    "user": {
                        "_id": "663272af2a4742700eb9fc4e",
                        "avatarUrl": "/avatars/aaa988209a7a7b1607885247da399a9a.svg",
                        "isPro": false,
                        "fullname": "Tejaswini Pedapati",
                        "user": "tejaswinipedapati",
                        "type": "user"
                    },
                    "name": "Tejaswini Pedapati",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:45:41.001Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41db",
                    "user": {
                        "_id": "662a91eab771c8c6639f17d3",
                        "avatarUrl": "/avatars/815255e6cb81477247a8caca000e8800.svg",
                        "isPro": false,
                        "fullname": "Pierre Dognin",
                        "user": "pdognin",
                        "type": "user"
                    },
                    "name": "Pierre Dognin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:45:34.350Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41dc",
                    "name": "Keerthiram Murugesan",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41dd",
                    "user": {
                        "_id": "648de26451ab9e87e19d1eb7",
                        "avatarUrl": "/avatars/944046a729790c4f2661c4f6dae203d9.svg",
                        "isPro": true,
                        "fullname": "Erik Miehling",
                        "user": "erikjm",
                        "type": "user"
                    },
                    "name": "Erik Miehling",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:45:22.912Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41de",
                    "user": {
                        "_id": "631f80ffa6bd81a35968ccaa",
                        "avatarUrl": "/avatars/7f084fca19cf0794402dcc9ab365399b.svg",
                        "isPro": false,
                        "fullname": "Martín Santillán Cooper",
                        "user": "marsancoo",
                        "type": "user"
                    },
                    "name": "Martín Santillán Cooper",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:45:16.548Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41df",
                    "user": {
                        "_id": "65732419412ee7018583b24a",
                        "avatarUrl": "/avatars/cb13fcc2bcb76a7c01f41e5b0f3e2720.svg",
                        "isPro": false,
                        "fullname": "Kieran Fraser",
                        "user": "kieranfraser",
                        "type": "user"
                    },
                    "name": "Kieran Fraser",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:45:08.457Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e0",
                    "user": {
                        "_id": "669f96268925c9b04aabffad",
                        "avatarUrl": "/avatars/9eaac43f68f9f42f5dda791b5432486b.svg",
                        "isPro": false,
                        "fullname": "Giulio Zizzo",
                        "user": "GiulioZizzo",
                        "type": "user"
                    },
                    "name": "Giulio Zizzo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:44:50.304Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e1",
                    "user": {
                        "_id": "65dde3c28e13d0de4560f1df",
                        "avatarUrl": "/avatars/45fe78c2dfc295fdac90fc51892ddb13.svg",
                        "isPro": false,
                        "fullname": "Muhammad Zaid Hameed",
                        "user": "zaidhameed",
                        "type": "user"
                    },
                    "name": "Muhammad Zaid Hameed",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:43:49.432Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e2",
                    "user": {
                        "_id": "638978be5a3d2a335628d877",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669953557068-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Mark Purcell",
                        "user": "Allirog",
                        "type": "user"
                    },
                    "name": "Mark Purcell",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:43:42.820Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e3",
                    "user": {
                        "_id": "648b46a0be27fd317ddc0da9",
                        "avatarUrl": "/avatars/41ffd8579f6fd5d75c8124ef2113bfb9.svg",
                        "isPro": false,
                        "fullname": "Michael Desmond",
                        "user": "michaeldesmond",
                        "type": "user"
                    },
                    "name": "Michael Desmond",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:43:36.659Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e4",
                    "user": {
                        "_id": "673a5e12524a5d153f2598e2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/27C8WYYFJPP1vEebirz4B.png",
                        "isPro": false,
                        "fullname": "Qian Pan",
                        "user": "qpan5",
                        "type": "user"
                    },
                    "name": "Qian Pan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:43:24.581Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e5",
                    "name": "Inge Vejsbjerg",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e6",
                    "user": {
                        "_id": "65b9220465ca49fc97275371",
                        "avatarUrl": "/avatars/659dff4a9feabfd4eaacf6956a6ebb36.svg",
                        "isPro": false,
                        "fullname": "Elizabeth Daly",
                        "user": "cimbrone",
                        "type": "user"
                    },
                    "name": "Elizabeth M. Daly",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:43:02.426Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e7",
                    "user": {
                        "_id": "65fa028d3cf67ad371c6852f",
                        "avatarUrl": "/avatars/383f510f131af741d014e1737b600efb.svg",
                        "isPro": false,
                        "fullname": "Michael Hind",
                        "user": "mikehind",
                        "type": "user"
                    },
                    "name": "Michael Hind",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:40:49.497Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e8",
                    "name": "Werner Geyer",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41e9",
                    "user": {
                        "_id": "65daa88d1ed8dc6d8235fdc4",
                        "avatarUrl": "/avatars/bc42dec63d8a54f092bf4b11eed17cc4.svg",
                        "isPro": false,
                        "fullname": "Ambrish Rawat",
                        "user": "ambrishrawat",
                        "type": "user"
                    },
                    "name": "Ambrish Rawat",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:40:24.628Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41ea",
                    "user": {
                        "_id": "66c34c2ca474a917fca71a8a",
                        "avatarUrl": "/avatars/7f0a09403d812812fcfc7795fcd116c3.svg",
                        "isPro": false,
                        "fullname": "Kush Varshney",
                        "user": "krvarshney",
                        "type": "user"
                    },
                    "name": "Kush R. Varshney",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:40:17.867Z",
                    "hidden": false
                },
                {
                    "_id": "675903756f804e05e3cf41eb",
                    "user": {
                        "_id": "63068ec0df993a789e69644b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63068ec0df993a789e69644b/hR4Qs1KFMpF7sW6VzXYH1.png",
                        "isPro": false,
                        "fullname": "Prasanna Sattigeri",
                        "user": "pronics2004",
                        "type": "user"
                    },
                    "name": "Prasanna Sattigeri",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:39:33.098Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T18:17:02.000Z",
            "title": "Granite Guardian",
            "summary": "We introduce the Granite Guardian models, a suite of safeguards designed to\nprovide risk detection for prompts and responses, enabling safe and responsible\nuse in combination with any large language model (LLM). These models offer\ncomprehensive coverage across multiple risk dimensions, including social bias,\nprofanity, violence, sexual content, unethical behavior, jailbreaking, and\nhallucination-related risks such as context relevance, groundedness, and answer\nrelevance for retrieval-augmented generation (RAG). Trained on a unique dataset\ncombining human annotations from diverse sources and synthetic data, Granite\nGuardian models address risks typically overlooked by traditional risk\ndetection models, such as jailbreaks and RAG-specific issues. With AUC scores\nof 0.871 and 0.854 on harmful content and RAG-hallucination-related benchmarks\nrespectively, Granite Guardian is the most generalizable and competitive model\navailable in the space. Released as open-source, Granite Guardian aims to\npromote responsible AI development across the community.\n  https://github.com/ibm-granite/granite-guardian",
            "upvotes": 13,
            "discussionId": "675903766f804e05e3cf4232"
        },
        "publishedAt": "2024-12-10T22:14:10.175Z",
        "title": "Granite Guardian",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07724.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5352
        }
    },
    {
        "paper": {
            "id": "2412.07583",
            "authors": [
                {
                    "_id": "67598660eff1d97bd2cf2b7b",
                    "user": {
                        "_id": "67598719eff1d97bd2cf6300",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/GoxSruke3IDDZP-vSyqyq.png",
                        "isPro": false,
                        "fullname": "Haitam Ben Yahia/",
                        "user": "haitamb",
                        "type": "user"
                    },
                    "name": "Haitam Ben Yahia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:57:42.350Z",
                    "hidden": false
                },
                {
                    "_id": "67598660eff1d97bd2cf2b7c",
                    "name": "Denis Korzhenkov",
                    "hidden": false
                },
                {
                    "_id": "67598660eff1d97bd2cf2b7d",
                    "name": "Ioannis Lelekas",
                    "hidden": false
                },
                {
                    "_id": "67598660eff1d97bd2cf2b7e",
                    "user": {
                        "_id": "65d31d1bfe21569868432e96",
                        "avatarUrl": "/avatars/195207d241f4eab121e4fed6cf5d578d.svg",
                        "isPro": false,
                        "fullname": "Amir",
                        "user": "aghodrati",
                        "type": "user"
                    },
                    "name": "Amir Ghodrati",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T13:39:02.200Z",
                    "hidden": false
                },
                {
                    "_id": "67598660eff1d97bd2cf2b7f",
                    "user": {
                        "_id": "628372aa09aa80237c6d2044",
                        "avatarUrl": "/avatars/c1e34dee217d73f5539a0807adc12c80.svg",
                        "isPro": false,
                        "fullname": "Amir Habibian",
                        "user": "habibian",
                        "type": "user"
                    },
                    "name": "Amirhossein Habibian",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T13:39:04.250Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T15:19:10.000Z",
            "title": "Mobile Video Diffusion",
            "summary": "Video diffusion models have achieved impressive realism and controllability\nbut are limited by high computational demands, restricting their use on mobile\ndevices. This paper introduces the first mobile-optimized video diffusion\nmodel. Starting from a spatio-temporal UNet from Stable Video Diffusion (SVD),\nwe reduce memory and computational cost by reducing the frame resolution,\nincorporating multi-scale temporal representations, and introducing two novel\npruning schema to reduce the number of channels and temporal blocks.\nFurthermore, we employ adversarial finetuning to reduce the denoising to a\nsingle step. Our model, coined as MobileVD, is 523x more efficient (1817.2 vs.\n4.34 TFLOPs) with a slight quality drop (FVD 149 vs. 171), generating latents\nfor a 14x512x256 px clip in 1.7 seconds on a Xiaomi-14 Pro. Our results are\navailable at https://qualcomm-ai-research.github.io/mobile-video-diffusion/",
            "upvotes": 12,
            "discussionId": "67598663eff1d97bd2cf2c8f"
        },
        "publishedAt": "2024-12-11T07:33:14.963Z",
        "title": "Mobile Video Diffusion",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07583.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "628372aa09aa80237c6d2044",
            "avatarUrl": "/avatars/c1e34dee217d73f5539a0807adc12c80.svg",
            "fullname": "Amir Habibian",
            "name": "habibian",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2412.07776",
            "authors": [
                {
                    "_id": "67592b708ac3b988434f8261",
                    "user": {
                        "_id": "63544cacb8aa3b0b3ebd9800",
                        "avatarUrl": "/avatars/7868b79742de27074376d5698e281003.svg",
                        "isPro": false,
                        "fullname": "Alexander Pondaven",
                        "user": "alexpondaven",
                        "type": "user"
                    },
                    "name": "Alexander Pondaven",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:19:44.410Z",
                    "hidden": false
                },
                {
                    "_id": "67592b708ac3b988434f8262",
                    "user": {
                        "_id": "64276311eb9a0ed86180715b",
                        "avatarUrl": "/avatars/76f933cd549f10e5e2db379de235d304.svg",
                        "isPro": false,
                        "fullname": "Aliaksandr Siarohin",
                        "user": "aliaksandr-siarohin",
                        "type": "user"
                    },
                    "name": "Aliaksandr Siarohin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:35:51.963Z",
                    "hidden": false
                },
                {
                    "_id": "67592b708ac3b988434f8263",
                    "name": "Sergey Tulyakov",
                    "hidden": false
                },
                {
                    "_id": "67592b708ac3b988434f8264",
                    "user": {
                        "_id": "6565ed28a5ec0231cb07225f",
                        "avatarUrl": "/avatars/7f95bba9aa7811d56eecb380827abfac.svg",
                        "isPro": false,
                        "fullname": "prof philip torr",
                        "user": "philiptorr",
                        "type": "user"
                    },
                    "name": "Philip Torr",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:36:23.031Z",
                    "hidden": false
                },
                {
                    "_id": "67592b708ac3b988434f8265",
                    "user": {
                        "_id": "62bdcba92dd4214c0622ea30",
                        "avatarUrl": "/avatars/b62d86d01597473e05f9991ec04baf57.svg",
                        "isPro": false,
                        "fullname": "Fabio Pizzati",
                        "user": "fabvio",
                        "type": "user"
                    },
                    "name": "Fabio Pizzati",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:36:52.234Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T18:59:58.000Z",
            "title": "Video Motion Transfer with Diffusion Transformers",
            "summary": "We propose DiTFlow, a method for transferring the motion of a reference video\nto a newly synthesized one, designed specifically for Diffusion Transformers\n(DiT). We first process the reference video with a pre-trained DiT to analyze\ncross-frame attention maps and extract a patch-wise motion signal called the\nAttention Motion Flow (AMF). We guide the latent denoising process in an\noptimization-based, training-free, manner by optimizing latents with our AMF\nloss to generate videos reproducing the motion of the reference one. We also\napply our optimization strategy to transformer positional embeddings, granting\nus a boost in zero-shot motion transfer capabilities. We evaluate DiTFlow\nagainst recently published methods, outperforming all across multiple metrics\nand human evaluation.",
            "upvotes": 12,
            "discussionId": "67592b778ac3b988434f8479"
        },
        "publishedAt": "2024-12-11T01:58:11.725Z",
        "title": "Video Motion Transfer with Diffusion Transformers",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07776.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "634cfebc350bcee9bed20a4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/634cfebc350bcee9bed20a4d/fN47nN5rhw-HJaFLBZWQy.png",
            "fullname": "Xingyi Yang",
            "name": "adamdad",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 11
        }
    },
    {
        "paper": {
            "id": "2412.06578",
            "authors": [
                {
                    "_id": "675985c7b51431a566ca75f9",
                    "user": {
                        "_id": "6759879b2f34dfa21f6789e8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/CvoocygVY6KfegcQPpW0t.png",
                        "isPro": false,
                        "fullname": "Adil Karjauv",
                        "user": "mikolez",
                        "type": "user"
                    },
                    "name": "Adil Karjauv",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:50:31.797Z",
                    "hidden": false
                },
                {
                    "_id": "675985c7b51431a566ca75fa",
                    "user": {
                        "_id": "64f066ac479ac4e6146908c1",
                        "avatarUrl": "/avatars/4dbd00c724039230334abb023f4b41a9.svg",
                        "isPro": false,
                        "fullname": "Noor Fathima",
                        "user": "Noor000",
                        "type": "user"
                    },
                    "name": "Noor Fathima",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:50:37.583Z",
                    "hidden": false
                },
                {
                    "_id": "675985c7b51431a566ca75fb",
                    "name": "Ioannis Lelekas",
                    "hidden": false
                },
                {
                    "_id": "675985c7b51431a566ca75fc",
                    "name": "Fatih Porikli",
                    "hidden": false
                },
                {
                    "_id": "675985c7b51431a566ca75fd",
                    "user": {
                        "_id": "65d31d1bfe21569868432e96",
                        "avatarUrl": "/avatars/195207d241f4eab121e4fed6cf5d578d.svg",
                        "isPro": false,
                        "fullname": "Amir",
                        "user": "aghodrati",
                        "type": "user"
                    },
                    "name": "Amir Ghodrati",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T13:39:05.718Z",
                    "hidden": false
                },
                {
                    "_id": "675985c7b51431a566ca75fe",
                    "user": {
                        "_id": "628372aa09aa80237c6d2044",
                        "avatarUrl": "/avatars/c1e34dee217d73f5539a0807adc12c80.svg",
                        "isPro": false,
                        "fullname": "Amir Habibian",
                        "user": "habibian",
                        "type": "user"
                    },
                    "name": "Amirhossein Habibian",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T13:39:07.789Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-09T15:30:09.000Z",
            "title": "MoViE: Mobile Diffusion for Video Editing",
            "summary": "Recent progress in diffusion-based video editing has shown remarkable\npotential for practical applications. However, these methods remain\nprohibitively expensive and challenging to deploy on mobile devices. In this\nstudy, we introduce a series of optimizations that render mobile video editing\nfeasible. Building upon the existing image editing model, we first optimize its\narchitecture and incorporate a lightweight autoencoder. Subsequently, we extend\nclassifier-free guidance distillation to multiple modalities, resulting in a\nthreefold on-device speedup. Finally, we reduce the number of sampling steps to\none by introducing a novel adversarial distillation scheme which preserves the\ncontrollability of the editing process. Collectively, these optimizations\nenable video editing at 12 frames per second on mobile devices, while\nmaintaining high quality. Our results are available at\nhttps://qualcomm-ai-research.github.io/mobile-video-editing/",
            "upvotes": 11,
            "discussionId": "675985c9b51431a566ca7660"
        },
        "publishedAt": "2024-12-11T07:30:52.450Z",
        "title": "MoViE: Mobile Diffusion for Video Editing",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.06578.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "628372aa09aa80237c6d2044",
            "avatarUrl": "/avatars/c1e34dee217d73f5539a0807adc12c80.svg",
            "fullname": "Amir Habibian",
            "name": "habibian",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2412.07334",
            "authors": [
                {
                    "_id": "675901290af2c04c55dea9e2",
                    "user": {
                        "_id": "658e9a59a02954c982dda930",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/lUtXFdHAJE6wE0t5miyeP.png",
                        "isPro": false,
                        "fullname": "Pedro H. V. Valois",
                        "user": "pvalois",
                        "type": "user"
                    },
                    "name": "Pedro H. V. Valois",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:22:25.202Z",
                    "hidden": false
                },
                {
                    "_id": "675901290af2c04c55dea9e3",
                    "name": "Lincon S. Souza",
                    "hidden": false
                },
                {
                    "_id": "675901290af2c04c55dea9e4",
                    "name": "Erica K. Shimomoto",
                    "hidden": false
                },
                {
                    "_id": "675901290af2c04c55dea9e5",
                    "name": "Kazuhiro Fukui",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T09:25:39.000Z",
            "title": "Frame Representation Hypothesis: Multi-Token LLM Interpretability and\n  Concept-Guided Text Generation",
            "summary": "Interpretability is a key challenge in fostering trust for Large Language\nModels (LLMs), which stems from the complexity of extracting reasoning from\nmodel's parameters. We present the Frame Representation Hypothesis, a\ntheoretically robust framework grounded in the Linear Representation Hypothesis\n(LRH) to interpret and control LLMs by modeling multi-token words. Prior\nresearch explored LRH to connect LLM representations with linguistic concepts,\nbut was limited to single token analysis. As most words are composed of several\ntokens, we extend LRH to multi-token words, thereby enabling usage on any\ntextual data with thousands of concepts. To this end, we propose words can be\ninterpreted as frames, ordered sequences of vectors that better capture\ntoken-word relationships. Then, concepts can be represented as the average of\nword frames sharing a common concept. We showcase these tools through Top-k\nConcept-Guided Decoding, which can intuitively steer text generation using\nconcepts of choice. We verify said ideas on Llama 3.1, Gemma 2, and Phi 3\nfamilies, demonstrating gender and language biases, exposing harmful content,\nbut also potential to remediate them, leading to safer and more transparent\nLLMs. Code is available at\nhttps://github.com/phvv-me/frame-representation-hypothesis.git",
            "upvotes": 11,
            "discussionId": "6759012b0af2c04c55deaa71"
        },
        "publishedAt": "2024-12-11T02:23:20.327Z",
        "title": "Frame Representation Hypothesis: Multi-Token LLM Interpretability and Concept-Guided Text Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07334.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "658e9a59a02954c982dda930",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/lUtXFdHAJE6wE0t5miyeP.png",
            "fullname": "Pedro H. V. Valois",
            "name": "pvalois",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2412.03548",
            "authors": [
                {
                    "_id": "675880b250e4b1a8f1f54e78",
                    "user": {
                        "_id": "636d316effbe479c979692e8",
                        "avatarUrl": "/avatars/f1004a8d788c3ee94f2cfd1abf314485.svg",
                        "isPro": false,
                        "fullname": "Mahtab Bigverdi",
                        "user": "Mahtab",
                        "type": "user"
                    },
                    "name": "Mahtab Bigverdi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:37:32.728Z",
                    "hidden": false
                },
                {
                    "_id": "675880b250e4b1a8f1f54e79",
                    "name": "Zelun Luo",
                    "hidden": false
                },
                {
                    "_id": "675880b250e4b1a8f1f54e7a",
                    "user": {
                        "_id": "6408e8663461c51cf73480e4",
                        "avatarUrl": "/avatars/7e4cbdb4b933181c673c9dc9ad041767.svg",
                        "isPro": false,
                        "fullname": "Cheng-Yu Hsieh",
                        "user": "cydhsieh01",
                        "type": "user"
                    },
                    "name": "Cheng-Yu Hsieh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:38:32.254Z",
                    "hidden": false
                },
                {
                    "_id": "675880b250e4b1a8f1f54e7b",
                    "user": {
                        "_id": "65f7ee498fb2b15357cd6286",
                        "avatarUrl": "/avatars/a060fdd27b6a23346a8772d49df39018.svg",
                        "isPro": false,
                        "fullname": "shen",
                        "user": "Ethanshen",
                        "type": "user"
                    },
                    "name": "Ethan Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:38:09.784Z",
                    "hidden": false
                },
                {
                    "_id": "675880b250e4b1a8f1f54e7c",
                    "user": {
                        "_id": "65e2be1e630e2db23829ee8d",
                        "avatarUrl": "/avatars/294f9ba909037f03669dc0bb80cabfe3.svg",
                        "isPro": false,
                        "fullname": "Dongping Chen",
                        "user": "fjchendp",
                        "type": "user"
                    },
                    "name": "Dongping Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:37:53.324Z",
                    "hidden": false
                },
                {
                    "_id": "675880b250e4b1a8f1f54e7d",
                    "user": {
                        "_id": "64f5fffec368198fe66befaa",
                        "avatarUrl": "/avatars/19169267bfbf93b670e725edccc5366a.svg",
                        "isPro": false,
                        "fullname": "Linda Shapiro",
                        "user": "Linshap",
                        "type": "user"
                    },
                    "name": "Linda G. Shapiro",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:37:44.571Z",
                    "hidden": false
                },
                {
                    "_id": "675880b250e4b1a8f1f54e7e",
                    "user": {
                        "_id": "66429868ab89e3a3a85668b0",
                        "avatarUrl": "/avatars/170e0daa454838deee2bf946f7118651.svg",
                        "isPro": false,
                        "fullname": "Ranjay Krishna",
                        "user": "ranjaykrishna",
                        "type": "user"
                    },
                    "name": "Ranjay Krishna",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:37:18.312Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-04T18:45:35.000Z",
            "title": "Perception Tokens Enhance Visual Reasoning in Multimodal Language Models",
            "summary": "Multimodal language models (MLMs) still face challenges in fundamental visual\nperception tasks where specialized models excel. Tasks requiring reasoning\nabout 3D structures benefit from depth estimation, and reasoning about 2D\nobject instances benefits from object detection. Yet, MLMs can not produce\nintermediate depth or boxes to reason over. Finetuning MLMs on relevant data\ndoesn't generalize well and outsourcing computation to specialized vision tools\nis too compute-intensive and memory-inefficient. To address this, we introduce\nPerception Tokens, intrinsic image representations designed to assist reasoning\ntasks where language is insufficient. Perception tokens act as auxiliary\nreasoning tokens, akin to chain-of-thought prompts in language models. For\nexample, in a depth-related task, an MLM augmented with perception tokens can\nreason by generating a depth map as tokens, enabling it to solve the problem\neffectively. We propose AURORA, a training method that augments MLMs with\nperception tokens for improved reasoning over visual inputs. AURORA leverages a\nVQVAE to transform intermediate image representations, such as depth maps into\na tokenized format and bounding box tokens, which is then used in a multi-task\ntraining framework. AURORA achieves notable improvements across counting\nbenchmarks: +10.8% on BLINK, +11.3% on CVBench, and +8.3% on SEED-Bench,\noutperforming finetuning approaches in generalization across datasets. It also\nimproves on relative depth: over +6% on BLINK. With perception tokens, AURORA\nexpands the scope of MLMs beyond language-based reasoning, paving the way for\nmore effective visual reasoning capabilities.",
            "upvotes": 10,
            "discussionId": "675880b450e4b1a8f1f54eca"
        },
        "publishedAt": "2024-12-11T00:06:59.931Z",
        "title": "Perception Tokens Enhance Visual Reasoning in Multimodal Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.03548.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "643be8879f5d314db2d9ed23",
            "avatarUrl": "/avatars/64e9bb2c4e10fbe03e2b81afedf40865.svg",
            "fullname": "Chen Dongping",
            "name": "shuaishuaicdp",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        }
    },
    {
        "paper": {
            "id": "2412.06674",
            "authors": [
                {
                    "_id": "67592785adabd5ddff254756",
                    "name": "Jiangning Zhang",
                    "hidden": false
                },
                {
                    "_id": "67592785adabd5ddff254757",
                    "name": "Teng Hu",
                    "hidden": false
                },
                {
                    "_id": "67592785adabd5ddff254758",
                    "user": {
                        "_id": "65b9f891efa633aa9a9a8315",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/onhK-rjtHmaqSmHpSS11S.jpeg",
                        "isPro": false,
                        "fullname": "haoyang He",
                        "user": "hhy724",
                        "type": "user"
                    },
                    "name": "Haoyang He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T10:38:08.473Z",
                    "hidden": false
                },
                {
                    "_id": "67592785adabd5ddff254759",
                    "name": "Zhucun Xue",
                    "hidden": false
                },
                {
                    "_id": "67592785adabd5ddff25475a",
                    "name": "Yabiao Wang",
                    "hidden": false
                },
                {
                    "_id": "67592785adabd5ddff25475b",
                    "name": "Chengjie Wang",
                    "hidden": false
                },
                {
                    "_id": "67592785adabd5ddff25475c",
                    "name": "Yong Liu",
                    "hidden": false
                },
                {
                    "_id": "67592785adabd5ddff25475d",
                    "user": {
                        "_id": "63958b4414513eaf9029ebf1",
                        "avatarUrl": "/avatars/1f5e9b9dfcc16df8e88e3dcecfcb4e10.svg",
                        "isPro": false,
                        "fullname": "Xiangtai Li",
                        "user": "LXT",
                        "type": "user"
                    },
                    "name": "Xiangtai Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:19:46.630Z",
                    "hidden": false
                },
                {
                    "_id": "67592785adabd5ddff25475e",
                    "name": "Dacheng Tao",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-09T17:12:22.000Z",
            "title": "EMOv2: Pushing 5M Vision Model Frontier",
            "summary": "This work focuses on developing parameter-efficient and lightweight models\nfor dense predictions while trading off parameters, FLOPs, and performance. Our\ngoal is to set up the new frontier of the 5M magnitude lightweight model on\nvarious downstream tasks. Inverted Residual Block (IRB) serves as the\ninfrastructure for lightweight CNNs, but no counterparts have been recognized\nby attention-based design. Our work rethinks the lightweight infrastructure of\nefficient IRB and practical components in Transformer from a unified\nperspective, extending CNN-based IRB to attention-based models and abstracting\na one-residual Meta Mobile Block (MMBlock) for lightweight model design.\nFollowing neat but effective design criterion, we deduce a modern Improved\nInverted Residual Mobile Block (i2RMB) and improve a hierarchical Efficient\nMOdel (EMOv2) with no elaborate complex structures. Considering the\nimperceptible latency for mobile users when downloading models under 4G/5G\nbandwidth and ensuring model performance, we investigate the performance upper\nlimit of lightweight models with a magnitude of 5M. Extensive experiments on\nvarious vision recognition, dense prediction, and image generation tasks\ndemonstrate the superiority of our EMOv2 over state-of-the-art methods, e.g.,\nEMOv2-1M/2M/5M achieve 72.3, 75.8, and 79.4 Top-1 that surpass equal-order\nCNN-/Attention-based models significantly. At the same time, EMOv2-5M equipped\nRetinaNet achieves 41.5 mAP for object detection tasks that surpasses the\nprevious EMO-5M by +2.6. When employing the more robust training recipe, our\nEMOv2-5M eventually achieves 82.9 Top-1 accuracy, which elevates the\nperformance of 5M magnitude models to a new level. Code is available at\nhttps://github.com/zhangzjn/EMOv2.",
            "upvotes": 9,
            "discussionId": "6759278badabd5ddff2548c2"
        },
        "publishedAt": "2024-12-11T00:51:34.374Z",
        "title": "EMOv2: Pushing 5M Vision Model Frontier",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.06674.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63958b4414513eaf9029ebf1",
            "avatarUrl": "/avatars/1f5e9b9dfcc16df8e88e3dcecfcb4e10.svg",
            "fullname": "Xiangtai Li",
            "name": "LXT",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 6
        }
    },
    {
        "paper": {
            "id": "2412.06673",
            "authors": [
                {
                    "_id": "67588d470cdb85095c3f6729",
                    "user": {
                        "_id": "67060e1eccd611adc1c56740",
                        "avatarUrl": "/avatars/936850d0a3f0e4caf55fdaf2937c24ab.svg",
                        "isPro": false,
                        "fullname": "chunwei",
                        "user": "chunwei0224",
                        "type": "user"
                    },
                    "name": "Chunwei Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:47:08.436Z",
                    "hidden": false
                },
                {
                    "_id": "67588d470cdb85095c3f672a",
                    "name": "Guansong Lu",
                    "hidden": false
                },
                {
                    "_id": "67588d470cdb85095c3f672b",
                    "user": {
                        "_id": "66a9e095539f1ccd196692b7",
                        "avatarUrl": "/avatars/9fcdab9c3546bc090a9136ae29de1e4e.svg",
                        "isPro": false,
                        "fullname": "Yang",
                        "user": "JunweiYang",
                        "type": "user"
                    },
                    "name": "Junwei Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:48:17.456Z",
                    "hidden": false
                },
                {
                    "_id": "67588d470cdb85095c3f672c",
                    "name": "Runhui Huang",
                    "hidden": false
                },
                {
                    "_id": "67588d470cdb85095c3f672d",
                    "name": "Jianhua Han",
                    "hidden": false
                },
                {
                    "_id": "67588d470cdb85095c3f672e",
                    "name": "Lu Hou",
                    "hidden": false
                },
                {
                    "_id": "67588d470cdb85095c3f672f",
                    "name": "Wei Zhang",
                    "hidden": false
                },
                {
                    "_id": "67588d470cdb85095c3f6730",
                    "name": "Hang Xu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-09T17:11:50.000Z",
            "title": "ILLUME: Illuminating Your LLMs to See, Draw, and Self-Enhance",
            "summary": "In this paper, we introduce ILLUME, a unified multimodal large language model\n(MLLM) that seamlessly integrates multimodal understanding and generation\ncapabilities within a single large language model through a unified next-token\nprediction formulation. To address the large dataset size typically required\nfor image-text alignment, we propose to enhance data efficiency through the\ndesign of a vision tokenizer that incorporates semantic information and a\nprogressive multi-stage training procedure. This approach reduces the dataset\nsize to just 15M for pretraining -- over four times fewer than what is\ntypically needed -- while achieving competitive or even superior performance\nwith existing unified MLLMs, such as Janus. Additionally, to promote\nsynergistic enhancement between understanding and generation capabilities,\nwhich is under-explored in previous works, we introduce a novel self-enhancing\nmultimodal alignment scheme. This scheme supervises the MLLM to self-assess the\nconsistency between text descriptions and self-generated images, facilitating\nthe model to interpret images more accurately and avoid unrealistic and\nincorrect predictions caused by misalignment in image generation. Based on\nextensive experiments, our proposed ILLUME stands out and competes with\nstate-of-the-art unified MLLMs and specialized models across various benchmarks\nfor multimodal understanding, generation, and editing.",
            "upvotes": 8,
            "discussionId": "67588d490cdb85095c3f67a8"
        },
        "publishedAt": "2024-12-10T21:47:23.300Z",
        "title": "ILLUME: Illuminating Your LLMs to See, Draw, and Self-Enhance",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.06673.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "67060e1eccd611adc1c56740",
            "avatarUrl": "/avatars/936850d0a3f0e4caf55fdaf2937c24ab.svg",
            "fullname": "chunwei",
            "name": "chunwei0224",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.05148",
            "authors": [
                {
                    "_id": "67570c548e4eeb4b6f040bef",
                    "user": {
                        "_id": "651ed00e8ed730cc0066c2fb",
                        "avatarUrl": "/avatars/2790728f588075cf767a0db157115d19.svg",
                        "isPro": false,
                        "fullname": "Donald Shenaj",
                        "user": "donaldssh",
                        "type": "user"
                    },
                    "name": "Donald Shenaj",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:20:52.312Z",
                    "hidden": false
                },
                {
                    "_id": "67570c548e4eeb4b6f040bf0",
                    "user": {
                        "_id": "65b11831c9a5a7680faa8cc9",
                        "avatarUrl": "/avatars/e14a0f7ee2883926e7f6e146365c7ccf.svg",
                        "isPro": false,
                        "fullname": "Ondrej Bohdal",
                        "user": "obohdal",
                        "type": "user"
                    },
                    "name": "Ondrej Bohdal",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:20:49.872Z",
                    "hidden": false
                },
                {
                    "_id": "67570c548e4eeb4b6f040bf1",
                    "user": {
                        "_id": "65bced24c63d6a8d7f400b8b",
                        "avatarUrl": "/avatars/91212d7f39eba91158d7a0d0c823bc45.svg",
                        "isPro": false,
                        "fullname": "Mete Ozay",
                        "user": "mosams",
                        "type": "user"
                    },
                    "name": "Mete Ozay",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:50:54.799Z",
                    "hidden": false
                },
                {
                    "_id": "67570c548e4eeb4b6f040bf2",
                    "name": "Pietro Zanuttigh",
                    "hidden": false
                },
                {
                    "_id": "67570c548e4eeb4b6f040bf3",
                    "user": {
                        "_id": "646f1879c261dc4133830dd6",
                        "avatarUrl": "/avatars/f4134a8fb171f93c098a43f1c7a94eb6.svg",
                        "isPro": false,
                        "fullname": "Umberto Michieli",
                        "user": "u-michieli",
                        "type": "user"
                    },
                    "name": "Umberto Michieli",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:51:08.508Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-06T16:04:56.000Z",
            "title": "LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style\n  Conditioned Image Generation",
            "summary": "Recent advancements in image generation models have enabled personalized\nimage creation with both user-defined subjects (content) and styles. Prior\nworks achieved personalization by merging corresponding low-rank adaptation\nparameters (LoRAs) through optimization-based methods, which are\ncomputationally demanding and unsuitable for real-time use on\nresource-constrained devices like smartphones. To address this, we introduce\nLoRA.rar, a method that not only improves image quality but also achieves a\nremarkable speedup of over 4000times in the merging process. LoRA.rar\npre-trains a hypernetwork on a diverse set of content-style LoRA pairs,\nlearning an efficient merging strategy that generalizes to new, unseen\ncontent-style pairs, enabling fast, high-quality personalization. Moreover, we\nidentify limitations in existing evaluation metrics for content-style quality\nand propose a new protocol using multimodal large language models (MLLM) for\nmore accurate assessment. Our method significantly outperforms the current\nstate of the art in both content and style fidelity, as validated by MLLM\nassessments and human evaluations.",
            "upvotes": 7,
            "discussionId": "67570c588e4eeb4b6f040d34"
        },
        "publishedAt": "2024-12-11T06:54:05.262Z",
        "title": "LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/651ed00e8ed730cc0066c2fb/JObktMUD2QAn5annKa7OF.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.05148.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "651ed00e8ed730cc0066c2fb",
            "avatarUrl": "/avatars/2790728f588075cf767a0db157115d19.svg",
            "fullname": "Donald Shenaj",
            "name": "donaldssh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.07721",
            "authors": [
                {
                    "_id": "6759180441b35c9329025a5e",
                    "user": {
                        "_id": "64db92a5858f8a41c11669b7",
                        "avatarUrl": "/avatars/e834d8f1d4781e3bb0b5d6d25b3b3505.svg",
                        "isPro": false,
                        "fullname": "Zhouxia Wang",
                        "user": "wzhouxiff",
                        "type": "user"
                    },
                    "name": "Zhouxia Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:50:16.745Z",
                    "hidden": false
                },
                {
                    "_id": "6759180441b35c9329025a5f",
                    "user": {
                        "_id": "64b55f62e6b0c53f97e64034",
                        "avatarUrl": "/avatars/d5fc53de37d4fb0b5095a5fb21b43503.svg",
                        "isPro": true,
                        "fullname": "LAN YUSHI",
                        "user": "yslan",
                        "type": "user"
                    },
                    "name": "Yushi Lan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:50:10.996Z",
                    "hidden": false
                },
                {
                    "_id": "6759180441b35c9329025a60",
                    "user": {
                        "_id": "62e57662ae9d3f10acbb1b1b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e57662ae9d3f10acbb1b1b/lg58jdbNyv6LGH2LFnZDF.png",
                        "isPro": false,
                        "fullname": "Shangchen Zhou",
                        "user": "sczhou",
                        "type": "user"
                    },
                    "name": "Shangchen Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:50:00.183Z",
                    "hidden": false
                },
                {
                    "_id": "6759180441b35c9329025a61",
                    "user": {
                        "_id": "67459d997a49660f7f62452f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/X25yTdxC_hcLVxpx4voZo.png",
                        "isPro": false,
                        "fullname": "Chen Change Loy",
                        "user": "cavanloy",
                        "type": "user"
                    },
                    "name": "Chen Change Loy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:49:54.135Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T18:14:30.000Z",
            "title": "ObjCtrl-2.5D: Training-free Object Control with Camera Poses",
            "summary": "This study aims to achieve more precise and versatile object control in\nimage-to-video (I2V) generation. Current methods typically represent the\nspatial movement of target objects with 2D trajectories, which often fail to\ncapture user intention and frequently produce unnatural results. To enhance\ncontrol, we present ObjCtrl-2.5D, a training-free object control approach that\nuses a 3D trajectory, extended from a 2D trajectory with depth information, as\na control signal. By modeling object movement as camera movement, ObjCtrl-2.5D\nrepresents the 3D trajectory as a sequence of camera poses, enabling object\nmotion control using an existing camera motion control I2V generation model\n(CMC-I2V) without training. To adapt the CMC-I2V model originally designed for\nglobal motion control to handle local object motion, we introduce a module to\nisolate the target object from the background, enabling independent local\ncontrol. In addition, we devise an effective way to achieve more accurate\nobject control by sharing low-frequency warped latent within the object's\nregion across frames. Extensive experiments demonstrate that ObjCtrl-2.5D\nsignificantly improves object control accuracy compared to training-free\nmethods and offers more diverse control capabilities than training-based\napproaches using 2D trajectories, enabling complex effects like object\nrotation. Code and results are available at\nhttps://wzhouxiff.github.io/projects/ObjCtrl-2.5D/.",
            "upvotes": 6,
            "discussionId": "6759180541b35c9329025ab5"
        },
        "publishedAt": "2024-12-11T00:17:46.701Z",
        "title": "ObjCtrl-2.5D: Training-free Object Control with Camera Poses",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64db92a5858f8a41c11669b7/jomuc0GE_4-AY2Vkp1azs.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07721.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "64db92a5858f8a41c11669b7",
            "avatarUrl": "/avatars/e834d8f1d4781e3bb0b5d6d25b3b3505.svg",
            "fullname": "Zhouxia Wang",
            "name": "wzhouxiff",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 8
        }
    },
    {
        "paper": {
            "id": "2412.06845",
            "authors": [
                {
                    "_id": "6758ff6ea90b1c382daf3526",
                    "name": "Pu Zhao",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3527",
                    "name": "Xuan Shen",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3528",
                    "name": "Zhenglun Kong",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3529",
                    "user": {
                        "_id": "65e02dcd121aa0d0b4a95963",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/6C5bq1weQxI9s80u3Z8v1.jpeg",
                        "isPro": false,
                        "fullname": "Yixin",
                        "user": "yixinshen1",
                        "type": "user"
                    },
                    "name": "Yixin Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:54:16.438Z",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf352a",
                    "name": "Sung-En Chang",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf352b",
                    "name": "Timothy Rupprecht",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf352c",
                    "name": "Lei Lu",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf352d",
                    "user": {
                        "_id": "65382338ef7d2bb8c4b373bc",
                        "avatarUrl": "/avatars/a469924cf3b983c6e420ee4dccce0290.svg",
                        "isPro": false,
                        "fullname": "ENFU NAN",
                        "user": "nanenfu",
                        "type": "user"
                    },
                    "name": "Enfu Nan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:54:31.486Z",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf352e",
                    "user": {
                        "_id": "654321438caf77017835e5c0",
                        "avatarUrl": "/avatars/999e63e33e17058baa2ce53d90f49d63.svg",
                        "isPro": false,
                        "fullname": "yangchangdi",
                        "user": "yangchangdi",
                        "type": "user"
                    },
                    "name": "Changdi Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:54:43.185Z",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf352f",
                    "user": {
                        "_id": "66c9ec0edf893af1ae3329b3",
                        "avatarUrl": "/avatars/0a09c5ad9e56bee64eb098d893b1c969.svg",
                        "isPro": false,
                        "fullname": "Yumei He",
                        "user": "Joy2024HuggingFace",
                        "type": "user"
                    },
                    "name": "Yumei He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:54:51.471Z",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3530",
                    "name": "Xingchen Xu",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3531",
                    "user": {
                        "_id": "6463d44a9dd8b530a85fe6c9",
                        "avatarUrl": "/avatars/24364533d8e3ccec20c0043c98967f35.svg",
                        "isPro": false,
                        "fullname": "Yu Huang",
                        "user": "yuhuang",
                        "type": "user"
                    },
                    "name": "Yu Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:55:07.226Z",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3532",
                    "name": "Wei Wang",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3533",
                    "name": "Yue Chen",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3534",
                    "user": {
                        "_id": "674f84d2b2c5d446d8fcbe72",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Vpq1zbM_8hZX9YENKnC-Q.png",
                        "isPro": false,
                        "fullname": "Yong He",
                        "user": "heyong4725",
                        "type": "user"
                    },
                    "name": "Yong He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:53:21.591Z",
                    "hidden": false
                },
                {
                    "_id": "6758ff6ea90b1c382daf3535",
                    "name": "Yanzhi Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-08T02:01:46.000Z",
            "title": "Fully Open Source Moxin-7B Technical Report",
            "summary": "Recently, Large Language Models (LLMs) have undergone a significant\ntransformation, marked by a rapid rise in both their popularity and\ncapabilities. Leading this evolution are proprietary LLMs like GPT-4 and\nGPT-o1, which have captured widespread attention in the AI community due to\ntheir remarkable performance and versatility. Simultaneously, open-source LLMs,\nsuch as LLaMA and Mistral, have made great contributions to the ever-increasing\npopularity of LLMs due to the ease to customize and deploy the models across\ndiverse applications. Although open-source LLMs present unprecedented\nopportunities for innovation and research, the commercialization of LLMs has\nraised concerns about transparency, reproducibility, and safety. Many\nopen-source LLMs fail to meet fundamental transparency requirements by\nwithholding essential components like training code and data, and some use\nrestrictive licenses whilst claiming to be \"open-source,\" which may hinder\nfurther innovations on LLMs. To mitigate this issue, we introduce Moxin 7B, a\nfully open-source LLM developed in accordance with the Model Openness Framework\n(MOF), a ranked classification system that evaluates AI models based on model\ncompleteness and openness, adhering to principles of open science, open source,\nopen data, and open access. Our model achieves the highest MOF classification\nlevel of \"open science\" through the comprehensive release of pre-training code\nand configurations, training and fine-tuning datasets, and intermediate and\nfinal checkpoints. Experiments show that our model achieves superior\nperformance in zero-shot evaluation compared with popular 7B models and\nperforms competitively in few-shot evaluation.",
            "upvotes": 6,
            "discussionId": "6758ff6ea90b1c382daf354f"
        },
        "publishedAt": "2024-12-10T21:58:29.706Z",
        "title": "Fully Open Source Moxin-7B Technical Report",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.06845.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5352
        }
    },
    {
        "paper": {
            "id": "2412.05983",
            "authors": [
                {
                    "_id": "675958c2528f1296b6789dc8",
                    "user": {
                        "_id": "6538dd471ad9b3ba7c2df861",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6538dd471ad9b3ba7c2df861/MbEa7KHAK6u7PRb7WiPUC.jpeg",
                        "isPro": false,
                        "fullname": "Tianshuo Peng",
                        "user": "Potentialts",
                        "type": "user"
                    },
                    "name": "Tianshuo Peng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:51:28.371Z",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dc9",
                    "user": {
                        "_id": "674d8c97d086436faf52c890",
                        "avatarUrl": "/avatars/c4bde24b0796f725a9f4e68f72fe6a44.svg",
                        "isPro": false,
                        "fullname": "mingsheng li",
                        "user": "mingsheng1",
                        "type": "user"
                    },
                    "name": "Mingsheng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:51:34.844Z",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dca",
                    "name": "Hongbin Zhou",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dcb",
                    "user": {
                        "_id": "65b7ae76768464877cdb2e39",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65b7ae76768464877cdb2e39/uAWPo4tpkqbZoDeEkc7y0.jpeg",
                        "isPro": false,
                        "fullname": "Renqiu Xia",
                        "user": "renqiux0302",
                        "type": "user"
                    },
                    "name": "Renqiu Xia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:51:47.602Z",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dcc",
                    "name": "Renrui Zhang",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dcd",
                    "name": "Lei Bai",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dce",
                    "name": "Song Mao",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dcf",
                    "user": {
                        "_id": "5e49e8cf37cb5b49818287ae",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5e49e8cf37cb5b49818287ae/MqW09HJ0CX0mJeH3H5aSc.jpeg",
                        "isPro": false,
                        "fullname": "Bin Wang",
                        "user": "binwang",
                        "type": "user"
                    },
                    "name": "Bin Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:52:09.628Z",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dd0",
                    "user": {
                        "_id": "63f9fca8d4349b157a109eec",
                        "avatarUrl": "/avatars/fa1f2ae7972d7cde99dab178136ccbb0.svg",
                        "isPro": false,
                        "fullname": "Conghui He",
                        "user": "conghui",
                        "type": "user"
                    },
                    "name": "Conghui He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:52:15.773Z",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dd1",
                    "user": {
                        "_id": "637de1520d5bb06fbe5207a9",
                        "avatarUrl": "/avatars/1090851217270c5a858b13e013356d4f.svg",
                        "isPro": false,
                        "fullname": "AJ.Zhou",
                        "user": "AJZhou",
                        "type": "user"
                    },
                    "name": "Aojun Zhou",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T13:39:14.372Z",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dd2",
                    "user": {
                        "_id": "643df87f7cd64d872cb9fabd",
                        "avatarUrl": "/avatars/c53bfabcee08de448dde973915e8b31d.svg",
                        "isPro": false,
                        "fullname": "Botian Shi",
                        "user": "friskit",
                        "type": "user"
                    },
                    "name": "Botian Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:52:21.114Z",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dd3",
                    "user": {
                        "_id": "64fc225152992431a6013ebd",
                        "avatarUrl": "/avatars/c3320cfb88b4fd21884bc401f71caa6f.svg",
                        "isPro": false,
                        "fullname": "Chen Tao",
                        "user": "taochen",
                        "type": "user"
                    },
                    "name": "Tao Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:52:28.097Z",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dd4",
                    "name": "Bo Zhang",
                    "hidden": false
                },
                {
                    "_id": "675958c2528f1296b6789dd5",
                    "user": {
                        "_id": "666a8f24e2990b0cb16b7bf9",
                        "avatarUrl": "/avatars/fcbaf8f1e3e53a2a4a819b7cb2c53aa4.svg",
                        "isPro": false,
                        "fullname": "Xiangyu Yue",
                        "user": "xyyue",
                        "type": "user"
                    },
                    "name": "Xiangyu Yue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T13:51:21.617Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-08T16:10:42.000Z",
            "title": "Chimera: Improving Generalist Model with Domain-Specific Experts",
            "summary": "Recent advancements in Large Multi-modal Models (LMMs) underscore the\nimportance of scaling by increasing image-text paired data, achieving\nimpressive performance on general tasks. Despite their effectiveness in broad\napplications, generalist models are primarily trained on web-scale datasets\ndominated by natural images, resulting in the sacrifice of specialized\ncapabilities for domain-specific tasks that require extensive domain prior\nknowledge. Moreover, directly integrating expert models tailored for specific\ndomains is challenging due to the representational gap and imbalanced\noptimization between the generalist model and experts. To address these\nchallenges, we introduce Chimera, a scalable and low-cost multi-modal pipeline\ndesigned to boost the ability of existing LMMs with domain-specific experts.\nSpecifically, we design a progressive training strategy to integrate features\nfrom expert models into the input of a generalist LMM. To address the\nimbalanced optimization caused by the well-aligned general visual encoder, we\nintroduce a novel Generalist-Specialist Collaboration Masking (GSCM) mechanism.\nThis results in a versatile model that excels across the chart, table, math,\nand document domains, achieving state-of-the-art performance on multi-modal\nreasoning and visual content extraction tasks, both of which are challenging\ntasks for assessing existing LMMs.",
            "upvotes": 5,
            "discussionId": "675958c4528f1296b6789e1f"
        },
        "publishedAt": "2024-12-11T04:18:44.314Z",
        "title": "Chimera: Improving Generalist Model with Domain-Specific Experts",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.05983.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "65b7ae76768464877cdb2e39",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65b7ae76768464877cdb2e39/uAWPo4tpkqbZoDeEkc7y0.jpeg",
            "fullname": "Renqiu Xia",
            "name": "renqiux0302",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 0
        }
    },
    {
        "paper": {
            "id": "2412.07282",
            "authors": [
                {
                    "_id": "67595e5f6621cef8bdbde626",
                    "user": {
                        "_id": "631f1d51c1a8269da3941374",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631f1d51c1a8269da3941374/53__nPiD9t0e1qzrY0DlD.png",
                        "isPro": false,
                        "fullname": "Romain Storaï",
                        "user": "romsto",
                        "type": "user"
                    },
                    "name": "Romain Storaï",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:54:16.623Z",
                    "hidden": false
                },
                {
                    "_id": "67595e5f6621cef8bdbde627",
                    "name": "Seung-won Hwang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T08:12:22.000Z",
            "title": "HARP: Hesitation-Aware Reframing in Transformer Inference Pass",
            "summary": "This paper aims to improve the performance of large language models by\naddressing the variable computational demands in inference steps, where some\ntokens require more computational resources than others. We present HARP, a\nsimple modification to \"off-the-shelf\" Transformer forward pass. Drawing from\nhesitation and the framing effect in decision-making, HARP selectively applies\nadditional computation when the model encounters uncertainty during token\ngeneration. Our method mimics human cognitive processes by pausing at difficult\ndecision points and reframing inputs for a different perspective. Unlike other\napproaches, HARP is model-agnostic, training-free, and easy to implement. We\nthoroughly evaluate our method across various downstream tasks and model sizes,\ndemonstrating performance improvements up to +5.16%. Notably, HARP achieves\nthese gains while maintaining inference times twice faster than beam search.\nSimple and yet with significant gains, HARP offers a practical solution for\nenhancing the performance of Transformer-based language models with minimal\ncomputational impact.",
            "upvotes": 3,
            "discussionId": "67595e606621cef8bdbde65f"
        },
        "publishedAt": "2024-12-11T08:12:13.210Z",
        "title": "HARP: Hesitation-Aware Reframing in Transformer Inference Pass",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07282.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "631f1d51c1a8269da3941374",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631f1d51c1a8269da3941374/53__nPiD9t0e1qzrY0DlD.png",
            "fullname": "Romain Storaï",
            "name": "romsto",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        }
    },
    {
        "paper": {
            "id": "2412.06089",
            "authors": [
                {
                    "_id": "67599c0672fd1d07c3b42832",
                    "user": {
                        "_id": "60c8304a672c96a317b85508",
                        "avatarUrl": "/avatars/1a2f27b3da9c6801a52e287de0ddd0bd.svg",
                        "isPro": false,
                        "fullname": "Ashish Goswami",
                        "user": "aggr8",
                        "type": "user"
                    },
                    "name": "Ashish Goswami",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T14:07:56.054Z",
                    "hidden": false
                },
                {
                    "_id": "67599c0672fd1d07c3b42833",
                    "name": "Satyam Kumar Modi",
                    "hidden": false
                },
                {
                    "_id": "67599c0672fd1d07c3b42834",
                    "name": "Santhosh Rishi Deshineni",
                    "hidden": false
                },
                {
                    "_id": "67599c0672fd1d07c3b42835",
                    "name": "Harman Singh",
                    "hidden": false
                },
                {
                    "_id": "67599c0672fd1d07c3b42836",
                    "name": "Prathosh A. P",
                    "hidden": false
                },
                {
                    "_id": "67599c0672fd1d07c3b42837",
                    "name": "Parag Singla",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-08T22:29:56.000Z",
            "title": "GraPE: A Generate-Plan-Edit Framework for Compositional T2I Synthesis",
            "summary": "Text-to-image (T2I) generation has seen significant progress with diffusion\nmodels, enabling generation of photo-realistic images from text prompts.\nDespite this progress, existing methods still face challenges in following\ncomplex text prompts, especially those requiring compositional and multi-step\nreasoning. Given such complex instructions, SOTA models often make mistakes in\nfaithfully modeling object attributes, and relationships among them. In this\nwork, we present an alternate paradigm for T2I synthesis, decomposing the task\nof complex multi-step generation into three steps, (a) Generate: we first\ngenerate an image using existing diffusion models (b) Plan: we make use of\nMulti-Modal LLMs (MLLMs) to identify the mistakes in the generated image\nexpressed in terms of individual objects and their properties, and produce a\nsequence of corrective steps required in the form of an edit-plan. (c) Edit: we\nmake use of an existing text-guided image editing models to sequentially\nexecute our edit-plan over the generated image to get the desired image which\nis faithful to the original instruction. Our approach derives its strength from\nthe fact that it is modular in nature, is training free, and can be applied\nover any combination of image generation and editing models. As an added\ncontribution, we also develop a model capable of compositional editing, which\nfurther helps improve the overall accuracy of our proposed approach. Our method\nflexibly trades inference time compute with performance on compositional text\nprompts. We perform extensive experimental evaluation across 3 benchmarks and\n10 T2I models including DALLE-3 and the latest -- SD-3.5-Large. Our approach\nnot only improves the performance of the SOTA models, by upto 3 points, it also\nreduces the performance gap between weaker and stronger models.\nhttps://dair-iitd.github.io/GraPE/{https://dair-iitd.github.io/GraPE/}",
            "upvotes": 2,
            "discussionId": "67599c0e72fd1d07c3b42a39"
        },
        "publishedAt": "2024-12-11T09:09:05.166Z",
        "title": "GraPE: A Generate-Plan-Edit Framework for Compositional T2I Synthesis",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.06089.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "60c8304a672c96a317b85508",
            "avatarUrl": "/avatars/1a2f27b3da9c6801a52e287de0ddd0bd.svg",
            "fullname": "Ashish Goswami",
            "name": "aggr8",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2412.07338",
            "authors": [
                {
                    "_id": "67596ab7d8405153709c28cf",
                    "user": {
                        "_id": "655f1923324de022a39223ee",
                        "avatarUrl": "/avatars/a7bdca0b554a379daed493cc5ab1359a.svg",
                        "isPro": false,
                        "fullname": "Lorenzo Cima",
                        "user": "LCima",
                        "type": "user"
                    },
                    "name": "Lorenzo Cima",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:00:33.127Z",
                    "hidden": false
                },
                {
                    "_id": "67596ab7d8405153709c28d0",
                    "user": {
                        "_id": "62e3fe792a8df5b22feed15e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e3fe792a8df5b22feed15e/iy8J4oGhW8Nr9QAgoH8ES.jpeg",
                        "isPro": false,
                        "fullname": "Alessio Miaschi",
                        "user": "alemiaschi",
                        "type": "user"
                    },
                    "name": "Alessio Miaschi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T13:39:12.918Z",
                    "hidden": false
                },
                {
                    "_id": "67596ab7d8405153709c28d1",
                    "name": "Amaury Trujillo",
                    "hidden": false
                },
                {
                    "_id": "67596ab7d8405153709c28d2",
                    "name": "Marco Avvenuti",
                    "hidden": false
                },
                {
                    "_id": "67596ab7d8405153709c28d3",
                    "user": {
                        "_id": "663ca4637527788a57f4d73f",
                        "avatarUrl": "/avatars/797e68ee21492a753df82a9f7c2e800e.svg",
                        "isPro": false,
                        "fullname": "Felice Dell'Orletta",
                        "user": "Falice10",
                        "type": "user"
                    },
                    "name": "Felice Dell'Orletta",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:01:31.477Z",
                    "hidden": false
                },
                {
                    "_id": "67596ab7d8405153709c28d4",
                    "name": "Stefano Cresci",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T09:29:52.000Z",
            "title": "Contextualized Counterspeech: Strategies for Adaptation,\n  Personalization, and Evaluation",
            "summary": "AI-generated counterspeech offers a promising and scalable strategy to curb\nonline toxicity through direct replies that promote civil discourse. However,\ncurrent counterspeech is one-size-fits-all, lacking adaptation to the\nmoderation context and the users involved. We propose and evaluate multiple\nstrategies for generating tailored counterspeech that is adapted to the\nmoderation context and personalized for the moderated user. We instruct an\nLLaMA2-13B model to generate counterspeech, experimenting with various\nconfigurations based on different contextual information and fine-tuning\nstrategies. We identify the configurations that generate persuasive\ncounterspeech through a combination of quantitative indicators and human\nevaluations collected via a pre-registered mixed-design crowdsourcing\nexperiment. Results show that contextualized counterspeech can significantly\noutperform state-of-the-art generic counterspeech in adequacy and\npersuasiveness, without compromising other characteristics. Our findings also\nreveal a poor correlation between quantitative indicators and human\nevaluations, suggesting that these methods assess different aspects and\nhighlighting the need for nuanced evaluation methodologies. The effectiveness\nof contextualized AI-generated counterspeech and the divergence between human\nand algorithmic evaluations underscore the importance of increased human-AI\ncollaboration in content moderation.",
            "upvotes": 2,
            "discussionId": "67596ab8d8405153709c2912"
        },
        "publishedAt": "2024-12-11T06:12:48.859Z",
        "title": "Contextualized Counterspeech: Strategies for Adaptation, Personalization, and Evaluation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07338.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "62e3fe792a8df5b22feed15e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e3fe792a8df5b22feed15e/iy8J4oGhW8Nr9QAgoH8ES.jpeg",
            "fullname": "Alessio Miaschi",
            "name": "alemiaschi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 6
        }
    },
    {
        "paper": {
            "id": "2412.04835",
            "authors": [
                {
                    "_id": "67595a8662950d6eeb940516",
                    "user": {
                        "_id": "64bd3e29e38420aabacdd0c8",
                        "avatarUrl": "/avatars/568cbeabc3717b3ade128dba2652ee57.svg",
                        "isPro": false,
                        "fullname": "ran tian",
                        "user": "nkrtian",
                        "type": "user"
                    },
                    "name": "Ran Tian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:04:06.591Z",
                    "hidden": false
                },
                {
                    "_id": "67595a8662950d6eeb940517",
                    "name": "Yilin Wu",
                    "hidden": false
                },
                {
                    "_id": "67595a8662950d6eeb940518",
                    "user": {
                        "_id": "654ca71d5255ee86711b52c5",
                        "avatarUrl": "/avatars/52bf00fd74c8db5643c4daa185c678e6.svg",
                        "isPro": false,
                        "fullname": "Chenfeng Xu",
                        "user": "chenfengx",
                        "type": "user"
                    },
                    "name": "Chenfeng Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:03:46.829Z",
                    "hidden": false
                },
                {
                    "_id": "67595a8662950d6eeb940519",
                    "name": "Masayoshi Tomizuka",
                    "hidden": false
                },
                {
                    "_id": "67595a8662950d6eeb94051a",
                    "user": {
                        "_id": "65369a95605a07338de78ab0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/sGFjOjLT2akN-sn5beVWL.jpeg",
                        "isPro": false,
                        "fullname": "Jitendra Malik ",
                        "user": "jitendra1995",
                        "type": "user"
                    },
                    "name": "Jitendra Malik",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:03:37.137Z",
                    "hidden": false
                },
                {
                    "_id": "67595a8662950d6eeb94051b",
                    "name": "Andrea Bajcsy",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-06T08:04:02.000Z",
            "title": "Maximizing Alignment with Minimal Feedback: Efficiently Learning Rewards\n  for Visuomotor Robot Policy Alignment",
            "summary": "Visuomotor robot policies, increasingly pre-trained on large-scale datasets,\npromise significant advancements across robotics domains. However, aligning\nthese policies with end-user preferences remains a challenge, particularly when\nthe preferences are hard to specify. While reinforcement learning from human\nfeedback (RLHF) has become the predominant mechanism for alignment in\nnon-embodied domains like large language models, it has not seen the same\nsuccess in aligning visuomotor policies due to the prohibitive amount of human\nfeedback required to learn visual reward functions. To address this limitation,\nwe propose Representation-Aligned Preference-based Learning (RAPL), an\nobservation-only method for learning visual rewards from significantly less\nhuman preference feedback. Unlike traditional RLHF, RAPL focuses human feedback\non fine-tuning pre-trained vision encoders to align with the end-user's visual\nrepresentation and then constructs a dense visual reward via feature matching\nin this aligned representation space. We first validate RAPL through simulation\nexperiments in the X-Magical benchmark and Franka Panda robotic manipulation,\ndemonstrating that it can learn rewards aligned with human preferences, more\nefficiently uses preference data, and generalizes across robot embodiments.\nFinally, our hardware experiments align pre-trained Diffusion Policies for\nthree object manipulation tasks. We find that RAPL can fine-tune these policies\nwith 5x less real human preference data, taking the first step towards\nminimizing human feedback while maximizing visuomotor robot policy alignment.",
            "upvotes": 2,
            "discussionId": "67595a8962950d6eeb9405b6"
        },
        "publishedAt": "2024-12-11T04:29:11.374Z",
        "title": "Maximizing Alignment with Minimal Feedback: Efficiently Learning Rewards for Visuomotor Robot Policy Alignment",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.04835.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6535786a24c3063696804cdf",
            "avatarUrl": "/avatars/2e59a26b691a9ab9825a015c7d47f9aa.svg",
            "fullname": "Ran (Thomas) Tian",
            "name": "thomasrantian",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2412.07187",
            "authors": [
                {
                    "_id": "67592b7d07803203aeea219b",
                    "user": {
                        "_id": "668f440894dfc0ed1a7006ed",
                        "avatarUrl": "/avatars/fa0d328300b03bcbbf9b3a7532f28458.svg",
                        "isPro": false,
                        "fullname": "Pengxin Guo",
                        "user": "gpx333",
                        "type": "user"
                    },
                    "name": "Pengxin Guo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-11T09:19:40.358Z",
                    "hidden": false
                },
                {
                    "_id": "67592b7d07803203aeea219c",
                    "user": {
                        "_id": "66712ff09c609c2484ce4aa0",
                        "avatarUrl": "/avatars/717b96ddef8a4c19ce07ea1fd9e9fd66.svg",
                        "isPro": false,
                        "fullname": "Shuang Zeng",
                        "user": "stevezs",
                        "type": "user"
                    },
                    "name": "Shuang Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:07:33.274Z",
                    "hidden": false
                },
                {
                    "_id": "67592b7d07803203aeea219d",
                    "name": "Wenhao Chen",
                    "hidden": false
                },
                {
                    "_id": "67592b7d07803203aeea219e",
                    "user": {
                        "_id": "648fed7081a3fcd6749b0f8e",
                        "avatarUrl": "/avatars/3f4e6bf412231d451173a0ecfe3bdb91.svg",
                        "isPro": false,
                        "fullname": "Xiaodan Zhang",
                        "user": "xdz618",
                        "type": "user"
                    },
                    "name": "Xiaodan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:07:06.224Z",
                    "hidden": false
                },
                {
                    "_id": "67592b7d07803203aeea219f",
                    "name": "Weihong Ren",
                    "hidden": false
                },
                {
                    "_id": "67592b7d07803203aeea21a0",
                    "user": {
                        "_id": "66c7fb4ce2c92fe5b132f314",
                        "avatarUrl": "/avatars/22d915fa339a70803c5c748255250256.svg",
                        "isPro": false,
                        "fullname": "Yuyin Zhou",
                        "user": "RitaCoding",
                        "type": "user"
                    },
                    "name": "Yuyin Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:06:51.689Z",
                    "hidden": false
                },
                {
                    "_id": "67592b7d07803203aeea21a1",
                    "user": {
                        "_id": "663058bc2653ec94f4a6235f",
                        "avatarUrl": "/avatars/f55b8c3c8100d6b6d65ba61abc4fb014.svg",
                        "isPro": false,
                        "fullname": "Liangqiong Qu",
                        "user": "Liangqiong-QU",
                        "type": "user"
                    },
                    "name": "Liangqiong Qu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-11T14:06:45.686Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-12-10T04:53:42.000Z",
            "title": "A New Federated Learning Framework Against Gradient Inversion Attacks",
            "summary": "Federated Learning (FL) aims to protect data privacy by enabling clients to\ncollectively train machine learning models without sharing their raw data.\nHowever, recent studies demonstrate that information exchanged during FL is\nsubject to Gradient Inversion Attacks (GIA) and, consequently, a variety of\nprivacy-preserving methods have been integrated into FL to thwart such attacks,\nsuch as Secure Multi-party Computing (SMC), Homomorphic Encryption (HE), and\nDifferential Privacy (DP). Despite their ability to protect data privacy, these\napproaches inherently involve substantial privacy-utility trade-offs. By\nrevisiting the key to privacy exposure in FL under GIA, which lies in the\nfrequent sharing of model gradients that contain private data, we take a new\nperspective by designing a novel privacy preserve FL framework that effectively\n``breaks the direct connection'' between the shared parameters and the local\nprivate data to defend against GIA. Specifically, we propose a Hypernetwork\nFederated Learning (HyperFL) framework that utilizes hypernetworks to generate\nthe parameters of the local model and only the hypernetwork parameters are\nuploaded to the server for aggregation. Theoretical analyses demonstrate the\nconvergence rate of the proposed HyperFL, while extensive experimental results\nshow the privacy-preserving capability and comparable performance of HyperFL.\nCode is available at https://github.com/Pengxin-Guo/HyperFL.",
            "upvotes": 1,
            "discussionId": "67592b7f07803203aeea2243"
        },
        "publishedAt": "2024-12-11T01:05:18.828Z",
        "title": "A New Federated Learning Framework Against Gradient Inversion Attacks",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.07187.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "668f440894dfc0ed1a7006ed",
            "avatarUrl": "/avatars/fa0d328300b03bcbbf9b3a7532f28458.svg",
            "fullname": "Pengxin Guo",
            "name": "gpx333",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]