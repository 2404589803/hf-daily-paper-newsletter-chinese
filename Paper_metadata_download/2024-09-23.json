[
    {
        "paper": {
            "id": "2409.13346",
            "authors": [
                {
                    "_id": "66f0ecb3a4c40b65f651c498",
                    "user": {
                        "_id": "641b7d42ec5b871c0bcf2955",
                        "avatarUrl": "/avatars/f6e24742b4befa889e72c7e5eefd6cf6.svg",
                        "isPro": false,
                        "fullname": "He",
                        "user": "zechengh",
                        "type": "user"
                    },
                    "name": "Zecheng He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:13:18.477Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c499",
                    "name": "Bo Sun",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c49a",
                    "user": {
                        "_id": "6444e8911cfc9ae6bb3ad216",
                        "avatarUrl": "/avatars/8c06e064cf24789e4131f7af06dac86b.svg",
                        "isPro": false,
                        "fullname": "Xu",
                        "user": "FelixXu",
                        "type": "user"
                    },
                    "name": "Felix Juefei-Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:22:46.770Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c49b",
                    "user": {
                        "_id": "650a8979c19e5b4c8a6ff062",
                        "avatarUrl": "/avatars/272385e2246bcfd2ebe9fb2942783fb8.svg",
                        "isPro": false,
                        "fullname": "Haoyu Ma",
                        "user": "haoyum1997",
                        "type": "user"
                    },
                    "name": "Haoyu Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:22:27.813Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c49c",
                    "user": {
                        "_id": "667c9d6aaeba4a9f637f4a93",
                        "avatarUrl": "/avatars/3167b482986b822a923966a459f3e362.svg",
                        "isPro": false,
                        "fullname": "Ankit Ramchandani",
                        "user": "ankit61",
                        "type": "user"
                    },
                    "name": "Ankit Ramchandani",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:22:11.834Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c49d",
                    "name": "Vincent Cheung",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c49e",
                    "name": "Siddharth Shah",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c49f",
                    "user": {
                        "_id": "6573c2a8769f3ee9bdf98a74",
                        "avatarUrl": "/avatars/df40b6153ec7368561049746a9c8adc2.svg",
                        "isPro": false,
                        "fullname": "Anmol Kalia",
                        "user": "anmolkalia",
                        "type": "user"
                    },
                    "name": "Anmol Kalia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:21:24.727Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a0",
                    "user": {
                        "_id": "6303da377373aacccd868d0f",
                        "avatarUrl": "/avatars/88813105f863a0b2125fbe8bfffdec0e.svg",
                        "isPro": false,
                        "fullname": "Harihar Subramanyam",
                        "user": "Harihar",
                        "type": "user"
                    },
                    "name": "Harihar Subramanyam",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:21:18.664Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a1",
                    "name": "Alireza Zareian",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a2",
                    "name": "Li Chen",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a3",
                    "name": "Ankit Jain",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a4",
                    "name": "Ning Zhang",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a5",
                    "user": {
                        "_id": "6433a635a5aed21dd110381e",
                        "avatarUrl": "/avatars/b1fa4fe1c8bd7989875233820fa425af.svg",
                        "isPro": false,
                        "fullname": "Peizhao Zhang",
                        "user": "stzpz",
                        "type": "user"
                    },
                    "name": "Peizhao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:20:22.954Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a6",
                    "user": {
                        "_id": "6515c595f464644a73b50064",
                        "avatarUrl": "/avatars/119102c41fb8a7986c72b3f55ec6200f.svg",
                        "isPro": false,
                        "fullname": "Roshan sumbaly",
                        "user": "rsumbaly",
                        "type": "user"
                    },
                    "name": "Roshan Sumbaly",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:20:16.872Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a7",
                    "user": {
                        "_id": "636f4b35af79dd193603342b",
                        "avatarUrl": "/avatars/577328195738d92ac41a3d0ff3108d7c.svg",
                        "isPro": false,
                        "fullname": "Peter Vajda",
                        "user": "vaphab",
                        "type": "user"
                    },
                    "name": "Peter Vajda",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:20:10.159Z",
                    "hidden": false
                },
                {
                    "_id": "66f0ecb3a4c40b65f651c4a8",
                    "user": {
                        "_id": "63772d28e069bdcdbb8e4a29",
                        "avatarUrl": "/avatars/be71b00e009f2093a3ff79f07815e68e.svg",
                        "isPro": false,
                        "fullname": "Animesh Sinha",
                        "user": "animeshsinha",
                        "type": "user"
                    },
                    "name": "Animesh Sinha",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:19:52.007Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T09:21:49.000Z",
            "title": "Imagine yourself: Tuning-Free Personalized Image Generation",
            "summary": "Diffusion models have demonstrated remarkable efficacy across various\nimage-to-image tasks. In this research, we introduce Imagine yourself, a\nstate-of-the-art model designed for personalized image generation. Unlike\nconventional tuning-based personalization techniques, Imagine yourself operates\nas a tuning-free model, enabling all users to leverage a shared framework\nwithout individualized adjustments. Moreover, previous work met challenges\nbalancing identity preservation, following complex prompts and preserving good\nvisual quality, resulting in models having strong copy-paste effect of the\nreference images. Thus, they can hardly generate images following prompts that\nrequire significant changes to the reference image, \\eg, changing facial\nexpression, head and body poses, and the diversity of the generated images is\nlow. To address these limitations, our proposed method introduces 1) a new\nsynthetic paired data generation mechanism to encourage image diversity, 2) a\nfully parallel attention architecture with three text encoders and a fully\ntrainable vision encoder to improve the text faithfulness, and 3) a novel\ncoarse-to-fine multi-stage finetuning methodology that gradually pushes the\nboundary of visual quality. Our study demonstrates that Imagine yourself\nsurpasses the state-of-the-art personalization model, exhibiting superior\ncapabilities in identity preservation, visual quality, and text alignment. This\nmodel establishes a robust foundation for various personalization applications.\nHuman evaluation results validate the model's SOTA superiority across all\naspects (identity preservation, text faithfulness, and visual appeal) compared\nto the previous personalization models.",
            "upvotes": 36,
            "discussionId": "66f0ecbaa4c40b65f651caed"
        },
        "publishedAt": "2024-09-23T02:51:57.482Z",
        "title": "Imagine yourself: Tuning-Free Personalized Image Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13346.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.13592",
            "authors": [
                {
                    "_id": "66f18738e32a9f85b62c26d3",
                    "user": {
                        "_id": "5f89da6c5d083370c711f37c",
                        "avatarUrl": "/avatars/c2f17a4a636973817fd5da2ae6dbaac3.svg",
                        "isPro": false,
                        "fullname": "Abhilash Nandy",
                        "user": "abhi1nandy2",
                        "type": "user"
                    },
                    "name": "Abhilash Nandy",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-23T16:29:36.598Z",
                    "hidden": false
                },
                {
                    "_id": "66f18738e32a9f85b62c26d4",
                    "user": {
                        "_id": "66054e097c41a7efbc1fa842",
                        "avatarUrl": "/avatars/11e6c01db1f962be46a2e9122bc3066b.svg",
                        "isPro": false,
                        "fullname": "Yash Agarwal",
                        "user": "yashagarwal",
                        "type": "user"
                    },
                    "name": "Yash Agarwal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T16:31:28.934Z",
                    "hidden": false
                },
                {
                    "_id": "66f18738e32a9f85b62c26d5",
                    "name": "Ashish Patwa",
                    "hidden": false
                },
                {
                    "_id": "66f18738e32a9f85b62c26d6",
                    "user": {
                        "_id": "61a1284f5470d2bc8d8563e9",
                        "avatarUrl": "/avatars/04563e6f022f91c58d642c7e14c7d7d0.svg",
                        "isPro": false,
                        "fullname": "Millon Madhur Das",
                        "user": "Sleepyhead",
                        "type": "user"
                    },
                    "name": "Millon Madhur Das",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T16:31:37.988Z",
                    "hidden": false
                },
                {
                    "_id": "66f18738e32a9f85b62c26d7",
                    "name": "Aman Bansal",
                    "hidden": false
                },
                {
                    "_id": "66f18738e32a9f85b62c26d8",
                    "name": "Ankit Raj",
                    "hidden": false
                },
                {
                    "_id": "66f18738e32a9f85b62c26d9",
                    "user": {
                        "_id": "66d1436c55c3f7d512051c2e",
                        "avatarUrl": "/avatars/8ba01c299a244f350fc91d552192f0b5.svg",
                        "isPro": false,
                        "fullname": "Pawan Goyal",
                        "user": "pawang-iitkgp",
                        "type": "user"
                    },
                    "name": "Pawan Goyal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T16:31:51.286Z",
                    "hidden": false
                },
                {
                    "_id": "66f18738e32a9f85b62c26da",
                    "name": "Niloy Ganguly",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T15:45:29.000Z",
            "title": "YesBut: A High-Quality Annotated Multimodal Dataset for evaluating\n  Satire Comprehension capability of Vision-Language Models",
            "summary": "Understanding satire and humor is a challenging task for even current\nVision-Language models. In this paper, we propose the challenging tasks of\nSatirical Image Detection (detecting whether an image is satirical),\nUnderstanding (generating the reason behind the image being satirical), and\nCompletion (given one half of the image, selecting the other half from 2 given\noptions, such that the complete image is satirical) and release a high-quality\ndataset YesBut, consisting of 2547 images, 1084 satirical and 1463\nnon-satirical, containing different artistic styles, to evaluate those tasks.\nEach satirical image in the dataset depicts a normal scenario, along with a\nconflicting scenario which is funny or ironic. Despite the success of current\nVision-Language Models on multimodal tasks such as Visual QA and Image\nCaptioning, our benchmarking experiments show that such models perform poorly\non the proposed tasks on the YesBut Dataset in Zero-Shot Settings w.r.t both\nautomated as well as human evaluation. Additionally, we release a dataset of\n119 real, satirical photographs for further research. The dataset and code are\navailable at https://github.com/abhi1nandy2/yesbut_dataset.",
            "upvotes": 14,
            "discussionId": "66f1873ae32a9f85b62c2729"
        },
        "publishedAt": "2024-09-23T13:58:27.694Z",
        "title": "YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/G7xDoNSwei0FaH-528Xyu.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/sVcioiYjXbiNK388DjUv6.png",
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/i_7ICIUGMcq5bT8IJbcvX.png",
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/YaE1SsMqcy8Y1ftWTLcAB.png",
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/qSByu-t0QDhs6tlUzuANx.png",
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/dGB5Xn8FAJlVYjcBgDHRG.png",
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/PGuEEQUn1WS0jkczvNeEm.png",
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/0LKrWiMD9bH8B74a_kwFc.png",
            "https://cdn-uploads.huggingface.co/production/uploads/5f89da6c5d083370c711f37c/mLADCtqIWwxlM8lh-X9CH.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13592.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/c2f17a4a636973817fd5da2ae6dbaac3.svg",
            "fullname": "Abhilash Nandy",
            "name": "abhi1nandy2",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.13598",
            "authors": [
                {
                    "_id": "66f0c7e20c00b14702737322",
                    "user": {
                        "_id": "66e714ffe1e454e8b8cb929c",
                        "avatarUrl": "/avatars/1f7acae68e43cfd50a00fa39ba2aa344.svg",
                        "isPro": false,
                        "fullname": "Johannes Schmude",
                        "user": "johannesschmude",
                        "type": "user"
                    },
                    "name": "Johannes Schmude",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:38:33.054Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737323",
                    "user": {
                        "_id": "6488f1d3e22a0081a561ec8f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6488f1d3e22a0081a561ec8f/RFk5nPfSOvHsJj1DWOJ0R.png",
                        "isPro": false,
                        "fullname": "Sujit Roy",
                        "user": "thesujitroy",
                        "type": "user"
                    },
                    "name": "Sujit Roy",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-23T16:29:38.744Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737324",
                    "user": {
                        "_id": "66abb2ad80170b585a774248",
                        "avatarUrl": "/avatars/d3ec6e41e3467b8bbba600505d098c9e.svg",
                        "isPro": false,
                        "fullname": "Will Trojak",
                        "user": "WillTrojak",
                        "type": "user"
                    },
                    "name": "Will Trojak",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:39:01.731Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737325",
                    "user": {
                        "_id": "64b84a418b53fb5dbde793fa",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b84a418b53fb5dbde793fa/Xb35aMd-EUAG1IDlwD_aF.jpeg",
                        "isPro": false,
                        "fullname": "Johannes Jakubik",
                        "user": "jhnnsjkbk",
                        "type": "user"
                    },
                    "name": "Johannes Jakubik",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:39:07.496Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737326",
                    "user": {
                        "_id": "630395877b50dd9d0a33a6c2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/630395877b50dd9d0a33a6c2/PvsZUOjlJ0MbdAvk0uaCw.jpeg",
                        "isPro": false,
                        "fullname": "Daniel Salles Civitarese",
                        "user": "ds6574",
                        "type": "user"
                    },
                    "name": "Daniel Salles Civitarese",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:39:12.922Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737327",
                    "name": "Shraddha Singh",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737328",
                    "user": {
                        "_id": "64c8fd55b0e61287787739a1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64c8fd55b0e61287787739a1/aJ73octpRoU-2TcjNZl8L.jpeg",
                        "isPro": false,
                        "fullname": "Julian Kuehnert",
                        "user": "jubeku",
                        "type": "user"
                    },
                    "name": "Julian Kuehnert",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:39:51.079Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737329",
                    "user": {
                        "_id": "64c92ddc0b2ba05b2f66aee1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64c92ddc0b2ba05b2f66aee1/7-7NFmk5DJPYOmqt4sOPL.jpeg",
                        "isPro": false,
                        "fullname": "Ankur Kumar",
                        "user": "ankurk017",
                        "type": "user"
                    },
                    "name": "Kumar Ankur",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-23T13:48:37.940Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273732a",
                    "name": "Aman Gupta",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273732b",
                    "user": {
                        "_id": "64429c9dc82791fbe15ffa8b",
                        "avatarUrl": "/avatars/cdaddb91652ac020e32a6af3e4e01a22.svg",
                        "isPro": false,
                        "fullname": "Christopher Phillips",
                        "user": "CEPhillips",
                        "type": "user"
                    },
                    "name": "Christopher E Phillips",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:40:59.955Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273732c",
                    "user": {
                        "_id": "66559f32ccdee62544fe08da",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66559f32ccdee62544fe08da/Gc8P9qDJFxgJ1J0gM1nQp.jpeg",
                        "isPro": false,
                        "fullname": "Romeo Kienzler",
                        "user": "romeokienzler",
                        "type": "user"
                    },
                    "name": "Romeo Kienzler",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:41:07.135Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273732d",
                    "user": {
                        "_id": "64c949eae761f4706136148d",
                        "avatarUrl": "/avatars/4f9ffff84838f34c4cac534c368a483d.svg",
                        "isPro": false,
                        "fullname": "Daniela Szwarcman",
                        "user": "daniszw",
                        "type": "user"
                    },
                    "name": "Daniela Szwarcman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:41:12.851Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273732e",
                    "user": {
                        "_id": "65119331b6bdfa5be9b9fa67",
                        "avatarUrl": "/avatars/3b37828c433e03c518e9563bacf83ba8.svg",
                        "isPro": false,
                        "fullname": "Vishal Gaur",
                        "user": "swordsaintlancelot",
                        "type": "user"
                    },
                    "name": "Vishal Gaur",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:41:37.252Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273732f",
                    "user": {
                        "_id": "651acaa0551c9a100b084a2e",
                        "avatarUrl": "/avatars/6a5f264cc7c9fe34bf9064ceed1d090d.svg",
                        "isPro": false,
                        "fullname": "Rajat Shinde",
                        "user": "omshinde",
                        "type": "user"
                    },
                    "name": "Rajat Shinde",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:41:46.374Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737330",
                    "name": "Rohit Lal",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737331",
                    "name": "Arlindo Da Silva",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737332",
                    "name": "Jorge Luis Guevara Diaz",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737333",
                    "user": {
                        "_id": "66e19458a533df3d82955b0c",
                        "avatarUrl": "/avatars/3352538065eff47963081f48570afe1f.svg",
                        "isPro": false,
                        "fullname": "Anne Jones",
                        "user": "annezj",
                        "type": "user"
                    },
                    "name": "Anne Jones",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:42:16.857Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737334",
                    "user": {
                        "_id": "652f01139a99dd6bf69af838",
                        "avatarUrl": "/avatars/3d0c514da97ad50e52d39d2824f175e2.svg",
                        "isPro": false,
                        "fullname": "Simon Pfreundschuh",
                        "user": "simonpf",
                        "type": "user"
                    },
                    "name": "Simon Pfreundschuh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:42:22.817Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737335",
                    "name": "Amy Lin",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737336",
                    "name": "Aditi Sheshadri",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737337",
                    "name": "Udaysankar Nair",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737338",
                    "user": {
                        "_id": "62794873bba7c62cbab2456e",
                        "avatarUrl": "/avatars/ab3b503a340ad47a8c7224c4add464e2.svg",
                        "isPro": false,
                        "fullname": "Valentine Anantharaj",
                        "user": "anantharajvg",
                        "type": "user"
                    },
                    "name": "Valentine Anantharaj",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:42:59.237Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b14702737339",
                    "user": {
                        "_id": "6661a9965ebb442b5040ae27",
                        "avatarUrl": "/avatars/66830cc5e56516b403e3e9191ba80129.svg",
                        "isPro": false,
                        "fullname": "Hendrik Hamann",
                        "user": "HHamann",
                        "type": "user"
                    },
                    "name": "Hendrik Hamann",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:43:06.095Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273733a",
                    "user": {
                        "_id": "64766671d6c79c9d0e16ab3e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64766671d6c79c9d0e16ab3e/nTgk6_e3ctuhwiG4E7-Go.jpeg",
                        "isPro": false,
                        "fullname": "Campbell Watson",
                        "user": "camelstation",
                        "type": "user"
                    },
                    "name": "Campbell Watson",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:43:13.152Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273733b",
                    "user": {
                        "_id": "64ba94321e53e10faf0c14ca",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ba94321e53e10faf0c14ca/leAHIQoy8nk74Mdut3MJ7.jpeg",
                        "isPro": false,
                        "fullname": "Manil Maskey",
                        "user": "manilmaskey",
                        "type": "user"
                    },
                    "name": "Manil Maskey",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:43:19.668Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273733c",
                    "name": "Tsengdar J Lee",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273733d",
                    "name": "Juan Bernabe Moreno",
                    "hidden": false
                },
                {
                    "_id": "66f0c7e20c00b1470273733e",
                    "name": "Rahul Ramachandran",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T15:53:17.000Z",
            "title": "Prithvi WxC: Foundation Model for Weather and Climate",
            "summary": "Triggered by the realization that AI emulators can rival the performance of\ntraditional numerical weather prediction models running on HPC systems, there\nis now an increasing number of large AI models that address use cases such as\nforecasting, downscaling, or nowcasting. While the parallel developments in the\nAI literature focus on foundation models -- models that can be effectively\ntuned to address multiple, different use cases -- the developments on the\nweather and climate side largely focus on single-use cases with particular\nemphasis on mid-range forecasting. We close this gap by introducing Prithvi\nWxC, a 2.3 billion parameter foundation model developed using 160 variables\nfrom the Modern-Era Retrospective Analysis for Research and Applications,\nVersion 2 (MERRA-2). Prithvi WxC employs an encoder-decoder-based architecture,\nincorporating concepts from various recent transformer models to effectively\ncapture both regional and global dependencies in the input data. The model has\nbeen designed to accommodate large token counts to model weather phenomena in\ndifferent topologies at fine resolutions. Furthermore, it is trained with a\nmixed objective that combines the paradigms of masked reconstruction with\nforecasting. We test the model on a set of challenging downstream tasks namely:\nAutoregressive rollout forecasting, Downscaling, Gravity wave flux\nparameterization, and Extreme events estimation. The pretrained model with 2.3\nbillion parameters, along with the associated fine-tuning workflows, has been\npublicly released as an open-source contribution via Hugging Face.",
            "upvotes": 13,
            "discussionId": "66f0c7e60c00b14702737434"
        },
        "publishedAt": "2024-09-23T02:56:33.660Z",
        "title": "Prithvi WxC: Foundation Model for Weather and Climate",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13598.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.13216",
            "authors": [
                {
                    "_id": "66f0c6b4831eacfcad5a970b",
                    "user": {
                        "_id": "642fd482450c0de9a1d1c8b5",
                        "avatarUrl": "/avatars/3765b121feb979e410f665bf20191161.svg",
                        "isPro": false,
                        "fullname": "yaoxunxu",
                        "user": "yaoxunxu",
                        "type": "user"
                    },
                    "name": "Yaoxun Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:32:36.922Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c6b4831eacfcad5a970c",
                    "user": {
                        "_id": "631b2dbd0f22997ce6728e27",
                        "avatarUrl": "/avatars/84dc35edbda6c071fcecec01918c5c56.svg",
                        "isPro": false,
                        "fullname": "Hangting Chen",
                        "user": "hangtingchen",
                        "type": "user"
                    },
                    "name": "Hangting Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:32:42.807Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c6b4831eacfcad5a970d",
                    "name": "Jianwei Yu",
                    "hidden": false
                },
                {
                    "_id": "66f0c6b4831eacfcad5a970e",
                    "name": "Wei Tan",
                    "hidden": false
                },
                {
                    "_id": "66f0c6b4831eacfcad5a970f",
                    "name": "Rongzhi Gu",
                    "hidden": false
                },
                {
                    "_id": "66f0c6b4831eacfcad5a9710",
                    "user": {
                        "_id": "6531768050f0ed02addafa95",
                        "avatarUrl": "/avatars/b6689d42ab2f994ba0f149fba7732261.svg",
                        "isPro": false,
                        "fullname": "Shun Lei",
                        "user": "lglg666",
                        "type": "user"
                    },
                    "name": "Shun Lei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:33:26.089Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c6b4831eacfcad5a9711",
                    "name": "Zhiwei Lin",
                    "hidden": false
                },
                {
                    "_id": "66f0c6b4831eacfcad5a9712",
                    "user": {
                        "_id": "6280e830e99dccaac4bbfde5",
                        "avatarUrl": "/avatars/9242b8d2826ce2f79af9bb794bba2b61.svg",
                        "isPro": false,
                        "fullname": "Zhiyong Wu",
                        "user": "zy001",
                        "type": "user"
                    },
                    "name": "Zhiyong Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:34:09.118Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T05:06:49.000Z",
            "title": "MuCodec: Ultra Low-Bitrate Music Codec",
            "summary": "Music codecs are a vital aspect of audio codec research, and ultra\nlow-bitrate compression holds significant importance for music transmission and\ngeneration. Due to the complexity of music backgrounds and the richness of\nvocals, solely relying on modeling semantic or acoustic information cannot\neffectively reconstruct music with both vocals and backgrounds. To address this\nissue, we propose MuCodec, specifically targeting music compression and\nreconstruction tasks at ultra low bitrates. MuCodec employs MuEncoder to\nextract both acoustic and semantic features, discretizes them with RVQ, and\nobtains Mel-VAE features via flow-matching. The music is then reconstructed\nusing a pre-trained MEL-VAE decoder and HiFi-GAN. MuCodec can reconstruct\nhigh-fidelity music at ultra low (0.35kbps) or high bitrates (1.35kbps),\nachieving the best results to date in both subjective and objective metrics.\nCode and Demo: https://xuyaoxun.github.io/MuCodec_demo/.",
            "upvotes": 13,
            "discussionId": "66f0c6b4831eacfcad5a9731"
        },
        "publishedAt": "2024-09-23T00:09:07.820Z",
        "title": "MuCodec: Ultra Low-Bitrate Music Codec",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13216.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.13690",
            "authors": [
                {
                    "_id": "66f0e6b12e2c3d8539f6f815",
                    "user": {
                        "_id": "655e75ea56e5ceaf052536f0",
                        "avatarUrl": "/avatars/ab3f84eef186f839f1dff5cf348c38c4.svg",
                        "isPro": false,
                        "fullname": "Chris Careaga",
                        "user": "ccareaga",
                        "type": "user"
                    },
                    "name": "Chris Careaga",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:44:16.008Z",
                    "hidden": false
                },
                {
                    "_id": "66f0e6b12e2c3d8539f6f816",
                    "name": "Yağız Aksoy",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T17:59:40.000Z",
            "title": "Colorful Diffuse Intrinsic Image Decomposition in the Wild",
            "summary": "Intrinsic image decomposition aims to separate the surface reflectance and\nthe effects from the illumination given a single photograph. Due to the\ncomplexity of the problem, most prior works assume a single-color illumination\nand a Lambertian world, which limits their use in illumination-aware image\nediting applications. In this work, we separate an input image into its diffuse\nalbedo, colorful diffuse shading, and specular residual components. We arrive\nat our result by gradually removing first the single-color illumination and\nthen the Lambertian-world assumptions. We show that by dividing the problem\ninto easier sub-problems, in-the-wild colorful diffuse shading estimation can\nbe achieved despite the limited ground-truth datasets. Our extended intrinsic\nmodel enables illumination-aware analysis of photographs and can be used for\nimage editing applications such as specularity removal and per-pixel white\nbalancing.",
            "upvotes": 8,
            "discussionId": "66f0e6b32e2c3d8539f6f871"
        },
        "publishedAt": "2024-09-23T02:25:36.043Z",
        "title": "Colorful Diffuse Intrinsic Image Decomposition in the Wild",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13690.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.13591",
            "authors": [
                {
                    "_id": "66f0c86916bffdccd54da55b",
                    "name": "Xuan Gao",
                    "hidden": false
                },
                {
                    "_id": "66f0c86916bffdccd54da55c",
                    "name": "Haiyao Xiao",
                    "hidden": false
                },
                {
                    "_id": "66f0c86916bffdccd54da55d",
                    "name": "Chenglai Zhong",
                    "hidden": false
                },
                {
                    "_id": "66f0c86916bffdccd54da55e",
                    "user": {
                        "_id": "6522b0095e7247c2917269c0",
                        "avatarUrl": "/avatars/746db425094a0d997446e0c0fe53a733.svg",
                        "isPro": false,
                        "fullname": "Hu Shimin",
                        "user": "sisyphe28",
                        "type": "user"
                    },
                    "name": "Shimin Hu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:37:06.926Z",
                    "hidden": false
                },
                {
                    "_id": "66f0c86916bffdccd54da55f",
                    "name": "Yudong Guo",
                    "hidden": false
                },
                {
                    "_id": "66f0c86916bffdccd54da560",
                    "name": "Juyong Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T15:45:13.000Z",
            "title": "Portrait Video Editing Empowered by Multimodal Generative Priors",
            "summary": "We introduce PortraitGen, a powerful portrait video editing method that\nachieves consistent and expressive stylization with multimodal prompts.\nTraditional portrait video editing methods often struggle with 3D and temporal\nconsistency, and typically lack in rendering quality and efficiency. To address\nthese issues, we lift the portrait video frames to a unified dynamic 3D\nGaussian field, which ensures structural and temporal coherence across frames.\nFurthermore, we design a novel Neural Gaussian Texture mechanism that not only\nenables sophisticated style editing but also achieves rendering speed over\n100FPS. Our approach incorporates multimodal inputs through knowledge distilled\nfrom large-scale 2D generative models. Our system also incorporates expression\nsimilarity guidance and a face-aware portrait editing module, effectively\nmitigating degradation issues associated with iterative dataset updates.\nExtensive experiments demonstrate the temporal consistency, editing efficiency,\nand superior rendering quality of our method. The broad applicability of the\nproposed approach is demonstrated through various applications, including\ntext-driven editing, image-driven editing, and relighting, highlighting its\ngreat potential to advance the field of video editing. Demo videos and released\ncode are provided in our project page: https://ustc3dv.github.io/PortraitGen/",
            "upvotes": 8,
            "discussionId": "66f0c86d16bffdccd54da6a5"
        },
        "publishedAt": "2024-09-23T00:16:24.308Z",
        "title": "Portrait Video Editing Empowered by Multimodal Generative Priors",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13591.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.13689",
            "authors": [
                {
                    "_id": "66f11acd16bffdccd567e57c",
                    "user": {
                        "_id": "64b7c3d5f72c6cd946dff515",
                        "avatarUrl": "/avatars/f579bc83b529782bbe6109f18d89837a.svg",
                        "isPro": false,
                        "fullname": "Ilpo Viertola",
                        "user": "bilpo",
                        "type": "user"
                    },
                    "name": "Ilpo Viertola",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:44:42.556Z",
                    "hidden": false
                },
                {
                    "_id": "66f11acd16bffdccd567e57d",
                    "user": {
                        "_id": "64b7c3d5f72c6cd946dff515",
                        "avatarUrl": "/avatars/f579bc83b529782bbe6109f18d89837a.svg",
                        "isPro": false,
                        "fullname": "Ilpo Viertola",
                        "user": "bilpo",
                        "type": "user"
                    },
                    "name": "Vladimir Iashin",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-09-23T07:37:50.179Z",
                    "hidden": false
                },
                {
                    "_id": "66f11acd16bffdccd567e57e",
                    "user": {
                        "_id": "651eb538fff19a2bc3aa2f1f",
                        "avatarUrl": "/avatars/8332a6803a5ae3c7bf5d7f9aa1e35983.svg",
                        "isPro": false,
                        "fullname": "Esa Rahtu",
                        "user": "erahtu",
                        "type": "user"
                    },
                    "name": "Esa Rahtu",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-09-23T07:37:50.179Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T17:59:01.000Z",
            "title": "Temporally Aligned Audio for Video with Autoregression",
            "summary": "We introduce V-AURA, the first autoregressive model to achieve high temporal\nalignment and relevance in video-to-audio generation. V-AURA uses a\nhigh-framerate visual feature extractor and a cross-modal audio-visual feature\nfusion strategy to capture fine-grained visual motion events and ensure precise\ntemporal alignment. Additionally, we propose VisualSound, a benchmark dataset\nwith high audio-visual relevance. VisualSound is based on VGGSound, a video\ndataset consisting of in-the-wild samples extracted from YouTube. During the\ncuration, we remove samples where auditory events are not aligned with the\nvisual ones. V-AURA outperforms current state-of-the-art models in temporal\nalignment and semantic relevance while maintaining comparable audio quality.\nCode, samples, VisualSound and models are available at\nhttps://v-aura.notion.site",
            "upvotes": 5,
            "discussionId": "66f11ace16bffdccd567e5ce"
        },
        "publishedAt": "2024-09-23T06:12:02.448Z",
        "title": "Temporally Aligned Audio for Video with Autoregression",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13689.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/f579bc83b529782bbe6109f18d89837a.svg",
            "fullname": "Ilpo Viertola",
            "name": "bilpo",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.13648",
            "authors": [
                {
                    "_id": "66f0dfa1507a27eac7ce7acd",
                    "user": {
                        "_id": "66deb739174e9c697101202f",
                        "avatarUrl": "/avatars/e63e133486c469868b93925517c6043e.svg",
                        "isPro": false,
                        "fullname": "Penghao Wang",
                        "user": "Penghowdy",
                        "type": "user"
                    },
                    "name": "Penghao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:47:47.845Z",
                    "hidden": false
                },
                {
                    "_id": "66f0dfa1507a27eac7ce7ace",
                    "name": "Zhirui Zhang",
                    "hidden": false
                },
                {
                    "_id": "66f0dfa1507a27eac7ce7acf",
                    "user": {
                        "_id": "64180cb3db24526c7c9b011e",
                        "avatarUrl": "/avatars/bcbfe1e18a2c6402d5db14520279b04b.svg",
                        "isPro": false,
                        "fullname": "wliao",
                        "user": "liaowang11",
                        "type": "user"
                    },
                    "name": "Liao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:48:37.407Z",
                    "hidden": false
                },
                {
                    "_id": "66f0dfa1507a27eac7ce7ad0",
                    "name": "Kaixin Yao",
                    "hidden": false
                },
                {
                    "_id": "66f0dfa1507a27eac7ce7ad1",
                    "name": "Siyuan Xie",
                    "hidden": false
                },
                {
                    "_id": "66f0dfa1507a27eac7ce7ad2",
                    "user": {
                        "_id": "63ffcec6e7767a89533b8f80",
                        "avatarUrl": "/avatars/b9e8673943741c2e7b80b15a061bb951.svg",
                        "isPro": false,
                        "fullname": "JINGYI Yu",
                        "user": "Daluuu",
                        "type": "user"
                    },
                    "name": "Jingyi Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:49:12.361Z",
                    "hidden": false
                },
                {
                    "_id": "66f0dfa1507a27eac7ce7ad3",
                    "user": {
                        "_id": "656ef1678d218bc3ce4b7845",
                        "avatarUrl": "/avatars/09e4091f486024c5fd97f77339096f8f.svg",
                        "isPro": false,
                        "fullname": "Minye Wu",
                        "user": "wuminye",
                        "type": "user"
                    },
                    "name": "Minye Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T07:49:18.290Z",
                    "hidden": false
                },
                {
                    "_id": "66f0dfa1507a27eac7ce7ad4",
                    "name": "Lan Xu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T16:54:27.000Z",
            "title": "V^3: Viewing Volumetric Videos on Mobiles via Streamable 2D Dynamic\n  Gaussians",
            "summary": "Experiencing high-fidelity volumetric video as seamlessly as 2D videos is a\nlong-held dream. However, current dynamic 3DGS methods, despite their high\nrendering quality, face challenges in streaming on mobile devices due to\ncomputational and bandwidth constraints. In this paper, we introduce\nV3(Viewing Volumetric Videos), a novel approach that enables\nhigh-quality mobile rendering through the streaming of dynamic Gaussians. Our\nkey innovation is to view dynamic 3DGS as 2D videos, facilitating the use of\nhardware video codecs. Additionally, we propose a two-stage training strategy\nto reduce storage requirements with rapid training speed. The first stage\nemploys hash encoding and shallow MLP to learn motion, then reduces the number\nof Gaussians through pruning to meet the streaming requirements, while the\nsecond stage fine tunes other Gaussian attributes using residual entropy loss\nand temporal loss to improve temporal continuity. This strategy, which\ndisentangles motion and appearance, maintains high rendering quality with\ncompact storage requirements. Meanwhile, we designed a multi-platform player to\ndecode and render 2D Gaussian videos. Extensive experiments demonstrate the\neffectiveness of V3, outperforming other methods by enabling\nhigh-quality rendering and streaming on common devices, which is unseen before.\nAs the first to stream dynamic Gaussians on mobile devices, our companion\nplayer offers users an unprecedented volumetric video experience, including\nsmooth scrolling and instant sharing. Our project page with source code is\navailable at https://authoritywang.github.io/v3/.",
            "upvotes": 5,
            "discussionId": "66f0dfa5507a27eac7ce7ba5"
        },
        "publishedAt": "2024-09-23T01:58:00.393Z",
        "title": "V^3: Viewing Volumetric Videos on Mobiles via Streamable 2D Dynamic Gaussians",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13648.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.12941",
            "authors": [
                {
                    "_id": "66ed96efce6e5db9b396f912",
                    "user": {
                        "_id": "6186fef1b1085ab638324e7f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6186fef1b1085ab638324e7f/BL6_WJCkxB-BatBUBilT8.jpeg",
                        "isPro": false,
                        "fullname": "Satya",
                        "user": "skrishna",
                        "type": "user"
                    },
                    "name": "Satyapriya Krishna",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-23T13:48:40.554Z",
                    "hidden": false
                },
                {
                    "_id": "66ed96efce6e5db9b396f913",
                    "user": {
                        "_id": "62b9f1034dde8074b78cc6f2",
                        "avatarUrl": "/avatars/2bde72c6b8baee2b31f318b3010e483a.svg",
                        "isPro": false,
                        "fullname": "Kalpesh Krishna",
                        "user": "kalpeshk2011",
                        "type": "user"
                    },
                    "name": "Kalpesh Krishna",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T16:30:53.112Z",
                    "hidden": false
                },
                {
                    "_id": "66ed96efce6e5db9b396f914",
                    "name": "Anhad Mohananey",
                    "hidden": false
                },
                {
                    "_id": "66ed96efce6e5db9b396f915",
                    "user": {
                        "_id": "651c3ddd09e70aeed232ff97",
                        "avatarUrl": "/avatars/aa92d8568ced53c932c79c7441d3b5da.svg",
                        "isPro": false,
                        "fullname": "Steven Schwarcz",
                        "user": "OMN",
                        "type": "user"
                    },
                    "name": "Steven Schwarcz",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-23T16:31:05.703Z",
                    "hidden": false
                },
                {
                    "_id": "66ed96efce6e5db9b396f916",
                    "name": "Adam Stambler",
                    "hidden": false
                },
                {
                    "_id": "66ed96efce6e5db9b396f917",
                    "name": "Shyam Upadhyay",
                    "hidden": false
                },
                {
                    "_id": "66ed96efce6e5db9b396f918",
                    "name": "Manaal Faruqui",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-19T17:52:07.000Z",
            "title": "Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented\n  Generation",
            "summary": "Large Language Models (LLMs) have demonstrated significant performance\nimprovements across various cognitive tasks. An emerging application is using\nLLMs to enhance retrieval-augmented generation (RAG) capabilities. These\nsystems require LLMs to understand user queries, retrieve relevant information,\nand synthesize coherent and accurate responses. Given the increasing real-world\ndeployment of such systems, comprehensive evaluation becomes crucial. To this\nend, we propose FRAMES (Factuality, Retrieval, And reasoning MEasurement Set),\na high-quality evaluation dataset designed to test LLMs' ability to provide\nfactual responses, assess retrieval capabilities, and evaluate the reasoning\nrequired to generate final answers. While previous work has provided datasets\nand benchmarks to evaluate these abilities in isolation, FRAMES offers a\nunified framework that provides a clearer picture of LLM performance in\nend-to-end RAG scenarios. Our dataset comprises challenging multi-hop questions\nthat require the integration of information from multiple sources. We present\nbaseline results demonstrating that even state-of-the-art LLMs struggle with\nthis task, achieving 0.40 accuracy with no retrieval. The accuracy is\nsignificantly improved with our proposed multi-step retrieval pipeline,\nachieving an accuracy of 0.66 (>50% improvement). We hope our work will help\nbridge evaluation gaps and assist in developing more robust and capable RAG\nsystems.",
            "upvotes": 3,
            "discussionId": "66ed96efce6e5db9b396f949"
        },
        "publishedAt": "2024-09-23T11:56:30.576Z",
        "title": "Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.12941.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6186fef1b1085ab638324e7f/BL6_WJCkxB-BatBUBilT8.jpeg",
            "fullname": "Satya",
            "name": "skrishna",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.11276",
            "authors": [
                {
                    "_id": "66f129857972f6224f3b5909",
                    "user": {
                        "_id": "637b9fba787dab5e6b349fbe",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637b9fba787dab5e6b349fbe/XyomA6tgZSdAv1tSHbzFN.jpeg",
                        "isPro": false,
                        "fullname": "Maria Rigaki",
                        "user": "marik0",
                        "type": "user"
                    },
                    "name": "Maria Rigaki",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-23T13:07:03.093Z",
                    "hidden": false
                },
                {
                    "_id": "66f129857972f6224f3b590a",
                    "name": "Carlos Catania",
                    "hidden": false
                },
                {
                    "_id": "66f129857972f6224f3b590b",
                    "name": "Sebastian Garcia",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-17T15:28:25.000Z",
            "title": "Hackphyr: A Local Fine-Tuned LLM Agent for Network Security Environments",
            "summary": "Large Language Models (LLMs) have shown remarkable potential across various\ndomains, including cybersecurity. Using commercial cloud-based LLMs may be\nundesirable due to privacy concerns, costs, and network connectivity\nconstraints. In this paper, we present Hackphyr, a locally fine-tuned LLM to be\nused as a red-team agent within network security environments. Our fine-tuned 7\nbillion parameter model can run on a single GPU card and achieves performance\ncomparable with much larger and more powerful commercial models such as GPT-4.\nHackphyr clearly outperforms other models, including GPT-3.5-turbo, and\nbaselines, such as Q-learning agents in complex, previously unseen scenarios.\nTo achieve this performance, we generated a new task-specific cybersecurity\ndataset to enhance the base model's capabilities. Finally, we conducted a\ncomprehensive analysis of the agents' behaviors that provides insights into the\nplanning abilities and potential shortcomings of such agents, contributing to\nthe broader understanding of LLM-based agents in cybersecurity contexts",
            "upvotes": 3,
            "discussionId": "66f129877972f6224f3b593a"
        },
        "publishedAt": "2024-09-23T11:55:50.486Z",
        "title": "Hackphyr: A Local Fine-Tuned LLM Agent for Network Security Environments",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/637b9fba787dab5e6b349fbe/A3v705GE8R3xvv30iERlP.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.11276.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637b9fba787dab5e6b349fbe/XyomA6tgZSdAv1tSHbzFN.jpeg",
            "fullname": "Maria Rigaki",
            "name": "marik0",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.13449",
            "authors": [
                {
                    "_id": "66f14c92caf6968847a713d1",
                    "user": {
                        "_id": "644378a96cea0db46dc96b39",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644378a96cea0db46dc96b39/wjGNaXjfhSdWr8kM6Amai.jpeg",
                        "isPro": false,
                        "fullname": "Ming Wang",
                        "user": "sci-m-wang",
                        "type": "user"
                    },
                    "name": "Ming Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-23T14:22:36.918Z",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713d2",
                    "name": "Yuanzhong Liu",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713d3",
                    "name": "Xiaoyu Liang",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713d4",
                    "name": "Yijie Huang",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713d5",
                    "name": "Daling Wang",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713d6",
                    "name": "Xiaocui Yang",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713d7",
                    "name": "Sijia Shen",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713d8",
                    "name": "Shi Feng",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713d9",
                    "name": "Xiaoming Zhang",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713da",
                    "name": "Chaofeng Guan",
                    "hidden": false
                },
                {
                    "_id": "66f14c92caf6968847a713db",
                    "name": "Yifei Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-20T12:30:03.000Z",
            "title": "Minstrel: Structural Prompt Generation with Multi-Agents Coordination\n  for Non-AI Experts",
            "summary": "LLMs have demonstrated commendable performance across diverse domains.\nNevertheless, formulating high-quality prompts to assist them in their work\nposes a challenge for non-AI experts. Existing research in prompt engineering\nsuggests somewhat scattered optimization principles and designs empirically\ndependent prompt optimizers. Unfortunately, these endeavors lack a structural\ndesign, incurring high learning costs and it is not conducive to the iterative\nupdating of prompts, especially for non-AI experts. Inspired by structured\nreusable programming languages, we propose LangGPT, a structural prompt design\nframework. Furthermore, we introduce Minstrel, a multi-generative agent system\nwith reflection to automate the generation of structural prompts. Experiments\nand the case study illustrate that structural prompts generated by Minstrel or\nwritten manually significantly enhance the performance of LLMs. Furthermore, we\nanalyze the ease of use of structural prompts through a user survey in our\nonline community.",
            "upvotes": 3,
            "discussionId": "66f14c93caf6968847a71436"
        },
        "publishedAt": "2024-09-23T09:44:21.437Z",
        "title": "Minstrel: Structural Prompt Generation with Multi-Agents Coordination for Non-AI Experts",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.13449.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644378a96cea0db46dc96b39/wjGNaXjfhSdWr8kM6Amai.jpeg",
            "fullname": "Ming Wang",
            "name": "sci-m-wang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]