[
    {
        "paper": {
            "id": "2408.16357",
            "authors": [
                {
                    "_id": "66d125133da2d178ceee1935",
                    "user": {
                        "_id": "64374254a701a7e744c033a1",
                        "avatarUrl": "/avatars/a103d27fe32c520cb51191920a5b548a.svg",
                        "isPro": false,
                        "fullname": "Shijia Yang",
                        "user": "shijiay",
                        "type": "user"
                    },
                    "name": "Shijia Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-08-30T07:49:37.279Z",
                    "hidden": false
                },
                {
                    "_id": "66d125133da2d178ceee1936",
                    "user": {
                        "_id": "642fb0309b2484d7d857dbae",
                        "avatarUrl": "/avatars/7b10993e665198e80bd6627bf584ed71.svg",
                        "isPro": false,
                        "fullname": "Bohan Zhai",
                        "user": "Borise",
                        "type": "user"
                    },
                    "name": "Bohan Zhai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:43:03.322Z",
                    "hidden": false
                },
                {
                    "_id": "66d125133da2d178ceee1937",
                    "user": {
                        "_id": "642bb8c87f152f6e72b8d3cd",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642bb8c87f152f6e72b8d3cd/MXxTssocydbabGZ6XFIic.png",
                        "isPro": false,
                        "fullname": "Quanzeng You",
                        "user": "Ye27",
                        "type": "user"
                    },
                    "name": "Quanzeng You",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:43:11.747Z",
                    "hidden": false
                },
                {
                    "_id": "66d125133da2d178ceee1938",
                    "user": {
                        "_id": "656d32d99ced9d5ff5846233",
                        "avatarUrl": "/avatars/e02f42e5a4f6ccfaa1aaf345eda47dea.svg",
                        "isPro": false,
                        "fullname": "Yuan JianBo",
                        "user": "WaterInSea",
                        "type": "user"
                    },
                    "name": "Jianbo Yuan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:43:22.508Z",
                    "hidden": false
                },
                {
                    "_id": "66d125133da2d178ceee1939",
                    "name": "Hongxia Yang",
                    "hidden": false
                },
                {
                    "_id": "66d125133da2d178ceee193a",
                    "user": {
                        "_id": "654ca71d5255ee86711b52c5",
                        "avatarUrl": "/avatars/52bf00fd74c8db5643c4daa185c678e6.svg",
                        "isPro": false,
                        "fullname": "Chenfeng Xu",
                        "user": "chenfengx",
                        "type": "user"
                    },
                    "name": "Chenfeng Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-08-30T07:18:01.667Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-29T08:56:48.000Z",
            "title": "Law of Vision Representation in MLLMs",
            "summary": "We present the \"Law of Vision Representation\" in multimodal large language\nmodels (MLLMs). It reveals a strong correlation between the combination of\ncross-modal alignment, correspondence in vision representation, and MLLM\nperformance. We quantify the two factors using the cross-modal Alignment and\nCorrespondence score (AC score). Through extensive experiments involving\nthirteen different vision representation settings and evaluations across eight\nbenchmarks, we find that the AC score is linearly correlated to model\nperformance. By leveraging this relationship, we are able to identify and train\nthe optimal vision representation only, which does not require finetuning the\nlanguage model every time, resulting in a 99.7% reduction in computational\ncost.",
            "upvotes": 51,
            "discussionId": "66d125143da2d178ceee1979"
        },
        "publishedAt": "2024-08-30T00:20:29.217Z",
        "title": "Law of Vision Representation in MLLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.16357.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/52bf00fd74c8db5643c4daa185c678e6.svg",
            "fullname": "Chenfeng Xu",
            "name": "chenfengx",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2408.16500",
            "authors": [
                {
                    "_id": "66d1255a3b8f08e1b2de17be",
                    "user": {
                        "_id": "62ecd24cb8764c7738ef2793",
                        "avatarUrl": "/avatars/c1b80b5c55f9d652c1aaac7919e1fa32.svg",
                        "isPro": false,
                        "fullname": "Wenyi Hong",
                        "user": "wenyi",
                        "type": "user"
                    },
                    "name": "Wenyi Hong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:19:24.884Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17bf",
                    "name": "Weihan Wang",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c0",
                    "name": "Ming Ding",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c1",
                    "user": {
                        "_id": "649d3d271bafbcc83acec930",
                        "avatarUrl": "/avatars/0c42aabf4c6601686c22cc1308c318de.svg",
                        "isPro": false,
                        "fullname": "Wenmeng Yu",
                        "user": "iyuge2",
                        "type": "user"
                    },
                    "name": "Wenmeng Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:24:30.771Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c2",
                    "user": {
                        "_id": "61bd8ac694bd578f7286181b",
                        "avatarUrl": "/avatars/ff14b64339217858927ae01c2b2fa28d.svg",
                        "isPro": false,
                        "fullname": "Qingsong Lv",
                        "user": "qingsonglv",
                        "type": "user"
                    },
                    "name": "Qingsong Lv",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:24:37.541Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c3",
                    "name": "Yan Wang",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c4",
                    "user": {
                        "_id": "65acc5afe2a2c8635614de43",
                        "avatarUrl": "/avatars/c5fce792792cc0b52ed7475d72460c58.svg",
                        "isPro": false,
                        "fullname": "Yean Cheng",
                        "user": "LiquidAmmonia",
                        "type": "user"
                    },
                    "name": "Yean Cheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:27:04.116Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c5",
                    "user": {
                        "_id": "6406db5cd684369027166986",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6406db5cd684369027166986/Zl-orrGcbY0RbfjfKszn1.jpeg",
                        "isPro": false,
                        "fullname": "Shiyu Huang",
                        "user": "ShiyuHuang",
                        "type": "user"
                    },
                    "name": "Shiyu Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:27:10.517Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c6",
                    "name": "Junhui Ji",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c7",
                    "name": "Zhao Xue",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c8",
                    "name": "Lei Zhao",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17c9",
                    "user": {
                        "_id": "6466d1640ed2f7a8cba87503",
                        "avatarUrl": "/avatars/652746e63dfeb5154ae7d34039d1a485.svg",
                        "isPro": false,
                        "fullname": "Zhuoyi Yang",
                        "user": "zyyangzy",
                        "type": "user"
                    },
                    "name": "Zhuoyi Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:28:04.753Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17ca",
                    "name": "Xiaotao Gu",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17cb",
                    "name": "Xiaohan Zhang",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17cc",
                    "user": {
                        "_id": "64d996d6bcab729cb400cb70",
                        "avatarUrl": "/avatars/3db57c8b643fba8302ed39d8cf0f4ddb.svg",
                        "isPro": false,
                        "fullname": "Guanyu Feng",
                        "user": "jiguanglizipao",
                        "type": "user"
                    },
                    "name": "Guanyu Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:54:14.645Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17cd",
                    "name": "Da Yin",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17ce",
                    "name": "Zihan Wang",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17cf",
                    "name": "Ji Qi",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17d0",
                    "user": {
                        "_id": "63f36b504745321de3510823",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1679311624745-63f36b504745321de3510823.jpeg",
                        "isPro": false,
                        "fullname": "Song XiXuan",
                        "user": "DrSong",
                        "type": "user"
                    },
                    "name": "Xixuan Song",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:50:05.317Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17d1",
                    "name": "Peng Zhang",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17d2",
                    "name": "Debing Liu",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17d3",
                    "name": "Bin Xu",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17d4",
                    "user": {
                        "_id": "65df8cbc2705d9672f55d1aa",
                        "avatarUrl": "/avatars/63e46f15bb76bd9d4508fd0f54f39829.svg",
                        "isPro": false,
                        "fullname": "Juanzi Li",
                        "user": "juanli",
                        "type": "user"
                    },
                    "name": "Juanzi Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:49:11.275Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17d5",
                    "user": {
                        "_id": "640e73bdfdeaae1390857b62",
                        "avatarUrl": "/avatars/cd6779e30f716002a7838ed93d5c0754.svg",
                        "isPro": false,
                        "fullname": "Yuxiao Dong",
                        "user": "yuxiaod",
                        "type": "user"
                    },
                    "name": "Yuxiao Dong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:49:02.883Z",
                    "hidden": false
                },
                {
                    "_id": "66d1255a3b8f08e1b2de17d6",
                    "user": {
                        "_id": "640dff05474aa6f89556677e",
                        "avatarUrl": "/avatars/1b4591c7322d649c797b3125148f1915.svg",
                        "isPro": false,
                        "fullname": "Jie Tang",
                        "user": "jerytang",
                        "type": "user"
                    },
                    "name": "Jie Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T07:48:54.483Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-29T12:59:12.000Z",
            "title": "CogVLM2: Visual Language Models for Image and Video Understanding",
            "summary": "Beginning with VisualGLM and CogVLM, we are continuously exploring VLMs in\npursuit of enhanced vision-language fusion, efficient higher-resolution\narchitecture, and broader modalities and applications. Here we propose the\nCogVLM2 family, a new generation of visual language models for image and video\nunderstanding including CogVLM2, CogVLM2-Video and GLM-4V. As an image\nunderstanding model, CogVLM2 inherits the visual expert architecture with\nimproved training recipes in both pre-training and post-training stages,\nsupporting input resolution up to 1344 times 1344 pixels. As a video\nunderstanding model, CogVLM2-Video integrates multi-frame input with timestamps\nand proposes automated temporal grounding data construction. Notably, CogVLM2\nfamily has achieved state-of-the-art results on benchmarks like MMBench,\nMM-Vet, TextVQA, MVBench and VCGBench. All models are open-sourced in\nhttps://github.com/THUDM/CogVLM2 and https://github.com/THUDM/GLM-4,\ncontributing to the advancement of the field.",
            "upvotes": 33,
            "discussionId": "66d1255c3b8f08e1b2de18b4"
        },
        "publishedAt": "2024-08-30T00:21:08.918Z",
        "title": "CogVLM2: Visual Language Models for Image and Video Understanding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.16500.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2408.16767",
            "authors": [
                {
                    "_id": "66d126dd5ab9ab8cb4d8974d",
                    "user": {
                        "_id": "6505a02f9310ce8c400edc63",
                        "avatarUrl": "/avatars/bbf781594fc8c812316711aa8e2797aa.svg",
                        "isPro": false,
                        "fullname": "Fangfu Liu",
                        "user": "Liuff23",
                        "type": "user"
                    },
                    "name": "Fangfu Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:46:29.326Z",
                    "hidden": false
                },
                {
                    "_id": "66d126dd5ab9ab8cb4d8974e",
                    "user": {
                        "_id": "64897b1f0ec897cfe579a399",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64897b1f0ec897cfe579a399/ICR_75b877BaSE94gjBuj.jpeg",
                        "isPro": false,
                        "fullname": "wenq",
                        "user": "wenqsun",
                        "type": "user"
                    },
                    "name": "Wenqiang Sun",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-08-30T13:08:54.418Z",
                    "hidden": false
                },
                {
                    "_id": "66d126dd5ab9ab8cb4d8974f",
                    "name": "Hanyang Wang",
                    "hidden": false
                },
                {
                    "_id": "66d126dd5ab9ab8cb4d89750",
                    "user": {
                        "_id": "64206b35e40f66bcd1e3c985",
                        "avatarUrl": "/avatars/a8f830d1c47702f642045399e59c9fe8.svg",
                        "isPro": false,
                        "fullname": "Yikai Wang",
                        "user": "yikaiw",
                        "type": "user"
                    },
                    "name": "Yikai Wang",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-08-30T01:57:21.093Z",
                    "hidden": false
                },
                {
                    "_id": "66d126dd5ab9ab8cb4d89751",
                    "name": "Haowen Sun",
                    "hidden": false
                },
                {
                    "_id": "66d126dd5ab9ab8cb4d89752",
                    "user": {
                        "_id": "65a420cd90e65dc39a6abe9e",
                        "avatarUrl": "/avatars/81ac5b749043e899f5017782409f9e28.svg",
                        "isPro": false,
                        "fullname": "yejunliang",
                        "user": "yejunliang23",
                        "type": "user"
                    },
                    "name": "Junliang Ye",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-08-30T07:17:57.430Z",
                    "hidden": false
                },
                {
                    "_id": "66d126dd5ab9ab8cb4d89753",
                    "name": "Jun Zhang",
                    "hidden": false
                },
                {
                    "_id": "66d126dd5ab9ab8cb4d89754",
                    "user": {
                        "_id": "66c8131afafc0fc87ca99650",
                        "avatarUrl": "/avatars/a6eeba2ccf011d5c9964fd38f85bd671.svg",
                        "isPro": false,
                        "fullname": "Yueqi Duan",
                        "user": "duanyueqi",
                        "type": "user"
                    },
                    "name": "Yueqi Duan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:56:21.321Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-29T17:59:40.000Z",
            "title": "ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion\n  Model",
            "summary": "Advancements in 3D scene reconstruction have transformed 2D images from the\nreal world into 3D models, producing realistic 3D results from hundreds of\ninput photos. Despite great success in dense-view reconstruction scenarios,\nrendering a detailed scene from insufficient captured views is still an\nill-posed optimization problem, often resulting in artifacts and distortions in\nunseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction\nparadigm that reframes the ambiguous reconstruction challenge as a temporal\ngeneration task. The key insight is to unleash the strong generative prior of\nlarge pre-trained video diffusion models for sparse-view reconstruction.\nHowever, 3D view consistency struggles to be accurately preserved in directly\ngenerated video frames from pre-trained models. To address this, given limited\ninput views, the proposed ReconX first constructs a global point cloud and\nencodes it into a contextual space as the 3D structure condition. Guided by the\ncondition, the video diffusion model then synthesizes video frames that are\nboth detail-preserved and exhibit a high degree of 3D consistency, ensuring the\ncoherence of the scene from various perspectives. Finally, we recover the 3D\nscene from the generated video through a confidence-aware 3D Gaussian Splatting\noptimization scheme. Extensive experiments on various real-world datasets show\nthe superiority of our ReconX over state-of-the-art methods in terms of quality\nand generalizability.",
            "upvotes": 21,
            "discussionId": "66d126de5ab9ab8cb4d897af"
        },
        "publishedAt": "2024-08-30T00:26:50.363Z",
        "title": "ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.16767.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2408.16532",
            "authors": [
                {
                    "_id": "66d127fd3b8f08e1b2df37f2",
                    "user": {
                        "_id": "65afc920091a8ca32b1b0e96",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65afc920091a8ca32b1b0e96/2FxZXNbe7FNQngX5BDzxQ.jpeg",
                        "isPro": false,
                        "fullname": "jishengpeng",
                        "user": "novateur",
                        "type": "user"
                    },
                    "name": "Shengpeng Ji",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:58:34.099Z",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37f3",
                    "user": {
                        "_id": "6268b9d887d7f9040e0787d3",
                        "avatarUrl": "/avatars/5d022d1e1d7f247e94928ef8ad04c613.svg",
                        "isPro": false,
                        "fullname": "jiang",
                        "user": "ziyue",
                        "type": "user"
                    },
                    "name": "Ziyue Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:58:44.803Z",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37f4",
                    "user": {
                        "_id": "657543227068a85089680147",
                        "avatarUrl": "/avatars/a0e3371cc018deec7f18a12181eda3b0.svg",
                        "isPro": false,
                        "fullname": "xize cheng",
                        "user": "Exgc",
                        "type": "user"
                    },
                    "name": "Xize Cheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:58:50.582Z",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37f5",
                    "name": "Yifu Chen",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37f6",
                    "user": {
                        "_id": "6436516d82a2792675db5632",
                        "avatarUrl": "/avatars/9a21c012b14960386e386fdc4aa0b3d4.svg",
                        "isPro": false,
                        "fullname": "MingHuiFang",
                        "user": "MingHuiFang",
                        "type": "user"
                    },
                    "name": "Minghui Fang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:59:25.771Z",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37f7",
                    "user": {
                        "_id": "655c2dc713309a611ba2f796",
                        "avatarUrl": "/avatars/4de401bba2ab9ac3b67f7a58adba0efb.svg",
                        "isPro": false,
                        "fullname": "Jialong Zuo",
                        "user": "jlking",
                        "type": "user"
                    },
                    "name": "Jialong Zuo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T08:59:37.211Z",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37f8",
                    "name": "Qian Yang",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37f9",
                    "name": "Ruiqi Li",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37fa",
                    "name": "Ziang Zhang",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37fb",
                    "name": "Xiaoda Yang",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37fc",
                    "user": {
                        "_id": "62f6556e04e5e02f82ac8531",
                        "avatarUrl": "/avatars/01024815aeaaf8c4721e937b3db68903.svg",
                        "isPro": false,
                        "fullname": "Rongjiehuang",
                        "user": "Rongjiehuang",
                        "type": "user"
                    },
                    "name": "Rongjie Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:00:56.236Z",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37fd",
                    "user": {
                        "_id": "66d149784b87a685cc663c39",
                        "avatarUrl": "/avatars/7b3018a4a8b147c3dc57ff84014f3279.svg",
                        "isPro": false,
                        "fullname": "Jiang Yidi",
                        "user": "Yidiii",
                        "type": "user"
                    },
                    "name": "Yidi Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:01:10.220Z",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37fe",
                    "name": "Qian Chen",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df37ff",
                    "user": {
                        "_id": "649cda50f97bd6fd7114333f",
                        "avatarUrl": "/avatars/ceadd0bb06a116eba5b45081f92d3243.svg",
                        "isPro": false,
                        "fullname": "Siqi Zheng",
                        "user": "ckzheng",
                        "type": "user"
                    },
                    "name": "Siqi Zheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:01:21.689Z",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df3800",
                    "name": "Wen Wang",
                    "hidden": false
                },
                {
                    "_id": "66d127fd3b8f08e1b2df3801",
                    "name": "Zhou Zhao",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-29T13:43:36.000Z",
            "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio\n  Language Modeling",
            "summary": "Language models have been effectively applied to modeling natural signals,\nsuch as images, video, speech, and audio. A crucial component of these models\nis the codec tokenizer, which compresses high-dimensional natural signals into\nlower-dimensional discrete tokens. In this paper, we introduce WavTokenizer,\nwhich offers several advantages over previous SOTA acoustic codec models in the\naudio domain: 1)extreme compression. By compressing the layers of quantizers\nand the temporal dimension of the discrete codec, one-second audio of 24kHz\nsampling rate requires only a single quantizer with 40 or 75 tokens. 2)improved\nsubjective quality. Despite the reduced number of tokens, WavTokenizer achieves\nstate-of-the-art reconstruction quality with outstanding UTMOS scores and\ninherently contains richer semantic information. Specifically, we achieve these\nresults by designing a broader VQ space, extended contextual windows, and\nimproved attention networks, as well as introducing a powerful multi-scale\ndiscriminator and an inverse Fourier transform structure. We conducted\nextensive reconstruction experiments in the domains of speech, audio, and\nmusic. WavTokenizer exhibited strong performance across various objective and\nsubjective metrics compared to state-of-the-art models. We also tested semantic\ninformation, VQ utilization, and adaptability to generative models.\nComprehensive ablation studies confirm the necessity of each module in\nWavTokenizer. The related code, demos, and pre-trained models are available at\nhttps://github.com/jishengpeng/WavTokenizer.",
            "upvotes": 20,
            "discussionId": "66d127fe3b8f08e1b2df384f"
        },
        "publishedAt": "2024-08-30T00:31:39.576Z",
        "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.16532.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2408.16768",
            "authors": [
                {
                    "_id": "66d11cfebd2cd7aee09aba4b",
                    "user": {
                        "_id": "647d9ab61a1fcad2fdbf2d3d",
                        "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
                        "isPro": true,
                        "fullname": "Ziyu Guo",
                        "user": "ZiyuG",
                        "type": "user"
                    },
                    "name": "Ziyu Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T12:47:12.670Z",
                    "hidden": false
                },
                {
                    "_id": "66d11cfebd2cd7aee09aba4c",
                    "name": "Renrui Zhang",
                    "hidden": false
                },
                {
                    "_id": "66d11cfebd2cd7aee09aba4d",
                    "name": "Xiangyang Zhu",
                    "hidden": false
                },
                {
                    "_id": "66d11cfebd2cd7aee09aba4e",
                    "name": "Chengzhuo Tong",
                    "hidden": false
                },
                {
                    "_id": "66d11cfebd2cd7aee09aba4f",
                    "name": "Peng Gao",
                    "hidden": false
                },
                {
                    "_id": "66d11cfebd2cd7aee09aba50",
                    "user": {
                        "_id": "62aba526cae4462c0c6caa0f",
                        "avatarUrl": "/avatars/430560ec2c2547f819225769ab432f30.svg",
                        "isPro": false,
                        "fullname": "Chunyuan Li",
                        "user": "Chunyuan24",
                        "type": "user"
                    },
                    "name": "Chunyuan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T12:48:39.941Z",
                    "hidden": false
                },
                {
                    "_id": "66d11cfebd2cd7aee09aba51",
                    "name": "Pheng-Ann Heng",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-29T17:59:45.000Z",
            "title": "SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners",
            "summary": "We introduce SAM2Point, a preliminary exploration adapting Segment Anything\nModel 2 (SAM 2) for zero-shot and promptable 3D segmentation. SAM2Point\ninterprets any 3D data as a series of multi-directional videos, and leverages\nSAM 2 for 3D-space segmentation, without further training or 2D-3D projection.\nOur framework supports various prompt types, including 3D points, boxes, and\nmasks, and can generalize across diverse scenarios, such as 3D objects, indoor\nscenes, outdoor environments, and raw sparse LiDAR. Demonstrations on multiple\n3D datasets, e.g., Objaverse, S3DIS, ScanNet, Semantic3D, and KITTI, highlight\nthe robust generalization capabilities of SAM2Point. To our best knowledge, we\npresent the most faithful implementation of SAM in 3D, which may serve as a\nstarting point for future research in promptable 3D segmentation. Online Demo:\nhttps://huggingface.co/spaces/ZiyuG/SAM2Point . Code:\nhttps://github.com/ZiyuGuo99/SAM2Point .",
            "upvotes": 16,
            "discussionId": "66d11d00bd2cd7aee09aba9b"
        },
        "publishedAt": "2024-08-30T00:29:44.129Z",
        "title": "SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.16768.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2408.16766",
            "authors": [
                {
                    "_id": "66d126452ba3de746a831367",
                    "user": {
                        "_id": "649f7b742bf2e21d955c1067",
                        "avatarUrl": "/avatars/270026405d5640886a86f961a001b057.svg",
                        "isPro": false,
                        "fullname": "xing",
                        "user": "xingpng",
                        "type": "user"
                    },
                    "name": "Peng Xing",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-08-30T07:17:59.868Z",
                    "hidden": false
                },
                {
                    "_id": "66d126452ba3de746a831368",
                    "user": {
                        "_id": "637745113a63a2983ffbde13",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669187672174-637745113a63a2983ffbde13.jpeg",
                        "isPro": false,
                        "fullname": "Haofan Wang",
                        "user": "wanghaofan",
                        "type": "user"
                    },
                    "name": "Haofan Wang",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-08-30T01:54:15.817Z",
                    "hidden": false
                },
                {
                    "_id": "66d126452ba3de746a831369",
                    "user": {
                        "_id": "64297212e5f33939cf3a3d9b",
                        "avatarUrl": "/avatars/bd21759ab5d7e526b99fcb7ed813ffb3.svg",
                        "isPro": false,
                        "fullname": "yanpeng_sun",
                        "user": "syp115",
                        "type": "user"
                    },
                    "name": "Yanpeng Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:04:22.878Z",
                    "hidden": false
                },
                {
                    "_id": "66d126452ba3de746a83136a",
                    "user": {
                        "_id": "65e2e93bfcaff433f7a87b43",
                        "avatarUrl": "/avatars/020e008a6a748df75227c51f331d3bce.svg",
                        "isPro": false,
                        "fullname": "Qixun Wang",
                        "user": "NOVAglow646",
                        "type": "user"
                    },
                    "name": "Qixun Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:04:29.075Z",
                    "hidden": false
                },
                {
                    "_id": "66d126452ba3de746a83136b",
                    "name": "Xu Bai",
                    "hidden": false
                },
                {
                    "_id": "66d126452ba3de746a83136c",
                    "user": {
                        "_id": "66adcb66db3168f9d1354062",
                        "avatarUrl": "/avatars/f21c03206e3d9395bd41a4ad78332ba8.svg",
                        "isPro": false,
                        "fullname": "Hao Ai",
                        "user": "hobbyaih",
                        "type": "user"
                    },
                    "name": "Hao Ai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:04:38.433Z",
                    "hidden": false
                },
                {
                    "_id": "66d126452ba3de746a83136d",
                    "name": "Renyuan Huang",
                    "hidden": false
                },
                {
                    "_id": "66d126452ba3de746a83136e",
                    "name": "Zechao Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-29T17:59:30.000Z",
            "title": "CSGO: Content-Style Composition in Text-to-Image Generation",
            "summary": "The diffusion model has shown exceptional capabilities in controlled image\ngeneration, which has further fueled interest in image style transfer. Existing\nworks mainly focus on training free-based methods (e.g., image inversion) due\nto the scarcity of specific data. In this study, we present a data construction\npipeline for content-style-stylized image triplets that generates and\nautomatically cleanses stylized data triplets. Based on this pipeline, we\nconstruct a dataset IMAGStyle, the first large-scale style transfer dataset\ncontaining 210k image triplets, available for the community to explore and\nresearch. Equipped with IMAGStyle, we propose CSGO, a style transfer model\nbased on end-to-end training, which explicitly decouples content and style\nfeatures employing independent feature injection. The unified CSGO implements\nimage-driven style transfer, text-driven stylized synthesis, and text\nediting-driven stylized synthesis. Extensive experiments demonstrate the\neffectiveness of our approach in enhancing style control capabilities in image\ngeneration. Additional visualization and access to the source code can be\nlocated on the project page: https://csgo-gen.github.io/.",
            "upvotes": 10,
            "discussionId": "66d126472ba3de746a831453"
        },
        "publishedAt": "2024-08-30T00:24:18.770Z",
        "title": "CSGO: Content-Style Composition in Text-to-Image Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.16766.png",
        "numComments": 5,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2408.16061",
            "authors": [
                {
                    "_id": "66d1246f332325ec078e997e",
                    "user": {
                        "_id": "65f475985528c0b13a7bdcce",
                        "avatarUrl": "/avatars/5cac4d77028fe64886396aeff9db3974.svg",
                        "isPro": false,
                        "fullname": "Hengyi Wang",
                        "user": "HengyiWang",
                        "type": "user"
                    },
                    "name": "Hengyi Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T12:46:10.208Z",
                    "hidden": false
                },
                {
                    "_id": "66d1246f332325ec078e997f",
                    "name": "Lourdes Agapito",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-28T18:01:00.000Z",
            "title": "3D Reconstruction with Spatial Memory",
            "summary": "We present Spann3R, a novel approach for dense 3D reconstruction from ordered\nor unordered image collections. Built on the DUSt3R paradigm, Spann3R uses a\ntransformer-based architecture to directly regress pointmaps from images\nwithout any prior knowledge of the scene or camera parameters. Unlike DUSt3R,\nwhich predicts per image-pair pointmaps each expressed in its local coordinate\nframe, Spann3R can predict per-image pointmaps expressed in a global coordinate\nsystem, thus eliminating the need for optimization-based global alignment. The\nkey idea of Spann3R is to manage an external spatial memory that learns to keep\ntrack of all previous relevant 3D information. Spann3R then queries this\nspatial memory to predict the 3D structure of the next frame in a global\ncoordinate system. Taking advantage of DUSt3R's pre-trained weights, and\nfurther fine-tuning on a subset of datasets, Spann3R shows competitive\nperformance and generalization ability on various unseen datasets and can\nprocess ordered image collections in real time. Project page:\nhttps://hengyiwang.github.io/projects/spanner",
            "upvotes": 6,
            "discussionId": "66d12475332325ec078e9b2e"
        },
        "publishedAt": "2024-08-30T00:16:31.487Z",
        "title": "3D Reconstruction with Spatial Memory",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.16061.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2408.15666",
            "authors": [
                {
                    "_id": "66d10278c02f48f9078b51fb",
                    "user": {
                        "_id": "6557a4b8a474e3962c9af99f",
                        "avatarUrl": "/avatars/e6b35c2531ac60168f6f80259c2e5e6f.svg",
                        "isPro": false,
                        "fullname": "Jillian Fisher",
                        "user": "jrfish",
                        "type": "user"
                    },
                    "name": "Jillian Fisher",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:08:43.982Z",
                    "hidden": false
                },
                {
                    "_id": "66d10278c02f48f9078b51fc",
                    "user": {
                        "_id": "637d38fcb8e573d75bedc033",
                        "avatarUrl": "/avatars/bf8437ae5eb751f6a609d04c4d6fb06d.svg",
                        "isPro": true,
                        "fullname": "Skyler Hallinan",
                        "user": "hallisky",
                        "type": "user"
                    },
                    "name": "Skyler Hallinan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-08-30T07:18:08.784Z",
                    "hidden": false
                },
                {
                    "_id": "66d10278c02f48f9078b51fd",
                    "user": {
                        "_id": "640928bd3461c51cf7378707",
                        "avatarUrl": "/avatars/429d1ba8327df82a8f8360c0f55e199c.svg",
                        "isPro": false,
                        "fullname": "Ximing Lu",
                        "user": "Ximing",
                        "type": "user"
                    },
                    "name": "Ximing Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:08:49.785Z",
                    "hidden": false
                },
                {
                    "_id": "66d10278c02f48f9078b51fe",
                    "name": "Mitchell Gordon",
                    "hidden": false
                },
                {
                    "_id": "66d10278c02f48f9078b51ff",
                    "name": "Zaid Harchaoui",
                    "hidden": false
                },
                {
                    "_id": "66d10278c02f48f9078b5200",
                    "user": {
                        "_id": "64d42729f63b01b7f676b176",
                        "avatarUrl": "/avatars/52e54bdd6a1fb6c774a40cd70f3d7925.svg",
                        "isPro": false,
                        "fullname": "Yejin Choi",
                        "user": "yejinchoinka",
                        "type": "user"
                    },
                    "name": "Yejin Choi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:09:24.173Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-28T09:35:15.000Z",
            "title": "StyleRemix: Interpretable Authorship Obfuscation via Distillation and\n  Perturbation of Style Elements",
            "summary": "Authorship obfuscation, rewriting a text to intentionally obscure the\nidentity of the author, is an important but challenging task. Current methods\nusing large language models (LLMs) lack interpretability and controllability,\noften ignoring author-specific stylistic features, resulting in less robust\nperformance overall.\n  To address this, we develop StyleRemix, an adaptive and interpretable\nobfuscation method that perturbs specific, fine-grained style elements of the\noriginal input text. StyleRemix uses pre-trained Low Rank Adaptation (LoRA)\nmodules to rewrite an input specifically along various stylistic axes (e.g.,\nformality and length) while maintaining low computational cost. StyleRemix\noutperforms state-of-the-art baselines and much larger LLMs in a variety of\ndomains as assessed by both automatic and human evaluation.\n  Additionally, we release AuthorMix, a large set of 30K high-quality,\nlong-form texts from a diverse set of 14 authors and 4 domains, and DiSC, a\nparallel corpus of 1,500 texts spanning seven style axes in 16 unique\ndirections",
            "upvotes": 5,
            "discussionId": "66d1027ac02f48f9078b5249"
        },
        "publishedAt": "2024-08-30T01:28:00.420Z",
        "title": "StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/637d38fcb8e573d75bedc033/q9MOl_ZEX82DmoIrDESIR.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.15666.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/bf8437ae5eb751f6a609d04c4d6fb06d.svg",
            "fullname": "Skyler Hallinan",
            "name": "hallisky",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2408.16046",
            "authors": [
                {
                    "_id": "66d123e173bc1d219a6a559a",
                    "user": {
                        "_id": "65adf6fbae773a8112f4b9ad",
                        "avatarUrl": "/avatars/38d2eb81bf1f9b8c4a1903d21c48f365.svg",
                        "isPro": false,
                        "fullname": "Jesse Cresswell",
                        "user": "JesseCresswell",
                        "type": "user"
                    },
                    "name": "Jesse C. Cresswell",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:09:43.553Z",
                    "hidden": false
                },
                {
                    "_id": "66d123e173bc1d219a6a559b",
                    "user": {
                        "_id": "666d972cf98a92bc89418c73",
                        "avatarUrl": "/avatars/1d81926bce5a8760e9e79321fada62f2.svg",
                        "isPro": false,
                        "fullname": "Taewoo Kim",
                        "user": "TaewooKim",
                        "type": "user"
                    },
                    "name": "Taewoo Kim",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-08-30T09:10:01.584Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-08-28T18:00:00.000Z",
            "title": "Scaling Up Diffusion and Flow-based XGBoost Models",
            "summary": "Novel machine learning methods for tabular data generation are often\ndeveloped on small datasets which do not match the scale required for\nscientific applications. We investigate a recent proposal to use XGBoost as the\nfunction approximator in diffusion and flow-matching models on tabular data,\nwhich proved to be extremely memory intensive, even on tiny datasets. In this\nwork, we conduct a critical analysis of the existing implementation from an\nengineering perspective, and show that these limitations are not fundamental to\nthe method; with better implementation it can be scaled to datasets 370x larger\nthan previously used. Our efficient implementation also unlocks scaling models\nto much larger sizes which we show directly leads to improved performance on\nbenchmark tasks. We also propose algorithmic improvements that can further\nbenefit resource usage and model performance, including multi-output trees\nwhich are well-suited to generative modeling. Finally, we present results on\nlarge-scale scientific datasets derived from experimental particle physics as\npart of the Fast Calorimeter Simulation Challenge. Code is available at\nhttps://github.com/layer6ai-labs/calo-forest.",
            "upvotes": 5,
            "discussionId": "66d123e273bc1d219a6a55ef"
        },
        "publishedAt": "2024-08-30T00:14:05.627Z",
        "title": "Scaling Up Diffusion and Flow-based XGBoost Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2408.16046.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    }
]