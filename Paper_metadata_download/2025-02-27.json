[
  {
    "paper": {
      "id": "2502.18934",
      "authors": [
        {
          "_id": "67bfe1bf4426925c82fe5953",
          "name": "Kanana LLM Team",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5954",
          "name": "Yunju Bak",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5955",
          "name": "Hojin Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5956",
          "name": "Minho Ryu",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5957",
          "name": "Jiyeon Ham",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5958",
          "name": "Seungjae Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5959",
          "name": "Daniel Wontae Nam",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595a",
          "name": "Taegyeong Eo",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595b",
          "name": "Donghun Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595c",
          "name": "Doohae Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595d",
          "name": "Boseop Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595e",
          "name": "Nayeon Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe595f",
          "name": "Jaesun Park",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5960",
          "name": "Hyunho Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5961",
          "name": "Hyunwoong Ko",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5962",
          "name": "Changmin Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5963",
          "name": "Kyoung-Woon On",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5964",
          "name": "Seulye Baeg",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5965",
          "name": "Junrae Cho",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5966",
          "name": "Sunghee Jung",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5967",
          "name": "Jieun Kang",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5968",
          "name": "EungGyun Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe5969",
          "name": "Eunhwa Kim",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596a",
          "name": "Byeongil Ko",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596b",
          "name": "Daniel Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596c",
          "name": "Minchul Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596d",
          "name": "Miok Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596e",
          "name": "Shinbok Lee",
          "hidden": false
        },
        {
          "_id": "67bfe1bf4426925c82fe596f",
          "name": "Gaeun Seo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T08:36:20.000Z",
      "title": "Kanana: Compute-efficient Bilingual Language Models",
      "summary": "We introduce Kanana, a series of bilingual language models that demonstrate\nexceeding performance in Korean and competitive performance in English. The\ncomputational cost of Kanana is significantly lower than that of\nstate-of-the-art models of similar size. The report details the techniques\nemployed during pre-training to achieve compute-efficient yet competitive\nmodels, including high quality data filtering, staged pre-training, depth\nup-scaling, and pruning and distillation. Furthermore, the report outlines the\nmethodologies utilized during the post-training of the Kanana models,\nencompassing supervised fine-tuning and preference optimization, aimed at\nenhancing their capability for seamless interaction with users. Lastly, the\nreport elaborates on plausible approaches used for language model adaptation to\nspecific scenarios, such as embedding, retrieval augmented generation, and\nfunction calling. The Kanana model series spans from 2.1B to 32.5B parameters\nwith 2.1B models (base, instruct, embedding) publicly released to promote\nresearch on Korean language models.",
      "upvotes": 34,
      "discussionId": "67bfe1c04426925c82fe59a1"
    },
    "publishedAt": "2025-02-26T23:05:13.440Z",
    "title": "Kanana: Compute-efficient Bilingual Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18934.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60436d159e905013ae8715d7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
      "fullname": "Minho Ryu",
      "name": "bzantium",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19400",
      "authors": [
        {
          "_id": "67bfd6f15db054ee3c5a766b",
          "name": "Max Ku",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766c",
          "user": {
            "_id": "6365d5baa7a1324ccd5ecdb9",
            "avatarUrl": "/avatars/636d3f410b878e451a878a6cf171dd53.svg",
            "isPro": false,
            "fullname": "Thomas Chong",
            "user": "chongcht",
            "type": "user"
          },
          "name": "Thomas Chong",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T03:58:44.647Z",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766d",
          "name": "Jonathan Leung",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766e",
          "name": "Krish Shah",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a766f",
          "name": "Alvin Yu",
          "hidden": false
        },
        {
          "_id": "67bfd6f15db054ee3c5a7670",
          "name": "Wenhu Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:50:09.000Z",
      "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem\n  Understanding",
      "summary": "Understanding domain-specific theorems often requires more than just\ntext-based reasoning; effective communication through structured visual\nexplanations is crucial for deeper comprehension. While large language models\n(LLMs) demonstrate strong performance in text-based theorem reasoning, their\nability to generate coherent and pedagogically meaningful visual explanations\nremains an open challenge. In this work, we introduce TheoremExplainAgent, an\nagentic approach for generating long-form theorem explanation videos (over 5\nminutes) using Manim animations. To systematically evaluate multimodal theorem\nexplanations, we propose TheoremExplainBench, a benchmark covering 240 theorems\nacross multiple STEM disciplines, along with 5 automated evaluation metrics.\nOur results reveal that agentic planning is essential for generating detailed\nlong-form videos, and the o3-mini agent achieves a success rate of 93.8% and an\noverall score of 0.77. However, our quantitative and qualitative studies show\nthat most of the videos produced exhibit minor issues with visual element\nlayout. Furthermore, multimodal explanations expose deeper reasoning flaws that\ntext-based explanations fail to reveal, highlighting the importance of\nmultimodal explanations.",
      "upvotes": 16,
      "discussionId": "67bfd6f25db054ee3c5a7699"
    },
    "publishedAt": "2025-02-26T22:07:49.438Z",
    "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19400.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6230
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19328",
      "authors": [
        {
          "_id": "67bfcb774d22a9379b29334c",
          "name": "Hao Peng",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334d",
          "name": "Yunjia Qi",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334e",
          "name": "Xiaozhi Wang",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b29334f",
          "name": "Zijun Yao",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293350",
          "name": "Bin Xu",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293351",
          "name": "Lei Hou",
          "hidden": false
        },
        {
          "_id": "67bfcb774d22a9379b293352",
          "name": "Juanzi Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T17:19:12.000Z",
      "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable\n  Correctness Signals for Reliable Reward Systems",
      "summary": "Reward models (RMs) are crucial for the training and inference-time scaling\nup of large language models (LLMs). However, existing reward models primarily\nfocus on human preferences, neglecting verifiable correctness signals which\nhave shown strong potential in training LLMs. In this paper, we propose agentic\nreward modeling, a reward system that combines reward models with verifiable\ncorrectness signals from different aspects to provide reliable rewards. We\nempirically implement a reward agent, named RewardAgent, that combines human\npreference rewards with two verifiable signals: factuality and instruction\nfollowing, to provide more reliable rewards. We conduct comprehensive\nexperiments on existing reward model benchmarks and inference time best-of-n\nsearches on real-world downstream tasks. RewardAgent significantly outperforms\nvanilla reward models, demonstrating its effectiveness. We further construct\ntraining preference pairs using RewardAgent and train an LLM with the DPO\nobjective, achieving superior performance on various NLP benchmarks compared to\nconventional reward models. Our codes are publicly released to facilitate\nfurther research (https://github.com/THU-KEG/Agentic-Reward-Modeling).",
      "upvotes": 9,
      "discussionId": "67bfcb784d22a9379b29338f"
    },
    "publishedAt": "2025-02-26T22:05:16.150Z",
    "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19328.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "625a5446f1063e7085d5178a",
      "avatarUrl": "/avatars/5e78186f13f74b14e01583e06ff6c4dc.svg",
      "fullname": "Hao Peng",
      "name": "Wesleythu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19361",
      "authors": [
        {
          "_id": "67bfe435ca6e3c22b6e29442",
          "name": "Yancheng He",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29443",
          "name": "Shilong Li",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29444",
          "name": "Jiaheng Liu",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29445",
          "name": "Weixun Wang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29446",
          "name": "Xingyuan Bu",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29447",
          "name": "Ge Zhang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29448",
          "name": "Zhongyuan Peng",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e29449",
          "name": "Zhaoxiang Zhang",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e2944a",
          "name": "Wenbo Su",
          "hidden": false
        },
        {
          "_id": "67bfe435ca6e3c22b6e2944b",
          "name": "Bo Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T17:59:27.000Z",
      "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought\n  Reasoning?",
      "summary": "Recently, o1-like models have drawn significant attention, where these models\nproduce the long Chain-of-Thought (CoT) reasoning steps to improve the\nreasoning abilities of existing Large Language Models (LLMs). In this paper, to\nunderstand the qualities of these long CoTs and measure the critique abilities\nof existing LLMs on these long CoTs, we introduce the DeltaBench, including the\ngenerated long CoTs from different o1-like models (e.g., QwQ, DeepSeek-R1) for\ndifferent reasoning tasks (e.g., Math, Code, General Reasoning), to measure the\nability to detect errors in long CoT reasoning. Based on DeltaBench, we first\nperform fine-grained analysis of the generated long CoTs to discover the\neffectiveness and efficiency of different o1-like models. Then, we conduct\nextensive evaluations of existing process reward models (PRMs) and critic\nmodels to detect the errors of each annotated process, which aims to\ninvestigate the boundaries and limitations of existing PRMs and critic models.\nFinally, we hope that DeltaBench could guide developers to better understand\nthe long CoT reasoning abilities of their models.",
      "upvotes": 8,
      "discussionId": "67bfe438ca6e3c22b6e2948e"
    },
    "publishedAt": "2025-02-26T23:04:47.406Z",
    "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19361.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65377c30e48353201e6fdda0",
      "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
      "fullname": "Jiaheng Liu",
      "name": "CheeryLJH",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18864",
      "authors": [
        {
          "_id": "67bfd957c2a9b64ab3f97aa7",
          "name": "Juraj Gottweis",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aa8",
          "name": "Wei-Hung Weng",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aa9",
          "name": "Alexander Daryin",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aaa",
          "name": "Tao Tu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aab",
          "name": "Anil Palepu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aac",
          "name": "Petar Sirkovic",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aad",
          "name": "Artiom Myaskovsky",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aae",
          "name": "Felix Weissenberger",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aaf",
          "name": "Keran Rong",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab0",
          "name": "Ryutaro Tanno",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab1",
          "name": "Khaled Saab",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab2",
          "name": "Dan Popovici",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab3",
          "name": "Jacob Blum",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab4",
          "name": "Fan Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab5",
          "name": "Katherine Chou",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab6",
          "name": "Avinatan Hassidim",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab7",
          "name": "Burak Gokturk",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab8",
          "name": "Amin Vahdat",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ab9",
          "name": "Pushmeet Kohli",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97aba",
          "name": "Yossi Matias",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abb",
          "name": "Andrew Carroll",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abc",
          "name": "Kavita Kulkarni",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abd",
          "name": "Nenad Tomasev",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abe",
          "name": "Yuan Guan",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97abf",
          "name": "Vikram Dhillon",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac0",
          "name": "Eeshit Dhaval Vaishnav",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac1",
          "name": "Byron Lee",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac2",
          "name": "Tiago R D Costa",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac3",
          "name": "José R Penadés",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac4",
          "name": "Gary Peltz",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac5",
          "name": "Yunhan Xu",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac6",
          "name": "Annalisa Pawlosky",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac7",
          "name": "Alan Karthikesalingam",
          "hidden": false
        },
        {
          "_id": "67bfd957c2a9b64ab3f97ac8",
          "name": "Vivek Natarajan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T06:17:13.000Z",
      "title": "Towards an AI co-scientist",
      "summary": "Scientific discovery relies on scientists generating novel hypotheses that\nundergo rigorous experimental validation. To augment this process, we introduce\nan AI co-scientist, a multi-agent system built on Gemini 2.0. The AI\nco-scientist is intended to help uncover new, original knowledge and to\nformulate demonstrably novel research hypotheses and proposals, building upon\nprior evidence and aligned to scientist-provided research objectives and\nguidance. The system's design incorporates a generate, debate, and evolve\napproach to hypothesis generation, inspired by the scientific method and\naccelerated by scaling test-time compute. Key contributions include: (1) a\nmulti-agent architecture with an asynchronous task execution framework for\nflexible compute scaling; (2) a tournament evolution process for self-improving\nhypotheses generation. Automated evaluations show continued benefits of\ntest-time compute, improving hypothesis quality. While general purpose, we\nfocus development and validation in three biomedical areas: drug repurposing,\nnovel target discovery, and explaining mechanisms of bacterial evolution and\nanti-microbial resistance. For drug repurposing, the system proposes candidates\nwith promising validation findings, including candidates for acute myeloid\nleukemia that show tumor inhibition in vitro at clinically applicable\nconcentrations. For novel target discovery, the AI co-scientist proposed new\nepigenetic targets for liver fibrosis, validated by anti-fibrotic activity and\nliver cell regeneration in human hepatic organoids. Finally, the AI\nco-scientist recapitulated unpublished experimental results via a parallel in\nsilico discovery of a novel gene transfer mechanism in bacterial evolution.\nThese results, detailed in separate, co-timed reports, demonstrate the\npotential to augment biomedical and scientific discovery and usher an era of AI\nempowered scientists.",
      "upvotes": 7,
      "discussionId": "67bfd958c2a9b64ab3f97afa"
    },
    "publishedAt": "2025-02-26T22:18:06.494Z",
    "title": "Towards an AI co-scientist",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18864.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6230
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17955",
      "authors": [
        {
          "_id": "67bff526ca6e3c22b6e89d71",
          "user": {
            "_id": "65d2f1e0fe21569868393411",
            "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
            "isPro": false,
            "fullname": "Tushar Aggarwal",
            "user": "AggarwalTushar",
            "type": "user"
          },
          "name": "Tushar Aggarwal",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T05:16:24.257Z",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d72",
          "name": "Kumar Tanmay",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d73",
          "name": "Ayush Agrawal",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d74",
          "name": "Kumar Ayush",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d75",
          "name": "Hamid Palangi",
          "hidden": false
        },
        {
          "_id": "67bff526ca6e3c22b6e89d76",
          "name": "Paul Pu Liang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-25T08:27:18.000Z",
      "title": "Language Models' Factuality Depends on the Language of Inquiry",
      "summary": "Multilingual language models (LMs) are expected to recall factual knowledge\nconsistently across languages, yet they often fail to transfer knowledge\nbetween languages even when they possess the correct information in one of the\nlanguages. For example, we find that an LM may correctly identify Rashed Al\nShashai as being from Saudi Arabia when asked in Arabic, but consistently fails\nto do so when asked in English or Swahili. To systematically investigate this\nlimitation, we introduce a benchmark of 10,000 country-related facts across 13\nlanguages and propose three novel metrics: Factual Recall Score, Knowledge\nTransferability Score, and Cross-Lingual Factual Knowledge Transferability\nScore-to quantify factual recall and knowledge transferability in LMs across\ndifferent languages. Our results reveal fundamental weaknesses in today's\nstate-of-the-art LMs, particularly in cross-lingual generalization where models\nfail to transfer knowledge effectively across different languages, leading to\ninconsistent performance sensitive to the language used. Our findings emphasize\nthe need for LMs to recognize language-specific factual reliability and\nleverage the most trustworthy information across languages. We release our\nbenchmark and evaluation framework to drive future research in multilingual\nknowledge transfer.",
      "upvotes": 6,
      "discussionId": "67bff528ca6e3c22b6e89ddd"
    },
    "publishedAt": "2025-02-27T00:17:58.262Z",
    "title": "Language Models' Factuality Depends on the Language of Inquiry",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17955.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65d2f1e0fe21569868393411",
      "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
      "fullname": "Tushar Aggarwal",
      "name": "AggarwalTushar",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.16776",
      "authors": [
        {
          "_id": "67bfd8d546083445aacb4605",
          "name": "Zhexin Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4606",
          "name": "Leqi Lei",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4607",
          "name": "Junxiao Yang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4608",
          "name": "Xijie Huang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4609",
          "name": "Yida Lu",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460a",
          "name": "Shiyao Cui",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460b",
          "name": "Renmiao Chen",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460c",
          "name": "Qinglin Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460d",
          "name": "Xinyuan Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460e",
          "name": "Hao Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb460f",
          "name": "Hao Li",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4610",
          "name": "Xianqi Lei",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4611",
          "name": "Chengwei Pan",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4612",
          "name": "Lei Sha",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4613",
          "name": "Hongning Wang",
          "hidden": false
        },
        {
          "_id": "67bfd8d546083445aacb4614",
          "name": "Minlie Huang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T02:11:52.000Z",
      "title": "AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and\n  Improvement",
      "summary": "As AI models are increasingly deployed across diverse real-world scenarios,\nensuring their safety remains a critical yet underexplored challenge. While\nsubstantial efforts have been made to evaluate and enhance AI safety, the lack\nof a standardized framework and comprehensive toolkit poses significant\nobstacles to systematic research and practical adoption. To bridge this gap, we\nintroduce AISafetyLab, a unified framework and toolkit that integrates\nrepresentative attack, defense, and evaluation methodologies for AI safety.\nAISafetyLab features an intuitive interface that enables developers to\nseamlessly apply various techniques while maintaining a well-structured and\nextensible codebase for future advancements. Additionally, we conduct empirical\nstudies on Vicuna, analyzing different attack and defense strategies to provide\nvaluable insights into their comparative effectiveness. To facilitate ongoing\nresearch and development in AI safety, AISafetyLab is publicly available at\nhttps://github.com/thu-coai/AISafetyLab, and we are committed to its continuous\nmaintenance and improvement.",
      "upvotes": 4,
      "discussionId": "67bfd8d646083445aacb464f"
    },
    "publishedAt": "2025-02-26T22:16:03.582Z",
    "title": "AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16776.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "61b58aa0d65058ce70beb98c",
      "avatarUrl": "/avatars/aefd9271b891abc6dd2ded1a30eebca4.svg",
      "fullname": "Zhexin Zhang",
      "name": "nonstopfor",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18906",
      "authors": [
        {
          "_id": "67bfd5d2381f8fcb67e5ad36",
          "name": "Jiani Zheng",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad37",
          "name": "Lu Wang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad38",
          "name": "Fangkai Yang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad39",
          "name": "Chaoyun Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3a",
          "name": "Lingrui Mei",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3b",
          "name": "Wenjie Yin",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3c",
          "name": "Qingwei Lin",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3d",
          "name": "Dongmei Zhang",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3e",
          "name": "Saravan Rajmohan",
          "hidden": false
        },
        {
          "_id": "67bfd5d2381f8fcb67e5ad3f",
          "name": "Qi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T07:52:02.000Z",
      "title": "VEM: Environment-Free Exploration for Training GUI Agent with Value\n  Environment Model",
      "summary": "Training Vision-Language Models (VLMs) for Graphical User Interfaces (GUI)\nagents via Reinforcement Learning (RL) faces critical challenges:\nenvironment-based RL requires costly interactions, while environment-free\nmethods struggle with distribution shift and reward generalization. We propose\nan environment-free RL framework that decouples value estimation from policy\noptimization by leveraging a pretrained Value Environment Model (VEM). VEM\npredicts state-action values directly from offline data, distilling human-like\npriors about GUI interaction outcomes without requiring next-state prediction\nor environmental feedback. This avoids compounding errors and enhances\nresilience to UI changes by focusing on semantic reasoning (e.g., Does this\naction advance the user's goal?). The framework operates in two stages: (1)\npretraining VEM to estimate long-term action utilities and (2) guiding policy\nexploration with frozen VEM signals, enabling layout-agnostic GUI automation.\nEvaluated on Android-in-the-Wild benchmarks, VEM achieves state-of-the-art\nperformance in both offline and online settings, outperforming environment-free\nbaselines significantly and matching environment-based approaches without\ninteraction costs. Importantly, VEM demonstrates that semantic-aware value\nestimation can achieve comparable performance with online-trained methods.",
      "upvotes": 4,
      "discussionId": "67bfd5d7381f8fcb67e5ae3d"
    },
    "publishedAt": "2025-02-26T22:02:50.690Z",
    "title": "VEM: Environment-Free Exploration for Training GUI Agent with Value Environment Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18906.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "654dbac9938fbf1e696be8aa",
      "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
      "fullname": "Chaoyun Zhang",
      "name": "vyokky",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19414",
      "authors": [
        {
          "_id": "67c01587925b73feaf61ac41",
          "name": "Shiven Sinha",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac42",
          "name": "Shashwat Goel",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac43",
          "name": "Ponnurangam Kumaraguru",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac44",
          "name": "Jonas Geiping",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac45",
          "name": "Matthias Bethge",
          "hidden": false
        },
        {
          "_id": "67c01587925b73feaf61ac46",
          "name": "Ameya Prabhu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T18:58:13.000Z",
      "title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with\n  Counterexample Creation",
      "summary": "There is growing excitement about the potential of Language Models (LMs) to\naccelerate scientific discovery. Falsifying hypotheses is key to scientific\nprogress, as it allows claims to be iteratively refined over time. This process\nrequires significant researcher effort, reasoning, and ingenuity. Yet current\nbenchmarks for LMs predominantly assess their ability to generate solutions\nrather than challenge them. We advocate for developing benchmarks that evaluate\nthis inverse capability - creating counterexamples for subtly incorrect\nsolutions. To demonstrate this approach, we start with the domain of\nalgorithmic problem solving, where counterexamples can be evaluated\nautomatically using code execution. Specifically, we introduce REFUTE, a\ndynamically updating benchmark that includes recent problems and incorrect\nsubmissions from programming competitions, where human experts successfully\nidentified counterexamples. Our analysis finds that the best reasoning agents,\neven OpenAI o3-mini (high) with code execution feedback, can create\ncounterexamples for only <9% of incorrect solutions in REFUTE, even though\nratings indicate its ability to solve up to 48% of these problems from scratch.\nWe hope our work spurs progress in evaluating and enhancing LMs' ability to\nfalsify incorrect solutions - a capability that is crucial for both\naccelerating research and making models self-improve through reliable\nreflective reasoning.",
      "upvotes": 3,
      "discussionId": "67c01588925b73feaf61ad2c"
    },
    "publishedAt": "2025-02-27T02:36:29.037Z",
    "title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19414.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6506832221ac448013f94995",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6506832221ac448013f94995/sVUI1JV4Dxan5l-MqNze4.jpeg",
      "fullname": "Shashwat Goel",
      "name": "shash42",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19204",
      "authors": [
        {
          "_id": "67bfd735ca6e3c22b6de43c7",
          "name": "Xiankang He",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43c8",
          "name": "Dongyan Guo",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43c9",
          "name": "Hongji Li",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43ca",
          "name": "Ruibo Li",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43cb",
          "name": "Ying Cui",
          "hidden": false
        },
        {
          "_id": "67bfd735ca6e3c22b6de43cc",
          "name": "Chi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T15:10:05.000Z",
      "title": "Distill Any Depth: Distillation Creates a Stronger Monocular Depth\n  Estimator",
      "summary": "Monocular depth estimation (MDE) aims to predict scene depth from a single\nRGB image and plays a crucial role in 3D scene understanding. Recent advances\nin zero-shot MDE leverage normalized depth representations and\ndistillation-based learning to improve generalization across diverse scenes.\nHowever, current depth normalization methods for distillation, relying on\nglobal normalization, can amplify noisy pseudo-labels, reducing distillation\neffectiveness. In this paper, we systematically analyze the impact of different\ndepth normalization strategies on pseudo-label distillation. Based on our\nfindings, we propose Cross-Context Distillation, which integrates global and\nlocal depth cues to enhance pseudo-label quality. Additionally, we introduce a\nmulti-teacher distillation framework that leverages complementary strengths of\ndifferent depth estimation models, leading to more robust and accurate depth\npredictions. Extensive experiments on benchmark datasets demonstrate that our\napproach significantly outperforms state-of-the-art methods, both\nquantitatively and qualitatively.",
      "upvotes": 3,
      "discussionId": "67bfd736ca6e3c22b6de441e"
    },
    "publishedAt": "2025-02-26T22:10:20.646Z",
    "title": "Distill Any Depth: Distillation Creates a Stronger Monocular Depth Estimator",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64196320ed725fef64419c2a/k13rSuJPlDkMtzwdHXCXm.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19204.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64196320ed725fef64419c2a",
      "avatarUrl": "/avatars/96feb22fb5e8931d6c9e0ea06148266f.svg",
      "fullname": "Chi Zhang",
      "name": "DrChiZhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.18772",
      "authors": [
        {
          "_id": "67bfc297ca6e3c22b6d99c78",
          "name": "Xueqing Peng",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c79",
          "name": "Triantafillos Papadopoulos",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7a",
          "name": "Efstathia Soufleri",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7b",
          "name": "Polydoros Giannouris",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7c",
          "name": "Ruoyu Xiang",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7d",
          "name": "Yan Wang",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7e",
          "name": "Lingfei Qian",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c7f",
          "user": {
            "_id": "63b58ed5889aa6707f0bb0f4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
            "isPro": true,
            "fullname": "Jimin Huang",
            "user": "jiminHuang",
            "type": "user"
          },
          "name": "Jimin Huang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T01:40:40.189Z",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c80",
          "name": "Qianqian Xie",
          "hidden": false
        },
        {
          "_id": "67bfc297ca6e3c22b6d99c81",
          "name": "Sophia Ananiadou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T03:04:01.000Z",
      "title": "Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance",
      "summary": "Despite Greece's pivotal role in the global economy, large language models\n(LLMs) remain underexplored for Greek financial context due to the linguistic\ncomplexity of Greek and the scarcity of domain-specific datasets. Previous\nefforts in multilingual financial natural language processing (NLP) have\nexposed considerable performance disparities, yet no dedicated Greek financial\nbenchmarks or Greek-specific financial LLMs have been developed until now. To\nbridge this gap, we introduce Plutus-ben, the first Greek Financial Evaluation\nBenchmark, and Plutus-8B, the pioneering Greek Financial LLM, fine-tuned with\nGreek domain-specific data. Plutus-ben addresses five core financial NLP tasks\nin Greek: numeric and textual named entity recognition, question answering,\nabstractive summarization, and topic classification, thereby facilitating\nsystematic and reproducible LLM assessments. To underpin these tasks, we\npresent three novel, high-quality Greek financial datasets, thoroughly\nannotated by expert native Greek speakers, augmented by two existing resources.\nOur comprehensive evaluation of 22 LLMs on Plutus-ben reveals that Greek\nfinancial NLP remains challenging due to linguistic complexity, domain-specific\nterminology, and financial reasoning gaps. These findings underscore the\nlimitations of cross-lingual transfer, the necessity for financial expertise in\nGreek-trained models, and the challenges of adapting financial LLMs to Greek\ntext. We release Plutus-ben, Plutus-8B, and all associated datasets publicly to\npromote reproducible research and advance Greek financial NLP, fostering\nbroader multilingual inclusivity in finance.",
      "upvotes": 2,
      "discussionId": "67bfc298ca6e3c22b6d99caa"
    },
    "publishedAt": "2025-02-27T00:08:09.082Z",
    "title": "Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18772.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63b58ed5889aa6707f0bb0f4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
      "fullname": "Jimin Huang",
      "name": "jiminHuang",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.19279",
      "authors": [
        {
          "_id": "67bffaca3f838c1e33e074e7",
          "name": "Honglin Guo",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074e8",
          "name": "Kai Lv",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074e9",
          "name": "Qipeng Guo",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ea",
          "name": "Tianyi Liang",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074eb",
          "name": "Zhiheng Xi",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ec",
          "name": "Demin Song",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ed",
          "name": "Qiuyinzhe Zhang",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ee",
          "name": "Yu Sun",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074ef",
          "name": "Kai Chen",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074f0",
          "name": "Xipeng Qiu",
          "hidden": false
        },
        {
          "_id": "67bffaca3f838c1e33e074f1",
          "name": "Tao Gui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T16:33:41.000Z",
      "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
      "summary": "Language model heavily depends on high-quality data for optimal performance.\nExisting approaches rely on manually designed heuristics, the perplexity of\nexisting models, training classifiers, or careful prompt engineering, which\nrequire significant expert experience and human annotation effort while\nintroduce biases. We introduce CritiQ, a novel data selection method that\nautomatically mines criteria from human preferences for data quality with only\nsim30 human-annotated pairs and performs efficient data selection. The main\ncomponent, CritiQ Flow, employs a manager agent to evolve quality criteria and\nworker agents to make pairwise judgments. We build a knowledge base that\nextracts quality criteria from previous work to boost CritiQ Flow. Compared to\nperplexity- and classifier- based methods, verbal criteria are more\ninterpretable and possess reusable value. After deriving the criteria, we train\nthe CritiQ Scorer to give quality scores and perform efficient data selection.\nWe demonstrate the effectiveness of our method in the code, math, and logic\ndomains, achieving high accuracy on human-annotated test sets. To validate the\nquality of the selected data, we continually train Llama 3.1 models and observe\nimproved performance on downstream tasks compared to uniform sampling. Ablation\nstudies validate the benefits of the knowledge base and the reflection process.\nWe analyze how criteria evolve and the effectiveness of majority voting.",
      "upvotes": 1,
      "discussionId": "67bffacc3f838c1e33e075a2"
    },
    "publishedAt": "2025-02-27T00:47:02.948Z",
    "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19279.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "638ef0b0c67af472d31674a6",
      "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
      "fullname": "Honglin Guo",
      "name": "KYLN24",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.17540",
      "authors": [
        {
          "_id": "67bff9608d761fc6a75e24ad",
          "name": "Rohit Saxena",
          "hidden": false
        },
        {
          "_id": "67bff9608d761fc6a75e24ae",
          "name": "Pasquale Minervini",
          "hidden": false
        },
        {
          "_id": "67bff9608d761fc6a75e24af",
          "name": "Frank Keller",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-24T18:35:39.000Z",
      "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
      "summary": "Generating accurate and concise textual summaries from multimodal documents\nis challenging, especially when dealing with visually complex content like\nscientific posters. We introduce PosterSum, a novel benchmark to advance the\ndevelopment of vision-language models that can understand and summarize\nscientific posters into research paper abstracts. Our dataset contains 16,305\nconference posters paired with their corresponding abstracts as summaries. Each\nposter is provided in image format and presents diverse visual understanding\nchallenges, such as complex layouts, dense text regions, tables, and figures.\nWe benchmark state-of-the-art Multimodal Large Language Models (MLLMs) on\nPosterSum and demonstrate that they struggle to accurately interpret and\nsummarize scientific posters. We propose Segment & Summarize, a hierarchical\nmethod that outperforms current MLLMs on automated metrics, achieving a 3.14%\ngain in ROUGE-L. This will serve as a starting point for future research on\nposter summarization.",
      "upvotes": 1,
      "discussionId": "67bff96d8d761fc6a75e27a0"
    },
    "publishedAt": "2025-02-27T00:37:24.965Z",
    "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17540.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "657ccbf2869d5bb0e53b482f",
      "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
      "fullname": "Rohit Saxena",
      "name": "rohitsaxena",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.16284",
      "authors": [
        {
          "_id": "67bfdbd0302c06f220658e9d",
          "name": "Liang Wang",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658e9e",
          "name": "Shaozhen Liu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658e9f",
          "name": "Yu Rong",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea0",
          "name": "Deli Zhao",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea1",
          "name": "Qiang Liu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea2",
          "name": "Shu Wu",
          "hidden": false
        },
        {
          "_id": "67bfdbd0302c06f220658ea3",
          "name": "Liang Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-22T16:34:32.000Z",
      "title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal\n  Energy Spectra",
      "summary": "Establishing the relationship between 3D structures and the energy states of\nmolecular systems has proven to be a promising approach for learning 3D\nmolecular representations. However, existing methods are limited to modeling\nthe molecular energy states from classical mechanics. This limitation results\nin a significant oversight of quantum mechanical effects, such as quantized\n(discrete) energy level structures, which offer a more accurate estimation of\nmolecular energy and can be experimentally measured through energy spectra. In\nthis paper, we propose to utilize the energy spectra to enhance the\npre-training of 3D molecular representations (MolSpectra), thereby infusing the\nknowledge of quantum mechanics into the molecular representations.\nSpecifically, we propose SpecFormer, a multi-spectrum encoder for encoding\nmolecular spectra via masked patch reconstruction. By further aligning outputs\nfrom the 3D encoder and spectrum encoder using a contrastive objective, we\nenhance the 3D encoder's understanding of molecules. Evaluations on public\nbenchmarks reveal that our pre-trained representations surpass existing methods\nin predicting molecular properties and modeling dynamics.",
      "upvotes": 1,
      "discussionId": "67bfdbd1302c06f220658ece"
    },
    "publishedAt": "2025-02-26T22:29:40.056Z",
    "title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16284.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e84ec6d41a68b065bf78a7",
      "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
      "fullname": "Liang Wang",
      "name": "AzureLeon1",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.19187",
      "authors": [
        {
          "_id": "67c01747e8c7d56a8e0cbdc3",
          "name": "Mehran Kazemi",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc4",
          "user": {
            "_id": "654e97ef5da3196a78409341",
            "avatarUrl": "/avatars/1a5ea7351ca21960891cf9721b9f4667.svg",
            "isPro": false,
            "fullname": "Bahare Fatemi",
            "user": "baharefatemi",
            "type": "user"
          },
          "name": "Bahare Fatemi",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-27T07:42:00.525Z",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc5",
          "name": "Hritik Bansal",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc6",
          "name": "John Palowitch",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc7",
          "name": "Chrysovalantis Anastasiou",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc8",
          "name": "Sanket Vaibhav Mehta",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdc9",
          "name": "Lalit K. Jain",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdca",
          "name": "Virginia Aglietti",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcb",
          "name": "Disha Jindal",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcc",
          "name": "Peter Chen",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcd",
          "name": "Nishanth Dikkala",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdce",
          "name": "Gladys Tyen",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdcf",
          "name": "Xin Liu",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd0",
          "name": "Uri Shalit",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd1",
          "name": "Silvia Chiappa",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd2",
          "name": "Kate Olszewska",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd3",
          "name": "Yi Tay",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd4",
          "name": "Vinh Q. Tran",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd5",
          "name": "Quoc V. Le",
          "hidden": false
        },
        {
          "_id": "67c01747e8c7d56a8e0cbdd6",
          "name": "Orhan Firat",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-26T14:50:50.000Z",
      "title": "BIG-Bench Extra Hard",
      "summary": "Large language models (LLMs) are increasingly deployed in everyday\napplications, demanding robust general reasoning capabilities and diverse\nreasoning skillset. However, current LLM reasoning benchmarks predominantly\nfocus on mathematical and coding abilities, leaving a gap in evaluating broader\nreasoning proficiencies. One particular exception is the BIG-Bench dataset,\nwhich has served as a crucial benchmark for evaluating the general reasoning\ncapabilities of LLMs, thanks to its diverse set of challenging tasks that\nallowed for a comprehensive assessment of general reasoning across various\nskills within a unified framework. However, recent advances in LLMs have led to\nsaturation on BIG-Bench, and its harder version BIG-Bench Hard (BBH).\nState-of-the-art models achieve near-perfect scores on many tasks in BBH, thus\ndiminishing its utility. To address this limitation, we introduce BIG-Bench\nExtra Hard (BBEH), a new benchmark designed to push the boundaries of LLM\nreasoning evaluation. BBEH replaces each task in BBH with a novel task that\nprobes a similar reasoning capability but exhibits significantly increased\ndifficulty. We evaluate various models on BBEH and observe a (harmonic) average\naccuracy of 9.8\\% for the best general-purpose model and 44.8\\% for the best\nreasoning-specialized model, indicating substantial room for improvement and\nhighlighting the ongoing challenge of achieving robust general reasoning in\nLLMs. We release BBEH publicly at: https://github.com/google-deepmind/bbeh.",
      "upvotes": 0,
      "discussionId": "67c01748e8c7d56a8e0cbe0b"
    },
    "publishedAt": "2025-02-27T02:43:05.341Z",
    "title": "BIG-Bench Extra Hard",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19187.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5f1158120c833276f61f1a84",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
      "fullname": "Niels Rogge",
      "name": "nielsr",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 773
    },
    "isAuthorParticipating": false
  }
]