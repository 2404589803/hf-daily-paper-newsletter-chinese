[
  {
    "paper": {
      "id": "2502.01456",
      "authors": [
        {
          "_id": "67a19d705efa4fab15497775",
          "name": "Ganqu Cui",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497776",
          "name": "Lifan Yuan",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497777",
          "name": "Zefan Wang",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497778",
          "name": "Hanbin Wang",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497779",
          "name": "Wendi Li",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777a",
          "name": "Bingxiang He",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777b",
          "name": "Yuchen Fan",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777c",
          "name": "Tianyu Yu",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777d",
          "name": "Qixin Xu",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777e",
          "name": "Weize Chen",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549777f",
          "name": "Jiarui Yuan",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497780",
          "name": "Huayu Chen",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497781",
          "name": "Kaiyan Zhang",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497782",
          "name": "Xingtai Lv",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497783",
          "name": "Shuo Wang",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497784",
          "name": "Yuan Yao",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497785",
          "name": "Xu Han",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497786",
          "name": "Hao Peng",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497787",
          "name": "Yu Cheng",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497788",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab15497789",
          "name": "Maosong Sun",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549778a",
          "name": "Bowen Zhou",
          "hidden": false
        },
        {
          "_id": "67a19d705efa4fab1549778b",
          "name": "Ning Ding",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T15:43:48.000Z",
      "title": "Process Reinforcement through Implicit Rewards",
      "summary": "Dense process rewards have proven a more effective alternative to the sparse\noutcome-level rewards in the inference-time scaling of large language models\n(LLMs), particularly in tasks requiring complex multi-step reasoning. While\ndense rewards also offer an appealing choice for the reinforcement learning\n(RL) of LLMs since their fine-grained rewards have the potential to address\nsome inherent issues of outcome rewards, such as training efficiency and credit\nassignment, this potential remains largely unrealized. This can be primarily\nattributed to the challenges of training process reward models (PRMs) online,\nwhere collecting high-quality process labels is prohibitively expensive, making\nthem particularly vulnerable to reward hacking. To address these challenges, we\npropose PRIME (Process Reinforcement through IMplicit rEwards), which enables\nonline PRM updates using only policy rollouts and outcome labels through\nimplict process rewards. PRIME combines well with various advantage functions\nand forgoes the dedicated reward model training phrase that existing approaches\nrequire, substantially reducing the development overhead. We demonstrate\nPRIME's effectiveness on competitional math and coding. Starting from\nQwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several\nkey reasoning benchmarks over the SFT model. Notably, our resulting model,\nEurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning\nbenchmarks with 10% of its training data.",
      "upvotes": 19,
      "discussionId": "67a19d705efa4fab154977d0"
    },
    "publishedAt": "2025-02-04T00:02:39.922Z",
    "title": "Process Reinforcement through Implicit Rewards",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01456.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6321152b8c0da827c72c7c16",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678783813705-6321152b8c0da827c72c7c16.jpeg",
      "fullname": "Hanbin Wang",
      "name": "hanbin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 12
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01534",
      "authors": [
        {
          "_id": "67a1ad77d797fac51fa80770",
          "name": "Dawei Li",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80771",
          "name": "Renliang Sun",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80772",
          "name": "Yue Huang",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80773",
          "name": "Ming Zhong",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80774",
          "name": "Bohan Jiang",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80775",
          "name": "Jiawei Han",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80776",
          "name": "Xiangliang Zhang",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80777",
          "name": "Wei Wang",
          "hidden": false
        },
        {
          "_id": "67a1ad77d797fac51fa80778",
          "name": "Huan Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T17:13:03.000Z",
      "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
      "summary": "Large Language Models (LLMs) as judges and LLM-based data synthesis have\nemerged as two fundamental LLM-driven data annotation methods in model\ndevelopment. While their combination significantly enhances the efficiency of\nmodel training and evaluation, little attention has been given to the potential\ncontamination brought by this new model development paradigm. In this work, we\nexpose preference leakage, a contamination problem in LLM-as-a-judge caused by\nthe relatedness between the synthetic data generators and LLM-based evaluators.\nTo study this issue, we first define three common relatednesses between data\ngenerator LLM and judge LLM: being the same model, having an inheritance\nrelationship, and belonging to the same model family. Through extensive\nexperiments, we empirically confirm the bias of judges towards their related\nstudent models caused by preference leakage across multiple LLM baselines and\nbenchmarks. Further analysis suggests that preference leakage is a pervasive\nissue that is harder to detect compared to previously identified biases in\nLLM-as-a-judge scenarios. All of these findings imply that preference leakage\nis a widespread and challenging problem in the area of LLM-as-a-judge. We\nrelease all codes and data at:\nhttps://github.com/David-Li0406/Preference-Leakage.",
      "upvotes": 7,
      "discussionId": "67a1ad78d797fac51fa807c1"
    },
    "publishedAt": "2025-02-04T01:04:33.630Z",
    "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01534.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6474e1afb68461d5cf7c41cc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
      "fullname": "Dawei Li",
      "name": "wjldw",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01068",
      "authors": [
        {
          "_id": "67a1a75f6aa8429da4945eeb",
          "name": "Dongwon Jo",
          "hidden": false
        },
        {
          "_id": "67a1a75f6aa8429da4945eec",
          "name": "Jiwon Song",
          "hidden": false
        },
        {
          "_id": "67a1a75f6aa8429da4945eed",
          "name": "Yulhwa Kim",
          "hidden": false
        },
        {
          "_id": "67a1a75f6aa8429da4945eee",
          "name": "Jae-Joon Kim",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T05:25:09.000Z",
      "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with\n  Token-Selective Propagation",
      "summary": "While large language models (LLMs) excel at handling long-context sequences,\nthey require substantial key-value (KV) caches to store contextual information,\nwhich can heavily burden computational efficiency and memory usage. Previous\nefforts to compress these KV caches primarily focused on reducing memory\ndemands but were limited in enhancing latency. To address this issue, we\nintroduce FastKV, a KV cache compression method designed to enhance latency for\nlong-context sequences. To enhance processing speeds while maintaining\naccuracy, FastKV adopts a novel Token-Selective Propagation (TSP) approach that\nretains the full context information in the initial layers of LLMs and\nselectively propagates only a portion of this information in deeper layers even\nin the prefill stage. Additionally, FastKV incorporates grouped-query attention\n(GQA)-aware KV cache compression to exploit the advantages of GQA in both\nmemory and computational efficiency. Our experimental results show that FastKV\nachieves 2.00times and 1.40times improvements in time-to-first-token\n(TTFT) and throughput, respectively, compared to HeadKV, the state-of-the-art\nKV cache compression method. Moreover, FastKV successfully maintains accuracy\non long-context benchmarks at levels comparable to the baselines. Our code is\navailable at https://github.com/dongwonjo/FastKV.",
      "upvotes": 6,
      "discussionId": "67a1a7616aa8429da4945f95"
    },
    "publishedAt": "2025-02-04T00:45:45.545Z",
    "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01068.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "639ffbc6beb95d698de9640d",
      "avatarUrl": "/avatars/7ef1aaadd5b378d00e17dc548e42cb7e.svg",
      "fullname": "Dongwon Jo",
      "name": "dongwonjo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.00094",
      "authors": [
        {
          "_id": "67a185ab908f4534beb94b8c",
          "name": "Ahmed Heakl",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b8d",
          "name": "Sara Ghaboura",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b8e",
          "name": "Omkar Thawkar",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b8f",
          "name": "Fahad Shahbaz Khan",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b90",
          "name": "Hisham Cholakkal",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b91",
          "name": "Rao Muhammad Anwer",
          "hidden": false
        },
        {
          "_id": "67a185ab908f4534beb94b92",
          "name": "Salman Khan",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-31T18:58:20.000Z",
      "title": "AIN: The Arabic INclusive Large Multimodal Model",
      "summary": "Amid the swift progress of large language models (LLMs) and their evolution\ninto large multimodal models (LMMs), significant strides have been made in\nhigh-resource languages such as English and Chinese. While Arabic LLMs have\nseen notable progress, Arabic LMMs remain largely unexplored, often narrowly\nfocusing on a few specific aspects of the language and visual understanding. To\nbridge this gap, we introduce AIN-the Arabic Inclusive Multimodal\nModel-designed to excel across diverse domains. AIN is an English-Arabic\nbilingual LMM designed to excel in English and Arabic, leveraging carefully\nconstructed 3.6 million high-quality Arabic-English multimodal data samples.\nAIN demonstrates state-of-the-art Arabic performance, while also possessing\nstrong English-language visual capabilities. On the recent CAMEL-Bench\nbenchmark comprising 38 sub-domains including, multi-image understanding,\ncomplex visual perception, handwritten document understanding, video\nunderstanding, medical imaging, plant diseases, and remote sensing-based land\nuse understanding, our AIN demonstrates strong performance with the 7B model\noutperforming GPT-4o by an absolute gain of 3.4% averaged over eight domains\nand 38 sub-domains. AIN's superior capabilities position it as a significant\nstep toward empowering Arabic speakers with advanced multimodal generative AI\ntools across diverse applications.",
      "upvotes": 6,
      "discussionId": "67a185b0908f4534beb94c49"
    },
    "publishedAt": "2025-02-03T22:22:44.375Z",
    "title": "AIN: The Arabic INclusive Large Multimodal Model",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/mmf9V_8rdsi9hN-QdFZV8.png",
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/uLq0E1qq75-P4P1KV4xWF.png",
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/1eixiKjHGNVm6RaJpdWeq.png",
      "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/XVJSPAgIQcQn8Zi4gUVwi.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00094.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "656864e12d73834278a8dea7",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
      "fullname": "Ahmed Heakl",
      "name": "ahmedheakl",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 17
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01081",
      "authors": [
        {
          "_id": "67a1a56d83c3565727d22f0c",
          "name": "Vernon Y. H. Toh",
          "hidden": false
        },
        {
          "_id": "67a1a56d83c3565727d22f0d",
          "name": "Yew Ken Chia",
          "hidden": false
        },
        {
          "_id": "67a1a56d83c3565727d22f0e",
          "name": "Deepanway Ghosal",
          "hidden": false
        },
        {
          "_id": "67a1a56d83c3565727d22f0f",
          "name": "Soujanya Poria",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T05:47:04.000Z",
      "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning\n  Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
      "summary": "The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large\nLanguage Models towards advanced reasoning capabilities. Notably, o3\noutperformed humans in novel problem-solving and skill acquisition on the\nAbstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI).\nHowever, this benchmark is limited to symbolic patterns, whereas humans often\nperceive and reason about multimodal scenarios involving both vision and\nlanguage data. Thus, there is an urgent need to investigate advanced reasoning\ncapabilities in multimodal tasks. To this end, we track the evolution of the\nGPT-[n] and o-[n] series models on challenging multimodal puzzles, requiring\nfine-grained visual perception with abstract or algorithmic reasoning. The\nsuperior performance of o1 comes at nearly 750 times the computational cost of\nGPT-4o, raising concerns about its efficiency. Our results reveal a clear\nupward trend in reasoning capabilities across model iterations, with notable\nperformance jumps across GPT-series models and subsequently to o1. Nonetheless,\nwe observe that the o1 model still struggles with simple multimodal puzzles\nrequiring abstract reasoning. Furthermore, its performance in algorithmic\npuzzles remains poor. We plan to continuously track new models in the series\nand update our results in this paper accordingly. All resources used in this\nevaluation are openly available https://github.com/declare-lab/LLM-PuzzleTest.",
      "upvotes": 5,
      "discussionId": "67a1a57083c3565727d22fc6"
    },
    "publishedAt": "2025-02-04T00:28:35.436Z",
    "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01081.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5926
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01061",
      "authors": [
        {
          "_id": "67a1a7a166a8a88726963ef4",
          "name": "Gaojie Lin",
          "hidden": false
        },
        {
          "_id": "67a1a7a166a8a88726963ef5",
          "name": "Jianwen Jiang",
          "hidden": false
        },
        {
          "_id": "67a1a7a166a8a88726963ef6",
          "name": "Jiaqi Yang",
          "hidden": false
        },
        {
          "_id": "67a1a7a166a8a88726963ef7",
          "name": "Zerong Zheng",
          "hidden": false
        },
        {
          "_id": "67a1a7a166a8a88726963ef8",
          "name": "Chao Liang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T05:17:32.000Z",
      "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human\n  Animation Models",
      "summary": "End-to-end human animation, such as audio-driven talking human generation,\nhas undergone notable advancements in the recent few years. However, existing\nmethods still struggle to scale up as large general video generation models,\nlimiting their potential in real applications. In this paper, we propose\nOmniHuman, a Diffusion Transformer-based framework that scales up data by\nmixing motion-related conditions into the training phase. To this end, we\nintroduce two training principles for these mixed conditions, along with the\ncorresponding model architecture and inference strategy. These designs enable\nOmniHuman to fully leverage data-driven motion generation, ultimately achieving\nhighly realistic human video generation. More importantly, OmniHuman supports\nvarious portrait contents (face close-up, portrait, half-body, full-body),\nsupports both talking and singing, handles human-object interactions and\nchallenging body poses, and accommodates different image styles. Compared to\nexisting end-to-end audio-driven methods, OmniHuman not only produces more\nrealistic videos, but also offers greater flexibility in inputs. It also\nsupports multiple driving modalities (audio-driven, video-driven and combined\ndriving signals). Video samples are provided on the ttfamily project page\n(https://omnihuman-lab.github.io)",
      "upvotes": 4,
      "discussionId": "67a1a7a466a8a88726963f90"
    },
    "publishedAt": "2025-02-04T00:37:57.949Z",
    "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01061.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5926
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01441",
      "authors": [
        {
          "_id": "67a189e8fbbab3ce03462fb3",
          "name": "Quan Dao",
          "hidden": false
        },
        {
          "_id": "67a189e8fbbab3ce03462fb4",
          "name": "Khanh Doan",
          "hidden": false
        },
        {
          "_id": "67a189e8fbbab3ce03462fb5",
          "name": "Di Liu",
          "hidden": false
        },
        {
          "_id": "67a189e8fbbab3ce03462fb6",
          "user": {
            "_id": "66db7db231e772c5ec4c5576",
            "avatarUrl": "/avatars/aa0eb054bd6c881054431a22daf1aea1.svg",
            "isPro": false,
            "fullname": "Trung Le",
            "user": "trungleuc",
            "type": "user"
          },
          "name": "Trung Le",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-04T03:30:50.175Z",
          "hidden": false
        },
        {
          "_id": "67a189e8fbbab3ce03462fb7",
          "name": "Dimitris Metaxas",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T15:25:58.000Z",
      "title": "Improved Training Technique for Latent Consistency Models",
      "summary": "Consistency models are a new family of generative models capable of producing\nhigh-quality samples in either a single step or multiple steps. Recently,\nconsistency models have demonstrated impressive performance, achieving results\non par with diffusion models in the pixel space. However, the success of\nscaling consistency training to large-scale datasets, particularly for\ntext-to-image and video generation tasks, is determined by performance in the\nlatent space. In this work, we analyze the statistical differences between\npixel and latent spaces, discovering that latent data often contains highly\nimpulsive outliers, which significantly degrade the performance of iCT in the\nlatent space. To address this, we replace Pseudo-Huber losses with Cauchy\nlosses, effectively mitigating the impact of outliers. Additionally, we\nintroduce a diffusion loss at early timesteps and employ optimal transport (OT)\ncoupling to further enhance performance. Lastly, we introduce the adaptive\nscaling-c scheduler to manage the robust training process and adopt\nNon-scaling LayerNorm in the architecture to better capture the statistics of\nthe features and reduce outlier impact. With these strategies, we successfully\ntrain latent consistency models capable of high-quality sampling with one or\ntwo steps, significantly narrowing the performance gap between latent\nconsistency and diffusion models. The implementation is released here:\nhttps://github.com/quandao10/sLCT/",
      "upvotes": 2,
      "discussionId": "67a189eafbbab3ce0346300b"
    },
    "publishedAt": "2025-02-03T22:32:23.956Z",
    "title": "Improved Training Technique for Latent Consistency Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01441.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63e083e6f351dc0745745d17",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e083e6f351dc0745745d17/N0GE4uLrkm14blAQMnm2E.jpeg",
      "fullname": "Quan Dao",
      "name": "quandao10",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01100",
      "authors": [
        {
          "_id": "67a1a649f4aecd0dfc96ebf4",
          "name": "Bill Yuchen Lin",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf5",
          "user": {
            "_id": "635049104e753c9940fefd71",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/635049104e753c9940fefd71/HgR43XIFw3dneY5ufrAE8.jpeg",
            "isPro": false,
            "fullname": "Ronan Le Bras",
            "user": "ronanlb",
            "type": "user"
          },
          "name": "Ronan Le Bras",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-04T05:31:56.722Z",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf6",
          "name": "Kyle Richardson",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf7",
          "name": "Ashish Sabharwal",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf8",
          "name": "Radha Poovendran",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebf9",
          "name": "Peter Clark",
          "hidden": false
        },
        {
          "_id": "67a1a649f4aecd0dfc96ebfa",
          "name": "Yejin Choi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T06:44:49.000Z",
      "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
      "summary": "We investigate the logical reasoning capabilities of large language models\n(LLMs) and their scalability in complex non-monotonic reasoning. To this end,\nwe introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM\nreasoning performance on logic grid puzzles derived from constraint\nsatisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with\ncontrollable and quantifiable complexity, facilitating a systematic study of\nthe scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By\nencompassing a broad range of search space complexities and diverse logical\nconstraints, ZebraLogic provides a structured environment to evaluate reasoning\nunder increasing difficulty.\n  Our results reveal a significant decline in accuracy as problem complexity\ngrows -- a phenomenon we term the curse of complexity. This limitation persists\neven with larger models and increased inference-time computation, suggesting\ninherent constraints in current LLM reasoning capabilities. Additionally, we\nexplore strategies to enhance logical reasoning, including Best-of-N sampling,\nbacktracking mechanisms, and self-verification prompts. Our findings offer\ncritical insights into the scalability of LLM reasoning, highlight fundamental\nlimitations, and outline potential directions for improvement.",
      "upvotes": 1,
      "discussionId": "67a1a64cf4aecd0dfc96ecb8"
    },
    "publishedAt": "2025-02-04T00:32:03.929Z",
    "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01100.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5926
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01637",
      "authors": [
        {
          "_id": "67a1a51e6aa8429da493d0b5",
          "name": "Da Yu",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0b6",
          "name": "Edith Cohen",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0b7",
          "name": "Badih Ghazi",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0b8",
          "name": "Yangsibo Huang",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0b9",
          "name": "Pritish Kamath",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0ba",
          "name": "Ravi Kumar",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0bb",
          "name": "Daogao Liu",
          "hidden": false
        },
        {
          "_id": "67a1a51e6aa8429da493d0bc",
          "name": "Chiyuan Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:59:32.000Z",
      "title": "Scaling Embedding Layers in Language Models",
      "summary": "We propose SCONE (Scalable, Contextualized,\nOffloaded, N-gram Embedding), a method for\nextending input embedding layers to enhance language model performance as layer\nsize scales. To avoid increased decoding costs, SCONE retains the original\nvocabulary while introducing embeddings for a set of frequent n-grams. These\nembeddings provide contextualized representation for each input token and are\nlearned with a separate model during training. During inference, they are\nprecomputed and stored in off-accelerator memory with minimal impact on\ninference speed. SCONE enables two new scaling strategies: increasing the\nnumber of cached n-gram embeddings and scaling the model used to learn them,\nall while maintaining fixed inference-time FLOPS. We show that scaling both\naspects allows SCONE to outperform a 1.9B parameter baseline across diverse\ncorpora, while using only half the inference-time FLOPS.",
      "upvotes": 1,
      "discussionId": "67a1a51e6aa8429da493d0d5"
    },
    "publishedAt": "2025-02-04T00:27:13.960Z",
    "title": "Scaling Embedding Layers in Language Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01637.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5926
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01636",
      "authors": [
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb1",
          "user": {
            "_id": "64e8f4a24f3f7b0b84834315",
            "avatarUrl": "/avatars/242bb68c7ccffe5061c2d1c229ea3b0b.svg",
            "isPro": false,
            "fullname": "Akshat Gupta",
            "user": "akshat57",
            "type": "user"
          },
          "name": "Akshat Gupta",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-02-04T05:53:11.213Z",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb2",
          "name": "Phudish Prateepamornkul",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb3",
          "name": "Maochuan Lu",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb4",
          "name": "Ahmed Alaa",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb5",
          "name": "Thomas Hartvigsen",
          "hidden": false
        },
        {
          "_id": "67a1aa5dc7fa0ccf0a32ceb6",
          "name": "Gopala Anumanchipalli",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:59:14.000Z",
      "title": "Lifelong Sequential Knowledge Editing without Model Degradation",
      "summary": "Prior work in parameter-modifying knowledge editing has shown that\nlarge-scale sequential editing leads to significant model degradation. In this\npaper, we study the reasons behind this and scale sequential knowledge editing\nto 10,000 sequential edits, while maintaining the downstream performance of the\noriginal model. We first show that locate-then-edit knowledge editing methods\nlead to overfitting on the edited facts. We also show that continuous knowledge\nediting using these methods leads to disproportionate growth in the norm of the\nedited matrix. We then provide a crucial insight into the inner workings of\nlocate-then-edit methods. We show that norm-growth is a hidden trick employed\nby these methods that gives larger importance to the output activations\nproduced from the edited layers. With this \"importance hacking\", the edited\nlayers provide a much larger contributions to the model's output. To mitigate\nthese issues, we present ENCORE - Early stopping and Norm-Constrained Robust\nknowledge Editing. ENCORE controls for overfitting and the disproportionate\nnorm-growth to enable long-term sequential editing, where we are able to\nperform up to 10,000 sequential edits without loss of downstream performance.\nENCORE is also 61% faster than MEMIT and 64% faster than AlphaEdit on\nLlama3-8B.",
      "upvotes": 0,
      "discussionId": "67a1aa5fc7fa0ccf0a32cf90"
    },
    "publishedAt": "2025-02-04T00:50:46.370Z",
    "title": "Lifelong Sequential Knowledge Editing without Model Degradation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01636.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e8f4a24f3f7b0b84834315",
      "avatarUrl": "/avatars/242bb68c7ccffe5061c2d1c229ea3b0b.svg",
      "fullname": "Akshat Gupta",
      "name": "akshat57",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2502.01591",
      "authors": [
        {
          "_id": "67a1a4b72bf092a7612b36eb",
          "name": "Antoine Dedieu",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36ec",
          "name": "Joseph Ortiz",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36ed",
          "name": "Xinghua Lou",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36ee",
          "name": "Carter Wendelken",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36ef",
          "name": "Wolfgang Lehrach",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36f0",
          "name": "J Swaroop Guntupalli",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36f1",
          "name": "Miguel Lazaro-Gredilla",
          "hidden": false
        },
        {
          "_id": "67a1a4b72bf092a7612b36f2",
          "name": "Kevin Patrick Murphy",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:25:17.000Z",
      "title": "Improving Transformer World Models for Data-Efficient RL",
      "summary": "We present an approach to model-based RL that achieves a new state of the art\nperformance on the challenging Craftax-classic benchmark, an open-world 2D\nsurvival game that requires agents to exhibit a wide range of general abilities\n-- such as strong generalization, deep exploration, and long-term reasoning.\nWith a series of careful design choices aimed at improving sample efficiency,\nour MBRL algorithm achieves a reward of 67.4% after only 1M environment steps,\nsignificantly outperforming DreamerV3, which achieves 53.2%, and, for the first\ntime, exceeds human performance of 65.0%. Our method starts by constructing a\nSOTA model-free baseline, using a novel policy architecture that combines CNNs\nand RNNs. We then add three improvements to the standard MBRL setup: (a) \"Dyna\nwith warmup\", which trains the policy on real and imaginary data, (b) \"nearest\nneighbor tokenizer\" on image patches, which improves the scheme to create the\ntransformer world model (TWM) inputs, and (c) \"block teacher forcing\", which\nallows the TWM to reason jointly about the future tokens of the next timestep.",
      "upvotes": 0,
      "discussionId": "67a1a4b82bf092a7612b371b"
    },
    "publishedAt": "2025-02-04T00:25:52.071Z",
    "title": "Improving Transformer World Models for Data-Efficient RL",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01591.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5926
    },
    "isAuthorParticipating": false
  }
]