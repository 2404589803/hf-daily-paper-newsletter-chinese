[
    {
        "paper": {
            "id": "2411.18478",
            "authors": [
                {
                    "_id": "674b4af16421c587617a966f",
                    "user": {
                        "_id": "6747de57f8cab58c22ec94a2",
                        "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
                        "isPro": false,
                        "fullname": "Jinyang Wu",
                        "user": "Jinyang23",
                        "type": "user"
                    },
                    "name": "Jinyang Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T08:50:22.252Z",
                    "hidden": false
                },
                {
                    "_id": "674b4af16421c587617a9670",
                    "user": {
                        "_id": "660d13b85e00095e45ee28e0",
                        "avatarUrl": "/avatars/8f06c01edc2a791266feadc775acb901.svg",
                        "isPro": false,
                        "fullname": "FengMingkuan",
                        "user": "fmk345",
                        "type": "user"
                    },
                    "name": "Mingkuan Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:16:15.000Z",
                    "hidden": false
                },
                {
                    "_id": "674b4af16421c587617a9671",
                    "name": "Shuai Zhang",
                    "hidden": false
                },
                {
                    "_id": "674b4af16421c587617a9672",
                    "name": "Feihu Che",
                    "hidden": false
                },
                {
                    "_id": "674b4af16421c587617a9673",
                    "name": "Zengqi Wen",
                    "hidden": false
                },
                {
                    "_id": "674b4af16421c587617a9674",
                    "name": "Jianhua Tao",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T16:19:00.000Z",
            "title": "Beyond Examples: High-level Automated Reasoning Paradigm in In-Context\n  Learning via MCTS",
            "summary": "In-context Learning (ICL) enables large language models (LLMs) to tackle\ndownstream tasks through sophisticated prompting and high-quality\ndemonstrations. However, this traditional ICL paradigm shows limitations when\nfacing complex mathematical reasoning tasks, primarily due to its heavy\ndependence on example quality and the necessity for human intervention in\nchallenging scenarios. To address these limitations, this paper presents\nHiAR-ICL, a High-level Automated Reasoning paradigm\nin ICL that shifts focus from specific examples to abstract thinking\npatterns, extending the conventional concept of context in ICL. HiAR-ICL\nintroduces five atomic reasoning actions as fundamental components for\nconstructing chain-structured patterns. Using Monte Carlo Tree Search, we\nexplore reasoning paths and construct thought cards to guide subsequent\ninference. We then develop a cognitive complexity framework that dynamically\nmatches problems with appropriate thought cards. Experimental results\ndemonstrate HiAR-ICL's effectiveness, achieving state-of-the-art accuracy\n(79.6%) on the MATH benchmark with Qwen2.5-7B-Instruct, surpassing GPT-4o\n(76.6%) and Claude 3.5 (71.1%).",
            "upvotes": 20,
            "discussionId": "674b4af26421c587617a9699"
        },
        "publishedAt": "2024-12-02T04:04:28.357Z",
        "title": "Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18478.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
            "fullname": "Jinyang Wu",
            "name": "Jinyang23",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.19930",
            "authors": [
                {
                    "_id": "674d32f63965f56df21c340c",
                    "user": {
                        "_id": "649e6761f9134a06ed1e0cea",
                        "avatarUrl": "/avatars/00b5dcb744c54a4aa18fe08efd70d6ff.svg",
                        "isPro": false,
                        "fullname": "Daixuan Cheng",
                        "user": "daixuancheng",
                        "type": "user"
                    },
                    "name": "Daixuan Cheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T08:49:33.196Z",
                    "hidden": false
                },
                {
                    "_id": "674d32f63965f56df21c340d",
                    "user": {
                        "_id": "632bd2f72d6a805eeb4bc601",
                        "avatarUrl": "/avatars/6e1533e8a599f3068290aa69ac82cab7.svg",
                        "isPro": false,
                        "fullname": "HUANG SHAOHAN",
                        "user": "buaahsh",
                        "type": "user"
                    },
                    "name": "Shaohan Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:04:44.158Z",
                    "hidden": false
                },
                {
                    "_id": "674d32f63965f56df21c340e",
                    "user": {
                        "_id": "64d86d66d7e30889c6a2e955",
                        "avatarUrl": "/avatars/222fcbe4af3bd897f260d019a54cfb6d.svg",
                        "isPro": false,
                        "fullname": "ziyu zhu",
                        "user": "edward2021",
                        "type": "user"
                    },
                    "name": "Ziyu Zhu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:05:38.250Z",
                    "hidden": false
                },
                {
                    "_id": "674d32f63965f56df21c340f",
                    "name": "Xintong Zhang",
                    "hidden": false
                },
                {
                    "_id": "674d32f63965f56df21c3410",
                    "name": "Wayne Xin Zhao",
                    "hidden": false
                },
                {
                    "_id": "674d32f63965f56df21c3411",
                    "name": "Zhongzhi Luan",
                    "hidden": false
                },
                {
                    "_id": "674d32f63965f56df21c3412",
                    "user": {
                        "_id": "665e2bd0fbaa279db369b488",
                        "avatarUrl": "/avatars/8cbc18d17d2813617976dbe709235799.svg",
                        "isPro": false,
                        "fullname": "Bo Dai",
                        "user": "doubling",
                        "type": "user"
                    },
                    "name": "Bo Dai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T08:56:41.196Z",
                    "hidden": false
                },
                {
                    "_id": "674d32f63965f56df21c3413",
                    "name": "Zhenliang Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-29T18:42:28.000Z",
            "title": "On Domain-Specific Post-Training for Multimodal Large Language Models",
            "summary": "Recent years have witnessed the rapid development of general multimodal large\nlanguage models (MLLMs). However, adapting general MLLMs to specific domains,\nsuch as scientific fields and industrial applications, remains less explored.\nThis paper systematically investigates domain adaptation of MLLMs through\npost-training, focusing on data synthesis, training pipelines, and task\nevaluation. (1) Data Synthesis: Using open-source models, we develop a visual\ninstruction synthesizer that effectively generates diverse visual instruction\ntasks from domain-specific image-caption pairs. Our synthetic tasks surpass\nthose generated by manual rules, GPT-4, and GPT-4V in enhancing the\ndomain-specific performance of MLLMs. (2) Training Pipeline: While the\ntwo-stage training--initially on image-caption pairs followed by visual\ninstruction tasks--is commonly adopted for developing general MLLMs, we apply a\nsingle-stage training pipeline to enhance task diversity for domain-specific\npost-training. (3) Task Evaluation: We conduct experiments in two domains,\nbiomedicine and food, by post-training MLLMs of different sources and scales\n(e.g., Qwen2-VL-2B, LLaVA-v1.6-8B, Llama-3.2-11B), and then evaluating MLLM\nperformance on various domain-specific tasks. To support further research in\nMLLM domain adaptation, we will open-source our implementations.",
            "upvotes": 18,
            "discussionId": "674d32f73965f56df21c3452"
        },
        "publishedAt": "2024-12-01T23:12:46.420Z",
        "title": "On Domain-Specific Post-Training for Multimodal Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19930.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/00b5dcb744c54a4aa18fe08efd70d6ff.svg",
            "fullname": "Daixuan Cheng",
            "name": "daixuancheng",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 5
        }
    },
    {
        "paper": {
            "id": "2411.19189",
            "authors": [
                {
                    "_id": "674d64114e69219448bcf70d",
                    "user": {
                        "_id": "63d90391da4f72339244c2a8",
                        "avatarUrl": "/avatars/eb0e0259c391d59739c1a205c36bb539.svg",
                        "isPro": false,
                        "fullname": "Ke",
                        "user": "Bingxin",
                        "type": "user"
                    },
                    "name": "Bingxin Ke",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:44:14.028Z",
                    "hidden": false
                },
                {
                    "_id": "674d64114e69219448bcf70e",
                    "user": {
                        "_id": "674995c2d523f2743e6c3859",
                        "avatarUrl": "/avatars/41b60f776a41d85da9ea0b1ed7d7615b.svg",
                        "isPro": false,
                        "fullname": "Dominik Narnhofer",
                        "user": "dnarnhofer",
                        "type": "user"
                    },
                    "name": "Dominik Narnhofer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:44:18.859Z",
                    "hidden": false
                },
                {
                    "_id": "674d64114e69219448bcf70f",
                    "user": {
                        "_id": "65b277cd47674826d1a08fd6",
                        "avatarUrl": "/avatars/795fb6f321aafbc56535571bc4a85dee.svg",
                        "isPro": false,
                        "fullname": "Sheng-Yu Huang",
                        "user": "peterjohnson",
                        "type": "user"
                    },
                    "name": "Shengyu Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:44:25.115Z",
                    "hidden": false
                },
                {
                    "_id": "674d64114e69219448bcf710",
                    "name": "Lei Ke",
                    "hidden": false
                },
                {
                    "_id": "674d64114e69219448bcf711",
                    "user": {
                        "_id": "656d886ad848a6683a0f71c3",
                        "avatarUrl": "/avatars/494f5fd5d5fa7849850cfe21f574f12c.svg",
                        "isPro": false,
                        "fullname": "Torben Peters",
                        "user": "PeterTor",
                        "type": "user"
                    },
                    "name": "Torben Peters",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:44:39.755Z",
                    "hidden": false
                },
                {
                    "_id": "674d64114e69219448bcf712",
                    "name": "Katerina Fragkiadaki",
                    "hidden": false
                },
                {
                    "_id": "674d64114e69219448bcf713",
                    "user": {
                        "_id": "62f93abbc4817cfc0756b6f8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f93abbc4817cfc0756b6f8/rGYLaq-rmoJJYotkC1VXk.jpeg",
                        "isPro": false,
                        "fullname": "Anton Obukhov",
                        "user": "toshas",
                        "type": "user"
                    },
                    "name": "Anton Obukhov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:44:55.130Z",
                    "hidden": false
                },
                {
                    "_id": "674d64114e69219448bcf714",
                    "name": "Konrad Schindler",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-28T14:50:14.000Z",
            "title": "Video Depth without Video Models",
            "summary": "Video depth estimation lifts monocular video clips to 3D by inferring dense\ndepth at every frame. Recent advances in single-image depth estimation, brought\nabout by the rise of large foundation models and the use of synthetic training\ndata, have fueled a renewed interest in video depth. However, naively applying\na single-image depth estimator to every frame of a video disregards temporal\ncontinuity, which not only leads to flickering but may also break when camera\nmotion causes sudden changes in depth range. An obvious and principled solution\nwould be to build on top of video foundation models, but these come with their\nown limitations; including expensive training and inference, imperfect 3D\nconsistency, and stitching routines for the fixed-length (short) outputs. We\ntake a step back and demonstrate how to turn a single-image latent diffusion\nmodel (LDM) into a state-of-the-art video depth estimator. Our model, which we\ncall RollingDepth, has two main ingredients: (i) a multi-frame depth estimator\nthat is derived from a single-image LDM and maps very short video snippets\n(typically frame triplets) to depth snippets. (ii) a robust, optimization-based\nregistration algorithm that optimally assembles depth snippets sampled at\nvarious different frame rates back into a consistent video. RollingDepth is\nable to efficiently handle long videos with hundreds of frames and delivers\nmore accurate depth videos than both dedicated video depth estimators and\nhigh-performing single-frame models. Project page: rollingdepth.github.io.",
            "upvotes": 14,
            "discussionId": "674d64144e69219448bcf800"
        },
        "publishedAt": "2024-12-02T02:51:53.222Z",
        "title": "Video Depth without Video Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62f93abbc4817cfc0756b6f8/zNn6mopOAxkRN6UWy4luo.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19189.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62f93abbc4817cfc0756b6f8/rGYLaq-rmoJJYotkC1VXk.jpeg",
            "fullname": "Anton Obukhov",
            "name": "toshas",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 68
        }
    },
    {
        "paper": {
            "id": "2411.19146",
            "authors": [
                {
                    "_id": "674d3de96ab71cc666cce97e",
                    "user": {
                        "_id": "66857bd849a4ed9de4c31936",
                        "avatarUrl": "/avatars/f6f016bf36fad5b29f30fbec6cde3e4d.svg",
                        "isPro": false,
                        "fullname": "Akhiad Bercovich",
                        "user": "abercovich",
                        "type": "user"
                    },
                    "name": "Akhiad Bercovich",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:21:17.415Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce97f",
                    "user": {
                        "_id": "6671634f1820f293a9995b12",
                        "avatarUrl": "/avatars/50c8f7b4bfb00f2169b808f3c72c7686.svg",
                        "isPro": false,
                        "fullname": "Tomer Ronen",
                        "user": "tomer-nv",
                        "type": "user"
                    },
                    "name": "Tomer Ronen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:21:40.810Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce980",
                    "user": {
                        "_id": "668e7a379ab7631fcd434ee7",
                        "avatarUrl": "/avatars/68ddbc5e35125a779655e9033d24afe5.svg",
                        "isPro": false,
                        "fullname": "Talor Abramovich",
                        "user": "talor-abr",
                        "type": "user"
                    },
                    "name": "Talor Abramovich",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:21:55.666Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce981",
                    "user": {
                        "_id": "66bf1cee43a701a83775810f",
                        "avatarUrl": "/avatars/3b0cadcc77905facee1ae3511ec28999.svg",
                        "isPro": false,
                        "fullname": "Nir Ailon",
                        "user": "nailon-nvidia",
                        "type": "user"
                    },
                    "name": "Nir Ailon",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:22:03.393Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce982",
                    "user": {
                        "_id": "64df9df14a8463e302eb69c6",
                        "avatarUrl": "/avatars/cab988dffbbcee3384dfb28a100c8bef.svg",
                        "isPro": false,
                        "fullname": "Nave Assaf",
                        "user": "nav4",
                        "type": "user"
                    },
                    "name": "Nave Assaf",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:22:09.140Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce983",
                    "user": {
                        "_id": "63a4182f84a6a25c65bcfc71",
                        "avatarUrl": "/avatars/9e9c700ed5b06a2388a9bb0e93d5beb1.svg",
                        "isPro": false,
                        "fullname": "mohammad Dabbah",
                        "user": "mdabbah",
                        "type": "user"
                    },
                    "name": "Mohammad Dabbah",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:22:15.162Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce984",
                    "user": {
                        "_id": "66867535e44c9931f329ca43",
                        "avatarUrl": "/avatars/ec6fc05b9f596f1ce38ec061d3d1d230.svg",
                        "isPro": false,
                        "fullname": "Ido Galil",
                        "user": "IdoGalilNvidia",
                        "type": "user"
                    },
                    "name": "Ido Galil",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:22:30.830Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce985",
                    "user": {
                        "_id": "65006cac12c1442d993d6d51",
                        "avatarUrl": "/avatars/624e52c2fb35b998ef7b346cbc7d5800.svg",
                        "isPro": false,
                        "fullname": "Geifman",
                        "user": "AmnonGeifman",
                        "type": "user"
                    },
                    "name": "Amnon Geifman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:22:39.096Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce986",
                    "user": {
                        "_id": "66efe3f10989ae1ac1a1795f",
                        "avatarUrl": "/avatars/c798905aeaa0fca51fb0f7b1edeabdc2.svg",
                        "isPro": false,
                        "fullname": "Yonatan Geifman",
                        "user": "ygeifman",
                        "type": "user"
                    },
                    "name": "Yonatan Geifman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:22:56.831Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce987",
                    "user": {
                        "_id": "66cb4b53d9772842192b84c3",
                        "avatarUrl": "/avatars/f4820f60d509c3fa5f94ab72eff854c6.svg",
                        "isPro": false,
                        "fullname": "Izik Golan",
                        "user": "izikg",
                        "type": "user"
                    },
                    "name": "Izhak Golan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T12:52:28.542Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce988",
                    "name": "Netanel Haber",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce989",
                    "name": "Ehud Karpas",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce98a",
                    "user": {
                        "_id": "668578fdd24e614fec97eac8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/668578fdd24e614fec97eac8/n5xYnqo5nQbVX2tgaRfEi.jpeg",
                        "isPro": false,
                        "fullname": "Itay Levy",
                        "user": "itlevy",
                        "type": "user"
                    },
                    "name": "Itay Levy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:31:54.896Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce98b",
                    "user": {
                        "_id": "657018a04f3a65f869b10e21",
                        "avatarUrl": "/avatars/715630dc868a728a7866d68fdf9f9d26.svg",
                        "isPro": false,
                        "fullname": "Shahar Mor",
                        "user": "ShaharM98",
                        "type": "user"
                    },
                    "name": "Shahar Mor",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:32:05.610Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce98c",
                    "name": "Zach Moshe",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce98d",
                    "user": {
                        "_id": "6685860d852db86b9c91a1f3",
                        "avatarUrl": "/avatars/ea25dd7427375b423af9c7b412826fef.svg",
                        "isPro": false,
                        "fullname": "Najeeb Nabwani",
                        "user": "Najeebnv",
                        "type": "user"
                    },
                    "name": "Najeeb Nabwani",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:32:53.456Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce98e",
                    "name": "Omri Puny",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce98f",
                    "user": {
                        "_id": "65059361ffc738079c5d5583",
                        "avatarUrl": "/avatars/03361adea86fa519941a79f8171d867f.svg",
                        "isPro": false,
                        "fullname": "Ran Rubin",
                        "user": "ranrubin",
                        "type": "user"
                    },
                    "name": "Ran Rubin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:34:35.218Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce990",
                    "user": {
                        "_id": "665f0a46f065b1d42806000d",
                        "avatarUrl": "/avatars/927f042a3c95c5846621e2a381c66bbf.svg",
                        "isPro": false,
                        "fullname": "Itamar Schen",
                        "user": "ischen-nvidia",
                        "type": "user"
                    },
                    "name": "Itamar Schen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:34:29.156Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce991",
                    "user": {
                        "_id": "666ef13c14f1c262feeb706c",
                        "avatarUrl": "/avatars/7dca59acf5e069d96bdbb98dace9199b.svg",
                        "isPro": false,
                        "fullname": "Ido Shahaf",
                        "user": "ishahaf",
                        "type": "user"
                    },
                    "name": "Ido Shahaf",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:34:21.829Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce992",
                    "user": {
                        "_id": "66b089f14ae4ae811218cdb6",
                        "avatarUrl": "/avatars/a50fe725922dfdbe0e731fade381b22e.svg",
                        "isPro": false,
                        "fullname": "Oren Tropp",
                        "user": "otropp",
                        "type": "user"
                    },
                    "name": "Oren Tropp",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:34:14.298Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce993",
                    "user": {
                        "_id": "66a0d0b2d4ab10840b5af2b0",
                        "avatarUrl": "/avatars/8fa12818329de9457f93081e8f345117.svg",
                        "isPro": false,
                        "fullname": "Omer Ullman Argov",
                        "user": "oargov-nv",
                        "type": "user"
                    },
                    "name": "Omer Ullman Argov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:33:34.295Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce994",
                    "user": {
                        "_id": "666027917c3f9c72113cc75c",
                        "avatarUrl": "/avatars/a276ebe8e2731b6a05e3c61c2ae0ddae.svg",
                        "isPro": false,
                        "fullname": "Ran Zilberstein",
                        "user": "RanZilberstein-Nvidia",
                        "type": "user"
                    },
                    "name": "Ran Zilberstein",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:33:26.752Z",
                    "hidden": false
                },
                {
                    "_id": "674d3de96ab71cc666cce995",
                    "user": {
                        "_id": "66efd764155c986c6511b52d",
                        "avatarUrl": "/avatars/711f9c6954a8623a9e014c0c563ca708.svg",
                        "isPro": false,
                        "fullname": "Ran El-Yaniv",
                        "user": "relyaniv",
                        "type": "user"
                    },
                    "name": "Ran El-Yaniv",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:33:16.354Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-28T13:45:42.000Z",
            "title": "Puzzle: Distillation-Based NAS for Inference-Optimized LLMs",
            "summary": "Large language models (LLMs) have demonstrated remarkable capabilities, but\ntheir adoption is limited by high computational costs during inference. While\nincreasing parameter counts enhances accuracy, it also widens the gap between\nstate-of-the-art capabilities and practical deployability. We present Puzzle, a\nframework to accelerate LLM inference on specific hardware while preserving\ntheir capabilities. Through an innovative application of neural architecture\nsearch (NAS) at an unprecedented scale, Puzzle systematically optimizes models\nwith tens of billions of parameters under hardware constraints. Our approach\nutilizes blockwise local knowledge distillation (BLD) for parallel architecture\nexploration and employs mixed-integer programming for precise constraint\noptimization.\n  We demonstrate the real-world impact of our framework through\nLlama-3.1-Nemotron-51B-Instruct (Nemotron-51B), a publicly available model\nderived from Llama-3.1-70B-Instruct. Nemotron-51B achieves a 2.17x inference\nthroughput speedup, fitting on a single NVIDIA H100 GPU while preserving 98.4%\nof the original model's capabilities. Nemotron-51B currently stands as the most\naccurate language model capable of inference on a single GPU with large batch\nsizes. Remarkably, this transformation required just 45B training tokens,\ncompared to over 15T tokens used for the 70B model it was derived from. This\nestablishes a new paradigm where powerful models can be optimized for efficient\ndeployment with only negligible compromise of their capabilities, demonstrating\nthat inference performance, not parameter count alone, should guide model\nselection. With the release of Nemotron-51B and the presentation of the Puzzle\nframework, we provide practitioners immediate access to state-of-the-art\nlanguage modeling capabilities at significantly reduced computational costs.",
            "upvotes": 9,
            "discussionId": "674d3dea6ab71cc666cce9d9"
        },
        "publishedAt": "2024-12-01T23:56:50.380Z",
        "title": "Puzzle: Distillation-Based NAS for Inference-Optimized LLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19146.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5279
        }
    },
    {
        "paper": {
            "id": "2411.19108",
            "authors": [
                {
                    "_id": "674d371b5e924d18e56a450c",
                    "user": {
                        "_id": "661658b9e398e4f0757221ce",
                        "avatarUrl": "/avatars/9e9d55145661d00e2a9e029ba2e085d8.svg",
                        "isPro": false,
                        "fullname": "Liu Feng",
                        "user": "LiewFeng",
                        "type": "user"
                    },
                    "name": "Feng Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T09:34:03.626Z",
                    "hidden": false
                },
                {
                    "_id": "674d371b5e924d18e56a450d",
                    "user": {
                        "_id": "63a1200045edac9f7508bae9",
                        "avatarUrl": "/avatars/e84f0b045f32c5b8b4da43458650b925.svg",
                        "isPro": false,
                        "fullname": "Shiwei Zhang",
                        "user": "StevenZhang",
                        "type": "user"
                    },
                    "name": "Shiwei Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:11:39.991Z",
                    "hidden": false
                },
                {
                    "_id": "674d371b5e924d18e56a450e",
                    "user": {
                        "_id": "6426616ea5ec4a5cbc535634",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6426616ea5ec4a5cbc535634/hH6JsxnXeakH3mBTeNNmO.jpeg",
                        "isPro": false,
                        "fullname": "JeffWang",
                        "user": "Jeff-Wang",
                        "type": "user"
                    },
                    "name": "Xiaofeng Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T08:51:21.743Z",
                    "hidden": false
                },
                {
                    "_id": "674d371b5e924d18e56a450f",
                    "user": {
                        "_id": "637f70d6fab5db9101c3dfc8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637f70d6fab5db9101c3dfc8/NgkYNXWLDavLbrnCby2Fl.jpeg",
                        "isPro": false,
                        "fullname": "Yujie Wei",
                        "user": "weilllllls",
                        "type": "user"
                    },
                    "name": "Yujie Wei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:12:00.442Z",
                    "hidden": false
                },
                {
                    "_id": "674d371b5e924d18e56a4510",
                    "user": {
                        "_id": "63023b6ab002e9a4a2152890",
                        "avatarUrl": "/avatars/cae8ba0a8d61fb4e576934431f43991b.svg",
                        "isPro": false,
                        "fullname": "Haonan Qiu",
                        "user": "MoonQiu",
                        "type": "user"
                    },
                    "name": "Haonan Qiu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:12:05.919Z",
                    "hidden": false
                },
                {
                    "_id": "674d371b5e924d18e56a4511",
                    "name": "Yuzhong Zhao",
                    "hidden": false
                },
                {
                    "_id": "674d371b5e924d18e56a4512",
                    "user": {
                        "_id": "66f3dd5c0fc8cc6ae16af8d5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66f3dd5c0fc8cc6ae16af8d5/xd-PuVvj5Ber9yvAFm3jq.jpeg",
                        "isPro": false,
                        "fullname": "voidoc",
                        "user": "ldmLDM77",
                        "type": "user"
                    },
                    "name": "Yingya Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T09:34:01.699Z",
                    "hidden": false
                },
                {
                    "_id": "674d371b5e924d18e56a4513",
                    "name": "Qixiang Ye",
                    "hidden": false
                },
                {
                    "_id": "674d371b5e924d18e56a4514",
                    "name": "Fang Wan",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-28T12:50:05.000Z",
            "title": "Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model",
            "summary": "As a fundamental backbone for video generation, diffusion models are\nchallenged by low inference speed due to the sequential nature of denoising.\nPrevious methods speed up the models by caching and reusing model outputs at\nuniformly selected timesteps. However, such a strategy neglects the fact that\ndifferences among model outputs are not uniform across timesteps, which hinders\nselecting the appropriate model outputs to cache, leading to a poor balance\nbetween inference efficiency and visual quality. In this study, we introduce\nTimestep Embedding Aware Cache (TeaCache), a training-free caching approach\nthat estimates and leverages the fluctuating differences among model outputs\nacross timesteps. Rather than directly using the time-consuming model outputs,\nTeaCache focuses on model inputs, which have a strong correlation with the\nmodeloutputs while incurring negligible computational cost. TeaCache first\nmodulates the noisy inputs using the timestep embeddings to ensure their\ndifferences better approximating those of model outputs. TeaCache then\nintroduces a rescaling strategy to refine the estimated differences and\nutilizes them to indicate output caching. Experiments show that TeaCache\nachieves up to 4.41x acceleration over Open-Sora-Plan with negligible (-0.07%\nVbench score) degradation of visual quality.",
            "upvotes": 9,
            "discussionId": "674d371d5e924d18e56a45de"
        },
        "publishedAt": "2024-12-01T23:27:53.033Z",
        "title": "Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19108.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5279
        }
    },
    {
        "paper": {
            "id": "2411.19324",
            "authors": [
                {
                    "_id": "674d3226810801f2fa57b8ed",
                    "user": {
                        "_id": "650e37cc11f3210cf7910501",
                        "avatarUrl": "/avatars/dab5c9d647cfa97c59f5170216673a20.svg",
                        "isPro": false,
                        "fullname": "zeqixiao",
                        "user": "zeqixiao",
                        "type": "user"
                    },
                    "name": "Zeqi Xiao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:39:04.354Z",
                    "hidden": false
                },
                {
                    "_id": "674d3226810801f2fa57b8ee",
                    "user": {
                        "_id": "6487d9415d164d8c7f905bcf",
                        "avatarUrl": "/avatars/1c01dd4b88f88a9863a12c09a9a28bed.svg",
                        "isPro": false,
                        "fullname": "Wenqi Ouyang",
                        "user": "Vicky0522",
                        "type": "user"
                    },
                    "name": "Wenqi Ouyang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:38:53.298Z",
                    "hidden": false
                },
                {
                    "_id": "674d3226810801f2fa57b8ef",
                    "user": {
                        "_id": "64a63f9449b08110f761cd73",
                        "avatarUrl": "/avatars/61860202fc818b105ef24e74dd4f7d3c.svg",
                        "isPro": false,
                        "fullname": "Yifan Zhou",
                        "user": "SingleZombie",
                        "type": "user"
                    },
                    "name": "Yifan Zhou",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T12:52:33.458Z",
                    "hidden": false
                },
                {
                    "_id": "674d3226810801f2fa57b8f0",
                    "user": {
                        "_id": "62a54d0410334c1d024e2f59",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1664764278226-62a54d0410334c1d024e2f59.jpeg",
                        "isPro": false,
                        "fullname": "Shuai Yang",
                        "user": "PKUWilliamYang",
                        "type": "user"
                    },
                    "name": "Shuai Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:38:33.890Z",
                    "hidden": false
                },
                {
                    "_id": "674d3226810801f2fa57b8f1",
                    "user": {
                        "_id": "6626a471430a124253f197c8",
                        "avatarUrl": "/avatars/f5747fdbe495d1296fed9d16d8c95857.svg",
                        "isPro": false,
                        "fullname": "yl-1993",
                        "user": "yl-1993",
                        "type": "user"
                    },
                    "name": "Lei Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T12:52:31.720Z",
                    "hidden": false
                },
                {
                    "_id": "674d3226810801f2fa57b8f2",
                    "user": {
                        "_id": "6409693abf3e9a4bb2e64dfd",
                        "avatarUrl": "/avatars/3e2789fc37c907a7a3eddc75b688600c.svg",
                        "isPro": false,
                        "fullname": "Jianlou",
                        "user": "Jianlou",
                        "type": "user"
                    },
                    "name": "Jianlou Si",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:38:05.905Z",
                    "hidden": false
                },
                {
                    "_id": "674d3226810801f2fa57b8f3",
                    "user": {
                        "_id": "646758d6a9b4610868a138ff",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646758d6a9b4610868a138ff/fNBlK5g4g7vlPAR1bQimZ.png",
                        "isPro": false,
                        "fullname": "Xingang Pan",
                        "user": "Xingang-Pan",
                        "type": "user"
                    },
                    "name": "Xingang Pan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:37:47.316Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-28T18:59:51.000Z",
            "title": "Trajectory Attention for Fine-grained Video Motion Control",
            "summary": "Recent advancements in video generation have been greatly driven by video\ndiffusion models, with camera motion control emerging as a crucial challenge in\ncreating view-customized visual content. This paper introduces trajectory\nattention, a novel approach that performs attention along available pixel\ntrajectories for fine-grained camera motion control. Unlike existing methods\nthat often yield imprecise outputs or neglect temporal correlations, our\napproach possesses a stronger inductive bias that seamlessly injects trajectory\ninformation into the video generation process. Importantly, our approach models\ntrajectory attention as an auxiliary branch alongside traditional temporal\nattention. This design enables the original temporal attention and the\ntrajectory attention to work in synergy, ensuring both precise motion control\nand new content generation capability, which is critical when the trajectory is\nonly partially available. Experiments on camera motion control for images and\nvideos demonstrate significant improvements in precision and long-range\nconsistency while maintaining high-quality generation. Furthermore, we show\nthat our approach can be extended to other video motion control tasks, such as\nfirst-frame-guided video editing, where it excels in maintaining content\nconsistency over large spatial and temporal ranges.",
            "upvotes": 9,
            "discussionId": "674d3229810801f2fa57b9e8"
        },
        "publishedAt": "2024-12-01T23:06:57.506Z",
        "title": "Trajectory Attention for Fine-grained Video Motion Control",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19324.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/dab5c9d647cfa97c59f5170216673a20.svg",
            "fullname": "zeqixiao",
            "name": "zeqixiao",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        }
    },
    {
        "paper": {
            "id": "2411.18552",
            "authors": [
                {
                    "_id": "674d8ddeda397a3869dae2ba",
                    "name": "Haosen Yang",
                    "hidden": false
                },
                {
                    "_id": "674d8ddeda397a3869dae2bb",
                    "name": "Adrian Bulat",
                    "hidden": false
                },
                {
                    "_id": "674d8ddeda397a3869dae2bc",
                    "name": "Isma Hadji",
                    "hidden": false
                },
                {
                    "_id": "674d8ddeda397a3869dae2bd",
                    "name": "Hai X. Pham",
                    "hidden": false
                },
                {
                    "_id": "674d8ddeda397a3869dae2be",
                    "name": "Xiatian Zhu",
                    "hidden": false
                },
                {
                    "_id": "674d8ddeda397a3869dae2bf",
                    "name": "Georgios Tzimiropoulos",
                    "hidden": false
                },
                {
                    "_id": "674d8ddeda397a3869dae2c0",
                    "name": "Brais Martinez",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T17:51:44.000Z",
            "title": "FAM Diffusion: Frequency and Attention Modulation for High-Resolution\n  Image Generation with Stable Diffusion",
            "summary": "Diffusion models are proficient at generating high-quality images. They are\nhowever effective only when operating at the resolution used during training.\nInference at a scaled resolution leads to repetitive patterns and structural\ndistortions. Retraining at higher resolutions quickly becomes prohibitive.\nThus, methods enabling pre-existing diffusion models to operate at flexible\ntest-time resolutions are highly desirable. Previous works suffer from frequent\nartifacts and often introduce large latency overheads. We propose two simple\nmodules that combine to solve these issues. We introduce a Frequency Modulation\n(FM) module that leverages the Fourier domain to improve the global structure\nconsistency, and an Attention Modulation (AM) module which improves the\nconsistency of local texture patterns, a problem largely ignored in prior\nworks. Our method, coined Fam diffusion, can seamlessly integrate into any\nlatent diffusion model and requires no additional training. Extensive\nqualitative results highlight the effectiveness of our method in addressing\nstructural and local artifacts, while quantitative results show\nstate-of-the-art performance. Also, our method avoids redundant inference\ntricks for improved consistency such as patch-based or progressive generation,\nleading to negligible latency overheads.",
            "upvotes": 8,
            "discussionId": "674d8de3da397a3869dae3a5"
        },
        "publishedAt": "2024-12-02T05:41:04.486Z",
        "title": "FAM Diffusion: Frequency and Attention Modulation for High-Resolution Image Generation with Stable Diffusion",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18552.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/dae01f7054da8c9517e3808a6f10eb1a.svg",
            "fullname": "HY",
            "name": "happy0612",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.19527",
            "authors": [
                {
                    "_id": "674d17baaa794726fac6a6c9",
                    "user": {
                        "_id": "65b5d43419d2172f003fed47",
                        "avatarUrl": "/avatars/2f370314e5cac7dc77914bf13d169d0c.svg",
                        "isPro": false,
                        "fullname": "jbc",
                        "user": "whwjdqls99",
                        "type": "user"
                    },
                    "name": "Jungbin Cho",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T08:49:56.163Z",
                    "hidden": false
                },
                {
                    "_id": "674d17baaa794726fac6a6ca",
                    "user": {
                        "_id": "64c2c45ae818eec6128fdda3",
                        "avatarUrl": "/avatars/d4399e25e6399345e263c7902789047e.svg",
                        "isPro": false,
                        "fullname": "Jun-Wan KIM",
                        "user": "junwann",
                        "type": "user"
                    },
                    "name": "Junwan Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T08:49:53.178Z",
                    "hidden": false
                },
                {
                    "_id": "674d17baaa794726fac6a6cb",
                    "name": "Jisoo Kim",
                    "hidden": false
                },
                {
                    "_id": "674d17baaa794726fac6a6cc",
                    "user": {
                        "_id": "64f22ee8a2fc808156dd1872",
                        "avatarUrl": "/avatars/45d9140acbfdbb0a8b044c2f9d3c4fad.svg",
                        "isPro": false,
                        "fullname": "Kim Minseo",
                        "user": "min99830",
                        "type": "user"
                    },
                    "name": "Minseo Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T12:52:35.160Z",
                    "hidden": false
                },
                {
                    "_id": "674d17baaa794726fac6a6cd",
                    "name": "Mingu Kang",
                    "hidden": false
                },
                {
                    "_id": "674d17baaa794726fac6a6ce",
                    "name": "Sungeun Hong",
                    "hidden": false
                },
                {
                    "_id": "674d17baaa794726fac6a6cf",
                    "name": "Tae-Hyun Oh",
                    "hidden": false
                },
                {
                    "_id": "674d17baaa794726fac6a6d0",
                    "name": "Youngjae Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-29T07:54:56.000Z",
            "title": "DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow\n  Decoding",
            "summary": "Human motion, inherently continuous and dynamic, presents significant\nchallenges for generative models. Despite their dominance, discrete\nquantization methods, such as VQ-VAEs, suffer from inherent limitations,\nincluding restricted expressiveness and frame-wise noise artifacts. Continuous\napproaches, while producing smoother and more natural motions, often falter due\nto high-dimensional complexity and limited training data. To resolve this\n\"discord\" between discrete and continuous representations, we introduce\nDisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding, a\nnovel method that decodes discrete motion tokens into continuous motion through\nrectified flow. By employing an iterative refinement process in the continuous\nspace, DisCoRD captures fine-grained dynamics and ensures smoother and more\nnatural motions. Compatible with any discrete-based framework, our method\nenhances naturalness without compromising faithfulness to the conditioning\nsignals. Extensive evaluations demonstrate that DisCoRD achieves\nstate-of-the-art performance, with FID of 0.032 on HumanML3D and 0.169 on\nKIT-ML. These results solidify DisCoRD as a robust solution for bridging the\ndivide between discrete efficiency and continuous realism. Our project page is\navailable at: https://whwjdqls.github.io/discord.github.io/.",
            "upvotes": 8,
            "discussionId": "674d17bcaa794726fac6a755"
        },
        "publishedAt": "2024-12-02T04:38:21.019Z",
        "title": "DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19527.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/d4399e25e6399345e263c7902789047e.svg",
            "fullname": "Jun-Wan KIM",
            "name": "junwann",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2411.19950",
            "authors": [
                {
                    "_id": "674d422720c42228e89c477e",
                    "user": {
                        "_id": "64c903957b4d0d947ce86bc6",
                        "avatarUrl": "/avatars/61d70a3ba00c83a5950f5c909a1a06f8.svg",
                        "isPro": false,
                        "fullname": "Yuze He",
                        "user": "hyz317",
                        "type": "user"
                    },
                    "name": "Yuze He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:20:25.901Z",
                    "hidden": false
                },
                {
                    "_id": "674d422720c42228e89c477f",
                    "user": {
                        "_id": "66054d519af76210c2ee4b8e",
                        "avatarUrl": "/avatars/c1854765b1e45ec33602b2cb9443f82a.svg",
                        "isPro": false,
                        "fullname": "Wang Zhao",
                        "user": "thuzhaowang",
                        "type": "user"
                    },
                    "name": "Wang Zhao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T09:34:05.024Z",
                    "hidden": false
                },
                {
                    "_id": "674d422720c42228e89c4780",
                    "user": {
                        "_id": "635265ff3d604ecb3936e3d0",
                        "avatarUrl": "/avatars/53e7cd1a216f97c45fc3e51e3a8bae35.svg",
                        "isPro": false,
                        "fullname": "Shaohui Liu",
                        "user": "lshmouse",
                        "type": "user"
                    },
                    "name": "Shaohui Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:20:34.937Z",
                    "hidden": false
                },
                {
                    "_id": "674d422720c42228e89c4781",
                    "user": {
                        "_id": "672a099e6077b009b3c9972d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/lduG_xVw-XFElSKhZrava.jpeg",
                        "isPro": false,
                        "fullname": "Yubin Hu",
                        "user": "AlbertHuyb",
                        "type": "user"
                    },
                    "name": "Yubin Hu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:20:40.445Z",
                    "hidden": false
                },
                {
                    "_id": "674d422720c42228e89c4782",
                    "user": {
                        "_id": "64ed568ccf6118a9379a61b8",
                        "avatarUrl": "/avatars/6d040cbcb4a9b624cbe64c9d01cd5c88.svg",
                        "isPro": false,
                        "fullname": "Yushi Bai",
                        "user": "bys0318",
                        "type": "user"
                    },
                    "name": "Yushi Bai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:20:45.506Z",
                    "hidden": false
                },
                {
                    "_id": "674d422720c42228e89c4783",
                    "name": "Yu-Hui Wen",
                    "hidden": false
                },
                {
                    "_id": "674d422720c42228e89c4784",
                    "name": "Yong-Jin Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-29T18:59:52.000Z",
            "title": "AlphaTablets: A Generic Plane Representation for 3D Planar\n  Reconstruction from Monocular Videos",
            "summary": "We introduce AlphaTablets, a novel and generic representation of 3D planes\nthat features continuous 3D surface and precise boundary delineation. By\nrepresenting 3D planes as rectangles with alpha channels, AlphaTablets combine\nthe advantages of current 2D and 3D plane representations, enabling accurate,\nconsistent and flexible modeling of 3D planes. We derive differentiable\nrasterization on top of AlphaTablets to efficiently render 3D planes into\nimages, and propose a novel bottom-up pipeline for 3D planar reconstruction\nfrom monocular videos. Starting with 2D superpixels and geometric cues from\npre-trained models, we initialize 3D planes as AlphaTablets and optimize them\nvia differentiable rendering. An effective merging scheme is introduced to\nfacilitate the growth and refinement of AlphaTablets. Through iterative\noptimization and merging, we reconstruct complete and accurate 3D planes with\nsolid surfaces and clear boundaries. Extensive experiments on the ScanNet\ndataset demonstrate state-of-the-art performance in 3D planar reconstruction,\nunderscoring the great potential of AlphaTablets as a generic 3D plane\nrepresentation for various applications. Project page is available at:\nhttps://hyzcluster.github.io/alphatablets",
            "upvotes": 5,
            "discussionId": "674d422d20c42228e89c4937"
        },
        "publishedAt": "2024-12-02T01:54:45.261Z",
        "title": "AlphaTablets: A Generic Plane Representation for 3D Planar Reconstruction from Monocular Videos",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19950.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/61d70a3ba00c83a5950f5c909a1a06f8.svg",
            "fullname": "Yuze He",
            "name": "hyz317",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2411.19460",
            "authors": [
                {
                    "_id": "674d309e6a8ca5d12c0dac71",
                    "user": {
                        "_id": "673060959e631f353ae1b5e0",
                        "avatarUrl": "/avatars/d4b1e23de90ff1d02c38186a259b8d1e.svg",
                        "isPro": false,
                        "fullname": "Hosu Lee",
                        "user": "lakelee",
                        "type": "user"
                    },
                    "name": "Hosu Lee",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T08:49:36.175Z",
                    "hidden": false
                },
                {
                    "_id": "674d309e6a8ca5d12c0dac72",
                    "user": {
                        "_id": "653238bed0f5a9e537ed966d",
                        "avatarUrl": "/avatars/e97a83e68e770baa1c5df847777cf213.svg",
                        "isPro": false,
                        "fullname": "Junho Kim",
                        "user": "arkimjh",
                        "type": "user"
                    },
                    "name": "Junho Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T09:46:14.671Z",
                    "hidden": false
                },
                {
                    "_id": "674d309e6a8ca5d12c0dac73",
                    "name": "Hyunjun Kim",
                    "hidden": false
                },
                {
                    "_id": "674d309e6a8ca5d12c0dac74",
                    "user": {
                        "_id": "660603529e3555d648e3baf1",
                        "avatarUrl": "/avatars/0f54479afcfc19df00b25d5aedb4cf67.svg",
                        "isPro": false,
                        "fullname": "Yong Man Ro",
                        "user": "dwightro",
                        "type": "user"
                    },
                    "name": "Yong Man Ro",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:13:04.450Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-29T04:12:13.000Z",
            "title": "Look Every Frame All at Once: Video-Ma^2mba for Efficient Long-form\n  Video Understanding with Multi-Axis Gradient Checkpointing",
            "summary": "With the growing scale and complexity of video data, efficiently processing\nlong video sequences poses significant challenges due to the quadratic increase\nin memory and computational demands associated with existing transformer-based\nLarge Multi-modal Models (LMMs). To address these issues, we introduce\nVideo-Ma^2mba, a novel architecture that incorporates State Space Models\n(SSMs) within the Mamba-2 framework, replacing the attention mechanisms. This\nallows the LMMs to scale linearly in terms of time and memory requirements,\nmaking it feasible to handle long-duration video content. Furthermore, we\nenhance the memory efficiency introducing the Multi-Axis Gradient Checkpointing\n(MA-GC) method, which strategically manages memory by retaining only essential\nactivations across multiple computational axes. Our approach significantly\nreduces the memory footprint compared to standard gradient checkpointing.\nEmpirical analyses show that Video-Ma^2mba can process extensive video\nsequences-equivalent to millions of tokens or over two hours of continuous\nsequences at 1 FPS-on a single GPU. By maintaining a detailed capture of\ntemporal dynamics, our model improves the accuracy and relevance of responses\nin long video understanding tasks, demonstrating substantial advantages over\nexisting frameworks.",
            "upvotes": 5,
            "discussionId": "674d309f6a8ca5d12c0dacbb"
        },
        "publishedAt": "2024-12-01T23:41:11.161Z",
        "title": "Look Every Frame All at Once: Video-Ma$^2$mba for Efficient Long-form Video Understanding with Multi-Axis Gradient Checkpointing",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19460.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/e97a83e68e770baa1c5df847777cf213.svg",
            "fullname": "Junho Kim",
            "name": "arkimjh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.19638",
            "authors": [
                {
                    "_id": "674d5e4ee208467411046583",
                    "user": {
                        "_id": "636e15698ba65db4a09384ab",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/636e15698ba65db4a09384ab/jtkbytatqb7oiIIB3oWMF.jpeg",
                        "isPro": false,
                        "fullname": "Taja Kuzman",
                        "user": "TajaKuzman",
                        "type": "user"
                    },
                    "name": "Taja Kuzman",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-12-02T07:21:13.856Z",
                    "hidden": false
                },
                {
                    "_id": "674d5e4ee208467411046584",
                    "user": {
                        "_id": "601431aad1f82f3c09cb43ac",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1632563266956-601431aad1f82f3c09cb43ac.png",
                        "isPro": false,
                        "fullname": "Nikola Ljubešić",
                        "user": "nljubesi",
                        "type": "user"
                    },
                    "name": "Nikola Ljubešić",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:46:03.442Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-29T11:42:58.000Z",
            "title": "LLM Teacher-Student Framework for Text Classification With No Manually\n  Annotated Data: A Case Study in IPTC News Topic Classification",
            "summary": "With the ever-increasing number of news stories available online, classifying\nthem by topic, regardless of the language they are written in, has become\ncrucial for enhancing readers' access to relevant content. To address this\nchallenge, we propose a teacher-student framework based on large language\nmodels (LLMs) for developing multilingual news classification models of\nreasonable size with no need for manual data annotation. The framework employs\na Generative Pretrained Transformer (GPT) model as the teacher model to develop\nan IPTC Media Topic training dataset through automatic annotation of news\narticles in Slovenian, Croatian, Greek, and Catalan. The teacher model exhibits\na high zero-shot performance on all four languages. Its agreement with human\nannotators is comparable to that between the human annotators themselves. To\nmitigate the computational limitations associated with the requirement of\nprocessing millions of texts daily, smaller BERT-like student models are\nfine-tuned on the GPT-annotated dataset. These student models achieve high\nperformance comparable to the teacher model. Furthermore, we explore the impact\nof the training data size on the performance of the student models and\ninvestigate their monolingual, multilingual and zero-shot cross-lingual\ncapabilities. The findings indicate that student models can achieve high\nperformance with a relatively small number of training instances, and\ndemonstrate strong zero-shot cross-lingual abilities. Finally, we publish the\nbest-performing news topic classifier, enabling multilingual classification\nwith the top-level categories of the IPTC Media Topic schema.",
            "upvotes": 4,
            "discussionId": "674d5e4fe2084674110465d4"
        },
        "publishedAt": "2024-12-02T02:20:49.713Z",
        "title": "LLM Teacher-Student Framework for Text Classification With No Manually Annotated Data: A Case Study in IPTC News Topic Classification",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/636e15698ba65db4a09384ab/OM6J-8EW7urA0PZT6KCj4.png",
            "https://cdn-uploads.huggingface.co/production/uploads/636e15698ba65db4a09384ab/hE96ryBmAc1GIj17dwr3w.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19638.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/636e15698ba65db4a09384ab/jtkbytatqb7oiIIB3oWMF.jpeg",
            "fullname": "Taja Kuzman",
            "name": "TajaKuzman",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        }
    },
    {
        "paper": {
            "id": "2411.18673",
            "authors": [
                {
                    "_id": "674d35b82636ad461d487c2c",
                    "user": {
                        "_id": "647ef66c45baf21ad707b291",
                        "avatarUrl": "/avatars/4cd941cdca6dd829fdc9cb3fb788a99c.svg",
                        "isPro": false,
                        "fullname": "Sherwin Bahmani",
                        "user": "sherwinbahmani",
                        "type": "user"
                    },
                    "name": "Sherwin Bahmani",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:45:16.818Z",
                    "hidden": false
                },
                {
                    "_id": "674d35b82636ad461d487c2d",
                    "user": {
                        "_id": "63610db13c7147fae7de88e3",
                        "avatarUrl": "/avatars/d7e97a16cfee39e1e50d7a5b747876f1.svg",
                        "isPro": false,
                        "fullname": "Ivan Skorokhodov",
                        "user": "universome",
                        "type": "user"
                    },
                    "name": "Ivan Skorokhodov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:45:22.220Z",
                    "hidden": false
                },
                {
                    "_id": "674d35b82636ad461d487c2e",
                    "user": {
                        "_id": "645fed74335c21d19f3bf76c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645fed74335c21d19f3bf76c/gwVsllRWtSHbg4a1erkdF.jpeg",
                        "isPro": false,
                        "fullname": "Guocheng Qian",
                        "user": "guochengqian",
                        "type": "user"
                    },
                    "name": "Guocheng Qian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:45:27.259Z",
                    "hidden": false
                },
                {
                    "_id": "674d35b82636ad461d487c2f",
                    "user": {
                        "_id": "64276311eb9a0ed86180715b",
                        "avatarUrl": "/avatars/76f933cd549f10e5e2db379de235d304.svg",
                        "isPro": false,
                        "fullname": "Aliaksandr Siarohin",
                        "user": "aliaksandr-siarohin",
                        "type": "user"
                    },
                    "name": "Aliaksandr Siarohin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:45:32.409Z",
                    "hidden": false
                },
                {
                    "_id": "674d35b82636ad461d487c30",
                    "user": {
                        "_id": "6315358a362e3e95ea538081",
                        "avatarUrl": "/avatars/3b089a25a87c2e83c6b23ccb5d2dc73e.svg",
                        "isPro": false,
                        "fullname": "Willi Menapace",
                        "user": "willi-menapace",
                        "type": "user"
                    },
                    "name": "Willi Menapace",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T09:45:37.562Z",
                    "hidden": false
                },
                {
                    "_id": "674d35b82636ad461d487c31",
                    "name": "Andrea Tagliasacchi",
                    "hidden": false
                },
                {
                    "_id": "674d35b82636ad461d487c32",
                    "name": "David B. Lindell",
                    "hidden": false
                },
                {
                    "_id": "674d35b82636ad461d487c33",
                    "name": "Sergey Tulyakov",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T18:49:13.000Z",
            "title": "AC3D: Analyzing and Improving 3D Camera Control in Video Diffusion\n  Transformers",
            "summary": "Numerous works have recently integrated 3D camera control into foundational\ntext-to-video models, but the resulting camera control is often imprecise, and\nvideo generation quality suffers. In this work, we analyze camera motion from a\nfirst principles perspective, uncovering insights that enable precise 3D camera\nmanipulation without compromising synthesis quality. First, we determine that\nmotion induced by camera movements in videos is low-frequency in nature. This\nmotivates us to adjust train and test pose conditioning schedules, accelerating\ntraining convergence while improving visual and motion quality. Then, by\nprobing the representations of an unconditional video diffusion transformer, we\nobserve that they implicitly perform camera pose estimation under the hood, and\nonly a sub-portion of their layers contain the camera information. This\nsuggested us to limit the injection of camera conditioning to a subset of the\narchitecture to prevent interference with other video features, leading to 4x\nreduction of training parameters, improved training speed and 10% higher visual\nquality. Finally, we complement the typical dataset for camera control learning\nwith a curated dataset of 20K diverse dynamic videos with stationary cameras.\nThis helps the model disambiguate the difference between camera and scene\nmotion, and improves the dynamics of generated pose-conditioned videos. We\ncompound these findings to design the Advanced 3D Camera Control (AC3D)\narchitecture, the new state-of-the-art model for generative video modeling with\ncamera control.",
            "upvotes": 4,
            "discussionId": "674d35bc2636ad461d487e25"
        },
        "publishedAt": "2024-12-01T23:21:29.296Z",
        "title": "AC3D: Analyzing and Improving 3D Camera Control in Video Diffusion Transformers",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18673.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5279
        }
    },
    {
        "paper": {
            "id": "2411.19842",
            "authors": [
                {
                    "_id": "674dcdbf9e95621d1d73169e",
                    "name": "Julian D Parker",
                    "hidden": false
                },
                {
                    "_id": "674dcdbf9e95621d1d73169f",
                    "name": "Anton Smirnov",
                    "hidden": false
                },
                {
                    "_id": "674dcdbf9e95621d1d7316a0",
                    "name": "Jordi Pons",
                    "hidden": false
                },
                {
                    "_id": "674dcdbf9e95621d1d7316a1",
                    "name": "CJ Carr",
                    "hidden": false
                },
                {
                    "_id": "674dcdbf9e95621d1d7316a2",
                    "name": "Zack Zukowski",
                    "hidden": false
                },
                {
                    "_id": "674dcdbf9e95621d1d7316a3",
                    "name": "Zach Evans",
                    "hidden": false
                },
                {
                    "_id": "674dcdbf9e95621d1d7316a4",
                    "name": "Xubo Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-29T16:58:02.000Z",
            "title": "Scaling Transformers for Low-Bitrate High-Quality Speech Coding",
            "summary": "The tokenization of speech with neural audio codec models is a vital part of\nmodern AI pipelines for the generation or understanding of speech, alone or in\na multimodal context. Traditionally such tokenization models have concentrated\non low parameter-count architectures using only components with strong\ninductive biases. In this work we show that by scaling a transformer\narchitecture with large parameter count to this problem, and applying a\nflexible Finite Scalar Quantization (FSQ) based bottleneck, it is possible to\nreach state-of-the-art speech quality at extremely low bit-rates of 400 or\n700 bits-per-second. The trained models strongly out-perform existing\nbaselines in both objective and subjective tests.",
            "upvotes": 2,
            "discussionId": "674dcdc09e95621d1d7316ea"
        },
        "publishedAt": "2024-12-02T11:37:46.581Z",
        "title": "Scaling Transformers for Low-Bitrate High-Quality Speech Coding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19842.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5279
        }
    },
    {
        "paper": {
            "id": "2411.18664",
            "authors": [
                {
                    "_id": "674dcfe2aef5b4ffeca9afb2",
                    "name": "Junha Hyung",
                    "hidden": false
                },
                {
                    "_id": "674dcfe2aef5b4ffeca9afb3",
                    "user": {
                        "_id": "64797735a68454566356b708",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/MahGT-WiCIRHbjPUmTYl1.png",
                        "isPro": false,
                        "fullname": "Kinam Kim",
                        "user": "kinam0252",
                        "type": "user"
                    },
                    "name": "Kinam Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T16:11:06.066Z",
                    "hidden": false
                },
                {
                    "_id": "674dcfe2aef5b4ffeca9afb4",
                    "name": "Susung Hong",
                    "hidden": false
                },
                {
                    "_id": "674dcfe2aef5b4ffeca9afb5",
                    "name": "Min-Jung Kim",
                    "hidden": false
                },
                {
                    "_id": "674dcfe2aef5b4ffeca9afb6",
                    "name": "Jaegul Choo",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-27T15:59:48.000Z",
            "title": "Spatiotemporal Skip Guidance for Enhanced Video Diffusion Sampling",
            "summary": "Diffusion models have emerged as a powerful tool for generating high-quality\nimages, videos, and 3D content. While sampling guidance techniques like CFG\nimprove quality, they reduce diversity and motion. Autoguidance mitigates these\nissues but demands extra weak model training, limiting its practicality for\nlarge-scale models. In this work, we introduce Spatiotemporal Skip Guidance\n(STG), a simple training-free sampling guidance method for enhancing\ntransformer-based video diffusion models. STG employs an implicit weak model\nvia self-perturbation, avoiding the need for external models or additional\ntraining. By selectively skipping spatiotemporal layers, STG produces an\naligned, degraded version of the original model to boost sample quality without\ncompromising diversity or dynamic degree. Our contributions include: (1)\nintroducing STG as an efficient, high-performing guidance technique for video\ndiffusion models, (2) eliminating the need for auxiliary models by simulating a\nweak model through layer skipping, and (3) ensuring quality-enhanced guidance\nwithout compromising sample diversity or dynamics unlike CFG. For additional\nresults, visit https://junhahyung.github.io/STGuidance.",
            "upvotes": 1,
            "discussionId": "674dcfeaaef5b4ffeca9b351"
        },
        "publishedAt": "2024-12-02T11:19:44.245Z",
        "title": "Spatiotemporal Skip Guidance for Enhanced Video Diffusion Sampling",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.18664.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/MahGT-WiCIRHbjPUmTYl1.png",
            "fullname": "Kinam Kim",
            "name": "kinam0252",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2411.19865",
            "authors": [
                {
                    "_id": "674d1b7c6a8ca5d12c06f3ae",
                    "user": {
                        "_id": "62ce26129f723d34cf1f595a",
                        "avatarUrl": "/avatars/8e305ac7c170d70fbf83c109789b40d9.svg",
                        "isPro": false,
                        "fullname": "Justin Chen",
                        "user": "dinobby",
                        "type": "user"
                    },
                    "name": "Justin Chih-Yao Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-12-02T08:49:48.541Z",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3af",
                    "name": "Zifeng Wang",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b0",
                    "name": "Hamid Palangi",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b1",
                    "name": "Rujun Han",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b2",
                    "name": "Sayna Ebrahimi",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b3",
                    "name": "Long Le",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b4",
                    "name": "Vincent Perot",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b5",
                    "user": {
                        "_id": "61841feb7c380c66d40cad54",
                        "avatarUrl": "/avatars/7a79362a24b844860781fb0625527eae.svg",
                        "isPro": false,
                        "fullname": "Swaroop Mishra",
                        "user": "swaroop7",
                        "type": "user"
                    },
                    "name": "Swaroop Mishra",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T16:11:27.638Z",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b6",
                    "user": {
                        "_id": "665d9d3a057f7c508f98c625",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/665d9d3a057f7c508f98c625/u1R9P9sJoAl4zEIcetbPy.jpeg",
                        "isPro": false,
                        "fullname": "Mohit Bansal",
                        "user": "mohitbansal",
                        "type": "user"
                    },
                    "name": "Mohit Bansal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T16:11:20.589Z",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b7",
                    "user": {
                        "_id": "64d1fe784dfd5df7076bfd1a",
                        "avatarUrl": "/avatars/e2bb108d1f6b1383f0e3f263c4747b3d.svg",
                        "isPro": false,
                        "fullname": "Chen-Yu Lee",
                        "user": "chenyulee",
                        "type": "user"
                    },
                    "name": "Chen-Yu Lee",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-12-02T16:10:57.700Z",
                    "hidden": false
                },
                {
                    "_id": "674d1b7c6a8ca5d12c06f3b8",
                    "name": "Tomas Pfister",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-29T17:27:05.000Z",
            "title": "Reverse Thinking Makes LLMs Stronger Reasoners",
            "summary": "Reverse thinking plays a crucial role in human reasoning. Humans can reason\nnot only from a problem to a solution but also in reverse, i.e., start from the\nsolution and reason towards the problem. This often enhances overall reasoning\nperformance as it enables consistency checks between their forward and backward\nthinking. To enable Large Language Models (LLMs) to perform reverse thinking,\nwe introduce Reverse-Enhanced Thinking (RevThink), a framework composed of data\naugmentation and learning objectives. In RevThink, we augment the dataset by\ncollecting structured forward-backward reasoning from a teacher model,\nconsisting of: (1) the original question, (2) forward reasoning, (3) backward\nquestion, and (4) backward reasoning. We then employ three objectives to train\na smaller student model in a multi-task learning fashion: (a) generate forward\nreasoning from a question, (b) generate a backward question from a question,\nand (c) generate backward reasoning from the backward question. Experiments\nacross 12 datasets covering commonsense, math, and logical reasoning show an\naverage 13.53% improvement over the student model's zero-shot performance and a\n6.84% improvement over the strongest knowledge distillation baselines.\nMoreover, our method demonstrates sample efficiency -- using only 10% of the\ncorrect forward reasoning from the training data, it outperforms a standard\nfine-tuning method trained on 10x more forward reasoning. RevThink also\nexhibits strong generalization to out-of-distribution held-out datasets.",
            "upvotes": 1,
            "discussionId": "674d1b7c6a8ca5d12c06f3d9"
        },
        "publishedAt": "2024-12-02T10:31:20.957Z",
        "title": "Reverse Thinking Makes LLMs Stronger Reasoners",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.19865.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/8e305ac7c170d70fbf83c109789b40d9.svg",
            "fullname": "Justin Chen",
            "name": "dinobby",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]