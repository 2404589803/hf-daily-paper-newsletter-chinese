[
  {
    "paper": {
      "id": "2508.21104",
      "authors": [
        {
          "_id": "68b50650851c6e7b001eca07",
          "name": "Wenfeng Feng",
          "hidden": false
        },
        {
          "_id": "68b50650851c6e7b001eca08",
          "name": "Penghong Zhao",
          "hidden": false
        },
        {
          "_id": "68b50650851c6e7b001eca09",
          "user": {
            "_id": "644a1dbb9c340e5e1e713153",
            "avatarUrl": "/avatars/21cb93ad067a798a39829ef7e67c70b8.svg",
            "isPro": false,
            "fullname": "JGC",
            "user": "Nothing2Say",
            "type": "user"
          },
          "name": "Guochao Jiang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-09-01T07:50:45.446Z",
          "hidden": false
        },
        {
          "_id": "68b50650851c6e7b001eca0a",
          "name": "Chuzhan Hao",
          "hidden": false
        },
        {
          "_id": "68b50650851c6e7b001eca0b",
          "name": "Yuewei Zhang",
          "hidden": false
        },
        {
          "_id": "68b50650851c6e7b001eca0c",
          "name": "Hao Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-28T09:18:26.000Z",
      "submittedOnDailyAt": "2025-09-02T00:25:08.396Z",
      "title": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic\n  Reasoning",
      "submittedOnDailyBy": {
        "_id": "644a1dbb9c340e5e1e713153",
        "avatarUrl": "/avatars/21cb93ad067a798a39829ef7e67c70b8.svg",
        "isPro": false,
        "fullname": "JGC",
        "user": "Nothing2Say",
        "type": "user"
      },
      "summary": "Critic-free reinforcement learning methods, particularly group policies, have\nattracted considerable attention for their efficiency in complex tasks.\nHowever, these methods rely heavily on multiple sampling and comparisons within\nthe policy to estimate advantage, which may cause the policy to fall into local\noptimum and increase computational cost. To address these issues, we propose\nPVPO, an efficient reinforcement learning method enhanced by an advantage\nreference anchor and data pre-sampling. Specifically, we use the reference\nmodel to rollout in advance and employ the calculated reward score as a\nreference anchor. Our approach effectively corrects the cumulative bias\nintroduced by intra-group comparisons and significantly reduces reliance on the\nnumber of rollouts. Meanwhile, the reference model can assess sample difficulty\nduring data pre-sampling, enabling effective selection of high-gain data to\nimprove training efficiency. Experiments conducted on nine datasets across two\ndomains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our\napproach not only demonstrates robust generalization across multiple tasks, but\nalso exhibits scalable performance across models of varying scales.",
      "upvotes": 9,
      "discussionId": "68b50651851c6e7b001eca0d",
      "ai_summary": "PVPO, an enhanced reinforcement learning method using a reference anchor and data pre-sampling, achieves state-of-the-art performance with reduced computational cost and improved generalization.",
      "ai_keywords": [
        "critic-free reinforcement learning",
        "group policies",
        "advantage estimation",
        "local optimum",
        "computational cost",
        "advantage reference anchor",
        "data pre-sampling",
        "reference model",
        "rollout",
        "reward score",
        "cumulative bias",
        "intra-group comparisons",
        "sample difficulty",
        "high-gain data",
        "training efficiency",
        "state-of-the-art performance",
        "robust generalization",
        "scalable performance"
      ]
    },
    "publishedAt": "2025-08-28T05:18:26.000Z",
    "title": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic\n  Reasoning",
    "summary": "Critic-free reinforcement learning methods, particularly group policies, have\nattracted considerable attention for their efficiency in complex tasks.\nHowever, these methods rely heavily on multiple sampling and comparisons within\nthe policy to estimate advantage, which may cause the policy to fall into local\noptimum and increase computational cost. To address these issues, we propose\nPVPO, an efficient reinforcement learning method enhanced by an advantage\nreference anchor and data pre-sampling. Specifically, we use the reference\nmodel to rollout in advance and employ the calculated reward score as a\nreference anchor. Our approach effectively corrects the cumulative bias\nintroduced by intra-group comparisons and significantly reduces reliance on the\nnumber of rollouts. Meanwhile, the reference model can assess sample difficulty\nduring data pre-sampling, enabling effective selection of high-gain data to\nimprove training efficiency. Experiments conducted on nine datasets across two\ndomains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our\napproach not only demonstrates robust generalization across multiple tasks, but\nalso exhibits scalable performance across models of varying scales.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.21104.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "644a1dbb9c340e5e1e713153",
      "avatarUrl": "/avatars/21cb93ad067a798a39829ef7e67c70b8.svg",
      "fullname": "JGC",
      "name": "Nothing2Say",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2508.19060",
      "authors": [
        {
          "_id": "68b2a781851c6e7b001ec685",
          "user": {
            "_id": "644abca2bef23513f3e6eb55",
            "avatarUrl": "/avatars/1e5a40a90a6425b297118f3790ca7c79.svg",
            "isPro": false,
            "fullname": "Blaz Rolih",
            "user": "blaz-r",
            "type": "user"
          },
          "name": "Blaž Rolih",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-09-01T07:52:54.791Z",
          "hidden": false
        },
        {
          "_id": "68b2a781851c6e7b001ec686",
          "user": {
            "_id": "63636d302bff406cb0575289",
            "avatarUrl": "/avatars/cebc02551b7f0418f5d33466959e0796.svg",
            "isPro": false,
            "fullname": "Matic Fučka",
            "user": "MaticFuc",
            "type": "user"
          },
          "name": "Matic Fučka",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-09-01T13:51:37.034Z",
          "hidden": false
        },
        {
          "_id": "68b2a781851c6e7b001ec687",
          "name": "Danijel Skočaj",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-26T14:20:21.000Z",
      "submittedOnDailyAt": "2025-09-02T01:45:44.492Z",
      "title": "No Label Left Behind: A Unified Surface Defect Detection Model for all\n  Supervision Regimes",
      "submittedOnDailyBy": {
        "_id": "644abca2bef23513f3e6eb55",
        "avatarUrl": "/avatars/1e5a40a90a6425b297118f3790ca7c79.svg",
        "isPro": false,
        "fullname": "Blaz Rolih",
        "user": "blaz-r",
        "type": "user"
      },
      "summary": "Surface defect detection is a critical task across numerous industries, aimed\nat efficiently identifying and localising imperfections or irregularities on\nmanufactured components. While numerous methods have been proposed, many fail\nto meet industrial demands for high performance, efficiency, and adaptability.\nExisting approaches are often constrained to specific supervision scenarios and\nstruggle to adapt to the diverse data annotations encountered in real-world\nmanufacturing processes, such as unsupervised, weakly supervised, mixed\nsupervision, and fully supervised settings. To address these challenges, we\npropose SuperSimpleNet, a highly efficient and adaptable discriminative model\nbuilt on the foundation of SimpleNet. SuperSimpleNet incorporates a novel\nsynthetic anomaly generation process, an enhanced classification head, and an\nimproved learning procedure, enabling efficient training in all four\nsupervision scenarios, making it the first model capable of fully leveraging\nall available data annotations. SuperSimpleNet sets a new standard for\nperformance across all scenarios, as demonstrated by its results on four\nchallenging benchmark datasets. Beyond accuracy, it is very fast, achieving an\ninference time below 10 ms. With its ability to unify diverse supervision\nparadigms while maintaining outstanding speed and reliability, SuperSimpleNet\nrepresents a promising step forward in addressing real-world manufacturing\nchallenges and bridging the gap between academic research and industrial\napplications. Code: https://github.com/blaz-r/SuperSimpleNet",
      "upvotes": 1,
      "discussionId": "68b2a781851c6e7b001ec688",
      "githubRepo": "https://github.com/blaz-r/SuperSimplenet",
      "ai_summary": "SuperSimpleNet, an efficient and adaptable model based on SimpleNet, addresses diverse supervision scenarios in surface defect detection with high performance and low inference time.",
      "ai_keywords": [
        "SimpleNet",
        "synthetic anomaly generation",
        "classification head",
        "learning procedure",
        "unsupervised",
        "weakly supervised",
        "mixed supervision",
        "fully supervised",
        "benchmark datasets",
        "inference time"
      ],
      "githubStars": 77
    },
    "publishedAt": "2025-08-26T10:20:21.000Z",
    "title": "No Label Left Behind: A Unified Surface Defect Detection Model for all\n  Supervision Regimes",
    "summary": "Surface defect detection is a critical task across numerous industries, aimed\nat efficiently identifying and localising imperfections or irregularities on\nmanufactured components. While numerous methods have been proposed, many fail\nto meet industrial demands for high performance, efficiency, and adaptability.\nExisting approaches are often constrained to specific supervision scenarios and\nstruggle to adapt to the diverse data annotations encountered in real-world\nmanufacturing processes, such as unsupervised, weakly supervised, mixed\nsupervision, and fully supervised settings. To address these challenges, we\npropose SuperSimpleNet, a highly efficient and adaptable discriminative model\nbuilt on the foundation of SimpleNet. SuperSimpleNet incorporates a novel\nsynthetic anomaly generation process, an enhanced classification head, and an\nimproved learning procedure, enabling efficient training in all four\nsupervision scenarios, making it the first model capable of fully leveraging\nall available data annotations. SuperSimpleNet sets a new standard for\nperformance across all scenarios, as demonstrated by its results on four\nchallenging benchmark datasets. Beyond accuracy, it is very fast, achieving an\ninference time below 10 ms. With its ability to unify diverse supervision\nparadigms while maintaining outstanding speed and reliability, SuperSimpleNet\nrepresents a promising step forward in addressing real-world manufacturing\nchallenges and bridging the gap between academic research and industrial\napplications. Code: https://github.com/blaz-r/SuperSimpleNet",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.19060.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "644abca2bef23513f3e6eb55",
      "avatarUrl": "/avatars/1e5a40a90a6425b297118f3790ca7c79.svg",
      "fullname": "Blaz Rolih",
      "name": "blaz-r",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2508.17378",
      "authors": [
        {
          "_id": "68b69c0626d3ff3f69d5fdc8",
          "name": "Omer Nacar",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-24T14:32:15.000Z",
      "submittedOnDailyAt": "2025-09-02T05:56:22.215Z",
      "title": "UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via\n  HUMAIN Chat",
      "submittedOnDailyBy": {
        "_id": "628f7a71dd993507cfcbe587",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
        "isPro": true,
        "fullname": "Omartificial Intelligence Space",
        "user": "Omartificial-Intelligence-Space",
        "type": "user"
      },
      "summary": "Large language models (LLMs) trained primarily on English corpora often\nstruggle to capture the linguistic and cultural nuances of Arabic. To address\nthis gap, the Saudi Data and AI Authority (SDAIA) introduced the ALLaM family\nof Arabic-focused models. The most capable of these available to the public,\nALLaM-34B, was subsequently adopted by HUMAIN, who developed and deployed\nHUMAIN Chat, a closed conversational web service built on this model. This\npaper presents an expanded and refined UI-level evaluation of ALLaM-34B.\nUsing a prompt pack spanning modern standard Arabic, five regional dialects,\ncode-switching, factual knowledge, arithmetic and temporal reasoning, creative\ngeneration, and adversarial safety, we collected 115 outputs (23 prompts times\n5 runs) and scored each with three frontier LLM judges (GPT-5, Gemini 2.5 Pro,\nClaude Sonnet-4). We compute category-level means with 95\\% confidence\nintervals, analyze score distributions, and visualize dialect-wise metric heat\nmaps. The updated analysis reveals consistently high performance on generation\nand code-switching tasks (both averaging 4.92/5), alongside strong results in\nMSA handling (4.74/5), solid reasoning ability (4.64/5), and improved dialect\nfidelity (4.21/5). Safety-related prompts show stable, reliable performance of\n(4.54/5). Taken together, these results position ALLaM-34B as a robust and\nculturally grounded Arabic LLM, demonstrating both technical strength and\npractical readiness for real-world deployment.",
      "upvotes": 1,
      "discussionId": "68b69c0726d3ff3f69d5fdc9",
      "ai_summary": "The evaluation of ALLaM-34B, an Arabic-focused LLM, demonstrates high performance across various tasks including generation, code-switching, MSA handling, reasoning, dialect fidelity, and safety, positioning it as a robust and culturally grounded model.",
      "ai_keywords": [
        "LLMs",
        "Arabic-focused models",
        "ALLaM-34B",
        "HUMAIN Chat",
        "UI-level evaluation",
        "prompt pack",
        "regional dialects",
        "code-switching",
        "factual knowledge",
        "arithmetic",
        "temporal reasoning",
        "creative generation",
        "adversarial safety",
        "LLM judges",
        "category-level means",
        "confidence intervals",
        "score distributions",
        "dialect-wise metric heat maps",
        "MSA handling",
        "reasoning ability",
        "dialect fidelity",
        "safety-related prompts"
      ]
    },
    "publishedAt": "2025-08-24T10:32:15.000Z",
    "title": "UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via\n  HUMAIN Chat",
    "summary": "Large language models (LLMs) trained primarily on English corpora often\nstruggle to capture the linguistic and cultural nuances of Arabic. To address\nthis gap, the Saudi Data and AI Authority (SDAIA) introduced the ALLaM family\nof Arabic-focused models. The most capable of these available to the public,\nALLaM-34B, was subsequently adopted by HUMAIN, who developed and deployed\nHUMAIN Chat, a closed conversational web service built on this model. This\npaper presents an expanded and refined UI-level evaluation of ALLaM-34B.\nUsing a prompt pack spanning modern standard Arabic, five regional dialects,\ncode-switching, factual knowledge, arithmetic and temporal reasoning, creative\ngeneration, and adversarial safety, we collected 115 outputs (23 prompts times\n5 runs) and scored each with three frontier LLM judges (GPT-5, Gemini 2.5 Pro,\nClaude Sonnet-4). We compute category-level means with 95\\% confidence\nintervals, analyze score distributions, and visualize dialect-wise metric heat\nmaps. The updated analysis reveals consistently high performance on generation\nand code-switching tasks (both averaging 4.92/5), alongside strong results in\nMSA handling (4.74/5), solid reasoning ability (4.64/5), and improved dialect\nfidelity (4.21/5). Safety-related prompts show stable, reliable performance of\n(4.54/5). Taken together, these results position ALLaM-34B as a robust and\nculturally grounded Arabic LLM, demonstrating both technical strength and\npractical readiness for real-world deployment.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.17378.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "628f7a71dd993507cfcbe587",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
      "fullname": "Omartificial Intelligence Space",
      "name": "Omartificial-Intelligence-Space",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 128
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2508.20931",
      "authors": [
        {
          "_id": "68b6779026d3ff3f69d5fd0c",
          "name": "Venkatesh Mishra",
          "hidden": false
        },
        {
          "_id": "68b6779026d3ff3f69d5fd0d",
          "name": "Amir Saeidi",
          "hidden": false
        },
        {
          "_id": "68b6779026d3ff3f69d5fd0e",
          "name": "Satyam Raj",
          "hidden": false
        },
        {
          "_id": "68b6779026d3ff3f69d5fd0f",
          "name": "Mutsumi Nakamura",
          "hidden": false
        },
        {
          "_id": "68b6779026d3ff3f69d5fd10",
          "name": "Jayanth Srinivasa",
          "hidden": false
        },
        {
          "_id": "68b6779026d3ff3f69d5fd11",
          "name": "Gaowen Liu",
          "hidden": false
        },
        {
          "_id": "68b6779026d3ff3f69d5fd12",
          "name": "Ali Payani",
          "hidden": false
        },
        {
          "_id": "68b6779026d3ff3f69d5fd13",
          "name": "Chitta Baral",
          "hidden": false
        }
      ],
      "publishedAt": "2025-08-28T15:57:33.000Z",
      "submittedOnDailyAt": "2025-09-02T03:21:46.446Z",
      "title": "How Can Input Reformulation Improve Tool Usage Accuracy in a Complex\n  Dynamic Environment? A Study on τ-bench",
      "submittedOnDailyBy": {
        "_id": "640f6299ef5c6dcac8b1df52",
        "avatarUrl": "/avatars/022f21183abc8a8b5ce1b198d3ba96dc.svg",
        "isPro": false,
        "fullname": "Amir",
        "user": "sahsaeedi",
        "type": "user"
      },
      "summary": "Recent advances in reasoning and planning capabilities of large language\nmodels (LLMs) have enabled their potential as autonomous agents capable of tool\nuse in dynamic environments. However, in multi-turn conversational environments\nlike tau-bench, these agents often struggle with consistent reasoning,\nadherence to domain-specific policies, and extracting correct information over\na long horizon of tool-calls and conversation. To capture and mitigate these\nfailures, we conduct a comprehensive manual analysis of the common errors\noccurring in the conversation trajectories. We then experiment with\nreformulations of inputs to the tool-calling agent for improvement in agent\ndecision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)\nframework, which automatically reformulates user queries augmented with\nrelevant domain rules and tool suggestions for the tool-calling agent to focus\non. The results show that IRMA significantly outperforms ReAct, Function\nCalling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in\noverall pass^5 scores. These findings highlight the superior reliability and\nconsistency of IRMA compared to other methods in dynamic environments.",
      "upvotes": 0,
      "discussionId": "68b6779026d3ff3f69d5fd14",
      "ai_summary": "The IRMA framework improves the reliability and consistency of large language models in dynamic environments by reformulating user queries with domain rules and tool suggestions.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "autonomous agents",
        "tool use",
        "multi-turn conversational environments",
        "$\\tau$-bench",
        "consistent reasoning",
        "domain-specific policies",
        "conversation trajectories",
        "tool-calling",
        "agent decision making",
        "Input-Reformulation Multi-Agent",
        "IRMA",
        "ReAct",
        "Function Calling",
        "Self-Reflection",
        "pass^5 scores"
      ]
    },
    "publishedAt": "2025-08-28T11:57:33.000Z",
    "title": "How Can Input Reformulation Improve Tool Usage Accuracy in a Complex\n  Dynamic Environment? A Study on τ-bench",
    "summary": "Recent advances in reasoning and planning capabilities of large language\nmodels (LLMs) have enabled their potential as autonomous agents capable of tool\nuse in dynamic environments. However, in multi-turn conversational environments\nlike tau-bench, these agents often struggle with consistent reasoning,\nadherence to domain-specific policies, and extracting correct information over\na long horizon of tool-calls and conversation. To capture and mitigate these\nfailures, we conduct a comprehensive manual analysis of the common errors\noccurring in the conversation trajectories. We then experiment with\nreformulations of inputs to the tool-calling agent for improvement in agent\ndecision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)\nframework, which automatically reformulates user queries augmented with\nrelevant domain rules and tool suggestions for the tool-calling agent to focus\non. The results show that IRMA significantly outperforms ReAct, Function\nCalling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in\noverall pass^5 scores. These findings highlight the superior reliability and\nconsistency of IRMA compared to other methods in dynamic environments.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.20931.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "640f6299ef5c6dcac8b1df52",
      "avatarUrl": "/avatars/022f21183abc8a8b5ce1b198d3ba96dc.svg",
      "fullname": "Amir",
      "name": "sahsaeedi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  }
]