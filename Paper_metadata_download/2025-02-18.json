[
  {
    "paper": {
      "id": "2502.12152",
      "authors": [
        {
          "_id": "67b41ed52867282b4eb37ce4",
          "name": "Xialin He",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce5",
          "name": "Runpei Dong",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce6",
          "name": "Zixuan Chen",
          "hidden": false
        },
        {
          "_id": "67b41ed52867282b4eb37ce7",
          "name": "Saurabh Gupta",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:59:06.000Z",
      "title": "Learning Getting-Up Policies for Real-World Humanoid Robots",
      "summary": "Automatic fall recovery is a crucial prerequisite before humanoid robots can\nbe reliably deployed. Hand-designing controllers for getting up is difficult\nbecause of the varied configurations a humanoid can end up in after a fall and\nthe challenging terrains humanoid robots are expected to operate on. This paper\ndevelops a learning framework to produce controllers that enable humanoid\nrobots to get up from varying configurations on varying terrains. Unlike\nprevious successful applications of humanoid locomotion learning, the\ngetting-up task involves complex contact patterns, which necessitates\naccurately modeling the collision geometry and sparser rewards. We address\nthese challenges through a two-phase approach that follows a curriculum. The\nfirst stage focuses on discovering a good getting-up trajectory under minimal\nconstraints on smoothness or speed / torque limits. The second stage then\nrefines the discovered motions into deployable (i.e. smooth and slow) motions\nthat are robust to variations in initial configuration and terrains. We find\nthese innovations enable a real-world G1 humanoid robot to get up from two main\nsituations that we considered: a) lying face up and b) lying face down, both\ntested on flat, deformable, slippery surfaces and slopes (e.g., sloppy grass\nand snowfield). To the best of our knowledge, this is the first successful\ndemonstration of learned getting-up policies for human-sized humanoid robots in\nthe real world. Project page: https://humanoid-getup.github.io/",
      "upvotes": 21,
      "discussionId": "67b41edb2867282b4eb37ddf"
    },
    "publishedAt": "2025-02-18T00:49:53.124Z",
    "title": "Learning Getting-Up Policies for Real-World Humanoid Robots",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/6201fc5d91d53938a6432fbf/x35BuXOhc6ubukxLfiVzt.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12152.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6201fc5d91d53938a6432fbf",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
      "fullname": "Runpei Dong",
      "name": "RunpeiDong",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11190",
      "authors": [
        {
          "_id": "67b420dfb2528c023491f455",
          "name": "Haoming Xu",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f456",
          "name": "Ningyuan Zhao",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f457",
          "name": "Liming Yang",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f458",
          "name": "Sendong Zhao",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f459",
          "name": "Shumin Deng",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45a",
          "name": "Mengru Wang",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45b",
          "name": "Bryan Hooi",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45c",
          "name": "Nay Oo",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45d",
          "name": "Huajun Chen",
          "hidden": false
        },
        {
          "_id": "67b420dfb2528c023491f45e",
          "name": "Ningyu Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T16:31:00.000Z",
      "title": "ReLearn: Unlearning via Learning for Large Language Models",
      "summary": "Current unlearning methods for large language models usually rely on reverse\noptimization to reduce target token probabilities. However, this paradigm\ndisrupts the subsequent tokens prediction, degrading model performance and\nlinguistic coherence. Moreover, existing evaluation metrics overemphasize\ncontextual forgetting while inadequately assessing response fluency and\nrelevance. To address these challenges, we propose ReLearn, a data augmentation\nand fine-tuning pipeline for effective unlearning, along with a comprehensive\nevaluation framework. This framework introduces Knowledge Forgetting Rate (KFR)\nand Knowledge Retention Rate (KRR) to measure knowledge-level preservation, and\nLinguistic Score (LS) to evaluate generation quality. Our experiments show that\nReLearn successfully achieves targeted forgetting while preserving high-quality\noutput. Through mechanistic analysis, we further demonstrate how reverse\noptimization disrupts coherent text generation, while ReLearn preserves this\nessential capability. Code is available at https://github.com/zjunlp/unlearn.",
      "upvotes": 9,
      "discussionId": "67b420e2b2528c023491f506"
    },
    "publishedAt": "2025-02-18T00:58:24.094Z",
    "title": "ReLearn: Unlearning via Learning for Large Language Models",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/A4YB7t6hDVty6QrvLN0a7.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11190.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12148",
      "authors": [
        {
          "_id": "67b40c8cdb88dfd19ab917f3",
          "name": "Ling Yang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f4",
          "name": "Xinchen Zhang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f5",
          "name": "Ye Tian",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f6",
          "name": "Chenming Shang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f7",
          "name": "Minghao Xu",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f8",
          "name": "Wentao Zhang",
          "hidden": false
        },
        {
          "_id": "67b40c8cdb88dfd19ab917f9",
          "name": "Bin Cui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:57:51.000Z",
      "title": "HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and\n  Generation",
      "summary": "The remarkable success of the autoregressive paradigm has made significant\nadvancement in Multimodal Large Language Models (MLLMs), with powerful models\nlike Show-o, Transfusion and Emu3 achieving notable progress in unified image\nunderstanding and generation. For the first time, we uncover a common\nphenomenon: the understanding capabilities of MLLMs are typically stronger than\ntheir generative capabilities, with a significant gap between the two. Building\non this insight, we propose HermesFlow, a simple yet general framework designed\nto seamlessly bridge the gap between understanding and generation in MLLMs.\nSpecifically, we take the homologous data as input to curate homologous\npreference data of both understanding and generation. Through Pair-DPO and\nself-play iterative optimization, HermesFlow effectively aligns multimodal\nunderstanding and generation using homologous preference data. Extensive\nexperiments demonstrate the significant superiority of our approach over prior\nmethods, particularly in narrowing the gap between multimodal understanding and\ngeneration. These findings highlight the potential of HermesFlow as a general\nalignment framework for next-generation multimodal foundation models. Code:\nhttps://github.com/Gen-Verse/HermesFlow",
      "upvotes": 9,
      "discussionId": "67b40c8edb88dfd19ab9183f"
    },
    "publishedAt": "2025-02-17T23:29:29.396Z",
    "title": "HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12148.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653e5d31ffd60206c8b64bb5",
      "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
      "fullname": "Xinchen Zhang",
      "name": "comin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12115",
      "authors": [
        {
          "_id": "67b41a72a38d04cc6148d80e",
          "name": "Samuel Miserendino",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d80f",
          "name": "Michele Wang",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d810",
          "name": "Tejal Patwardhan",
          "hidden": false
        },
        {
          "_id": "67b41a72a38d04cc6148d811",
          "name": "Johannes Heidecke",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:41:16.000Z",
      "title": "SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance\n  Software Engineering?",
      "summary": "We introduce SWE-Lancer, a benchmark of over 1,400 freelance software\nengineering tasks from Upwork, valued at \\1 million USD total in real-world\npayouts. SWE-Lancer encompasses both independent engineering tasks--ranging\nfrom 50 bug fixes to \\$32,000 feature implementations--and managerial tasks,\nwhere models choose between technical implementation proposals. Independent\ntasks are graded with end-to-end tests triple-verified by experienced software\nengineers, while managerial decisions are assessed against the choices of the\noriginal hired engineering managers. We evaluate model performance and find\nthat frontier models are still unable to solve the majority of tasks. To\nfacilitate future research, we open-source a unified Docker image and a public\nevaluation split, SWE-Lancer Diamond\n(https://github.com/openai/SWELancer-Benchmark). By mapping model performance\nto monetary value, we hope SWE-Lancer enables greater research into the\neconomic impact of AI model development.",
      "upvotes": 6,
      "discussionId": "67b41a74a38d04cc6148d84b"
    },
    "publishedAt": "2025-02-18T00:28:31.293Z",
    "title": "SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12115.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6127
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.12146",
      "authors": [
        {
          "_id": "67b40ce4d3c5f50aa9b71df5",
          "name": "Ye Tian",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df6",
          "name": "Ling Yang",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df7",
          "name": "Xinchen Zhang",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df8",
          "name": "Yunhai Tong",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71df9",
          "name": "Mengdi Wang",
          "hidden": false
        },
        {
          "_id": "67b40ce4d3c5f50aa9b71dfa",
          "name": "Bin Cui",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T18:57:26.000Z",
      "title": "Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising\n  Trajectory Sharpening",
      "summary": "We propose Diffusion-Sharpening, a fine-tuning approach that enhances\ndownstream alignment by optimizing sampling trajectories. Existing RL-based\nfine-tuning methods focus on single training timesteps and neglect\ntrajectory-level alignment, while recent sampling trajectory optimization\nmethods incur significant inference NFE costs. Diffusion-Sharpening overcomes\nthis by using a path integral framework to select optimal trajectories during\ntraining, leveraging reward feedback, and amortizing inference costs. Our\nmethod demonstrates superior training efficiency with faster convergence, and\nbest inference efficiency without requiring additional NFEs. Extensive\nexperiments show that Diffusion-Sharpening outperforms RL-based fine-tuning\nmethods (e.g., Diffusion-DPO) and sampling trajectory optimization methods\n(e.g., Inference Scaling) across diverse metrics including text alignment,\ncompositional capabilities, and human preferences, offering a scalable and\nefficient solution for future diffusion model fine-tuning. Code:\nhttps://github.com/Gen-Verse/Diffusion-Sharpening",
      "upvotes": 6,
      "discussionId": "67b40ce8d3c5f50aa9b71f9a"
    },
    "publishedAt": "2025-02-17T23:30:53.097Z",
    "title": "Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising Trajectory Sharpening",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12146.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "653e5d31ffd60206c8b64bb5",
      "avatarUrl": "/avatars/5076795722ec1f9e031654f301d30e8f.svg",
      "fullname": "Xinchen Zhang",
      "name": "comin",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 13
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11167",
      "authors": [
        {
          "_id": "67b4221bbc387d2eda6f8637",
          "name": "Bohan Lyu",
          "hidden": false
        },
        {
          "_id": "67b4221bbc387d2eda6f8638",
          "name": "Siqiao Huang",
          "hidden": false
        },
        {
          "_id": "67b4221bbc387d2eda6f8639",
          "name": "Zichen Liang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T15:38:19.000Z",
      "title": "SURGE: On the Potential of Large Language Models as General-Purpose\n  Surrogate Code Executors",
      "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\ncode-related tasks, such as code understanding and code generation. However, an\nequally important yet underexplored question is whether LLMs can serve as\ngeneral-purpose surrogate code executors, to predict the output and behavior of\na program without actually running it. To systematically investigate this\ncapability, we introduce SURGE, a comprehensive benchmark covering eight key\naspects: multi-language programming tasks, competition-level programming\nproblems, repository-level code analysis, high-cost scientific computing,\ntime-complexity-intensive algorithms, buggy code analysis, programs dependent\non specific compilers or execution environments, and formal mathematical proof\nverification. We evaluate multiple open-source and proprietary LLMs on SURGE\nand conduct a scaling study to analyze the impact of model size and training\ndata scale on surrogate execution accuracy. Additionally, we categorize model\nprediction errors and explore potential areas for improvement. Our findings\nindicate that while LLMs can predict code execution results in certain cases,\nthey exhibit limitations in general-purpose surrogate execution. This study\nprovides empirical insights into the feasibility of using LLMs as surrogate\ncode executors. Code and dataset are released at\nhttps://github.com/Imbernoulli/SURGE.",
      "upvotes": 5,
      "discussionId": "67b4221ebc387d2eda6f8717"
    },
    "publishedAt": "2025-02-18T01:01:24.331Z",
    "title": "SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11167.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650267e7e751d03da933a24a",
      "avatarUrl": "/avatars/f047a047d1de304cd97027463541bdf3.svg",
      "fullname": "Bohan22",
      "name": "Bohan22",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11438",
      "authors": [
        {
          "_id": "67b406993d0f54ab381594f5",
          "name": "Jimin Lee",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f6",
          "name": "Ingeol Baek",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f7",
          "name": "Byeongjeong Kim",
          "hidden": false
        },
        {
          "_id": "67b406993d0f54ab381594f8",
          "name": "Hwanhee Lee",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T04:52:24.000Z",
      "title": "SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example\n  Selection for Text-to-SQL",
      "summary": "Text-to-SQL aims to convert natural language questions into executable SQL\nqueries. While previous approaches, such as skeleton-masked selection, have\ndemonstrated strong performance by retrieving similar training examples to\nguide large language models (LLMs), they struggle in real-world scenarios where\nsuch examples are unavailable. To overcome this limitation, we propose\nSelf-Augmentation in-context learning with Fine-grained Example selection for\nText-to-SQL (SAFE-SQL), a novel framework that improves SQL generation by\ngenerating and filtering self-augmented examples. SAFE-SQL first prompts an LLM\nto generate multiple Text-to-SQL examples relevant to the test input. Then\nSAFE-SQL filters these examples through three relevance assessments,\nconstructing high-quality in-context learning examples. Using self-generated\nexamples, SAFE-SQL surpasses the previous zero-shot, and few-shot Text-to-SQL\nframeworks, achieving higher execution accuracy. Notably, our approach provides\nadditional performance gains in extra hard and unseen scenarios, where\nconventional methods often fail.",
      "upvotes": 5,
      "discussionId": "67b4069a3d0f54ab38159520"
    },
    "publishedAt": "2025-02-17T23:06:03.562Z",
    "title": "SAFE-SQL: Self-Augmented In-Context Learning with Fine-grained Example Selection for Text-to-SQL",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11438.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63f6f245e94ed998c46316df",
      "avatarUrl": "/avatars/9c0ec8682d4a85b96d2180602b1bbe6c.svg",
      "fullname": "ingeolbaek",
      "name": "ingeol",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11196",
      "authors": [
        {
          "_id": "67b42223c2fe54b8d43efed6",
          "name": "Yixin Ou",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed7",
          "name": "Yunzhi Yao",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed8",
          "name": "Ningyu Zhang",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efed9",
          "name": "Hui Jin",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efeda",
          "name": "Jiacheng Sun",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedb",
          "name": "Shumin Deng",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedc",
          "name": "Zhenguo Li",
          "hidden": false
        },
        {
          "_id": "67b42223c2fe54b8d43efedd",
          "name": "Huajun Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T16:55:43.000Z",
      "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on\n  Continual Pre-Training",
      "summary": "Despite exceptional capabilities in knowledge-intensive tasks, Large Language\nModels (LLMs) face a critical gap in understanding how they internalize new\nknowledge, particularly how to structurally embed acquired knowledge in their\nneural computations. We address this issue through the lens of knowledge\ncircuit evolution, identifying computational subgraphs that facilitate\nknowledge storage and processing. Our systematic analysis of circuit evolution\nthroughout continual pre-training reveals several key findings: (1) the\nacquisition of new knowledge is influenced by its relevance to pre-existing\nknowledge; (2) the evolution of knowledge circuits exhibits a distinct phase\nshift from formation to optimization; (3) the evolution of knowledge circuits\nfollows a deep-to-shallow pattern. These insights not only advance our\ntheoretical understanding of the mechanisms of new knowledge acquisition in\nLLMs, but also provide potential implications for improving continual\npre-training strategies to enhance model performance. Code and data will be\navailable at https://github.com/zjunlp/DynamicKnowledgeCircuits.",
      "upvotes": 4,
      "discussionId": "67b42225c2fe54b8d43eff9b"
    },
    "publishedAt": "2025-02-18T01:02:25.236Z",
    "title": "How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/_LGnwvwslWc3YDIirfOKS.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11196.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 16
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.09061",
      "authors": [
        {
          "_id": "67b401de3995f28d45c212d6",
          "name": "Debangshu Banerjee",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d7",
          "name": "Tarun Suresh",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d8",
          "name": "Shubham Ugare",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212d9",
          "name": "Sasa Misailovic",
          "hidden": false
        },
        {
          "_id": "67b401de3995f28d45c212da",
          "name": "Gagandeep Singh",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-13T08:23:42.000Z",
      "title": "CRANE: Reasoning with constrained LLM generation",
      "summary": "Code generation, symbolic math reasoning, and other tasks require LLMs to\nproduce outputs that are both syntactically and semantically correct.\nConstrained LLM generation is a promising direction to enforce adherence to\nformal grammar, but prior works have empirically observed that strict\nenforcement of formal constraints often diminishes the reasoning capabilities\nof LLMs. In this work, we first provide a theoretical explanation for why\nconstraining LLM outputs to very restrictive grammars that only allow\nsyntactically valid final answers reduces the reasoning capabilities of the\nmodel. Second, we demonstrate that by augmenting the output grammar with\ncarefully designed additional rules, it is always possible to preserve the\nreasoning capabilities of the LLM while ensuring syntactic and semantic\ncorrectness in its outputs. Building on these theoretical insights, we propose\na reasoning-augmented constrained decoding algorithm, CRANE, which effectively\nbalances the correctness of constrained generation with the flexibility of\nunconstrained generation. Experiments on multiple open-source LLMs and\nbenchmarks show that CRANE significantly outperforms both state-of-the-art\nconstrained decoding strategies and standard unconstrained decoding, showing up\nto 10% points accuracy improvement over baselines on challenging symbolic\nreasoning benchmarks GSM-symbolic and FOLIO.",
      "upvotes": 4,
      "discussionId": "67b401e03995f28d45c21354"
    },
    "publishedAt": "2025-02-17T22:43:51.555Z",
    "title": "CRANE: Reasoning with constrained LLM generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09061.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65e7bb35e5e78134ab049942",
      "avatarUrl": "/avatars/3c0972f0d59e51ebb5c218ee736d4458.svg",
      "fullname": "Tarun Suresh",
      "name": "tarsur909",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11275",
      "authors": [
        {
          "_id": "67b3fa2862838a378b21860d",
          "name": "Letian Peng",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b21860e",
          "name": "Zilong Wang",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b21860f",
          "name": "Feng Yao",
          "hidden": false
        },
        {
          "_id": "67b3fa2862838a378b218610",
          "name": "Jingbo Shang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T21:32:20.000Z",
      "title": "Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest",
      "summary": "Massive high-quality data, both pre-training raw texts and post-training\nannotations, have been carefully prepared to incubate advanced large language\nmodels (LLMs). In contrast, for information extraction (IE), pre-training data,\nsuch as BIO-tagged sequences, are hard to scale up. We show that IE models can\nact as free riders on LLM resources by reframing next-token prediction\ninto extraction for tokens already present in the context. Specifically,\nour proposed next tokens extraction (NTE) paradigm learns a versatile IE model,\nCuckoo, with 102.6M extractive data converted from LLM's pre-training\nand post-training data. Under the few-shot setting, Cuckoo adapts effectively\nto traditional and complex instruction-following IE with better performance\nthan existing pre-trained IE models. As a free rider, Cuckoo can naturally\nevolve with the ongoing advancements in LLM data preparation, benefiting from\nimprovements in LLM training pipelines without additional manual effort.",
      "upvotes": 4,
      "discussionId": "67b3fa2962838a378b21867b"
    },
    "publishedAt": "2025-02-17T22:10:49.900Z",
    "title": "Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM's Nest",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11275.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64323dd503d81fa4d26deaf9",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64323dd503d81fa4d26deaf9/x3ES8VXEZJljxDWvFWaAf.png",
      "fullname": "Letian Peng",
      "name": "KomeijiForce",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 7
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11901",
      "authors": [
        {
          "_id": "67b3f8cc1bfe04e82830b752",
          "name": "Dylan Zhang",
          "hidden": false
        },
        {
          "_id": "67b3f8cc1bfe04e82830b753",
          "name": "Justin Wang",
          "hidden": false
        },
        {
          "_id": "67b3f8cc1bfe04e82830b754",
          "name": "Tianran Sun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T15:24:11.000Z",
      "title": "Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o\n  Under Data Scarsity",
      "summary": "Existing LMs struggle with proof-oriented programming due to data scarcity,\nwhich manifest in two key ways: (1) a lack of sufficient corpora for\nproof-oriented programming languages such as F*, and (2) the absence of\nlarge-scale, project-level proof-oriented implementations that can teach the\nmodel the intricate reasoning process when performing proof-oriented\nprogramming. We present the first on synthetic data augmentation for project\nlevel proof oriented programming for both generation and repair. Our method\naddresses data scarcity by synthesizing basic proof-oriented programming\nproblems for proficiency in that language; incorporating diverse coding data\nfor reasoning capability elicitation and creating new proofs and repair data\nwithin existing repositories. This approach enables language models to both\nsynthesize and repair proofs for function- and repository-level code. We show\nthat our fine-tuned 14B parameter model, PoPilot, can exceed the performance of\nthe models that outperforms GPT-4o in project-level proof-oriented programming\nby 64% relative margin, and can improve GPT-4o's performance by 54% by\nrepairing its outputs over GPT-4o's self-repair.",
      "upvotes": 3,
      "discussionId": "67b3f8cd1bfe04e82830b77f"
    },
    "publishedAt": "2025-02-17T22:05:54.047Z",
    "title": "Building A Proof-Oriented Programmer That Is 64% Better Than GPT-4o Under Data Scarsity",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11901.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642b8add48f67b6f21d4eb20",
      "avatarUrl": "/avatars/f15025b39248daa19a18e6ccb2eaaa0c.svg",
      "fullname": "Dylan",
      "name": "shizhuo2",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11330",
      "authors": [
        {
          "_id": "67b42c5632929e97a92dee90",
          "name": "Minbyul Jeong",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee91",
          "name": "Jungho Cho",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee92",
          "name": "Minsoo Khang",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee93",
          "name": "Dawoon Jung",
          "hidden": false
        },
        {
          "_id": "67b42c5632929e97a92dee94",
          "name": "Teakgyu Hong",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T01:05:31.000Z",
      "title": "System Message Generation for User Preferences using Open-Source Models",
      "summary": "System messages play a crucial role in interactions with large language\nmodels (LLMs), often serving as prompts to initiate conversations. Through\nsystem messages, users can assign specific roles, perform intended tasks,\nincorporate background information, specify various output formats and\ncommunication styles. Despite such versatility, publicly available data are\noften lack system messages and subject to strict license constraints in the\nindustry field. Manual labeling of publicly available data with system messages\nthat align with user instructions demands significant resources. In view of\nsuch challenges, our work introduces SysGen, a pipeline for generating system\nmessages with better aligned assistant responses from the supervised\nfine-tuning dataset without system messages. Training on SysGen data has\ndemonstrated substantial improvements in the alignment of model responses with\nsystem messages and user instructions, as demonstrated across various\nopen-source models on the Multifacet benchmark, while maintaining minimal\nimpact on other unseen benchmarks such as Open LLM Leaderboard 2. Our\nqualitative analysis highlights the importance of diverse system messages to\nensure better adaptability across different contexts.",
      "upvotes": 1,
      "discussionId": "67b42c5732929e97a92deed7"
    },
    "publishedAt": "2025-02-18T01:45:36.359Z",
    "title": "System Message Generation for User Preferences using Open-Source Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11330.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64587be872b60ae7a3817858",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64587be872b60ae7a3817858/BbdOOxOCEzWTvEpkWp8MM.png",
      "fullname": "Minbyul Jeong",
      "name": "Minbyul",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11775",
      "authors": [
        {
          "_id": "67b4147f7721b4fe4d2bd466",
          "name": "Guangzhi Sun",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd467",
          "name": "Yudong Yang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd468",
          "name": "Jimin Zhuang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd469",
          "name": "Changli Tang",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46a",
          "name": "Yixuan Li",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46b",
          "name": "Wei Li",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46c",
          "name": "Zejun MA",
          "hidden": false
        },
        {
          "_id": "67b4147f7721b4fe4d2bd46d",
          "name": "Chao Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T13:07:40.000Z",
      "title": "video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model",
      "summary": "While recent advancements in reasoning optimization have significantly\nenhanced the capabilities of large language models (LLMs), existing efforts to\nimprove reasoning have been limited to solving mathematical problems and\nfocusing on visual graphical inputs, neglecting broader applications in general\nvideo understanding.This paper proposes video-SALMONN-o1, the first open-source\nreasoning-enhanced audio-visual LLM designed for general video understanding\ntasks. To enhance its reasoning abilities, we develop a reasoning-intensive\ndataset featuring challenging audio-visual questions with step-by-step\nsolutions. We also propose process direct preference optimization (pDPO), which\nleverages contrastive step selection to achieve efficient step-level reward\nmodelling tailored for multimodal inputs. Additionally, we introduce RivaBench,\nthe first reasoning-intensive video understanding benchmark, featuring over\n4,000 high-quality, expert-curated question-answer pairs across scenarios such\nas standup comedy, academic presentations, and synthetic video detection.\nvideo-SALMONN-o1 achieves 3-8% accuracy improvements over the LLaVA-OneVision\nbaseline across different video reasoning benchmarks. Besides, pDPO achieves\n6-8% improvements compared to the supervised fine-tuning model on RivaBench.\nEnhanced reasoning enables video-SALMONN-o1 zero-shot synthetic video detection\ncapabilities.",
      "upvotes": 1,
      "discussionId": "67b414827721b4fe4d2bd534"
    },
    "publishedAt": "2025-02-18T00:06:55.671Z",
    "title": "video-SALMONN-o1: Reasoning-enhanced Audio-visual Large Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11775.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6127
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11098",
      "authors": [
        {
          "_id": "67b411e45e634139c0d86a1e",
          "name": "Zhao Wang",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a1f",
          "name": "Sota Moriyama",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a20",
          "name": "Wei-Yao Wang",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a21",
          "name": "Briti Gangopadhyay",
          "hidden": false
        },
        {
          "_id": "67b411e45e634139c0d86a22",
          "name": "Shingo Takamatsu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-16T12:26:58.000Z",
      "title": "Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM\n  Multi-Agent Systems",
      "summary": "Recent advancements in LLM-based multi-agent (LLM-MA) systems have shown\npromise, yet significant challenges remain in managing communication and\nrefinement when agents collaborate on complex tasks. In this paper, we propose\nTalk Structurally, Act Hierarchically (TalkHier), a novel framework\nthat introduces a structured communication protocol for context-rich exchanges\nand a hierarchical refinement system to address issues such as incorrect\noutputs, falsehoods, and biases. TalkHier surpasses various types of\nSoTA, including inference scaling model (OpenAI-o1), open-source multi-agent\nmodels (e.g., AgentVerse), and majority voting strategies on current LLM and\nsingle-agent baselines (e.g., ReAct, GPT4o), across diverse tasks, including\nopen-domain question answering, domain-specific selective questioning, and\npractical advertisement text generation. These results highlight its potential\nto set a new standard for LLM-MA systems, paving the way for more effective,\nadaptable, and collaborative multi-agent frameworks. The code is available\nhttps://github.com/sony/talkhier.",
      "upvotes": 1,
      "discussionId": "67b411e55e634139c0d86a4c"
    },
    "publishedAt": "2025-02-17T23:51:50.821Z",
    "title": "Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11098.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6127
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.10454",
      "authors": [
        {
          "_id": "67b40e56bffd44cc85976ecd",
          "name": "Yinghui Li",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ece",
          "name": "Jiayi Kuang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ecf",
          "name": "Haojing Huang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed0",
          "name": "Zhikun Xu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed1",
          "name": "Xinnian Liang",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed2",
          "name": "Yi Yu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed3",
          "name": "Wenlian Lu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed4",
          "name": "Yangning Li",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed5",
          "name": "Xiaoyu Tan",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed6",
          "name": "Chao Qu",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed7",
          "name": "Ying Shen",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed8",
          "name": "Hai-Tao Zheng",
          "hidden": false
        },
        {
          "_id": "67b40e56bffd44cc85976ed9",
          "name": "Philip S. Yu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-12T02:01:10.000Z",
      "title": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual\n  Reasoning in Mathematical LLMs",
      "summary": "Leveraging mathematical Large Language Models (LLMs) for proof generation is\na fundamental topic in LLMs research. We argue that the ability of current LLMs\nto prove statements largely depends on whether they have encountered the\nrelevant proof process during training. This reliance limits their deeper\nunderstanding of mathematical theorems and related concepts. Inspired by the\npedagogical method of \"proof by counterexamples\" commonly used in human\nmathematics education, our work aims to enhance LLMs' ability to conduct\nmathematical reasoning and proof through counterexamples. Specifically, we\nmanually create a high-quality, university-level mathematical benchmark,\nCounterMATH, which requires LLMs to prove mathematical statements by providing\ncounterexamples, thereby assessing their grasp of mathematical concepts.\nAdditionally, we develop a data engineering framework to automatically obtain\ntraining data for further model improvement. Extensive experiments and detailed\nanalyses demonstrate that CounterMATH is challenging, indicating that LLMs,\nsuch as OpenAI o1, have insufficient counterexample-driven proof capabilities.\nMoreover, our exploration into model training reveals that strengthening LLMs'\ncounterexample-driven conceptual reasoning abilities is crucial for improving\ntheir overall mathematical capabilities. We believe that our work offers new\nperspectives on the community of mathematical LLMs.",
      "upvotes": 1,
      "discussionId": "67b40e57bffd44cc85976f0e"
    },
    "publishedAt": "2025-02-17T23:37:16.770Z",
    "title": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.10454.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 6127
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11574",
      "authors": [
        {
          "_id": "67b435c29e5685b308a8edac",
          "user": {
            "_id": "65bcbc01d6d0ffbceb8b2e6e",
            "avatarUrl": "/avatars/73edb2d6b7b11208439ac88b365079e8.svg",
            "isPro": false,
            "fullname": "Johan Boye",
            "user": "jboye",
            "type": "user"
          },
          "name": "Johan Boye",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-18T07:24:50.956Z",
          "hidden": false
        },
        {
          "_id": "67b435c29e5685b308a8edad",
          "name": "Birger Moell",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:07:32.000Z",
      "title": "Large Language Models and Mathematical Reasoning Failures",
      "summary": "This paper investigates the mathematical reasoning capabilities of large\nlanguage models (LLMs) using 50 newly constructed high-school-level word\nproblems. Unlike prior studies that focus solely on answer correctness, we\nrigorously analyze both final answers and solution steps to identify reasoning\nfailures. Evaluating eight state-of-the-art models - including Mixtral, Llama,\nGemini, GPT-4o, and OpenAI's o1 variants - we find that while newer models\n(e.g., o3-mini, deepseek-r1) achieve higher accuracy, all models exhibit errors\nin spatial reasoning, strategic planning, and arithmetic, sometimes producing\ncorrect answers through flawed logic. Common failure modes include unwarranted\nassumptions, over-reliance on numerical patterns, and difficulty translating\nphysical intuition into mathematical steps. Manual analysis reveals that models\nstruggle with problems requiring multi-step deduction or real-world knowledge,\ndespite possessing broad mathematical knowledge. Our results underscore the\nimportance of evaluating reasoning processes, not just answers, and caution\nagainst overestimating LLMs' problem-solving proficiency. The study highlights\npersistent gaps in LLMs' generalization abilities, emphasizing the need for\ntargeted improvements in structured reasoning and constraint handling.",
      "upvotes": 0,
      "discussionId": "67b435c29e5685b308a8edf1"
    },
    "publishedAt": "2025-02-18T02:26:18.856Z",
    "title": "Large Language Models and Mathematical Reasoning Failures",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11574.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6033e34a9aa44495c80dd043",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
      "fullname": "Birger Moell",
      "name": "birgermoell",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 36
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.11578",
      "authors": [
        {
          "_id": "67b435475bff5f34c1ebee1b",
          "name": "Birger Moell",
          "hidden": false
        },
        {
          "_id": "67b435475bff5f34c1ebee1c",
          "user": {
            "_id": "65bcbc01d6d0ffbceb8b2e6e",
            "avatarUrl": "/avatars/73edb2d6b7b11208439ac88b365079e8.svg",
            "isPro": false,
            "fullname": "Johan Boye",
            "user": "jboye",
            "type": "user"
          },
          "name": "Johan Boye",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-18T07:22:48.554Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-17T09:09:58.000Z",
      "title": "Language Complexity Measurement as a Noisy Zero-Shot Proxy for\n  Evaluating LLM Performance",
      "summary": "Large Language Models (LLMs) have made significant strides in natural\nlanguage generation but often face challenges in tasks requiring precise\ncalculations and structural analysis. This paper investigates the performance\nof state-of-the-art LLMs on language complexity measurement tasks, through the\ncomputation of the LIX readability metric and Average Dependency Distance\n(ADD). Using Swedish high school and university-level essays, we evaluate the\nmodels' abilities to compute LIX scores and perform dependency parsing,\ncomparing their results to established ground truths. Our findings reveal that\nwhile all models demonstrate some capacity for these tasks, ChatGPT-o1-mini\nperforms most consistently, achieving the highest accuracy in both LIX\ncomputation and dependency parsing. Additionally, we observe a strong\nsignificant correlation -0.875 p 0.026 (N=6) between the models' accuracy in\ncomputing LIX and their overall performance on the Massive Multitask Language\nUnderstanding (MMLU) benchmark. These results suggest that language complexity\nmeasurement abilities can serve as a noisy zero-shot proxies for assessing the\ngeneral capabilities of LLMs, providing a practical method for model evaluation\nwithout the need for extensive benchmarking datasets.",
      "upvotes": 0,
      "discussionId": "67b435485bff5f34c1ebee52"
    },
    "publishedAt": "2025-02-18T02:23:29.869Z",
    "title": "Language Complexity Measurement as a Noisy Zero-Shot Proxy for Evaluating LLM Performance",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11578.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6033e34a9aa44495c80dd043",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614079701740-6033e34a9aa44495c80dd043.jpeg",
      "fullname": "Birger Moell",
      "name": "birgermoell",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 36
    },
    "isAuthorParticipating": false
  }
]