[
    "{'paper': {'id': '2501.04519', 'authors': [{'_id': '677f3f364be6eaf5077001f6', 'name': 'Xinyu Guan', 'hidden': False}, {'_id': '677f3f364be6eaf5077001f7', 'user': {'_id': '62b0009c72043b05d29492b2', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62b0009c72043b05d29492b2/NqRkX2YLhlfOLvYysa7dD.png', 'isPro': False, 'fullname': 'Li Lyna Zhang', 'user': 'lynazhang', 'type': 'user'}, 'name': 'Li Lyna Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T10:14:40.859Z', 'hidden': False}, {'_id': '677f3f364be6eaf5077001f8', 'user': {'_id': '662d015a2d4c0e85da85ff0c', 'avatarUrl': '/avatars/ff38e82d1371fe9e69bacb9b04cfe444.svg', 'isPro': False, 'fullname': 'Yifei Liu', 'user': 'YF-L', 'type': 'user'}, 'name': 'Yifei Liu', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T19:58:00.452Z', 'hidden': False}, {'_id': '677f3f364be6eaf5077001f9', 'user': {'_id': '632bc663eafe8eca5e9bfdbc', 'avatarUrl': '/avatars/787553c73e9a96adc5219e67acd29c00.svg', 'isPro': False, 'fullname': 'Ning Shang', 'user': 'J-shang', 'type': 'user'}, 'name': 'Ning Shang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T10:16:39.284Z', 'hidden': False}, {'_id': '677f3f364be6eaf5077001fa', 'name': 'Youran Sun', 'hidden': False}, {'_id': '677f3f364be6eaf5077001fb', 'name': 'Yi Zhu', 'hidden': False}, {'_id': '677f3f364be6eaf5077001fc', 'name': 'Fan Yang', 'hidden': False}, {'_id': '677f3f364be6eaf5077001fd', 'name': 'Mao Yang', 'hidden': False}], 'publishedAt': '2025-01-08T14:12:57.000Z', 'title': 'rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep\\n  Thinking', 'summary': 'We present rStar-Math to demonstrate that small language models (SLMs) can\\nrival or even surpass the math reasoning capability of OpenAI o1, without\\ndistillation from superior models. rStar-Math achieves this by exercising \"deep\\nthinking\" through Monte Carlo Tree Search (MCTS), where a math policy SLM\\nperforms test-time search guided by an SLM-based process reward model.\\nrStar-Math introduces three innovations to tackle the challenges in training\\nthe two SLMs: (1) a novel code-augmented CoT data sythesis method, which\\nperforms extensive MCTS rollouts to generate step-by-step verified reasoning\\ntrajectories used to train the policy SLM; (2) a novel process reward model\\ntraining method that avoids na\\\\\"ive step-level score annotation, yielding a\\nmore effective process preference model (PPM); (3) a self-evolution recipe in\\nwhich the policy SLM and PPM are built from scratch and iteratively evolved to\\nimprove reasoning capabilities. Through 4 rounds of self-evolution with\\nmillions of synthesized solutions for 747k math problems, rStar-Math boosts\\nSLMs\\' math reasoning to state-of-the-art levels. On the MATH benchmark, it\\nimproves Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to\\n86.4%, surpassing o1-preview by +4.5% and +0.9%. On the USA Math Olympiad\\n(AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among\\nthe top 20% the brightest high school math students. Code and data will be\\navailable at https://github.com/microsoft/rStar.', 'upvotes': 118, 'discussionId': '677f3f374be6eaf507700262'}, 'publishedAt': '2025-01-08T22:29:05.974Z', 'title': 'rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04519.png', 'numComments': 10, 'submittedBy': {'_id': '62b0009c72043b05d29492b2', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62b0009c72043b05d29492b2/NqRkX2YLhlfOLvYysa7dD.png', 'fullname': 'Li Lyna Zhang', 'name': 'lynazhang', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 14}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04682', 'authors': [{'_id': '677f4e0d05ab3422540b88ff', 'name': 'Violet Xiang', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8900', 'name': 'Charlie Snell', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8901', 'name': 'Kanishk Gandhi', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8902', 'user': {'_id': '611a7ec4289467cafea62d13', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/611a7ec4289467cafea62d13/pck-0fmPQkoU7yzh6-WoL.jpeg', 'isPro': False, 'fullname': 'Alon Albalak', 'user': 'alon-albalak', 'type': 'user'}, 'name': 'Alon Albalak', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T19:57:57.972Z', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8903', 'user': {'_id': '6511ee845b7e52b0251fdee9', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6511ee845b7e52b0251fdee9/hTIwiIYBGOVnIrxtpri83.png', 'isPro': False, 'fullname': 'Anikait Singh', 'user': 'Asap7772', 'type': 'user'}, 'name': 'Anikait Singh', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T10:06:59.745Z', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8904', 'name': 'Chase Blagden', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8905', 'name': 'Duy Phung', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8906', 'name': 'Rafael Rafailov', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8907', 'user': {'_id': '61aa15fd8a9625ebfe284286', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/61aa15fd8a9625ebfe284286/KaGzIeijcgcN15JErCqft.jpeg', 'isPro': False, 'fullname': 'nathan lile', 'user': 'nlile', 'type': 'user'}, 'name': 'Nathan Lile', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T10:07:02.418Z', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8908', 'name': 'Dakota Mahan', 'hidden': False}, {'_id': '677f4e0d05ab3422540b8909', 'name': 'Louis Castricato', 'hidden': False}, {'_id': '677f4e0d05ab3422540b890a', 'name': 'Jan-Philipp Franken', 'hidden': False}, {'_id': '677f4e0d05ab3422540b890b', 'name': 'Nick Haber', 'hidden': False}, {'_id': '677f4e0d05ab3422540b890c', 'name': 'Chelsea Finn', 'hidden': False}], 'publishedAt': '2025-01-08T18:42:48.000Z', 'title': 'Towards System 2 Reasoning in LLMs: Learning How to Think With Meta\\n  Chain-of-Though', 'summary': 'We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends\\ntraditional Chain-of-Thought (CoT) by explicitly modeling the underlying\\nreasoning required to arrive at a particular CoT. We present empirical evidence\\nfrom state-of-the-art models exhibiting behaviors consistent with in-context\\nsearch, and explore methods for producing Meta-CoT via process supervision,\\nsynthetic data generation, and search algorithms. Finally, we outline a\\nconcrete pipeline for training a model to produce Meta-CoTs, incorporating\\ninstruction tuning with linearized search traces and reinforcement learning\\npost-training. Finally, we discuss open research questions, including scaling\\nlaws, verifier roles, and the potential for discovering novel reasoning\\nalgorithms. This work provides a theoretical and practical roadmap to enable\\nMeta-CoT in LLMs, paving the way for more powerful and human-like reasoning in\\nartificial intelligence.', 'upvotes': 46, 'discussionId': '677f4e1105ab3422540b8a2e'}, 'publishedAt': '2025-01-08T23:19:48.935Z', 'title': 'Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04682.png', 'numComments': 2, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5601}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.04686', 'authors': [{'_id': '677f62ca407edfda4408dd07', 'user': {'_id': '6548956fe49bd8d58e8adf0e', 'avatarUrl': '/avatars/24c54b14c253c87d4b7438193f16ce28.svg', 'isPro': False, 'fullname': 'Ruilin', 'user': 'Antimage01', 'type': 'user'}, 'name': 'Ruilin Luo', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T10:06:31.575Z', 'hidden': False}, {'_id': '677f62ca407edfda4408dd08', 'user': {'_id': '64ae0f825d48838462023c9b', 'avatarUrl': '/avatars/d3f348c1428376aea490339e94d4c239.svg', 'isPro': False, 'fullname': 'Zheng Zhuofan', 'user': 'fun6668', 'type': 'user'}, 'name': 'Zhuofan Zheng', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T11:09:45.251Z', 'hidden': False}, {'_id': '677f62ca407edfda4408dd09', 'name': 'Yifan Wang', 'hidden': False}, {'_id': '677f62ca407edfda4408dd0a', 'user': {'_id': '66b1eb17652012ddfb59e41e', 'avatarUrl': '/avatars/b1c8ce44e7a7d789a3eb2e29e2ddfebe.svg', 'isPro': False, 'fullname': 'Yiyao Yu', 'user': 'yiyaoyu', 'type': 'user'}, 'name': 'Yiyao Yu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:19:06.927Z', 'hidden': False}, {'_id': '677f62ca407edfda4408dd0b', 'name': 'Xinzhe Ni', 'hidden': False}, {'_id': '677f62ca407edfda4408dd0c', 'name': 'Zicheng Lin', 'hidden': False}, {'_id': '677f62ca407edfda4408dd0d', 'name': 'Jin Zeng', 'hidden': False}, {'_id': '677f62ca407edfda4408dd0e', 'user': {'_id': '64ca1fe838837b12d5e529b7', 'avatarUrl': '/avatars/44a3ad9e59318784ac531993b5f69f6b.svg', 'isPro': False, 'fullname': 'Yujiu Yang', 'user': 'Thu-redrobot', 'type': 'user'}, 'name': 'Yujiu Yang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:02:25.883Z', 'hidden': False}], 'publishedAt': '2025-01-08T18:49:41.000Z', 'title': 'URSA: Understanding and Verifying Chain-of-thought Reasoning in\\n  Multimodal Mathematics', 'summary': 'Chain-of-thought (CoT) reasoning has been widely applied in the mathematical\\nreasoning of Large Language Models (LLMs). Recently, the introduction of\\nderivative process supervision on CoT trajectories has sparked discussions on\\nenhancing scaling capabilities during test time, thereby boosting the potential\\nof these models. However, in multimodal mathematical reasoning, the scarcity of\\nhigh-quality CoT training data has hindered existing models from achieving\\nhigh-precision CoT reasoning and has limited the realization of reasoning\\npotential during test time. In this work, we propose a three-module synthesis\\nstrategy that integrates CoT distillation, trajectory-format rewriting, and\\nformat unification. It results in a high-quality CoT reasoning instruction\\nfine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensively\\nvalidate the state-of-the-art (SOTA) performance of the trained URSA-7B model\\non multiple multimodal mathematical benchmarks. For test-time scaling, we\\nintroduce a data synthesis strategy that automatically generates process\\nannotation datasets, known as DualMath-1.1M, focusing on both interpretation\\nand logic. By further training URSA-7B on DualMath-1.1M, we transition from CoT\\nreasoning capabilities to robust supervision abilities. The trained URSA-RM-7B\\nacts as a verifier, effectively enhancing the performance of URSA-7B at test\\ntime. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD)\\nverifying capabilities, showcasing its generalization. Model weights, training\\ndata and code will be open-sourced.', 'upvotes': 37, 'discussionId': '677f62cb407edfda4408dd5c'}, 'publishedAt': '2025-01-09T01:29:54.445Z', 'title': 'URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04686.png', 'numComments': 3, 'submittedBy': {'_id': '64292eb375bcc24c5e52c011', 'avatarUrl': '/avatars/c8cb03ca35ca12d8831be5f4e8547d54.svg', 'fullname': 'czl', 'name': 'Lin1557', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 4}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04227', 'authors': [{'_id': '677f4d709e9ddbcae5ce5364', 'name': 'Samuel Schmidgall', 'hidden': False}, {'_id': '677f4d709e9ddbcae5ce5365', 'user': {'_id': '632181ab2284fb8b5d39fc07', 'avatarUrl': '/avatars/467c7982b6b9b25689ebf677926f6ce0.svg', 'isPro': False, 'fullname': 'Yusheng Su', 'user': 'yushengsu', 'type': 'user'}, 'name': 'Yusheng Su', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:22:29.469Z', 'hidden': False}, {'_id': '677f4d709e9ddbcae5ce5366', 'name': 'Ze Wang', 'hidden': False}, {'_id': '677f4d709e9ddbcae5ce5367', 'name': 'Ximeng Sun', 'hidden': False}, {'_id': '677f4d709e9ddbcae5ce5368', 'user': {'_id': '66a966af504d582c8c65a2ee', 'avatarUrl': '/avatars/710df9f4637b9188c8d0d58d488caa9b.svg', 'isPro': False, 'fullname': 'Jialian Wu', 'user': 'jialianww', 'type': 'user'}, 'name': 'Jialian Wu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:24:01.650Z', 'hidden': False}, {'_id': '677f4d709e9ddbcae5ce5369', 'user': {'_id': '66f31375a3a9e600302f25d7', 'avatarUrl': '/avatars/c049575a5d17eeb8b76a5be5de7a5392.svg', 'isPro': False, 'fullname': 'Xiaodong Yu', 'user': 'xiaodongyu-amd', 'type': 'user'}, 'name': 'Xiaodong Yu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:23:43.262Z', 'hidden': False}, {'_id': '677f4d709e9ddbcae5ce536a', 'user': {'_id': '6328885bb0910efc277f42a0', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1663600974191-6328885bb0910efc277f42a0.jpeg', 'isPro': False, 'fullname': 'JiangLiu', 'user': 'JiangLiu', 'type': 'user'}, 'name': 'Jiang Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:23:35.567Z', 'hidden': False}, {'_id': '677f4d709e9ddbcae5ce536b', 'user': {'_id': '6569f6cb44ce94a70187f407', 'avatarUrl': '/avatars/414ecc9739ed23f9f395bd7cfa65055f.svg', 'isPro': False, 'fullname': 'Zicheng Liu', 'user': 'ZCLiu35', 'type': 'user'}, 'name': 'Zicheng Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:23:28.447Z', 'hidden': False}, {'_id': '677f4d709e9ddbcae5ce536c', 'user': {'_id': '65adc9d086f88a686be41215', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/65adc9d086f88a686be41215/xizVHuZPkE0Gu8_ulx0Fm.jpeg', 'isPro': False, 'fullname': 'Emad Barsoum', 'user': 'ebarsoum', 'type': 'user'}, 'name': 'Emad Barsoum', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:23:21.569Z', 'hidden': False}], 'publishedAt': '2025-01-08T01:58:42.000Z', 'title': 'Agent Laboratory: Using LLM Agents as Research Assistants', 'summary': 'Historically, scientific discovery has been a lengthy and costly process,\\ndemanding substantial time and resources from initial conception to final\\nresults. To accelerate scientific discovery, reduce research costs, and improve\\nresearch quality, we introduce Agent Laboratory, an autonomous LLM-based\\nframework capable of completing the entire research process. This framework\\naccepts a human-provided research idea and progresses through three\\nstages--literature review, experimentation, and report writing to produce\\ncomprehensive research outputs, including a code repository and a research\\nreport, while enabling users to provide feedback and guidance at each stage. We\\ndeploy Agent Laboratory with various state-of-the-art LLMs and invite multiple\\nresearchers to assess its quality by participating in a survey, providing human\\nfeedback to guide the research process, and then evaluate the final paper. We\\nfound that: (1) Agent Laboratory driven by o1-preview generates the best\\nresearch outcomes; (2) The generated machine learning code is able to achieve\\nstate-of-the-art performance compared to existing methods; (3) Human\\ninvolvement, providing feedback at each stage, significantly improves the\\noverall quality of research; (4) Agent Laboratory significantly reduces\\nresearch expenses, achieving an 84% decrease compared to previous autonomous\\nresearch methods. We hope Agent Laboratory enables researchers to allocate more\\neffort toward creative ideation rather than low-level coding and writing,\\nultimately accelerating scientific discovery.', 'upvotes': 36, 'discussionId': '677f4d739e9ddbcae5ce5412'}, 'publishedAt': '2025-01-08T23:16:01.215Z', 'title': 'Agent Laboratory: Using LLM Agents as Research Assistants', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04227.png', 'numComments': 4, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5601}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.04306', 'authors': [{'_id': '677f72d01178cdb06e266bc2', 'user': {'_id': '658d2075a6d1ddb400769196', 'avatarUrl': '/avatars/9e6030a9cb488943fc130eb55c2982bb.svg', 'isPro': False, 'fullname': 'Ziming Luo', 'user': 'Ziming2000', 'type': 'user'}, 'name': 'Ziming Luo', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:24:18.730Z', 'hidden': False}, {'_id': '677f72d01178cdb06e266bc3', 'user': {'_id': '646a11791556443f24b582e9', 'avatarUrl': '/avatars/b54d416ddca2f124492ba51bc4b95fd2.svg', 'isPro': False, 'fullname': 'Zonglin Yang', 'user': 'ZonglinY', 'type': 'user'}, 'name': 'Zonglin Yang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T10:06:03.156Z', 'hidden': False}, {'_id': '677f72d01178cdb06e266bc4', 'user': {'_id': '66cfe76a22493660a2fddf2c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/WQtmUTIQaqFVryT2YY8zZ.jpeg', 'isPro': False, 'fullname': 'Zexin Xu', 'user': 'Ason-jay', 'type': 'user'}, 'name': 'Zexin Xu', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-01-09T06:55:13.005Z', 'hidden': False}, {'_id': '677f72d01178cdb06e266bc5', 'user': {'_id': '6408ec2ebf3e9a4bb2e0b7e9', 'avatarUrl': '/avatars/5a34796d778ac526aae8f3059c5e8c8d.svg', 'isPro': False, 'fullname': 'Wei Yang', 'user': 'weiyang15', 'type': 'user'}, 'name': 'Wei Yang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:24:27.358Z', 'hidden': False}, {'_id': '677f72d01178cdb06e266bc6', 'user': {'_id': '66c4154fb83a7e94d588ade3', 'avatarUrl': '/avatars/9f939a4045e96529aee7d124447624a3.svg', 'isPro': False, 'fullname': 'Xinya Du', 'user': 'xinyadu', 'type': 'user'}, 'name': 'Xinya Du', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T19:57:46.573Z', 'hidden': False}], 'publishedAt': '2025-01-08T06:44:02.000Z', 'title': 'LLM4SR: A Survey on Large Language Models for Scientific Research', 'summary': 'In recent years, the rapid advancement of Large Language Models (LLMs) has\\ntransformed the landscape of scientific research, offering unprecedented\\nsupport across various stages of the research cycle. This paper presents the\\nfirst systematic survey dedicated to exploring how LLMs are revolutionizing the\\nscientific research process. We analyze the unique roles LLMs play across four\\ncritical stages of research: hypothesis discovery, experiment planning and\\nimplementation, scientific writing, and peer reviewing. Our review\\ncomprehensively showcases the task-specific methodologies and evaluation\\nbenchmarks. By identifying current challenges and proposing future research\\ndirections, this survey not only highlights the transformative potential of\\nLLMs, but also aims to inspire and guide researchers and practitioners in\\nleveraging LLMs to advance scientific inquiry. Resources are available at the\\nfollowing repository: https://github.com/du-nlp-lab/LLM4SR', 'upvotes': 19, 'discussionId': '677f72d11178cdb06e266c0a'}, 'publishedAt': '2025-01-09T01:57:41.030Z', 'title': 'LLM4SR: A Survey on Large Language Models for Scientific Research', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04306.png', 'numComments': 2, 'submittedBy': {'_id': '646a11791556443f24b582e9', 'avatarUrl': '/avatars/b54d416ddca2f124492ba51bc4b95fd2.svg', 'fullname': 'Zonglin Yang', 'name': 'ZonglinY', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04575', 'authors': [{'_id': '677f5089a0843d06966ac68e', 'user': {'_id': '66dd4feb14f4776a44b071f2', 'avatarUrl': '/avatars/8b06fa3019999abb762de2b8d9961e2b.svg', 'isPro': False, 'fullname': 'Yuhang Liu', 'user': 'CausalLLMs', 'type': 'user'}, 'name': 'Yuhang Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:24:38.607Z', 'hidden': False}, {'_id': '677f5089a0843d06966ac68f', 'user': {'_id': '64245f2c089d5fae56b4549a', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/64245f2c089d5fae56b4549a/qUHFsL9Svwyj5BKpfMtaY.jpeg', 'isPro': False, 'fullname': 'Pengxiang Li', 'user': 'pengxiang', 'type': 'user'}, 'name': 'Pengxiang Li', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T10:06:37.729Z', 'hidden': False}, {'_id': '677f5089a0843d06966ac690', 'user': {'_id': '63909970937867f0cb400b09', 'avatarUrl': '/avatars/a360d5d5a3605e7312b078312eee79b6.svg', 'isPro': False, 'fullname': 'zishu wei', 'user': 'shu06', 'type': 'user'}, 'name': 'Zishu Wei', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:24:47.683Z', 'hidden': False}, {'_id': '677f5089a0843d06966ac691', 'user': {'_id': '6719f1ad725123d503b5ef3c', 'avatarUrl': '/avatars/08e1be1f4afa1b6e1501a15cdb786a47.svg', 'isPro': False, 'fullname': 'Congkai Xie', 'user': 'congkai', 'type': 'user'}, 'name': 'Congkai Xie', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:24:53.767Z', 'hidden': False}, {'_id': '677f5089a0843d06966ac692', 'user': {'_id': '65897684f8b453e1f57cdb26', 'avatarUrl': '/avatars/80096d6c808805e1a84a68fb6194a7d4.svg', 'isPro': False, 'fullname': 'huxueyu', 'user': 'huxueyu', 'type': 'user'}, 'name': 'Xueyu Hu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:25:09.450Z', 'hidden': False}, {'_id': '677f5089a0843d06966ac693', 'user': {'_id': '65601713baf1f5f902292bb6', 'avatarUrl': '/avatars/57c65cff29ffb4f25b943b5baccdc795.svg', 'isPro': False, 'fullname': 'Xinchen Xu', 'user': 'SHU-Xuxc', 'type': 'user'}, 'name': 'Xinchen Xu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:25:15.603Z', 'hidden': False}, {'_id': '677f5089a0843d06966ac694', 'name': 'Shengyu Zhang', 'hidden': False}, {'_id': '677f5089a0843d06966ac695', 'user': {'_id': '650dde4ce14eeb01d42b37a1', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/650dde4ce14eeb01d42b37a1/n5Yv24uofZ2XJjXdYCrKd.png', 'isPro': False, 'fullname': 'Xiaotian Han', 'user': 'xiaotianhan', 'type': 'user'}, 'name': 'Xiaotian Han', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T19:57:55.175Z', 'hidden': False}, {'_id': '677f5089a0843d06966ac696', 'name': 'Hongxia Yang', 'hidden': False}, {'_id': '677f5089a0843d06966ac697', 'name': 'Fei Wu', 'hidden': False}], 'publishedAt': '2025-01-08T15:45:21.000Z', 'title': 'InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning\\n  and Reflection', 'summary': 'Graphical User Interface (GUI) Agents, powered by multimodal large language\\nmodels (MLLMs), have shown great potential for task automation on computing\\ndevices such as computers and mobile phones. However, existing agents face\\nchallenges in multi-step reasoning and reliance on textual annotations,\\nlimiting their effectiveness. We introduce InfiGUIAgent, an MLLM-based\\nGUI Agent trained with a two-stage supervised fine-tuning pipeline. Stage 1\\nenhances fundamental skills such as GUI understanding and grounding, while\\nStage 2 integrates hierarchical reasoning and expectation-reflection reasoning\\nskills using synthesized data to enable native reasoning abilities of the\\nagents. InfiGUIAgent achieves competitive performance on several GUI\\nbenchmarks, highlighting the impact of native reasoning skills in enhancing GUI\\ninteraction for automation tasks. Resources are available at\\nhttps://github.com/Reallm-Labs/InfiGUIAgent.', 'upvotes': 15, 'discussionId': '677f5089a0843d06966ac6e3'}, 'publishedAt': '2025-01-08T23:35:19.486Z', 'title': 'InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04575.png', 'numComments': 2, 'submittedBy': {'_id': '64245f2c089d5fae56b4549a', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/64245f2c089d5fae56b4549a/qUHFsL9Svwyj5BKpfMtaY.jpeg', 'fullname': 'Pengxiang Li', 'name': 'pengxiang', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 2}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.02772', 'authors': [{'_id': '677ccfefb35098e1340b036f', 'user': {'_id': '64392c42abdc6ce5351f3ea3', 'avatarUrl': '/avatars/aafa7bd7f4eb11278924876e23b524d9.svg', 'isPro': False, 'fullname': 'Haoyu Liu', 'user': 'noobimp', 'type': 'user'}, 'name': 'Haoyu Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-08T21:29:31.230Z', 'hidden': False}, {'_id': '677ccfefb35098e1340b0370', 'user': {'_id': '632bd2f72d6a805eeb4bc601', 'avatarUrl': '/avatars/6e1533e8a599f3068290aa69ac82cab7.svg', 'isPro': False, 'fullname': 'HUANG SHAOHAN', 'user': 'buaahsh', 'type': 'user'}, 'name': 'Shaohan Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:26:59.222Z', 'hidden': False}, {'_id': '677ccfefb35098e1340b0371', 'user': {'_id': '62f1db70a39cf6f5c63fc5e5', 'avatarUrl': '/avatars/ff4a0f4f4ddab4cc87cf3b3abea0f232.svg', 'isPro': True, 'fullname': 'Jianfeng Liu', 'user': 'docacola', 'type': 'user'}, 'name': 'Jianfeng Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:27:21.174Z', 'hidden': False}, {'_id': '677ccfefb35098e1340b0372', 'name': 'Yuefeng Zhan', 'hidden': False}, {'_id': '677ccfefb35098e1340b0373', 'name': 'Hao Sun', 'hidden': False}, {'_id': '677ccfefb35098e1340b0374', 'user': {'_id': '642da49dc1adada5b345c72b', 'avatarUrl': '/avatars/5fa8d345a7248246454444999756105b.svg', 'isPro': False, 'fullname': 'deng', 'user': 'weiweideng', 'type': 'user'}, 'name': 'Weiwei Deng', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:27:50.251Z', 'hidden': False}, {'_id': '677ccfefb35098e1340b0375', 'user': {'_id': '64b88a7449bde5d9481e4755', 'avatarUrl': '/avatars/45a963517ec2c54c81ee80449d655014.svg', 'isPro': False, 'fullname': 'feng sun', 'user': 'forserty', 'type': 'user'}, 'name': 'Feng Sun', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:27:55.984Z', 'hidden': False}, {'_id': '677ccfefb35098e1340b0376', 'user': {'_id': '6368c512fbfe97c16a40baba', 'avatarUrl': '/avatars/1c23bc7c0b6d9225699ce27647623d7a.svg', 'isPro': False, 'fullname': 'Furu Wei', 'user': 'thegenerality', 'type': 'user'}, 'name': 'Furu Wei', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:28:01.282Z', 'hidden': False}, {'_id': '677ccfefb35098e1340b0377', 'name': 'Qi Zhang', 'hidden': False}], 'publishedAt': '2025-01-06T05:29:00.000Z', 'title': 'GeAR: Generation Augmented Retrieval', 'summary': 'Document retrieval techniques form the foundation for the development of\\nlarge-scale information systems. The prevailing methodology is to construct a\\nbi-encoder and compute the semantic similarity. However, such scalar similarity\\nis difficult to reflect enough information and impedes our comprehension of the\\nretrieval results. In addition, this computational process mainly emphasizes\\nthe global semantics and ignores the fine-grained semantic relationship between\\nthe query and the complex text in the document. In this paper, we propose a new\\nmethod called Generation Augmented Retrieval\\n(GeAR) that incorporates well-designed fusion and decoding modules.\\nThis enables GeAR to generate the relevant text from documents based on the\\nfused representation of the query and the document, thus learning to \"focus on\"\\nthe fine-grained information. Also when used as a retriever, GeAR does not add\\nany computational burden over bi-encoders. To support the training of the new\\nframework, we have introduced a pipeline to efficiently synthesize high-quality\\ndata by utilizing large language models. GeAR exhibits competitive retrieval\\nand localization performance across diverse scenarios and datasets. Moreover,\\nthe qualitative analysis and the results generated by GeAR provide novel\\ninsights into the interpretation of retrieval results. The code, data, and\\nmodels will be released after completing technical review to facilitate future\\nresearch.', 'upvotes': 11, 'discussionId': '677ccff2b35098e1340b0403'}, 'publishedAt': '2025-01-08T22:25:33.141Z', 'title': 'GeAR: Generation Augmented Retrieval', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/64392c42abdc6ce5351f3ea3/joC1ylCWVBkIK5OS4UMFB.jpeg', 'https://cdn-uploads.huggingface.co/production/uploads/64392c42abdc6ce5351f3ea3/pOkcJBcIjdAenbnRRBrg_.jpeg'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.02772.png', 'numComments': 2, 'submittedBy': {'_id': '64392c42abdc6ce5351f3ea3', 'avatarUrl': '/avatars/aafa7bd7f4eb11278924876e23b524d9.svg', 'fullname': 'Haoyu Liu', 'name': 'noobimp', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04689', 'authors': [{'_id': '677f73632fcceb4c315524de', 'name': 'Zixuan Huang', 'hidden': False}, {'_id': '677f73632fcceb4c315524df', 'user': {'_id': '64b7f06fda8017900e893eb4', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/64b7f06fda8017900e893eb4/3VcQFjERXyAjHQFLMFEJt.jpeg', 'isPro': False, 'fullname': 'Mark Boss', 'user': 'mboss', 'type': 'user'}, 'name': 'Mark Boss', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T10:06:00.640Z', 'hidden': False}, {'_id': '677f73632fcceb4c315524e0', 'name': 'Aaryaman Vasishta', 'hidden': False}, {'_id': '677f73632fcceb4c315524e1', 'name': 'James M. Rehg', 'hidden': False}, {'_id': '677f73632fcceb4c315524e2', 'user': {'_id': '630e7cfe3fc17ffc50f6e835', 'avatarUrl': '/avatars/0b742ff094a09f9374fafcd97ab9e002.svg', 'isPro': False, 'fullname': 'Varun Jampani', 'user': 'varunjampani', 'type': 'user'}, 'name': 'Varun Jampani', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:30:32.287Z', 'hidden': False}], 'publishedAt': '2025-01-08T18:52:03.000Z', 'title': 'SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single\\n  Images', 'summary': 'We study the problem of single-image 3D object reconstruction. Recent works\\nhave diverged into two directions: regression-based modeling and generative\\nmodeling. Regression methods efficiently infer visible surfaces, but struggle\\nwith occluded regions. Generative methods handle uncertain regions better by\\nmodeling distributions, but are computationally expensive and the generation is\\noften misaligned with visible surfaces. In this paper, we present SPAR3D, a\\nnovel two-stage approach aiming to take the best of both directions. The first\\nstage of SPAR3D generates sparse 3D point clouds using a lightweight point\\ndiffusion model, which has a fast sampling speed. The second stage uses both\\nthe sampled point cloud and the input image to create highly detailed meshes.\\nOur two-stage design enables probabilistic modeling of the ill-posed\\nsingle-image 3D task while maintaining high computational efficiency and great\\noutput fidelity. Using point clouds as an intermediate representation further\\nallows for interactive user edits. Evaluated on diverse datasets, SPAR3D\\ndemonstrates superior performance over previous state-of-the-art methods, at an\\ninference speed of 0.7 seconds. Project page with code and model:\\nhttps://spar3d.github.io', 'upvotes': 10, 'discussionId': '677f73642fcceb4c31552573'}, 'publishedAt': '2025-01-09T01:58:36.423Z', 'title': 'SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04689.png', 'numComments': 5, 'submittedBy': {'_id': '64b7f06fda8017900e893eb4', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/64b7f06fda8017900e893eb4/3VcQFjERXyAjHQFLMFEJt.jpeg', 'fullname': 'Mark Boss', 'name': 'mboss', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 21}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04144', 'authors': [{'_id': '677f9188fb22a3b146287a6c', 'user': {'_id': '646f9a9d5b8225e31ae5a408', 'avatarUrl': '/avatars/b6210993b51bb650ea8aa8c04e5fc351.svg', 'isPro': False, 'fullname': 'kamwoh', 'user': 'kamwoh', 'type': 'user'}, 'name': 'Kam Woh Ng', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:28:28.347Z', 'hidden': False}, {'_id': '677f9188fb22a3b146287a6d', 'user': {'_id': '64244f3b089d5fae56b3d487', 'avatarUrl': '/avatars/d23beaacff2eb1dda84f684a99e61b4f.svg', 'isPro': False, 'fullname': 'George Young', 'user': 'jingyang', 'type': 'user'}, 'name': 'Jing Yang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:28:37.012Z', 'hidden': False}, {'_id': '677f9188fb22a3b146287a6e', 'user': {'_id': '668c0d460eeb9552cbd45989', 'avatarUrl': '/avatars/a69dd6959c0d2df7c08c321d2a4b4e98.svg', 'isPro': False, 'fullname': 'Jia Wei Sii', 'user': 'siijiawei', 'type': 'user'}, 'name': 'Jia Wei Sii', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:28:43.193Z', 'hidden': False}, {'_id': '677f9188fb22a3b146287a6f', 'user': {'_id': '62cc7a38376917c0223dd24b', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1657566065867-noauth.png', 'isPro': False, 'fullname': 'JiankangDeng', 'user': 'JiankangDeng', 'type': 'user'}, 'name': 'Jiankang Deng', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:28:49.888Z', 'hidden': False}, {'_id': '677f9188fb22a3b146287a70', 'user': {'_id': '65785c327ee8616c7c179e64', 'avatarUrl': '/avatars/eb0a788aa05c5071e73885005f9f59c6.svg', 'isPro': False, 'fullname': 'Chee Seng Chan', 'user': 'cschan1313', 'type': 'user'}, 'name': 'Chee Seng Chan', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:28:55.545Z', 'hidden': False}, {'_id': '677f9188fb22a3b146287a71', 'name': 'Yi-Zhe Song', 'hidden': False}, {'_id': '677f9188fb22a3b146287a72', 'name': 'Tao Xiang', 'hidden': False}, {'_id': '677f9188fb22a3b146287a73', 'user': {'_id': '647ef9e7aa8c04bbf9362a8a', 'avatarUrl': '/avatars/dc23e15acf7ee7f3b9f1a68c2716a66d.svg', 'isPro': False, 'fullname': 'Xiatian Zhu', 'user': 'Xiatian-Zhu', 'type': 'user'}, 'name': 'Xiatian Zhu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:29:33.382Z', 'hidden': False}], 'publishedAt': '2025-01-07T21:14:11.000Z', 'title': 'Chirpy3D: Continuous Part Latents for Creative 3D Bird Generation', 'summary': 'In this paper, we push the boundaries of fine-grained 3D generation into\\ntruly creative territory. Current methods either lack intricate details or\\nsimply mimic existing objects -- we enable both. By lifting 2D fine-grained\\nunderstanding into 3D through multi-view diffusion and modeling part latents as\\ncontinuous distributions, we unlock the ability to generate entirely new, yet\\nplausible parts through interpolation and sampling. A self-supervised feature\\nconsistency loss further ensures stable generation of these unseen parts. The\\nresult is the first system capable of creating novel 3D objects with\\nspecies-specific details that transcend existing examples. While we demonstrate\\nour approach on birds, the underlying framework extends beyond things that can\\nchirp! Code will be released at https://github.com/kamwoh/chirpy3d.', 'upvotes': 9, 'discussionId': '677f918cfb22a3b146287b7a'}, 'publishedAt': '2025-01-09T04:08:54.695Z', 'title': 'Chirpy3D: Continuous Part Latents for Creative 3D Bird Generation', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04144.png', 'numComments': 3, 'submittedBy': {'_id': '646f9a9d5b8225e31ae5a408', 'avatarUrl': '/avatars/b6210993b51bb650ea8aa8c04e5fc351.svg', 'fullname': 'kamwoh', 'name': 'kamwoh', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 7}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.05366', 'authors': [{'_id': '678084b5883142429f3cf7a0', 'name': 'Xiaoxi Li', 'hidden': False}, {'_id': '678084b5883142429f3cf7a1', 'name': 'Guanting Dong', 'hidden': False}, {'_id': '678084b5883142429f3cf7a2', 'name': 'Jiajie Jin', 'hidden': False}, {'_id': '678084b5883142429f3cf7a3', 'name': 'Yuyao Zhang', 'hidden': False}, {'_id': '678084b5883142429f3cf7a4', 'name': 'Yujia Zhou', 'hidden': False}, {'_id': '678084b5883142429f3cf7a5', 'name': 'Yutao Zhu', 'hidden': False}, {'_id': '678084b5883142429f3cf7a6', 'name': 'Peitian Zhang', 'hidden': False}, {'_id': '678084b5883142429f3cf7a7', 'name': 'Zhicheng Dou', 'hidden': False}], 'publishedAt': '2025-01-09T16:48:17.000Z', 'title': 'Search-o1: Agentic Search-Enhanced Large Reasoning Models', 'summary': 'Large reasoning models (LRMs) like OpenAI-o1 have demonstrated impressive\\nlong stepwise reasoning capabilities through large-scale reinforcement\\nlearning. However, their extended reasoning processes often suffer from\\nknowledge insufficiency, leading to frequent uncertainties and potential\\nerrors. To address this limitation, we introduce Search-o1, a\\nframework that enhances LRMs with an agentic retrieval-augmented generation\\n(RAG) mechanism and a Reason-in-Documents module for refining retrieved\\ndocuments. Search-o1 integrates an agentic search workflow into the reasoning\\nprocess, enabling dynamic retrieval of external knowledge when LRMs encounter\\nuncertain knowledge points. Additionally, due to the verbose nature of\\nretrieved documents, we design a separate Reason-in-Documents module to deeply\\nanalyze the retrieved information before injecting it into the reasoning chain,\\nminimizing noise and preserving coherent reasoning flow. Extensive experiments\\non complex reasoning tasks in science, mathematics, and coding, as well as six\\nopen-domain QA benchmarks, demonstrate the strong performance of Search-o1.\\nThis approach enhances the trustworthiness and applicability of LRMs in complex\\nreasoning tasks, paving the way for more reliable and versatile intelligent\\nsystems. The code is available at\\nhttps://github.com/sunnynexus/Search-o1.', 'upvotes': 6, 'discussionId': '678084b6883142429f3cf7e7'}, 'publishedAt': '2025-01-09T21:24:30.115Z', 'title': 'Search-o1: Agentic Search-Enhanced Large Reasoning Models', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05366.png', 'numComments': 2, 'submittedBy': {'_id': '61cd4b833dd34ba1985e0753', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/61cd4b833dd34ba1985e0753/BfHfrwotoMESpXZOHiIe4.png', 'fullname': 'KABI', 'name': 'dongguanting', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 12}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2501.03271', 'authors': [{'_id': '677f70b49fd1b42991dbf051', 'user': {'_id': '637537dc08eebfdd0a36e561', 'avatarUrl': '/avatars/70f800e80bac457649b1a4deaf6291ba.svg', 'isPro': False, 'fullname': 'Amitava Das', 'user': 'dramitavadas', 'type': 'user'}, 'name': 'Amitava Das', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:32:21.610Z', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf052', 'name': 'Suranjana Trivedy', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf053', 'user': {'_id': '64731b1371f07ae738cffed6', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/64731b1371f07ae738cffed6/BoEiEgNrNZFXZPG5guWsu.jpeg', 'isPro': False, 'fullname': 'Danush Khanna', 'user': 'danushkhanna', 'type': 'user'}, 'name': 'Danush Khanna', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:32:34.248Z', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf054', 'user': {'_id': '65f84a28e67fd04a14b4bd2d', 'avatarUrl': '/avatars/951b43457820a4486d7e09df357718fd.svg', 'isPro': False, 'fullname': 'Rajarshi Roy', 'user': 'dextrr', 'type': 'user'}, 'name': 'Rajarshi Roy', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:32:40.821Z', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf055', 'name': 'Gurpreet Singh', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf056', 'user': {'_id': '638f1a6cc4444c6ca86fc4b4', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/638f1a6cc4444c6ca86fc4b4/t_2zcBUdcyNvS9KlcybPx.jpeg', 'isPro': False, 'fullname': 'Basab Ghosh', 'user': 'basab1142', 'type': 'user'}, 'name': 'Basab Ghosh', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T19:57:48.729Z', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf057', 'name': 'Yaswanth Narsupalli', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf058', 'user': {'_id': '6517bfecce732bf33a29d04b', 'avatarUrl': '/avatars/b6534a540fa10199df8f9acc497083d5.svg', 'isPro': False, 'fullname': 'Vinija Jain', 'user': 'Vinija', 'type': 'user'}, 'name': 'Vinija Jain', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:33:06.982Z', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf059', 'user': {'_id': '65492730a3d1682f79f3ab7a', 'avatarUrl': '/avatars/fc62605bdf10947dab393305c51ace96.svg', 'isPro': False, 'fullname': 'Vasu Sharma', 'user': 'vasusharma55', 'type': 'user'}, 'name': 'Vasu Sharma', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:33:14.847Z', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf05a', 'name': 'Aishwarya Naresh Reganti', 'hidden': False}, {'_id': '677f70b49fd1b42991dbf05b', 'user': {'_id': '63a4754927f1f64ed7238dac', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg', 'isPro': False, 'fullname': 'Aman Chadha', 'user': 'amanchadha', 'type': 'user'}, 'name': 'Aman Chadha', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T10:06:06.459Z', 'hidden': False}], 'publishedAt': '2025-01-05T00:08:52.000Z', 'title': 'DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich\\n  Paradigm for Direct Preference Optimization', 'summary': 'The rapid rise of large language models (LLMs) has unlocked many applications\\nbut also underscores the challenge of aligning them with diverse values and\\npreferences. Direct Preference Optimization (DPO) is central to alignment but\\nconstrained by fixed divergences and limited feature transformations. We\\npropose DPO-Kernels, which integrates kernel methods to address these issues\\nthrough four key contributions: (i) Kernelized Representations with polynomial,\\nRBF, Mahalanobis, and spectral kernels for richer transformations, plus a\\nhybrid loss combining embedding-based and probability-based objectives; (ii)\\nDivergence Alternatives (Jensen-Shannon, Hellinger, Renyi, Bhattacharyya,\\nWasserstein, and f-divergences) for greater stability; (iii) Data-Driven\\nSelection metrics that automatically choose the best kernel-divergence pair;\\nand (iv) a Hierarchical Mixture of Kernels for both local precision and global\\nmodeling. Evaluations on 12 datasets demonstrate state-of-the-art performance\\nin factuality, safety, reasoning, and instruction following. Grounded in\\nHeavy-Tailed Self-Regularization, DPO-Kernels maintains robust generalization\\nfor LLMs, offering a comprehensive resource for further alignment research.', 'upvotes': 5, 'discussionId': '677f70b89fd1b42991dbf199'}, 'publishedAt': '2025-01-09T01:46:57.692Z', 'title': 'DPO Kernels: A Semantically-Aware, Kernel-Enhanced, and Divergence-Rich Paradigm for Direct Preference Optimization', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.03271.png', 'numComments': 2, 'submittedBy': {'_id': '63a4754927f1f64ed7238dac', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg', 'fullname': 'Aman Chadha', 'name': 'amanchadha', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04694', 'authors': [{'_id': '677f68d5b8f3572fc35d6046', 'name': 'Yaoxiang Wang', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d6047', 'user': {'_id': '650be23ec4e52db6a4db63ef', 'avatarUrl': '/avatars/03af548029b38bee49ec295fefe74f9a.svg', 'isPro': False, 'fullname': 'Haoling Li', 'user': 'Ringo1110', 'type': 'user'}, 'name': 'Haoling Li', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T10:06:15.412Z', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d6048', 'user': {'_id': '641a9a4b05290a135041a3ed', 'avatarUrl': '/avatars/95d66ac607973abe95bd3558c6c93739.svg', 'isPro': False, 'fullname': 'Pluto', 'user': 'CharonBony', 'type': 'user'}, 'name': 'Xin Zhang', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-01-09T06:12:38.212Z', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d6049', 'name': 'Jie Wu', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d604a', 'user': {'_id': '63fb6e281b4b1bd4e7ffc5be', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg', 'isPro': False, 'fullname': 'Xiao Liu', 'user': 'lx865712528', 'type': 'user'}, 'name': 'Xiao Liu', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-01-09T19:57:52.589Z', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d604b', 'user': {'_id': '6327cafc46ffcfc27cfa4c9a', 'avatarUrl': '/avatars/4daea27b432ff428c41d590669f7330c.svg', 'isPro': False, 'fullname': 'Wenxiang Hu', 'user': 'wenxcs', 'type': 'user'}, 'name': 'Wenxiang Hu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:31:18.292Z', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d604c', 'name': 'Zhongxin Guo', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d604d', 'user': {'_id': '64c66647725ffa04b2fd6c94', 'avatarUrl': '/avatars/620f63f27fa1e90423b0dc22aa8e5809.svg', 'isPro': False, 'fullname': 'yangyu huang', 'user': 'yangyu90', 'type': 'user'}, 'name': 'Yangyu Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:31:33.079Z', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d604e', 'name': 'Ying Xin', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d604f', 'user': {'_id': '64ca1fe838837b12d5e529b7', 'avatarUrl': '/avatars/44a3ad9e59318784ac531993b5f69f6b.svg', 'isPro': False, 'fullname': 'Yujiu Yang', 'user': 'Thu-redrobot', 'type': 'user'}, 'name': 'Yujiu Yang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:31:49.764Z', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d6050', 'name': 'Jinsong Su', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d6051', 'user': {'_id': '6358c7db856b319a29bdb26b', 'avatarUrl': '/avatars/c806e76b6342c1b788bd1dc337f086b8.svg', 'isPro': False, 'fullname': 'QiChen', 'user': 'QiChen00', 'type': 'user'}, 'name': 'Qi Chen', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:32:03.897Z', 'hidden': False}, {'_id': '677f68d5b8f3572fc35d6052', 'user': {'_id': '67366efb049bfa3a9084e8d1', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/Bny5bUc6qFQ_RWpEKpRAW.jpeg', 'isPro': False, 'fullname': 'Scarlett Li', 'user': 'lisijia0504', 'type': 'user'}, 'name': 'Scarlett Li', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-01-09T20:32:10.147Z', 'hidden': False}], 'publishedAt': '2025-01-08T18:58:15.000Z', 'title': 'EpiCoder: Encompassing Diversity and Complexity in Code Generation', 'summary': 'Effective instruction tuning is indispensable for optimizing code LLMs,\\naligning model behavior with user expectations and enhancing model performance\\nin real-world applications. However, most existing methods focus on code\\nsnippets, which are limited to specific functionalities and rigid structures,\\nrestricting the complexity and diversity of the synthesized data. To address\\nthese limitations, we introduce a novel feature tree-based synthesis framework\\ninspired by Abstract Syntax Trees (AST). Unlike AST, which captures syntactic\\nstructure of code, our framework models semantic relationships between code\\nelements, enabling the generation of more nuanced and diverse data. The feature\\ntree is constructed from raw data and refined iteratively to increase the\\nquantity and diversity of the extracted features. This process enables the\\nidentification of more complex patterns and relationships within the code. By\\nsampling subtrees with controlled depth and breadth, our framework allows\\nprecise adjustments to the complexity of the generated code, supporting a wide\\nrange of tasks from simple function-level operations to intricate multi-file\\nscenarios. We fine-tuned widely-used base models to create the EpiCoder series,\\nachieving state-of-the-art performance at both the function and file levels\\nacross multiple benchmarks. Notably, empirical evidence indicates that our\\napproach shows significant potential in synthesizing highly complex\\nrepository-level code data. Further analysis elucidates the merits of this\\napproach by rigorously assessing data complexity and diversity through software\\nengineering principles and LLM-as-a-judge method.', 'upvotes': 4, 'discussionId': '677f68d6b8f3572fc35d6091'}, 'publishedAt': '2025-01-09T07:05:25.005Z', 'title': 'EpiCoder: Encompassing Diversity and Complexity in Code Generation', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04694.png', 'numComments': 2, 'submittedBy': {'_id': '63fb6e281b4b1bd4e7ffc5be', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg', 'fullname': 'Xiao Liu', 'name': 'lx865712528', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 6}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2501.04652', 'authors': [{'_id': '677fdb64a907a4645d4ad7e2', 'user': {'_id': '607f060442beb4da0f990182', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/607f060442beb4da0f990182/j5W2tLyU6JqkaTf3kv66s.jpeg', 'isPro': False, 'fullname': 'Patrice Bechard', 'user': 'patricebechard', 'type': 'user'}, 'name': 'Patrice Bchard', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-09T14:24:03.741Z', 'hidden': False}, {'_id': '677fdb64a907a4645d4ad7e3', 'user': {'_id': '64820d2bd8662b0714a2a3cd', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/64820d2bd8662b0714a2a3cd/AHp4bGT05PNlaIGue5gDw.png', 'isPro': False, 'fullname': 'Orlando Marquez', 'user': 'marquezo', 'type': 'user'}, 'name': 'Orlando Marquez Ayala', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-01-09T18:53:32.679Z', 'hidden': False}], 'publishedAt': '2025-01-08T18:05:30.000Z', 'title': 'Multi-task retriever fine-tuning for domain-specific and efficient RAG', 'summary': 'Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying\\nLarge Language Models (LLMs), as it can address typical limitations such as\\ngenerating hallucinated or outdated information. However, when building\\nreal-world RAG applications, practical issues arise. First, the retrieved\\ninformation is generally domain-specific. Since it is computationally expensive\\nto fine-tune LLMs, it is more feasible to fine-tune the retriever to improve\\nthe quality of the data included in the LLM input. Second, as more applications\\nare deployed in the same real-world system, one cannot afford to deploy\\nseparate retrievers. Moreover, these RAG applications normally retrieve\\ndifferent kinds of data. Our solution is to instruction fine-tune a small\\nretriever encoder on a variety of domain-specific tasks to allow us to deploy\\none encoder that can serve many use cases, thereby achieving low-cost,\\nscalability, and speed. We show how this encoder generalizes to out-of-domain\\nsettings as well as to an unseen retrieval task on real-world enterprise use\\ncases.', 'upvotes': 2, 'discussionId': '677fdb65a907a4645d4ad80b'}, 'publishedAt': '2025-01-09T09:23:18.009Z', 'title': 'Multi-task retriever fine-tuning for domain-specific and efficient RAG', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04652.png', 'numComments': 2, 'submittedBy': {'_id': '607f060442beb4da0f990182', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/607f060442beb4da0f990182/j5W2tLyU6JqkaTf3kv66s.jpeg', 'fullname': 'Patrice Bechard', 'name': 'patricebechard', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}"
]