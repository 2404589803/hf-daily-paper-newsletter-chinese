[
    {
        "paper": {
            "id": "2407.01370",
            "authors": [
                {
                    "_id": "668504fa45d8ceb44608dff2",
                    "user": {
                        "avatarUrl": "/avatars/b6e5bba78425e9c28d1b75ee8a7eaac1.svg",
                        "isPro": false,
                        "fullname": "Philippe Laban",
                        "user": "philippelaban",
                        "type": "user"
                    },
                    "name": "Philippe Laban",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:46:00.151Z",
                    "hidden": false
                },
                {
                    "_id": "668504fa45d8ceb44608dff3",
                    "user": {
                        "avatarUrl": "/avatars/7c89167744703771e3f163665cdb66cc.svg",
                        "isPro": false,
                        "fullname": "Alexander Fabbri",
                        "user": "alexfabbri",
                        "type": "user"
                    },
                    "name": "Alexander R. Fabbri",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:46:27.630Z",
                    "hidden": false
                },
                {
                    "_id": "668504fa45d8ceb44608dff4",
                    "user": {
                        "avatarUrl": "/avatars/c87c273ca628dbcddccbf1ee19b2ce33.svg",
                        "isPro": false,
                        "fullname": "Caiming Xiong",
                        "user": "cxiong",
                        "type": "user"
                    },
                    "name": "Caiming Xiong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:46:34.196Z",
                    "hidden": false
                },
                {
                    "_id": "668504fa45d8ceb44608dff5",
                    "user": {
                        "avatarUrl": "/avatars/e49f53128b5305dfec44d80129c59ca3.svg",
                        "isPro": false,
                        "fullname": "Chien-Sheng (Jason) Wu",
                        "user": "jasonwu",
                        "type": "user"
                    },
                    "name": "Chien-Sheng Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:46:48.026Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-01T15:23:42.000Z",
            "title": "Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems",
            "summary": "LLMs and RAG systems are now capable of handling millions of input tokens or\nmore. However, evaluating the output quality of such systems on long-context\ntasks remains challenging, as tasks like Needle-in-a-Haystack lack complexity.\nIn this work, we argue that summarization can play a central role in such\nevaluation. We design a procedure to synthesize Haystacks of documents,\nensuring that specific insights repeat across documents. The \"Summary\nof a Haystack\" (SummHay) task then requires a system to process the Haystack\nand generate, given a query, a summary that identifies the relevant insights\nand precisely cites the source documents. Since we have precise knowledge of\nwhat insights should appear in a haystack summary and what documents should be\ncited, we implement a highly reproducible automatic evaluation that can score\nsummaries on two aspects - Coverage and Citation. We generate Haystacks in two\ndomains (conversation, news), and perform a large-scale evaluation of 10 LLMs\nand corresponding 50 RAG systems. Our findings indicate that SummHay is an open\nchallenge for current systems, as even systems provided with an Oracle signal\nof document relevance lag our estimate of human performance (56\\%) by 10+\npoints on a Joint Score. Without a retriever, long-context LLMs like GPT-4o and\nClaude 3 Opus score below 20% on SummHay. We show SummHay can also be used to\nstudy enterprise RAG systems and position bias in long-context models. We hope\nfuture systems can equal and surpass human performance on SummHay.",
            "upvotes": 33
        },
        "publishedAt": "2024-07-03T06:58:18.142Z",
        "title": "Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.01370.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1624629516652-5ff5d596f244529b3ec0fb89.png",
            "fullname": "Philipp Schmid",
            "name": "philschmid",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02371",
            "authors": [
                {
                    "_id": "668520f158b83aeb6bcd8415",
                    "name": "Kepan Nan",
                    "hidden": false
                },
                {
                    "_id": "668520f158b83aeb6bcd8416",
                    "user": {
                        "avatarUrl": "/avatars/e488058397f2b7a617515a4f721a9a00.svg",
                        "isPro": false,
                        "fullname": "Rui Xie",
                        "user": "SherryX",
                        "type": "user"
                    },
                    "name": "Rui Xie",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T13:44:40.826Z",
                    "hidden": false
                },
                {
                    "_id": "668520f158b83aeb6bcd8417",
                    "name": "Penghao Zhou",
                    "hidden": false
                },
                {
                    "_id": "668520f158b83aeb6bcd8418",
                    "name": "Tiehan Fan",
                    "hidden": false
                },
                {
                    "_id": "668520f158b83aeb6bcd8419",
                    "name": "Zhenheng Yang",
                    "hidden": false
                },
                {
                    "_id": "668520f158b83aeb6bcd841a",
                    "user": {
                        "avatarUrl": "/avatars/9ff160b0a76dd56f913948d34dd045c8.svg",
                        "isPro": false,
                        "fullname": "Zhijie Chen",
                        "user": "Zhijie-Chen",
                        "type": "user"
                    },
                    "name": "Zhijie Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T14:44:52.848Z",
                    "hidden": false
                },
                {
                    "_id": "668520f158b83aeb6bcd841b",
                    "name": "Xiang Li",
                    "hidden": false
                },
                {
                    "_id": "668520f158b83aeb6bcd841c",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "668520f158b83aeb6bcd841d",
                    "user": {
                        "avatarUrl": "/avatars/d6310ed861972fd691687d8f47413f33.svg",
                        "isPro": false,
                        "fullname": "Ying Tai",
                        "user": "yingtai",
                        "type": "user"
                    },
                    "name": "Ying Tai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T13:44:42.564Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T15:40:29.000Z",
            "title": "OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video\n  Generation",
            "summary": "Text-to-video (T2V) generation has recently garnered significant attention\nthanks to the large multi-modality model Sora. However, T2V generation still\nfaces two important challenges: 1) Lacking a precise open sourced high-quality\ndataset. The previous popular video datasets, e.g. WebVid-10M and Panda-70M,\nare either with low quality or too large for most research institutions.\nTherefore, it is challenging but crucial to collect a precise high-quality\ntext-video pairs for T2V generation. 2) Ignoring to fully utilize textual\ninformation. Recent T2V methods have focused on vision transformers, using a\nsimple cross attention module for video generation, which falls short of\nthoroughly extracting semantic information from text prompt. To address these\nissues, we introduce OpenVid-1M, a precise high-quality dataset with expressive\ncaptions. This open-scenario dataset contains over 1 million text-video pairs,\nfacilitating research on T2V generation. Furthermore, we curate 433K 1080p\nvideos from OpenVid-1M to create OpenVidHD-0.4M, advancing high-definition\nvideo generation. Additionally, we propose a novel Multi-modal Video Diffusion\nTransformer (MVDiT) capable of mining both structure information from visual\ntokens and semantic information from text tokens. Extensive experiments and\nablation studies verify the superiority of OpenVid-1M over previous datasets\nand the effectiveness of our MVDiT.",
            "upvotes": 22
        },
        "publishedAt": "2024-07-03T10:55:47.642Z",
        "title": "OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/65734004769f3ee9bde1af10/5GJfj_iHsVBFSJ6ztPPSB.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02371.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "/avatars/d6310ed861972fd691687d8f47413f33.svg",
            "fullname": "Ying Tai",
            "name": "yingtai",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.01489",
            "authors": [
                {
                    "_id": "6684e6b5c1cbe5e008dbf21a",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645ac350c35da9c7afd82379/nRNoSz0QA2yJmqK3C3F95.jpeg",
                        "isPro": false,
                        "fullname": "Chunqiu Steven Xia",
                        "user": "nevetsaix",
                        "type": "user"
                    },
                    "name": "Chunqiu Steven Xia",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T07:37:42.167Z",
                    "hidden": false
                },
                {
                    "_id": "6684e6b5c1cbe5e008dbf21b",
                    "user": {
                        "avatarUrl": "/avatars/42695a25ebdab0c82940ca5309fdbc18.svg",
                        "isPro": false,
                        "fullname": "Deng",
                        "user": "Yinlin",
                        "type": "user"
                    },
                    "name": "Yinlin Deng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T07:54:02.536Z",
                    "hidden": false
                },
                {
                    "_id": "6684e6b5c1cbe5e008dbf21c",
                    "name": "Soren Dunn",
                    "hidden": false
                },
                {
                    "_id": "6684e6b5c1cbe5e008dbf21d",
                    "user": {
                        "avatarUrl": "/avatars/8f4fef3d835a7a11c2ab66dbf04f3424.svg",
                        "isPro": false,
                        "fullname": "Lingming Zhang",
                        "user": "lingming",
                        "type": "user"
                    },
                    "name": "Lingming Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T07:57:02.292Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-01T17:24:45.000Z",
            "title": "Agentless: Demystifying LLM-based Software Engineering Agents",
            "summary": "Recent advancements in large language models (LLMs) have significantly\nadvanced the automation of software development tasks, including code\nsynthesis, program repair, and test generation. More recently, researchers and\nindustry practitioners have developed various autonomous LLM agents to perform\nend-to-end software development tasks. These agents are equipped with the\nability to use tools, run commands, observe feedback from the environment, and\nplan for future actions. However, the complexity of these agent-based\napproaches, together with the limited abilities of current LLMs, raises the\nfollowing question: Do we really have to employ complex autonomous software\nagents? To attempt to answer this question, we build Agentless -- an agentless\napproach to automatically solve software development problems. Compared to the\nverbose and complex setup of agent-based approaches, Agentless employs a\nsimplistic two-phase process of localization followed by repair, without\nletting the LLM decide future actions or operate with complex tools. Our\nresults on the popular SWE-bench Lite benchmark show that surprisingly the\nsimplistic Agentless is able to achieve both the highest performance (27.33%)\nand lowest cost (\\$0.34) compared with all existing open-source software\nagents! Furthermore, we manually classified the problems in SWE-bench Lite and\nfound problems with exact ground truth patch or insufficient/misleading issue\ndescriptions. As such, we construct SWE-bench Lite-S by excluding such\nproblematic issues to perform more rigorous evaluation and comparison. Our work\nhighlights the current overlooked potential of a simple, interpretable\ntechnique in autonomous software development. We hope Agentless will help reset\nthe baseline, starting point, and horizon for autonomous software agents, and\ninspire future work along this crucial direction.",
            "upvotes": 16
        },
        "publishedAt": "2024-07-03T04:33:10.175Z",
        "title": "Agentless: Demystifying LLM-based Software Engineering Agents",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.01489.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645ac350c35da9c7afd82379/nRNoSz0QA2yJmqK3C3F95.jpeg",
            "fullname": "Chunqiu Steven Xia",
            "name": "nevetsaix",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02490",
            "authors": [
                {
                    "_id": "6684aff23780e7f96dc29274",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6278bd42541f3d2dfa77ea70/ejn49eapnB3UXQckAYdTd.jpeg",
                        "isPro": true,
                        "fullname": "Huiqiang Jiang",
                        "user": "iofu728",
                        "type": "user"
                    },
                    "name": "Huiqiang Jiang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T07:37:55.043Z",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc29275",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63d00710645dd8d34ea9bcc6/ocxkwGAAHc8bgggAtA1ih.jpeg",
                        "isPro": false,
                        "fullname": "Yucheng",
                        "user": "liyucheng",
                        "type": "user"
                    },
                    "name": "Yucheng Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T07:41:33.975Z",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc29276",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64646896884f2e3e1ced3cd5/86-t8V8LGMNaPQRXnADiD.png",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "Chengruidong",
                        "type": "user"
                    },
                    "name": "Chengruidong Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:22:52.134Z",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc29277",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63ef330b1e695b35aa484e11/bXwpGy0dl8JXeJwJ--ilr.jpeg",
                        "isPro": false,
                        "fullname": "Qianhui WU",
                        "user": "qianhuiwu",
                        "type": "user"
                    },
                    "name": "Qianhui Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:22:59.496Z",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc29278",
                    "user": {
                        "avatarUrl": "/avatars/f09181c0825763dff692c4bc65effc4c.svg",
                        "isPro": false,
                        "fullname": "Xufang Luo",
                        "user": "luoxufang",
                        "type": "user"
                    },
                    "name": "Xufang Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:23:06.765Z",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc29279",
                    "name": "Surin Ahn",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc2927a",
                    "user": {
                        "avatarUrl": "/avatars/a07755847ec8d05052221d351a3ae20f.svg",
                        "isPro": false,
                        "fullname": "Zhenhua Han",
                        "user": "hzhua",
                        "type": "user"
                    },
                    "name": "Zhenhua Han",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:23:18.553Z",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc2927b",
                    "name": "Amir H. Abdi",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc2927c",
                    "name": "Dongsheng Li",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc2927d",
                    "name": "Chin-Yew Lin",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc2927e",
                    "name": "Yuqing Yang",
                    "hidden": false
                },
                {
                    "_id": "6684aff23780e7f96dc2927f",
                    "name": "Lili Qiu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T17:59:56.000Z",
            "title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via\n  Dynamic Sparse Attention",
            "summary": "The computational challenges of Large Language Model (LLM) inference remain a\nsignificant barrier to their widespread deployment, especially as prompt\nlengths continue to increase. Due to the quadratic complexity of the attention\ncomputation, it takes 30 minutes for an 8B LLM to process a prompt of 1M tokens\n(i.e., the pre-filling stage) on a single A100 GPU. Existing methods for\nspeeding up prefilling often fail to maintain acceptable accuracy or efficiency\nwhen applied to long-context LLMs. To address this gap, we introduce MInference\n(Milliontokens Inference), a sparse calculation method designed to accelerate\npre-filling of long-sequence processing. Specifically, we identify three unique\npatterns in long-context attention matrices-the A-shape, Vertical-Slash, and\nBlock-Sparsethat can be leveraged for efficient sparse computation on GPUs. We\ndetermine the optimal pattern for each attention head offline and dynamically\nbuild sparse indices based on the assigned pattern during inference. With the\npattern and sparse indices, we perform efficient sparse attention calculations\nvia our optimized GPU kernels to significantly reduce the latency in the\npre-filling stage of long-context LLMs. Our proposed technique can be directly\napplied to existing LLMs without any modifications to the pre-training setup or\nadditional fine-tuning. By evaluating on a wide range of downstream tasks,\nincluding InfiniteBench, RULER, PG-19, and Needle In A Haystack, and models\nincluding LLaMA-3-1M, GLM4-1M, Yi-200K, Phi-3-128K, and Qwen2-128K, we\ndemonstrate that MInference effectively reduces inference latency by up to 10x\nfor pre-filling on an A100, while maintaining accuracy. Our code is available\nat https://aka.ms/MInference.",
            "upvotes": 10
        },
        "publishedAt": "2024-07-03T03:53:47.851Z",
        "title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6278bd42541f3d2dfa77ea70/Pmx510-_703vitXUtP-K4.png",
            "https://cdn-uploads.huggingface.co/production/uploads/6278bd42541f3d2dfa77ea70/hHEfqM5awgWk8r3nkjxwJ.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02490.png",
        "numComments": 4,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6278bd42541f3d2dfa77ea70/ejn49eapnB3UXQckAYdTd.jpeg",
            "fullname": "Huiqiang Jiang",
            "name": "iofu728",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02398",
            "authors": [
                {
                    "_id": "6684acd0c1cbe5e008c99eab",
                    "name": "Ling Yang",
                    "hidden": false
                },
                {
                    "_id": "6684acd0c1cbe5e008c99eac",
                    "name": "Zixiang Zhang",
                    "hidden": false
                },
                {
                    "_id": "6684acd0c1cbe5e008c99ead",
                    "user": {
                        "avatarUrl": "/avatars/1a40e31656ab140503c213302bfc306d.svg",
                        "isPro": false,
                        "fullname": "Zhilong Zhang",
                        "user": "zzl35",
                        "type": "user"
                    },
                    "name": "Zhilong Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:20:32.301Z",
                    "hidden": false
                },
                {
                    "_id": "6684acd0c1cbe5e008c99eae",
                    "user": {
                        "avatarUrl": "/avatars/b9a4ed9573c49241bd9cb96c919f9e8f.svg",
                        "isPro": false,
                        "fullname": "Xingchao Liu",
                        "user": "XCLiu",
                        "type": "user"
                    },
                    "name": "Xingchao Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:20:38.901Z",
                    "hidden": false
                },
                {
                    "_id": "6684acd0c1cbe5e008c99eaf",
                    "user": {
                        "avatarUrl": "/avatars/374d53317cbccc30fae70e5152ca13e0.svg",
                        "isPro": false,
                        "fullname": "Minkai Xu",
                        "user": "mkxu",
                        "type": "user"
                    },
                    "name": "Minkai Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:20:46.679Z",
                    "hidden": false
                },
                {
                    "_id": "6684acd0c1cbe5e008c99eb0",
                    "name": "Wentao Zhang",
                    "hidden": false
                },
                {
                    "_id": "6684acd0c1cbe5e008c99eb1",
                    "name": "Chenlin Meng",
                    "hidden": false
                },
                {
                    "_id": "6684acd0c1cbe5e008c99eb2",
                    "user": {
                        "avatarUrl": "/avatars/5a8b2bb063c2ebc340504b22530f6811.svg",
                        "isPro": false,
                        "fullname": "Stefano Ermon",
                        "user": "ermonste",
                        "type": "user"
                    },
                    "name": "Stefano Ermon",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:21:23.591Z",
                    "hidden": false
                },
                {
                    "_id": "6684acd0c1cbe5e008c99eb3",
                    "name": "Bin Cui",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T16:15:37.000Z",
            "title": "Consistency Flow Matching: Defining Straight Flows with Velocity\n  Consistency",
            "summary": "Flow matching (FM) is a general framework for defining probability paths via\nOrdinary Differential Equations (ODEs) to transform between noise and data\nsamples. Recent approaches attempt to straighten these flow trajectories to\ngenerate high-quality samples with fewer function evaluations, typically\nthrough iterative rectification methods or optimal transport solutions. In this\npaper, we introduce Consistency Flow Matching (Consistency-FM), a novel FM\nmethod that explicitly enforces self-consistency in the velocity field.\nConsistency-FM directly defines straight flows starting from different times to\nthe same endpoint, imposing constraints on their velocity values. Additionally,\nwe propose a multi-segment training approach for Consistency-FM to enhance\nexpressiveness, achieving a better trade-off between sampling quality and\nspeed. Preliminary experiments demonstrate that our Consistency-FM\nsignificantly improves training efficiency by converging 4.4x faster than\nconsistency models and 1.7x faster than rectified flow models while achieving\nbetter generation quality. Our code is available at:\nhttps://github.com/YangLing0818/consistency_flow_matching",
            "upvotes": 9
        },
        "publishedAt": "2024-07-03T02:30:34.567Z",
        "title": "Consistency Flow Matching: Defining Straight Flows with Velocity Consistency",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02398.png",
        "numComments": 4,
        "submittedBy": {
            "avatarUrl": "/avatars/061a69d858b86d1600be916122cae7fc.svg",
            "fullname": "Ling Yang",
            "name": "Lingaaaaaaa",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.19568",
            "authors": [
                {
                    "_id": "66851684fb78936cdbfd16d2",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a7fe360f4bad61a44aafbe/ocs7Qf3AT5q1S3WjGDYDh.jpeg",
                        "isPro": false,
                        "fullname": "Chirui Chang",
                        "user": "JustinSheung",
                        "type": "user"
                    },
                    "name": "Chirui Chang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T09:47:54.002Z",
                    "hidden": false
                },
                {
                    "_id": "66851684fb78936cdbfd16d3",
                    "name": "Zhengzhe Liu",
                    "hidden": false
                },
                {
                    "_id": "66851684fb78936cdbfd16d4",
                    "name": "Xiaoyang Lyu",
                    "hidden": false
                },
                {
                    "_id": "66851684fb78936cdbfd16d5",
                    "name": "Xiaojuan Qi",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-27T23:03:58.000Z",
            "title": "What Matters in Detecting AI-Generated Videos like Sora?",
            "summary": "Recent advancements in diffusion-based video generation have showcased\nremarkable results, yet the gap between synthetic and real-world videos remains\nunder-explored. In this study, we examine this gap from three fundamental\nperspectives: appearance, motion, and geometry, comparing real-world videos\nwith those generated by a state-of-the-art AI model, Stable Video Diffusion. To\nachieve this, we train three classifiers using 3D convolutional networks, each\ntargeting distinct aspects: vision foundation model features for appearance,\noptical flow for motion, and monocular depth for geometry. Each classifier\nexhibits strong performance in fake video detection, both qualitatively and\nquantitatively. This indicates that AI-generated videos are still easily\ndetectable, and a significant gap between real and fake videos persists.\nFurthermore, utilizing the Grad-CAM, we pinpoint systematic failures of\nAI-generated videos in appearance, motion, and geometry. Finally, we propose an\nEnsemble-of-Experts model that integrates appearance, optical flow, and depth\ninformation for fake video detection, resulting in enhanced robustness and\ngeneralization ability. Our model is capable of detecting videos generated by\nSora with high accuracy, even without exposure to any Sora videos during\ntraining. This suggests that the gap between real and fake videos can be\ngeneralized across various video generative models. Project page:\nhttps://justin-crchang.github.io/3DCNNDetection.github.io/",
            "upvotes": 8
        },
        "publishedAt": "2024-07-03T08:22:26.735Z",
        "title": "What Matters in Detecting AI-Generated Videos like Sora?",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.19568.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a7fe360f4bad61a44aafbe/ocs7Qf3AT5q1S3WjGDYDh.jpeg",
            "fullname": "Chirui Chang",
            "name": "JustinSheung",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.01494",
            "authors": [
                {
                    "_id": "66836152e365c0f6665bcfd2",
                    "user": {
                        "avatarUrl": "/avatars/d2dd2040a521de4f55c7335cb7771c75.svg",
                        "isPro": false,
                        "fullname": "Yiming Zhang",
                        "user": "ymzhang319",
                        "type": "user"
                    },
                    "name": "Yiming Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T07:41:12.636Z",
                    "hidden": false
                },
                {
                    "_id": "66836152e365c0f6665bcfd3",
                    "name": "Yicheng Gu",
                    "hidden": false
                },
                {
                    "_id": "66836152e365c0f6665bcfd4",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676365795587-63d4b843df01ef426a0f79fb.jpeg",
                        "isPro": false,
                        "fullname": "Yanhong Zeng",
                        "user": "zengyh1900",
                        "type": "user"
                    },
                    "name": "Yanhong Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:24:44.922Z",
                    "hidden": false
                },
                {
                    "_id": "66836152e365c0f6665bcfd5",
                    "user": {
                        "avatarUrl": "/avatars/25c1a68ee7b7d0cc7e9f56bde37f4914.svg",
                        "isPro": false,
                        "fullname": "Zhening Xing",
                        "user": "Leoxing",
                        "type": "user"
                    },
                    "name": "Zhening Xing",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:24:53.244Z",
                    "hidden": false
                },
                {
                    "_id": "66836152e365c0f6665bcfd6",
                    "user": {
                        "avatarUrl": "/avatars/a2ac1973800e8bb6a72e35fefb436a27.svg",
                        "isPro": false,
                        "fullname": "wangyuancheng",
                        "user": "CXKyyds199",
                        "type": "user"
                    },
                    "name": "Yuancheng Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T08:25:05.005Z",
                    "hidden": false
                },
                {
                    "_id": "66836152e365c0f6665bcfd7",
                    "name": "Zhizheng Wu",
                    "hidden": false
                },
                {
                    "_id": "66836152e365c0f6665bcfd8",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-01T17:35:56.000Z",
            "title": "FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized\n  Sounds",
            "summary": "We study Neural Foley, the automatic generation of high-quality sound effects\nsynchronizing with videos, enabling an immersive audio-visual experience.\nDespite its wide range of applications, existing approaches encounter\nlimitations when it comes to simultaneously synthesizing high-quality and\nvideo-aligned (i.e.,, semantic relevant and temporal synchronized) sounds. To\novercome these limitations, we propose FoleyCrafter, a novel framework that\nleverages a pre-trained text-to-audio model to ensure high-quality audio\ngeneration. FoleyCrafter comprises two key components: the semantic adapter for\nsemantic alignment and the temporal controller for precise audio-video\nsynchronization. The semantic adapter utilizes parallel cross-attention layers\nto condition audio generation on video features, producing realistic sound\neffects that are semantically relevant to the visual content. Meanwhile, the\ntemporal controller incorporates an onset detector and a timestampbased adapter\nto achieve precise audio-video alignment. One notable advantage of FoleyCrafter\nis its compatibility with text prompts, enabling the use of text descriptions\nto achieve controllable and diverse video-to-audio generation according to user\nintents. We conduct extensive quantitative and qualitative experiments on\nstandard benchmarks to verify the effectiveness of FoleyCrafter. Models and\ncodes are available at https://github.com/open-mmlab/FoleyCrafter.",
            "upvotes": 5
        },
        "publishedAt": "2024-07-03T01:09:03.357Z",
        "title": "FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.01494.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676365795587-63d4b843df01ef426a0f79fb.jpeg",
            "fullname": "Yanhong Zeng",
            "name": "zengyh1900",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.19238",
            "authors": [
                {
                    "_id": "667e6fb549c4138109a2488c",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1621514581657-60a643b9213fe60589b8fdf9.jpeg",
                        "isPro": false,
                        "fullname": "Dustin Wright",
                        "user": "dwright37",
                        "type": "user"
                    },
                    "name": "Dustin Wright",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T13:44:57.789Z",
                    "hidden": false
                },
                {
                    "_id": "667e6fb549c4138109a2488d",
                    "user": {
                        "avatarUrl": "/avatars/6a39cfa2fe45fad111a2a688b1d48a96.svg",
                        "isPro": false,
                        "fullname": "Arnav Arora",
                        "user": "ArnArora",
                        "type": "user"
                    },
                    "name": "Arnav Arora",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:02:56.980Z",
                    "hidden": false
                },
                {
                    "_id": "667e6fb549c4138109a2488e",
                    "user": {
                        "avatarUrl": "/avatars/9b18f368e5f80cfc935b2e339d42a85f.svg",
                        "isPro": false,
                        "fullname": "Nadav Borenstein",
                        "user": "Nadav",
                        "type": "user"
                    },
                    "name": "Nadav Borenstein",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T14:17:13.039Z",
                    "hidden": false
                },
                {
                    "_id": "667e6fb549c4138109a2488f",
                    "name": "Srishti Yadav",
                    "hidden": false
                },
                {
                    "_id": "667e6fb549c4138109a24890",
                    "name": "Serge Belongie",
                    "hidden": false
                },
                {
                    "_id": "667e6fb549c4138109a24891",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1621507769190-608918b7df398c3b285ce960.jpeg",
                        "isPro": false,
                        "fullname": "Isabelle Augenstein",
                        "user": "IAugenstein",
                        "type": "user"
                    },
                    "name": "Isabelle Augenstein",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:03:24.636Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-27T15:01:53.000Z",
            "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
            "summary": "Uncovering latent values and opinions in large language models (LLMs) can\nhelp identify biases and mitigate potential harm. Recently, this has been\napproached by presenting LLMs with survey questions and quantifying their\nstances towards morally and politically charged statements. However, the\nstances generated by LLMs can vary greatly depending on how they are prompted,\nand there are many ways to argue for or against a given position. In this work,\nwe propose to address this by analysing a large and robust dataset of 156k LLM\nresponses to the 62 propositions of the Political Compass Test (PCT) generated\nby 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of\ntheir generated stances and fine-grained analysis of the plain text\njustifications for those stances. For fine-grained analysis, we propose to\nidentify tropes in the responses: semantically similar phrases that are\nrecurrent and consistent across different prompts, revealing patterns in the\ntext that a given LLM is prone to produce. We find that demographic features\nadded to prompts significantly affect outcomes on the PCT, reflecting bias, as\nwell as disparities between the results of tests when eliciting closed-form vs.\nopen domain responses. Additionally, patterns in the plain text rationales via\ntropes show that similar justifications are repeatedly generated across models\nand prompts even with disparate stances.",
            "upvotes": 4
        },
        "publishedAt": "2024-07-03T12:16:53.491Z",
        "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/60a643b9213fe60589b8fdf9/Q2-YBcKUOGk8r9wUnIbkR.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.19238.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1621514581657-60a643b9213fe60589b8fdf9.jpeg",
            "fullname": "Dustin Wright",
            "name": "dwright37",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02477",
            "authors": [
                {
                    "_id": "668557da6c0ca62168747f72",
                    "name": "Elmira Amirloo",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f73",
                    "user": {
                        "avatarUrl": "/avatars/8fa8511baf2d9bd95d3ba4535a5b3d69.svg",
                        "isPro": false,
                        "fullname": "Jean-Philippe Fauconnier",
                        "user": "j4kn",
                        "type": "user"
                    },
                    "name": "Jean-Philippe Fauconnier",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:01:16.900Z",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f74",
                    "user": {
                        "avatarUrl": "/avatars/8ec5f7216ebd5c45291d0f0f722978c0.svg",
                        "isPro": false,
                        "fullname": "Christoph Roesmann",
                        "user": "croesmann",
                        "type": "user"
                    },
                    "name": "Christoph Roesmann",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T14:44:39.303Z",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f75",
                    "name": "Christian Kerl",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f76",
                    "name": "Rinu Boney",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f77",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d5d6e590119106db895670/SphTxh2E0MtT8T_bH0_zb.png",
                        "isPro": false,
                        "fullname": "Yusu Qian",
                        "user": "YusuQian",
                        "type": "user"
                    },
                    "name": "Yusu Qian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:01:38.374Z",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f78",
                    "name": "Zirui Wang",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f79",
                    "name": "Afshin Dehghan",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f7a",
                    "user": {
                        "avatarUrl": "/avatars/1eb737ec169967872f1ebf5ff29f1e6b.svg",
                        "isPro": false,
                        "fullname": "Yinfei Yang",
                        "user": "yinfeiy",
                        "type": "user"
                    },
                    "name": "Yinfei Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:02:18.572Z",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f7b",
                    "user": {
                        "avatarUrl": "/avatars/d9ed37ec77f2682878b2976a04d2fcd8.svg",
                        "isPro": false,
                        "fullname": "Zhe Gan",
                        "user": "zhegan27",
                        "type": "user"
                    },
                    "name": "Zhe Gan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:02:24.628Z",
                    "hidden": false
                },
                {
                    "_id": "668557da6c0ca62168747f7c",
                    "user": {
                        "avatarUrl": "/avatars/1c93d0e15f2b68281a1a2ea052450a45.svg",
                        "isPro": false,
                        "fullname": "Peter Grasch",
                        "user": "petergrasch",
                        "type": "user"
                    },
                    "name": "Peter Grasch",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:02:30.934Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T17:55:03.000Z",
            "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
            "summary": "Preference alignment has become a crucial component in enhancing the\nperformance of Large Language Models (LLMs), yet its impact in Multimodal Large\nLanguage Models (MLLMs) remains comparatively underexplored. Similar to\nlanguage models, MLLMs for image understanding tasks encounter challenges like\nhallucination. In MLLMs, hallucination can occur not only by stating incorrect\nfacts but also by producing responses that are inconsistent with the image\ncontent. A primary objective of alignment for MLLMs is to encourage these\nmodels to align responses more closely with image information. Recently,\nmultiple works have introduced preference datasets for MLLMs and examined\ndifferent alignment methods, including Direct Preference Optimization (DPO) and\nProximal Policy Optimization (PPO). However, due to variations in datasets,\nbase model types, and alignment methods, it remains unclear which specific\nelements contribute most significantly to the reported improvements in these\nworks. In this paper, we independently analyze each aspect of preference\nalignment in MLLMs. We start by categorizing the alignment algorithms into two\ngroups, offline (such as DPO), and online (such as online-DPO), and show that\ncombining offline and online methods can improve the performance of the model\nin certain scenarios. We review a variety of published multimodal preference\ndatasets and discuss how the details of their construction impact model\nperformance. Based on these insights, we introduce a novel way of creating\nmultimodal preference data called Bias-Driven Hallucination Sampling (BDHS)\nthat needs neither additional annotation nor external models, and show that it\ncan achieve competitive performance to previously published alignment work for\nmultimodal models across a range of benchmarks.",
            "upvotes": 3
        },
        "publishedAt": "2024-07-03T12:24:44.852Z",
        "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02477.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/8fa8511baf2d9bd95d3ba4535a5b3d69.svg",
            "fullname": "Jean-Philippe Fauconnier",
            "name": "j4kn",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.01920",
            "authors": [
                {
                    "_id": "6685059fdee2fc81210a28f6",
                    "user": {
                        "avatarUrl": "/avatars/7e9df47dd4e3cb6df193878e561cc2bc.svg",
                        "isPro": false,
                        "fullname": "Bozhong Tian",
                        "user": "bozhong",
                        "type": "user"
                    },
                    "name": "Bozhong Tian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T14:59:34.439Z",
                    "hidden": false
                },
                {
                    "_id": "6685059fdee2fc81210a28f7",
                    "user": {
                        "avatarUrl": "/avatars/1b81081c568271fe20d45130e271d0c4.svg",
                        "isPro": false,
                        "fullname": "Xiaozhuan Liang",
                        "user": "liangxz",
                        "type": "user"
                    },
                    "name": "Xiaozhuan Liang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T14:59:42.079Z",
                    "hidden": false
                },
                {
                    "_id": "6685059fdee2fc81210a28f8",
                    "user": {
                        "avatarUrl": "/avatars/30657bc50c660e256743c495f776d1c5.svg",
                        "isPro": false,
                        "fullname": "Siyuan Cheng",
                        "user": "ChancesYuan",
                        "type": "user"
                    },
                    "name": "Siyuan Cheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T14:59:48.395Z",
                    "hidden": false
                },
                {
                    "_id": "6685059fdee2fc81210a28f9",
                    "name": "Qingbin Liu",
                    "hidden": false
                },
                {
                    "_id": "6685059fdee2fc81210a28fa",
                    "user": {
                        "avatarUrl": "/avatars/da77c856ec997e2b812c06272a01c8b2.svg",
                        "isPro": false,
                        "fullname": "mengruwang",
                        "user": "mengru",
                        "type": "user"
                    },
                    "name": "Mengru Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:00:06.315Z",
                    "hidden": false
                },
                {
                    "_id": "6685059fdee2fc81210a28fb",
                    "user": {
                        "avatarUrl": "/avatars/93b11c28a58c5db71afd44e782493140.svg",
                        "isPro": false,
                        "fullname": "Dianbo Sui",
                        "user": "suidianbo",
                        "type": "user"
                    },
                    "name": "Dianbo Sui",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:00:13.444Z",
                    "hidden": false
                },
                {
                    "_id": "6685059fdee2fc81210a28fc",
                    "name": "Xi Chen",
                    "hidden": false
                },
                {
                    "_id": "6685059fdee2fc81210a28fd",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64931296137833d7ec7689cd/TBihNdp1ZwIWjhfAWjRr6.jpeg",
                        "isPro": false,
                        "fullname": "Huajun Chen",
                        "user": "huajunsir",
                        "type": "user"
                    },
                    "name": "Huajun Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-03T15:00:28.191Z",
                    "hidden": false
                },
                {
                    "_id": "6685059fdee2fc81210a28fe",
                    "user": {
                        "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
                        "isPro": false,
                        "fullname": "Ningyu Zhang",
                        "user": "Ningyu",
                        "type": "user"
                    },
                    "name": "Ningyu Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-03T13:44:50.301Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T03:34:16.000Z",
            "title": "To Forget or Not? Towards Practical Knowledge Unlearning for Large\n  Language Models",
            "summary": "Large Language Models (LLMs) trained on extensive corpora inevitably retain\nsensitive data, such as personal privacy information and copyrighted material.\nRecent advancements in knowledge unlearning involve updating LLM parameters to\nerase specific knowledge. However, current unlearning paradigms are mired in\nvague forgetting boundaries, often erasing knowledge indiscriminately. In this\nwork, we introduce KnowUnDo, a benchmark containing copyrighted content and\nuser privacy domains to evaluate if the unlearning process inadvertently erases\nessential knowledge. Our findings indicate that existing unlearning methods\noften suffer from excessive unlearning. To address this, we propose a simple\nyet effective method, MemFlex, which utilizes gradient information to precisely\ntarget and unlearn sensitive parameters. Experimental results show that MemFlex\nis superior to existing methods in both precise knowledge unlearning and\ngeneral knowledge retaining of LLMs. Code and dataset will be released at\nhttps://github.com/zjunlp/KnowUnDo.",
            "upvotes": 3
        },
        "publishedAt": "2024-07-03T11:29:49.517Z",
        "title": "To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/PkAEUY_OYGedBykaAXeVe.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.01920.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
            "fullname": "Ningyu Zhang",
            "name": "Ningyu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02489",
            "authors": [
                {
                    "_id": "66857aa5ef8d151431928941",
                    "name": "Nataniel Ruiz",
                    "hidden": false
                },
                {
                    "_id": "66857aa5ef8d151431928942",
                    "name": "Yuanzhen Li",
                    "hidden": false
                },
                {
                    "_id": "66857aa5ef8d151431928943",
                    "name": "Neal Wadhwa",
                    "hidden": false
                },
                {
                    "_id": "66857aa5ef8d151431928944",
                    "name": "Yael Pritch",
                    "hidden": false
                },
                {
                    "_id": "66857aa5ef8d151431928945",
                    "name": "Michael Rubinstein",
                    "hidden": false
                },
                {
                    "_id": "66857aa5ef8d151431928946",
                    "name": "David E. Jacobs",
                    "hidden": false
                },
                {
                    "_id": "66857aa5ef8d151431928947",
                    "name": "Shlomi Fruchter",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T17:59:50.000Z",
            "title": "Magic Insert: Style-Aware Drag-and-Drop",
            "summary": "We present Magic Insert, a method for dragging-and-dropping subjects from a\nuser-provided image into a target image of a different style in a physically\nplausible manner while matching the style of the target image. This work\nformalizes the problem of style-aware drag-and-drop and presents a method for\ntackling it by addressing two sub-problems: style-aware personalization and\nrealistic object insertion in stylized images. For style-aware personalization,\nour method first fine-tunes a pretrained text-to-image diffusion model using\nLoRA and learned text tokens on the subject image, and then infuses it with a\nCLIP representation of the target style. For object insertion, we use\nBootstrapped Domain Adaption to adapt a domain-specific photorealistic object\ninsertion model to the domain of diverse artistic styles. Overall, the method\nsignificantly outperforms traditional approaches such as inpainting. Finally,\nwe present a dataset, SubjectPlop, to facilitate evaluation and future progress\nin this area. Project page: https://magicinsert.github.io/",
            "upvotes": 1
        },
        "publishedAt": "2024-07-03T15:03:12.631Z",
        "title": "Magic Insert: Style-Aware Drag-and-Drop",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6318c6e6cb116eab31d70a16/xE_lpX43-VXFQGEVuryGA.png",
            "https://cdn-uploads.huggingface.co/production/uploads/6318c6e6cb116eab31d70a16/tVGscd94X6LQIaTiVhjWe.png",
            "https://cdn-uploads.huggingface.co/production/uploads/6318c6e6cb116eab31d70a16/AoivRMG68wWOvEehv1_BC.qt"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02489.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6318c6e6cb116eab31d70a16/yAw5XtvqaPUkPj2B6JOzz.jpeg",
            "fullname": "Nataniel",
            "name": "flavoredquark",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]