[
  {
    "paper": {
      "id": "2501.08313",
      "authors": [
        {
          "_id": "67871e6ef492fb2235af8978",
          "name": "MiniMax",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8979",
          "name": "Aonian Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af897a",
          "name": "Bangwei Gong",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af897b",
          "name": "Bo Yang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af897c",
          "name": "Boji Shan",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af897d",
          "name": "Chang Liu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af897e",
          "name": "Cheng Zhu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af897f",
          "name": "Chunhao Zhang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8980",
          "name": "Congchao Guo",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8981",
          "name": "Da Chen",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8982",
          "name": "Dong Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8983",
          "name": "Enwei Jiao",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8984",
          "name": "Gengxin Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8985",
          "name": "Guojun Zhang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8986",
          "name": "Haohai Sun",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8987",
          "name": "Houze Dong",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8988",
          "name": "Jiadai Zhu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8989",
          "name": "Jiaqi Zhuang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af898a",
          "name": "Jiayuan Song",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af898b",
          "name": "Jin Zhu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af898c",
          "name": "Jingtao Han",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af898d",
          "name": "Jingyang Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af898e",
          "name": "Junbin Xie",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af898f",
          "name": "Junhao Xu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8990",
          "name": "Junjie Yan",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8991",
          "name": "Kaishun Zhang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8992",
          "name": "Kecheng Xiao",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8993",
          "name": "Kexi Kang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8994",
          "name": "Le Han",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8995",
          "name": "Leyang Wang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8996",
          "name": "Lianfei Yu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8997",
          "name": "Liheng Feng",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8998",
          "name": "Lin Zheng",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af8999",
          "name": "Linbo Chai",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af899a",
          "name": "Long Xing",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af899b",
          "name": "Meizhi Ju",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af899c",
          "name": "Mingyuan Chi",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af899d",
          "name": "Mozhi Zhang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af899e",
          "name": "Peikai Huang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af899f",
          "name": "Pengcheng Niu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a0",
          "name": "Pengfei Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a1",
          "name": "Pengyu Zhao",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a2",
          "name": "Qi Yang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a3",
          "name": "Qidi Xu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a4",
          "name": "Qiexiang Wang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a5",
          "name": "Qin Wang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a6",
          "name": "Qiuhui Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a7",
          "name": "Ruitao Leng",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a8",
          "name": "Shengmin Shi",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89a9",
          "name": "Shuqi Yu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89aa",
          "name": "Sichen Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89ab",
          "name": "Songquan Zhu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89ac",
          "name": "Tao Huang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89ad",
          "name": "Tianrun Liang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89ae",
          "name": "Weigao Sun",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89af",
          "name": "Weixuan Sun",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b0",
          "name": "Weiyu Cheng",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b1",
          "name": "Wenkai Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b2",
          "name": "Xiangjun Song",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b3",
          "name": "Xiao Su",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b4",
          "name": "Xiaodong Han",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b5",
          "name": "Xinjie Zhang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b6",
          "name": "Xinzhu Hou",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b7",
          "name": "Xu Min",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b8",
          "name": "Xun Zou",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89b9",
          "name": "Xuyang Shen",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89ba",
          "name": "Yan Gong",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89bb",
          "name": "Yingjie Zhu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89bc",
          "name": "Yipeng Zhou",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89bd",
          "name": "Yiran Zhong",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89be",
          "name": "Yongyi Hu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89bf",
          "name": "Yuanxiang Fan",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c0",
          "name": "Yue Yu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c1",
          "name": "Yufeng Yang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c2",
          "name": "Yuhao Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c3",
          "name": "Yunan Huang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c4",
          "name": "Yunji Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c5",
          "name": "Yunpeng Huang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c6",
          "name": "Yunzhi Xu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c7",
          "name": "Yuxin Mao",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c8",
          "name": "Zehan Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89c9",
          "name": "Zekang Li",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89ca",
          "name": "Zewei Tao",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89cb",
          "name": "Zewen Ying",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89cc",
          "name": "Zhaoyang Cong",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89cd",
          "name": "Zhen Qin",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89ce",
          "name": "Zhenhua Fan",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89cf",
          "name": "Zhihang Yu",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89d0",
          "name": "Zhuo Jiang",
          "hidden": false
        },
        {
          "_id": "67871e6ef492fb2235af89d1",
          "name": "Zijia Wu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T18:50:05.000Z",
      "title": "MiniMax-01: Scaling Foundation Models with Lightning Attention",
      "summary": "We introduce MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01,\nwhich are comparable to top-tier models while offering superior capabilities in\nprocessing longer contexts. The core lies in lightning attention and its\nefficient scaling. To maximize computational capacity, we integrate it with\nMixture of Experts (MoE), creating a model with 32 experts and 456 billion\ntotal parameters, of which 45.9 billion are activated for each token. We\ndevelop an optimized parallel strategy and highly efficient\ncomputation-communication overlap techniques for MoE and lightning attention.\nThis approach enables us to conduct efficient training and inference on models\nwith hundreds of billions of parameters across contexts spanning millions of\ntokens. The context window of MiniMax-Text-01 can reach up to 1 million tokens\nduring training and extrapolate to 4 million tokens during inference at an\naffordable cost. Our vision-language model, MiniMax-VL-01 is built through\ncontinued training with 512 billion vision-language tokens. Experiments on both\nstandard and in-house benchmarks show that our models match the performance of\nstate-of-the-art models like GPT-4o and Claude-3.5-Sonnet while offering 20-32\ntimes longer context window. We publicly release MiniMax-01 at\nhttps://github.com/MiniMax-AI.",
      "upvotes": 130,
      "discussionId": "67871e6ff492fb2235af8a6a"
    },
    "publishedAt": "2025-01-14T21:48:31.318Z",
    "title": "MiniMax-01: Scaling Foundation Models with Lightning Attention",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08313.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642e4d4d6748dd4f8eeb7732",
      "avatarUrl": "/avatars/fd911e9143d1a7aedd21a7d611543fcc.svg",
      "fullname": "Xuyang Shen",
      "name": "Ryan1122",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.08187",
      "authors": [
        {
          "_id": "67871cb6ce7f3eb12692b222",
          "name": "Yin Fang",
          "hidden": false
        },
        {
          "_id": "67871cb6ce7f3eb12692b223",
          "name": "Xinle Deng",
          "hidden": false
        },
        {
          "_id": "67871cb6ce7f3eb12692b224",
          "name": "Kangwei Liu",
          "hidden": false
        },
        {
          "_id": "67871cb6ce7f3eb12692b225",
          "name": "Ningyu Zhang",
          "hidden": false
        },
        {
          "_id": "67871cb6ce7f3eb12692b226",
          "name": "Jingyang Qian",
          "hidden": false
        },
        {
          "_id": "67871cb6ce7f3eb12692b227",
          "name": "Penghui Yang",
          "hidden": false
        },
        {
          "_id": "67871cb6ce7f3eb12692b228",
          "name": "Xiaohui Fan",
          "hidden": false
        },
        {
          "_id": "67871cb6ce7f3eb12692b229",
          "name": "Huajun Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T15:12:19.000Z",
      "title": "A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction\n  Following",
      "summary": "Large language models excel at interpreting complex natural language\ninstructions, enabling them to perform a wide range of tasks. In the life\nsciences, single-cell RNA sequencing (scRNA-seq) data serves as the \"language\nof cellular biology\", capturing intricate gene expression patterns at the\nsingle-cell level. However, interacting with this \"language\" through\nconventional tools is often inefficient and unintuitive, posing challenges for\nresearchers. To address these limitations, we present InstructCell, a\nmulti-modal AI copilot that leverages natural language as a medium for more\ndirect and flexible single-cell analysis. We construct a comprehensive\nmulti-modal instruction dataset that pairs text-based instructions with\nscRNA-seq profiles from diverse tissues and species. Building on this, we\ndevelop a multi-modal cell language architecture capable of simultaneously\ninterpreting and processing both modalities. InstructCell empowers researchers\nto accomplish critical tasks-such as cell type annotation, conditional\npseudo-cell generation, and drug sensitivity prediction-using straightforward\nnatural language commands. Extensive evaluations demonstrate that InstructCell\nconsistently meets or exceeds the performance of existing single-cell\nfoundation models, while adapting to diverse experimental conditions. More\nimportantly, InstructCell provides an accessible and intuitive tool for\nexploring complex single-cell data, lowering technical barriers and enabling\ndeeper biological insights.",
      "upvotes": 14,
      "discussionId": "67871cbcce7f3eb12692b37e"
    },
    "publishedAt": "2025-01-14T21:58:03.573Z",
    "title": "A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/620b3bbb0668e435407c8d0a/Y3Br4s8MMP0E14TrwYF7E.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08187.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "620b3bbb0668e435407c8d0a",
      "avatarUrl": "/avatars/e0fccbb2577d76088e09f054c35cffbc.svg",
      "fullname": "Ningyu Zhang",
      "name": "Ningyu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 15
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.08332",
      "authors": [
        {
          "_id": "678727aadd2e5dbecdf08fe3",
          "name": "Zhiheng Liu",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08fe4",
          "name": "Ka Leong Cheng",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08fe5",
          "name": "Xi Chen",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08fe6",
          "name": "Jie Xiao",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08fe7",
          "name": "Hao Ouyang",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08fe8",
          "name": "Kai Zhu",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08fe9",
          "name": "Yu Liu",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08fea",
          "name": "Yujun Shen",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08feb",
          "name": "Qifeng Chen",
          "hidden": false
        },
        {
          "_id": "678727aadd2e5dbecdf08fec",
          "name": "Ping Luo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T18:59:55.000Z",
      "title": "MangaNinja: Line Art Colorization with Precise Reference Following",
      "summary": "Derived from diffusion models, MangaNinjia specializes in the task of\nreference-guided line art colorization. We incorporate two thoughtful designs\nto ensure precise character detail transcription, including a patch shuffling\nmodule to facilitate correspondence learning between the reference color image\nand the target line art, and a point-driven control scheme to enable\nfine-grained color matching. Experiments on a self-collected benchmark\ndemonstrate the superiority of our model over current solutions in terms of\nprecise colorization. We further showcase the potential of the proposed\ninteractive point control in handling challenging cases, cross-character\ncolorization, multi-reference harmonization, beyond the reach of existing\nalgorithms.",
      "upvotes": 12,
      "discussionId": "678727acdd2e5dbecdf09097"
    },
    "publishedAt": "2025-01-14T22:13:07.257Z",
    "title": "MangaNinja: Line Art Colorization with Precise Reference Following",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08332.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6479925ab77e18dbf640bd67",
      "avatarUrl": "/avatars/bb52ecd22ca4b49157f8668be35409e7.svg",
      "fullname": "Zhiheng Liu",
      "name": "Johanan0528",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.08316",
      "authors": [
        {
          "_id": "678725b38c1e7b6c4a69f88a",
          "name": "Shanchuan Lin",
          "hidden": false
        },
        {
          "_id": "678725b38c1e7b6c4a69f88b",
          "name": "Xin Xia",
          "hidden": false
        },
        {
          "_id": "678725b38c1e7b6c4a69f88c",
          "name": "Yuxi Ren",
          "hidden": false
        },
        {
          "_id": "678725b38c1e7b6c4a69f88d",
          "name": "Ceyuan Yang",
          "hidden": false
        },
        {
          "_id": "678725b38c1e7b6c4a69f88e",
          "name": "Xuefeng Xiao",
          "hidden": false
        },
        {
          "_id": "678725b38c1e7b6c4a69f88f",
          "name": "Lu Jiang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T18:51:48.000Z",
      "title": "Diffusion Adversarial Post-Training for One-Step Video Generation",
      "summary": "The diffusion models are widely used for image and video generation, but\ntheir iterative generation process is slow and expansive. While existing\ndistillation approaches have demonstrated the potential for one-step generation\nin the image domain, they still suffer from significant quality degradation. In\nthis work, we propose Adversarial Post-Training (APT) against real data\nfollowing diffusion pre-training for one-step video generation. To improve the\ntraining stability and quality, we introduce several improvements to the model\narchitecture and training procedures, along with an approximated R1\nregularization objective. Empirically, our experiments show that our\nadversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720,\n24fps videos in real time using a single forward evaluation step. Additionally,\nour model is capable of generating 1024px images in a single step, achieving\nquality comparable to state-of-the-art methods.",
      "upvotes": 8,
      "discussionId": "678725b68c1e7b6c4a69f911"
    },
    "publishedAt": "2025-01-14T22:04:35.473Z",
    "title": "Diffusion Adversarial Post-Training for One-Step Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08316.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5650
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.07730",
      "authors": [
        {
          "_id": "678734168c1e7b6c4a6e5ff9",
          "name": "Dongwon Kim",
          "hidden": false
        },
        {
          "_id": "678734168c1e7b6c4a6e5ffa",
          "name": "Ju He",
          "hidden": false
        },
        {
          "_id": "678734168c1e7b6c4a6e5ffb",
          "name": "Qihang Yu",
          "hidden": false
        },
        {
          "_id": "678734168c1e7b6c4a6e5ffc",
          "name": "Chenglin Yang",
          "hidden": false
        },
        {
          "_id": "678734168c1e7b6c4a6e5ffd",
          "name": "Xiaohui Shen",
          "hidden": false
        },
        {
          "_id": "678734168c1e7b6c4a6e5ffe",
          "name": "Suha Kwak",
          "hidden": false
        },
        {
          "_id": "678734168c1e7b6c4a6e5fff",
          "name": "Liang-Chieh Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-13T22:37:17.000Z",
      "title": "Democratizing Text-to-Image Masked Generative Models with Compact\n  Text-Aware One-Dimensional Tokens",
      "summary": "Image tokenizers form the foundation of modern text-to-image generative\nmodels but are notoriously difficult to train. Furthermore, most existing\ntext-to-image models rely on large-scale, high-quality private datasets, making\nthem challenging to replicate. In this work, we introduce Text-Aware\nTransformer-based 1-Dimensional Tokenizer (TA-TiTok), an efficient and powerful\nimage tokenizer that can utilize either discrete or continuous 1-dimensional\ntokens. TA-TiTok uniquely integrates textual information during the tokenizer\ndecoding stage (i.e., de-tokenization), accelerating convergence and enhancing\nperformance. TA-TiTok also benefits from a simplified, yet effective, one-stage\ntraining process, eliminating the need for the complex two-stage distillation\nused in previous 1-dimensional tokenizers. This design allows for seamless\nscalability to large datasets. Building on this, we introduce a family of\ntext-to-image Masked Generative Models (MaskGen), trained exclusively on open\ndata while achieving comparable performance to models trained on private data.\nWe aim to release both the efficient, strong TA-TiTok tokenizers and the\nopen-data, open-weight MaskGen models to promote broader access and democratize\nthe field of text-to-image masked generative models.",
      "upvotes": 4,
      "discussionId": "678734178c1e7b6c4a6e6071"
    },
    "publishedAt": "2025-01-14T23:11:25.137Z",
    "title": "Democratizing Text-to-Image Masked Generative Models with Compact Text-Aware One-Dimensional Tokens",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/661c9059bcd78151e5c06ea1/-7KLvUVPYbrrljt6Nx6iS.png",
      "https://cdn-uploads.huggingface.co/production/uploads/661c9059bcd78151e5c06ea1/SH9x-3yrSYBXH9Nkn9uNy.png",
      "https://cdn-uploads.huggingface.co/production/uploads/661c9059bcd78151e5c06ea1/ITR8a3J2vHuYGmCWfX-xS.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07730.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "661c9059bcd78151e5c06ea1",
      "avatarUrl": "/avatars/308745629823adedc6dfcade934ae143.svg",
      "fullname": "Ju He",
      "name": "turkeyju",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.08225",
      "authors": [
        {
          "_id": "67872d3659aa2a284c52ad5f",
          "name": "Yabo Zhang",
          "hidden": false
        },
        {
          "_id": "67872d3659aa2a284c52ad60",
          "name": "Xinpeng Zhou",
          "hidden": false
        },
        {
          "_id": "67872d3659aa2a284c52ad61",
          "name": "Yihan Zeng",
          "hidden": false
        },
        {
          "_id": "67872d3659aa2a284c52ad62",
          "name": "Hang Xu",
          "hidden": false
        },
        {
          "_id": "67872d3659aa2a284c52ad63",
          "name": "Hui Li",
          "hidden": false
        },
        {
          "_id": "67872d3659aa2a284c52ad64",
          "name": "Wangmeng Zuo",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T16:09:16.000Z",
      "title": "FramePainter: Endowing Interactive Image Editing with Video Diffusion\n  Priors",
      "summary": "Interactive image editing allows users to modify images through visual\ninteraction operations such as drawing, clicking, and dragging. Existing\nmethods construct such supervision signals from videos, as they capture how\nobjects change with various physical interactions. However, these models are\nusually built upon text-to-image diffusion models, so necessitate (i) massive\ntraining samples and (ii) an additional reference encoder to learn real-world\ndynamics and visual consistency. In this paper, we reformulate this task as an\nimage-to-video generation problem, so that inherit powerful video diffusion\npriors to reduce training costs and ensure temporal consistency. Specifically,\nwe introduce FramePainter as an efficient instantiation of this formulation.\nInitialized with Stable Video Diffusion, it only uses a lightweight sparse\ncontrol encoder to inject editing signals. Considering the limitations of\ntemporal attention in handling large motion between two frames, we further\npropose matching attention to enlarge the receptive field while encouraging\ndense correspondence between edited and source image tokens. We highlight the\neffectiveness and efficiency of FramePainter across various of editing signals:\nit domainantly outperforms previous state-of-the-art methods with far less\ntraining data, achieving highly seamless and coherent editing of images, \\eg,\nautomatically adjust the reflection of the cup. Moreover, FramePainter also\nexhibits exceptional generalization in scenarios not present in real-world\nvideos, \\eg, transform the clownfish into shark-like shape. Our code will be\navailable at https://github.com/YBYBZhang/FramePainter.",
      "upvotes": 3,
      "discussionId": "67872d3a59aa2a284c52aed0"
    },
    "publishedAt": "2025-01-14T22:36:58.221Z",
    "title": "FramePainter: Endowing Interactive Image Editing with Video Diffusion Priors",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08225.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62cd752ba9be5c19555c2b4c",
      "avatarUrl": "/avatars/ed72684f0f2139516ccde24cd467cea6.svg",
      "fullname": "YaboZhang",
      "name": "Yabo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.08328",
      "authors": [
        {
          "_id": "6787367e42691fc7dc545292",
          "name": "Richard Zhuang",
          "hidden": false
        },
        {
          "_id": "6787367e42691fc7dc545293",
          "user": {
            "_id": "64e8f4a24f3f7b0b84834315",
            "avatarUrl": "/avatars/242bb68c7ccffe5061c2d1c229ea3b0b.svg",
            "isPro": false,
            "fullname": "Akshat Gupta",
            "user": "akshat57",
            "type": "user"
          },
          "name": "Akshat Gupta",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-01-15T04:19:21.989Z",
          "hidden": false
        },
        {
          "_id": "6787367e42691fc7dc545294",
          "name": "Richard Yang",
          "hidden": false
        },
        {
          "_id": "6787367e42691fc7dc545295",
          "name": "Aniket Rahane",
          "hidden": false
        },
        {
          "_id": "6787367e42691fc7dc545296",
          "name": "Zhengyu Li",
          "hidden": false
        },
        {
          "_id": "6787367e42691fc7dc545297",
          "name": "Gopala Anumanchipalli",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T18:59:03.000Z",
      "title": "PokerBench: Training Large Language Models to become Professional Poker\n  Players",
      "summary": "We introduce PokerBench - a benchmark for evaluating the poker-playing\nabilities of large language models (LLMs). As LLMs excel in traditional NLP\ntasks, their application to complex, strategic games like poker poses a new\nchallenge. Poker, an incomplete information game, demands a multitude of skills\nsuch as mathematics, reasoning, planning, strategy, and a deep understanding of\ngame theory and human psychology. This makes Poker the ideal next frontier for\nlarge language models. PokerBench consists of a comprehensive compilation of\n11,000 most important scenarios, split between pre-flop and post-flop play,\ndeveloped in collaboration with trained poker players. We evaluate prominent\nmodels including GPT-4, ChatGPT 3.5, and various Llama and Gemma series models,\nfinding that all state-of-the-art LLMs underperform in playing optimal poker.\nHowever, after fine-tuning, these models show marked improvements. We validate\nPokerBench by having models with different scores compete with each other,\ndemonstrating that higher scores on PokerBench lead to higher win rates in\nactual poker games. Through gameplay between our fine-tuned model and GPT-4, we\nalso identify limitations of simple supervised fine-tuning for learning optimal\nplaying strategy, suggesting the need for more advanced methodologies for\neffectively training language models to excel in games. PokerBench thus\npresents a unique benchmark for a quick and reliable evaluation of the\npoker-playing ability of LLMs as well as a comprehensive benchmark to study the\nprogress of LLMs in complex game-playing scenarios. The dataset and code will\nbe made available at: https://github.com/pokerllm/pokerbench.",
      "upvotes": 2,
      "discussionId": "6787368042691fc7dc5452dd"
    },
    "publishedAt": "2025-01-14T23:17:00.915Z",
    "title": "PokerBench: Training Large Language Models to become Professional Poker Players",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08328.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64e8f4a24f3f7b0b84834315",
      "avatarUrl": "/avatars/242bb68c7ccffe5061c2d1c229ea3b0b.svg",
      "fullname": "Akshat Gupta",
      "name": "akshat57",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.08167",
      "authors": [
        {
          "_id": "678748ee95b9364769858656",
          "name": "Rewina Bedemariam",
          "hidden": false
        },
        {
          "_id": "678748ee95b9364769858657",
          "name": "Natalie Perez",
          "hidden": false
        },
        {
          "_id": "678748ee95b9364769858658",
          "name": "Sreyoshi Bhaduri",
          "hidden": false
        },
        {
          "_id": "678748ee95b9364769858659",
          "name": "Satya Kapoor",
          "hidden": false
        },
        {
          "_id": "678748ee95b936476985865a",
          "name": "Alex Gil",
          "hidden": false
        },
        {
          "_id": "678748ee95b936476985865b",
          "name": "Elizabeth Conjar",
          "hidden": false
        },
        {
          "_id": "678748ee95b936476985865c",
          "name": "Ikkei Itoku",
          "hidden": false
        },
        {
          "_id": "678748ee95b936476985865d",
          "name": "David Theil",
          "hidden": false
        },
        {
          "_id": "678748ee95b936476985865e",
          "name": "Aman Chadha",
          "hidden": false
        },
        {
          "_id": "678748ee95b936476985865f",
          "name": "Naumaan Nayyar",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T14:49:14.000Z",
      "title": "Potential and Perils of Large Language Models as Judges of Unstructured\n  Textual Data",
      "summary": "Rapid advancements in large language models have unlocked remarkable\ncapabilities when it comes to processing and summarizing unstructured text\ndata. This has implications for the analysis of rich, open-ended datasets, such\nas survey responses, where LLMs hold the promise of efficiently distilling key\nthemes and sentiments. However, as organizations increasingly turn to these\npowerful AI systems to make sense of textual feedback, a critical question\narises, can we trust LLMs to accurately represent the perspectives contained\nwithin these text based datasets? While LLMs excel at generating human-like\nsummaries, there is a risk that their outputs may inadvertently diverge from\nthe true substance of the original responses. Discrepancies between the\nLLM-generated outputs and the actual themes present in the data could lead to\nflawed decision-making, with far-reaching consequences for organizations. This\nresearch investigates the effectiveness of LLMs as judge models to evaluate the\nthematic alignment of summaries generated by other LLMs. We utilized an\nAnthropic Claude model to generate thematic summaries from open-ended survey\nresponses, with Amazon's Titan Express, Nova Pro, and Meta's Llama serving as\nLLM judges. The LLM-as-judge approach was compared to human evaluations using\nCohen's kappa, Spearman's rho, and Krippendorff's alpha, validating a scalable\nalternative to traditional human centric evaluation methods. Our findings\nreveal that while LLMs as judges offer a scalable solution comparable to human\nraters, humans may still excel at detecting subtle, context-specific nuances.\nThis research contributes to the growing body of knowledge on AI assisted text\nanalysis. We discuss limitations and provide recommendations for future\nresearch, emphasizing the need for careful consideration when generalizing LLM\njudge models across various contexts and use cases.",
      "upvotes": 1,
      "discussionId": "678748ee95b9364769858684"
    },
    "publishedAt": "2025-01-15T00:40:26.270Z",
    "title": "Potential and Perils of Large Language Models as Judges of Unstructured Textual Data",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08167.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "63a4754927f1f64ed7238dac",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
      "fullname": "Aman Chadha",
      "name": "amanchadha",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.08292",
      "authors": [
        {
          "_id": "678731bbe24feaaa753768b5",
          "name": "Abhilasha Ravichander",
          "hidden": false
        },
        {
          "_id": "678731bbe24feaaa753768b6",
          "name": "Shrusti Ghela",
          "hidden": false
        },
        {
          "_id": "678731bbe24feaaa753768b7",
          "name": "David Wadden",
          "hidden": false
        },
        {
          "_id": "678731bbe24feaaa753768b8",
          "name": "Yejin Choi",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T18:13:08.000Z",
      "title": "HALoGEN: Fantastic LLM Hallucinations and Where to Find Them",
      "summary": "Despite their impressive ability to generate high-quality and fluent text,\ngenerative large language models (LLMs) also produce hallucinations: statements\nthat are misaligned with established world knowledge or provided input context.\nHowever, measuring hallucination can be challenging, as having humans verify\nmodel generations on-the-fly is both expensive and time-consuming. In this\nwork, we release HALoGEN, a comprehensive hallucination benchmark consisting\nof: (1) 10,923 prompts for generative models spanning nine domains including\nprogramming, scientific attribution, and summarization, and (2) automatic\nhigh-precision verifiers for each use case that decompose LLM generations into\natomic units, and verify each unit against a high-quality knowledge source. We\nuse this framework to evaluate ~150,000 generations from 14 language models,\nfinding that even the best-performing models are riddled with hallucinations\n(sometimes up to 86% of generated atomic facts depending on the domain). We\nfurther define a novel error classification for LLM hallucinations based on\nwhether they likely stem from incorrect recollection of training data (Type A\nerrors), or incorrect knowledge in training data (Type B errors), or are\nfabrication (Type C errors). We hope our framework provides a foundation to\nenable the principled study of why generative models hallucinate, and advances\nthe development of trustworthy large language models.",
      "upvotes": 1,
      "discussionId": "678731bde24feaaa7537695b"
    },
    "publishedAt": "2025-01-14T23:01:53.467Z",
    "title": "HALoGEN: Fantastic LLM Hallucinations and Where to Find Them",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08292.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "645dbaa6f5760d1530d7580d",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
      "fullname": "Simeon Emanuilov",
      "name": "s-emanuilov",
      "type": "user",
      "isPro": true,
      "isHf": false,
      "isMod": false,
      "followerCount": 14
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.07888",
      "authors": [
        {
          "_id": "67873cdd1f65db189f9f64d7",
          "name": "Liping Yuan",
          "hidden": false
        },
        {
          "_id": "67873cdd1f65db189f9f64d8",
          "name": "Jiawei Wang",
          "hidden": false
        },
        {
          "_id": "67873cdd1f65db189f9f64d9",
          "name": "Haomiao Sun",
          "hidden": false
        },
        {
          "_id": "67873cdd1f65db189f9f64da",
          "name": "Yuchen Zhang",
          "hidden": false
        },
        {
          "_id": "67873cdd1f65db189f9f64db",
          "name": "Yuan Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-14T06:54:39.000Z",
      "title": "Tarsier2: Advancing Large Vision-Language Models from Detailed Video\n  Description to Comprehensive Video Understanding",
      "summary": "We introduce Tarsier2, a state-of-the-art large vision-language model (LVLM)\ndesigned for generating detailed and accurate video descriptions, while also\nexhibiting superior general video understanding capabilities. Tarsier2 achieves\nsignificant advancements through three key upgrades: (1) Scaling pre-training\ndata from 11M to 40M video-text pairs, enriching both volume and diversity; (2)\nPerforming fine-grained temporal alignment during supervised fine-tuning; (3)\nUsing model-based sampling to automatically construct preference data and\napplying DPO training for optimization. Extensive experiments show that\nTarsier2-7B consistently outperforms leading proprietary models, including\nGPT-4o and Gemini 1.5 Pro, in detailed video description tasks. On the DREAM-1K\nbenchmark, Tarsier2-7B improves F1 by 2.8\\% over GPT-4o and 5.8\\% over\nGemini-1.5-Pro. In human side-by-side evaluations, Tarsier2-7B shows a +8.6\\%\nperformance advantage over GPT-4o and +24.9\\% over Gemini-1.5-Pro. Tarsier2-7B\nalso sets new state-of-the-art results across 15 public benchmarks, spanning\ntasks such as video question-answering, video grounding, hallucination test,\nand embodied question-answering, demonstrating its versatility as a robust\ngeneralist vision-language model.",
      "upvotes": 0,
      "discussionId": "67873ce11f65db189f9f6615"
    },
    "publishedAt": "2025-01-14T23:43:33.935Z",
    "title": "Tarsier2: Advancing Large Vision-Language Models from Detailed Video Description to Comprehensive Video Understanding",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07888.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5650
    },
    "isAuthorParticipating": false
  }
]