[
  {
    "paper": {
      "id": "2506.11924",
      "authors": [
        {
          "_id": "684faeba60b4a34dbe007ae2",
          "name": "Min-Seop Kwak",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae3",
          "name": "Junho Kim",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae4",
          "name": "Sangdoo Yun",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae5",
          "name": "Dongyoon Han",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae6",
          "name": "Taekyoung Kim",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae7",
          "name": "Seungryong Kim",
          "hidden": false
        },
        {
          "_id": "684faeba60b4a34dbe007ae8",
          "name": "Jin-Hwa Kim",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T16:19:00.000Z",
      "submittedOnDailyAt": "2025-06-16T04:13:42.201Z",
      "title": "Aligned Novel View Image and Geometry Synthesis via Cross-modal\n  Attention Instillation",
      "submittedOnDailyBy": {
        "_id": "642673f185f26ab94af4b422",
        "avatarUrl": "/avatars/289d611e0907f02f72d4e489468e039c.svg",
        "isPro": false,
        "fullname": "Bracio",
        "user": "bracio9623",
        "type": "user"
      },
      "summary": "We introduce a diffusion-based framework that performs aligned novel view\nimage and geometry generation via a warping-and-inpainting methodology. Unlike\nprior methods that require dense posed images or pose-embedded generative\nmodels limited to in-domain views, our method leverages off-the-shelf geometry\npredictors to predict partial geometries viewed from reference images, and\nformulates novel-view synthesis as an inpainting task for both image and\ngeometry. To ensure accurate alignment between generated images and geometry,\nwe propose cross-modal attention distillation, where attention maps from the\nimage diffusion branch are injected into a parallel geometry diffusion branch\nduring both training and inference. This multi-task approach achieves\nsynergistic effects, facilitating geometrically robust image synthesis as well\nas well-defined geometry prediction. We further introduce proximity-based mesh\nconditioning to integrate depth and normal cues, interpolating between point\ncloud and filtering erroneously predicted geometry from influencing the\ngeneration process. Empirically, our method achieves high-fidelity\nextrapolative view synthesis on both image and geometry across a range of\nunseen scenes, delivers competitive reconstruction quality under interpolation\nsettings, and produces geometrically aligned colored point clouds for\ncomprehensive 3D completion. Project page is available at\nhttps://cvlab-kaist.github.io/MoAI.",
      "upvotes": 20,
      "discussionId": "684faebb60b4a34dbe007ae9",
      "projectPage": "https://cvlab-kaist.github.io/MoAI/",
      "githubRepo": "https://github.com/cvlab-kaist/MoAI",
      "ai_summary": "A diffusion-based framework generates aligned novel views of images and geometry using warping-and-inpainting with cross-modal attention distillation and proximity-based mesh conditioning, achieving high-fidelity synthesis and 3D completion.",
      "ai_keywords": [
        "diffusion-based framework",
        "warping-and-inpainting",
        "off-the-shelf geometry predictors",
        "cross-modal attention distillation",
        "proximity-based mesh conditioning",
        "novel-view synthesis",
        "multi-task approach",
        "geometrically robust image synthesis",
        "well-defined geometry prediction",
        "extrapolative view synthesis",
        "3D completion"
      ]
    },
    "publishedAt": "2025-06-13T12:19:00.000Z",
    "title": "Aligned Novel View Image and Geometry Synthesis via Cross-modal\n  Attention Instillation",
    "summary": "We introduce a diffusion-based framework that performs aligned novel view\nimage and geometry generation via a warping-and-inpainting methodology. Unlike\nprior methods that require dense posed images or pose-embedded generative\nmodels limited to in-domain views, our method leverages off-the-shelf geometry\npredictors to predict partial geometries viewed from reference images, and\nformulates novel-view synthesis as an inpainting task for both image and\ngeometry. To ensure accurate alignment between generated images and geometry,\nwe propose cross-modal attention distillation, where attention maps from the\nimage diffusion branch are injected into a parallel geometry diffusion branch\nduring both training and inference. This multi-task approach achieves\nsynergistic effects, facilitating geometrically robust image synthesis as well\nas well-defined geometry prediction. We further introduce proximity-based mesh\nconditioning to integrate depth and normal cues, interpolating between point\ncloud and filtering erroneously predicted geometry from influencing the\ngeneration process. Empirically, our method achieves high-fidelity\nextrapolative view synthesis on both image and geometry across a range of\nunseen scenes, delivers competitive reconstruction quality under interpolation\nsettings, and produces geometrically aligned colored point clouds for\ncomprehensive 3D completion. Project page is available at\nhttps://cvlab-kaist.github.io/MoAI.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11924.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "642673f185f26ab94af4b422",
      "avatarUrl": "/avatars/289d611e0907f02f72d4e489468e039c.svg",
      "fullname": "Bracio",
      "name": "bracio9623",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.10892",
      "authors": [
        {
          "_id": "684fb2f060b4a34dbe007aeb",
          "name": "Subham Sekhar Sahoo",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007aec",
          "name": "Justin Deschenaux",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007aed",
          "name": "Aaron Gokaslan",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007aee",
          "name": "Guanghan Wang",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007aef",
          "name": "Justin Chiu",
          "hidden": false
        },
        {
          "_id": "684fb2f060b4a34dbe007af0",
          "name": "Volodymyr Kuleshov",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/661839d73b412cdc851299c1/GmIlLMVIuyWjydykQPOt2.png",
        "https://cdn-uploads.huggingface.co/production/uploads/661839d73b412cdc851299c1/TjIhoD3hxygzenitTi75x.qt"
      ],
      "publishedAt": "2025-06-12T16:55:35.000Z",
      "submittedOnDailyAt": "2025-06-16T04:40:29.065Z",
      "title": "The Diffusion Duality",
      "submittedOnDailyBy": {
        "_id": "661839d73b412cdc851299c1",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/661839d73b412cdc851299c1/xicwANPQPTFdWfblisL2-.png",
        "isPro": false,
        "fullname": "Subham Sekhar Sahoo",
        "user": "s-sahoo",
        "type": "user"
      },
      "summary": "Uniform-state discrete diffusion models hold the promise of fast text\ngeneration due to their inherent ability to self-correct. However, they are\ntypically outperformed by autoregressive models and masked diffusion models. In\nthis work, we narrow this performance gap by leveraging a key insight:\nUniform-state diffusion processes naturally emerge from an underlying Gaussian\ndiffusion. Our method, Duo, transfers powerful techniques from Gaussian\ndiffusion to improve both training and sampling. First, we introduce a\ncurriculum learning strategy guided by the Gaussian process, doubling training\nspeed by reducing variance. Models trained with curriculum learning surpass\nautoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we\npresent Discrete Consistency Distillation, which adapts consistency\ndistillation from the continuous to the discrete setting. This algorithm\nunlocks few-step generation in diffusion language models by accelerating\nsampling by two orders of magnitude. We provide the code and model checkpoints\non the project page: http://s-sahoo.github.io/duo",
      "upvotes": 5,
      "discussionId": "684fb2f060b4a34dbe007af1",
      "projectPage": "https://s-sahoo.com/duo/",
      "githubRepo": "https://github.com/s-sahoo/duo",
      "ai_summary": "Duo improves uniform-state discrete diffusion models by transferring techniques from Gaussian diffusion, enhancing training speed and enabling fast few-step text generation.",
      "ai_keywords": [
        "discrete diffusion models",
        "Gaussian diffusion",
        "curriculum learning",
        "Discrete Consistency Distillation",
        "zero-shot perplexity",
        "few-step generation"
      ]
    },
    "publishedAt": "2025-06-12T12:55:35.000Z",
    "title": "The Diffusion Duality",
    "summary": "Uniform-state discrete diffusion models hold the promise of fast text\ngeneration due to their inherent ability to self-correct. However, they are\ntypically outperformed by autoregressive models and masked diffusion models. In\nthis work, we narrow this performance gap by leveraging a key insight:\nUniform-state diffusion processes naturally emerge from an underlying Gaussian\ndiffusion. Our method, Duo, transfers powerful techniques from Gaussian\ndiffusion to improve both training and sampling. First, we introduce a\ncurriculum learning strategy guided by the Gaussian process, doubling training\nspeed by reducing variance. Models trained with curriculum learning surpass\nautoregressive models in zero-shot perplexity on 3 of 7 benchmarks. Second, we\npresent Discrete Consistency Distillation, which adapts consistency\ndistillation from the continuous to the discrete setting. This algorithm\nunlocks few-step generation in diffusion language models by accelerating\nsampling by two orders of magnitude. We provide the code and model checkpoints\non the project page: http://s-sahoo.github.io/duo",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/661839d73b412cdc851299c1/GmIlLMVIuyWjydykQPOt2.png",
      "https://cdn-uploads.huggingface.co/production/uploads/661839d73b412cdc851299c1/TjIhoD3hxygzenitTi75x.qt"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.10892.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "661839d73b412cdc851299c1",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/661839d73b412cdc851299c1/xicwANPQPTFdWfblisL2-.png",
      "fullname": "Subham Sekhar Sahoo",
      "name": "s-sahoo",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.11928",
      "authors": [
        {
          "_id": "684fae8d60b4a34dbe007acd",
          "name": "Zihan Zheng",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ace",
          "name": "Zerui Cheng",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007acf",
          "name": "Zeyu Shen",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad0",
          "name": "Shang Zhou",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad1",
          "name": "Kaiyuan Liu",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad2",
          "name": "Hansen He",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad3",
          "name": "Dongruixuan Li",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad4",
          "name": "Stanley Wei",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad5",
          "name": "Hangyi Hao",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad6",
          "name": "Jianzhu Yao",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad7",
          "name": "Peiyao Sheng",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad8",
          "name": "Zixuan Wang",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ad9",
          "name": "Wenhao Chai",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ada",
          "name": "Aleksandra Korolova",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007adb",
          "name": "Peter Henderson",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007adc",
          "name": "Sanjeev Arora",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007add",
          "name": "Pramod Viswanath",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007ade",
          "name": "Jingbo Shang",
          "hidden": false
        },
        {
          "_id": "684fae8d60b4a34dbe007adf",
          "name": "Saining Xie",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T16:29:09.000Z",
      "submittedOnDailyAt": "2025-06-16T04:13:30.111Z",
      "title": "LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive\n  Programming?",
      "submittedOnDailyBy": {
        "_id": "637c7503fe115289cfecbe6b",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676361945047-637c7503fe115289cfecbe6b.jpeg",
        "isPro": false,
        "fullname": "Wenhao Chai",
        "user": "wchai",
        "type": "user"
      },
      "summary": "Recent reports claim that large language models (LLMs) now outperform elite\nhumans in competitive programming. Drawing on knowledge from a group of\nmedalists in international algorithmic contests, we revisit this claim,\nexamining how LLMs differ from human experts and where limitations still\nremain. We introduce LiveCodeBench Pro, a benchmark composed of problems from\nCodeforces, ICPC, and IOI that are continuously updated to reduce the\nlikelihood of data contamination. A team of Olympiad medalists annotates every\nproblem for algorithmic categories and conducts a line-by-line analysis of\nfailed model-generated submissions. Using this new data and benchmark, we find\nthat frontier models still have significant limitations: without external\ntools, the best model achieves only 53% pass@1 on medium-difficulty problems\nand 0% on hard problems, domains where expert humans still excel. We also find\nthat LLMs succeed at implementation-heavy problems but struggle with nuanced\nalgorithmic reasoning and complex case analysis, often generating confidently\nincorrect justifications. High performance appears largely driven by\nimplementation precision and tool augmentation, not superior reasoning.\nLiveCodeBench Pro thus highlights the significant gap to human grandmaster\nlevels, while offering fine-grained diagnostics to steer future improvements in\ncode-centric LLM reasoning.",
      "upvotes": 3,
      "discussionId": "684fae8d60b4a34dbe007ae0",
      "ai_summary": "LLMs perform well on implementation-heavy competitive programming problems but struggle with nuanced algorithmic reasoning, as highlighted by LiveCodeBench Pro.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "competitive programming",
        "LiveCodeBench Pro",
        "Codeforces",
        "ICPC",
        "IOI",
        "algorithmic categories",
        "algorithmic reasoning",
        "case analysis"
      ]
    },
    "publishedAt": "2025-06-13T12:29:09.000Z",
    "title": "LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive\n  Programming?",
    "summary": "Recent reports claim that large language models (LLMs) now outperform elite\nhumans in competitive programming. Drawing on knowledge from a group of\nmedalists in international algorithmic contests, we revisit this claim,\nexamining how LLMs differ from human experts and where limitations still\nremain. We introduce LiveCodeBench Pro, a benchmark composed of problems from\nCodeforces, ICPC, and IOI that are continuously updated to reduce the\nlikelihood of data contamination. A team of Olympiad medalists annotates every\nproblem for algorithmic categories and conducts a line-by-line analysis of\nfailed model-generated submissions. Using this new data and benchmark, we find\nthat frontier models still have significant limitations: without external\ntools, the best model achieves only 53% pass@1 on medium-difficulty problems\nand 0% on hard problems, domains where expert humans still excel. We also find\nthat LLMs succeed at implementation-heavy problems but struggle with nuanced\nalgorithmic reasoning and complex case analysis, often generating confidently\nincorrect justifications. High performance appears largely driven by\nimplementation precision and tool augmentation, not superior reasoning.\nLiveCodeBench Pro thus highlights the significant gap to human grandmaster\nlevels, while offering fine-grained diagnostics to steer future improvements in\ncode-centric LLM reasoning.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11928.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "637c7503fe115289cfecbe6b",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676361945047-637c7503fe115289cfecbe6b.jpeg",
      "fullname": "Wenhao Chai",
      "name": "wchai",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 34
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.09427",
      "authors": [
        {
          "_id": "684fa6d060b4a34dbe007aa7",
          "user": {
            "_id": "66d94f2a36aa5055694dfe04",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/grAN83brH0E4_S0__yLdv.jpeg",
            "isPro": false,
            "fullname": "fengyukang",
            "user": "finyorko",
            "type": "user"
          },
          "name": "Yukang Feng",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:48:14.381Z",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aa8",
          "name": "Jianwen Sun",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aa9",
          "user": {
            "_id": "6533f7ecb3852ed1ceb48e47",
            "avatarUrl": "/avatars/5d767c093e73f06a89f625c3a5903902.svg",
            "isPro": false,
            "fullname": "Chuanhao Li",
            "user": "cyrilli",
            "type": "user"
          },
          "name": "Chuanhao Li",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:48:30.156Z",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aaa",
          "name": "Zizhen Li",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aab",
          "name": "Jiaxin Ai",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aac",
          "user": {
            "_id": "665305eff0c8c891cae7fe01",
            "avatarUrl": "/avatars/1f372e3bc6a4eb19ef702ec96a391c96.svg",
            "isPro": false,
            "fullname": "Fanrui Zhang",
            "user": "fanrui00",
            "type": "user"
          },
          "name": "Fanrui Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:49:04.386Z",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aad",
          "name": "Yifan Chang",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aae",
          "name": "Sizhuo Zhou",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007aaf",
          "user": {
            "_id": "6674d02914e2aebef893779e",
            "avatarUrl": "/avatars/acdbe3820462b87126c8f1e14f0d1a60.svg",
            "isPro": false,
            "fullname": "ZhangShenglin",
            "user": "ZhangShenglin",
            "type": "user"
          },
          "name": "Shenglin Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:49:28.741Z",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007ab0",
          "name": "Yu Dai",
          "hidden": false
        },
        {
          "_id": "684fa6d060b4a34dbe007ab1",
          "user": {
            "_id": "63527f4e7d071f23d085ad45",
            "avatarUrl": "/avatars/99a51adef5673b3ac1a8c02eb47759c4.svg",
            "isPro": false,
            "fullname": "KAIPENG ZHANG",
            "user": "kpzhang",
            "type": "user"
          },
          "name": "Kaipeng Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-06-16T07:49:35.126Z",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/65f1713552c38a91e0a445e8/1FHKfzv4w4VzV4nhqKCJ7.png"
      ],
      "publishedAt": "2025-06-11T06:21:20.000Z",
      "submittedOnDailyAt": "2025-06-16T03:49:15.860Z",
      "title": "A High-Quality Dataset and Reliable Evaluation for Interleaved\n  Image-Text Generation",
      "submittedOnDailyBy": {
        "_id": "65f1713552c38a91e0a445e8",
        "avatarUrl": "/avatars/47ab3ada51c9b9976ac1cd0c4301c373.svg",
        "isPro": false,
        "fullname": "kaipeng",
        "user": "kpzhang996",
        "type": "user"
      },
      "summary": "Recent advancements in Large Multimodal Models (LMMs) have significantly\nimproved multimodal understanding and generation. However, these models still\nstruggle to generate tightly interleaved image-text outputs, primarily due to\nthe limited scale, quality and instructional richness of current training\ndatasets. To address this, we introduce InterSyn, a large-scale multimodal\ndataset constructed using our Self-Evaluation with Iterative Refinement (SEIR)\nmethod. InterSyn features multi-turn, instruction-driven dialogues with tightly\ninterleaved imagetext responses, providing rich object diversity and rigorous\nautomated quality refinement, making it well-suited for training\nnext-generation instruction-following LMMs. Furthermore, to address the lack of\nreliable evaluation tools capable of assessing interleaved multimodal outputs,\nwe introduce SynJudge, an automatic evaluation model designed to quantitatively\nassess multimodal outputs along four dimensions: text content, image content,\nimage quality, and image-text synergy.\n  Experimental studies show that the SEIR method leads to substantially higher\ndataset quality compared to an otherwise identical process without refinement.\n  Moreover, LMMs trained on InterSyn achieve uniform performance gains across\nall evaluation metrics, confirming InterSyn's utility for advancing multimodal\nsystems.",
      "upvotes": 3,
      "discussionId": "684fa6d060b4a34dbe007ab2",
      "ai_summary": "InterSyn, a large-scale dataset with tightly interleaved image-text outputs and automated quality refinement, improves multimodal understanding and generation through the SEIR method and SynJudge, an automatic evaluation tool.",
      "ai_keywords": [
        "Large Multimodal Models (LMMs)",
        "multimodal understanding",
        "multimodal generation",
        "Self-Evaluation with Iterative Refinement (SEIR)",
        "InterSyn",
        "image-text outputs",
        "SynJudge",
        "text content",
        "image content",
        "image quality",
        "image-text synergy"
      ]
    },
    "publishedAt": "2025-06-11T02:21:20.000Z",
    "title": "A High-Quality Dataset and Reliable Evaluation for Interleaved\n  Image-Text Generation",
    "summary": "Recent advancements in Large Multimodal Models (LMMs) have significantly\nimproved multimodal understanding and generation. However, these models still\nstruggle to generate tightly interleaved image-text outputs, primarily due to\nthe limited scale, quality and instructional richness of current training\ndatasets. To address this, we introduce InterSyn, a large-scale multimodal\ndataset constructed using our Self-Evaluation with Iterative Refinement (SEIR)\nmethod. InterSyn features multi-turn, instruction-driven dialogues with tightly\ninterleaved imagetext responses, providing rich object diversity and rigorous\nautomated quality refinement, making it well-suited for training\nnext-generation instruction-following LMMs. Furthermore, to address the lack of\nreliable evaluation tools capable of assessing interleaved multimodal outputs,\nwe introduce SynJudge, an automatic evaluation model designed to quantitatively\nassess multimodal outputs along four dimensions: text content, image content,\nimage quality, and image-text synergy.\n  Experimental studies show that the SEIR method leads to substantially higher\ndataset quality compared to an otherwise identical process without refinement.\n  Moreover, LMMs trained on InterSyn achieve uniform performance gains across\nall evaluation metrics, confirming InterSyn's utility for advancing multimodal\nsystems.",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/65f1713552c38a91e0a445e8/1FHKfzv4w4VzV4nhqKCJ7.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09427.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "65f1713552c38a91e0a445e8",
      "avatarUrl": "/avatars/47ab3ada51c9b9976ac1cd0c4301c373.svg",
      "fullname": "kaipeng",
      "name": "kpzhang996",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.09366",
      "authors": [
        {
          "_id": "684ae246dbd21a9cc27b111c",
          "user": {
            "_id": "62359088a17d7271859c88f4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1647677549197-noauth.jpeg",
            "isPro": false,
            "fullname": "Yuxuan Kuang",
            "user": "yxK",
            "type": "user"
          },
          "name": "Yuxuan Kuang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T07:17:03.322Z",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b111d",
          "name": "Haoran Geng",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b111e",
          "name": "Amine Elhafsi",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b111f",
          "name": "Tan-Dzung Do",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b1120",
          "name": "Pieter Abbeel",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b1121",
          "name": "Jitendra Malik",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b1122",
          "name": "Marco Pavone",
          "hidden": false
        },
        {
          "_id": "684ae246dbd21a9cc27b1123",
          "name": "Yue Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-11T03:24:26.000Z",
      "submittedOnDailyAt": "2025-06-16T04:37:55.714Z",
      "title": "SkillBlender: Towards Versatile Humanoid Whole-Body Loco-Manipulation\n  via Skill Blending",
      "submittedOnDailyBy": {
        "_id": "62359088a17d7271859c88f4",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1647677549197-noauth.jpeg",
        "isPro": false,
        "fullname": "Yuxuan Kuang",
        "user": "yxK",
        "type": "user"
      },
      "summary": "Humanoid robots hold significant potential in accomplishing daily tasks\nacross diverse environments thanks to their flexibility and human-like\nmorphology. Recent works have made significant progress in humanoid whole-body\ncontrol and loco-manipulation leveraging optimal control or reinforcement\nlearning. However, these methods require tedious task-specific tuning for each\ntask to achieve satisfactory behaviors, limiting their versatility and\nscalability to diverse tasks in daily scenarios. To that end, we introduce\nSkillBlender, a novel hierarchical reinforcement learning framework for\nversatile humanoid loco-manipulation. SkillBlender first pretrains\ngoal-conditioned task-agnostic primitive skills, and then dynamically blends\nthese skills to accomplish complex loco-manipulation tasks with minimal\ntask-specific reward engineering. We also introduce SkillBench, a parallel,\ncross-embodiment, and diverse simulated benchmark containing three embodiments,\nfour primitive skills, and eight challenging loco-manipulation tasks,\naccompanied by a set of scientific evaluation metrics balancing accuracy and\nfeasibility. Extensive simulated experiments show that our method significantly\noutperforms all baselines, while naturally regularizing behaviors to avoid\nreward hacking, resulting in more accurate and feasible movements for diverse\nloco-manipulation tasks in our daily scenarios. Our code and benchmark will be\nopen-sourced to the community to facilitate future research. Project page:\nhttps://usc-gvl.github.io/SkillBlender-web/.",
      "upvotes": 2,
      "discussionId": "684ae246dbd21a9cc27b1124",
      "projectPage": "https://usc-gvl.github.io/SkillBlender-web/",
      "githubRepo": "https://github.com/Humanoid-SkillBlender/SkillBlender",
      "ai_summary": "SkillBlender is a hierarchical reinforcement learning framework that uses pretrained primitive skills to efficiently solve diverse loco-manipulation tasks for humanoid robots.",
      "ai_keywords": [
        "reinforcement learning",
        "SkillBlender",
        "goal-conditioned",
        "task-agnostic primitive skills",
        "hierarchical reinforcement learning",
        "SkillBench",
        "cross-embodiment",
        "simulated benchmark",
        "loco-manipulation tasks",
        "reward engineering",
        "reward hacking"
      ]
    },
    "publishedAt": "2025-06-10T23:24:26.000Z",
    "title": "SkillBlender: Towards Versatile Humanoid Whole-Body Loco-Manipulation\n  via Skill Blending",
    "summary": "Humanoid robots hold significant potential in accomplishing daily tasks\nacross diverse environments thanks to their flexibility and human-like\nmorphology. Recent works have made significant progress in humanoid whole-body\ncontrol and loco-manipulation leveraging optimal control or reinforcement\nlearning. However, these methods require tedious task-specific tuning for each\ntask to achieve satisfactory behaviors, limiting their versatility and\nscalability to diverse tasks in daily scenarios. To that end, we introduce\nSkillBlender, a novel hierarchical reinforcement learning framework for\nversatile humanoid loco-manipulation. SkillBlender first pretrains\ngoal-conditioned task-agnostic primitive skills, and then dynamically blends\nthese skills to accomplish complex loco-manipulation tasks with minimal\ntask-specific reward engineering. We also introduce SkillBench, a parallel,\ncross-embodiment, and diverse simulated benchmark containing three embodiments,\nfour primitive skills, and eight challenging loco-manipulation tasks,\naccompanied by a set of scientific evaluation metrics balancing accuracy and\nfeasibility. Extensive simulated experiments show that our method significantly\noutperforms all baselines, while naturally regularizing behaviors to avoid\nreward hacking, resulting in more accurate and feasible movements for diverse\nloco-manipulation tasks in our daily scenarios. Our code and benchmark will be\nopen-sourced to the community to facilitate future research. Project page:\nhttps://usc-gvl.github.io/SkillBlender-web/.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09366.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "62359088a17d7271859c88f4",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1647677549197-noauth.jpeg",
      "fullname": "Yuxuan Kuang",
      "name": "yxK",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.08477",
      "authors": [
        {
          "_id": "684fb8cb60b4a34dbe007b05",
          "name": "Fengjun Pan",
          "hidden": false
        },
        {
          "_id": "684fb8cb60b4a34dbe007b06",
          "name": "Anh Tuan Luu",
          "hidden": false
        },
        {
          "_id": "684fb8cb60b4a34dbe007b07",
          "user": {
            "_id": "64cb02869e30a46f7b80b355",
            "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
            "isPro": false,
            "fullname": "Xiaobao Wu",
            "user": "bobxwu",
            "type": "user"
          },
          "name": "Xiaobao Wu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-06-16T07:16:04.938Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-10T06:10:45.000Z",
      "submittedOnDailyAt": "2025-06-16T04:59:02.024Z",
      "title": "Detecting Harmful Memes with Decoupled Understanding and Guided CoT\n  Reasoning",
      "submittedOnDailyBy": {
        "_id": "64cb02869e30a46f7b80b355",
        "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
        "isPro": false,
        "fullname": "Xiaobao Wu",
        "user": "bobxwu",
        "type": "user"
      },
      "summary": "Detecting harmful memes is essential for maintaining the integrity of online\nenvironments. However, current approaches often struggle with resource\nefficiency, flexibility, or explainability, limiting their practical deployment\nin content moderation systems. To address these challenges, we introduce\nU-CoT+, a novel framework for harmful meme detection. Instead of relying solely\non prompting or fine-tuning multimodal models, we first develop a high-fidelity\nmeme-to-text pipeline that converts visual memes into detail-preserving textual\ndescriptions. This design decouples meme interpretation from meme\nclassification, thus avoiding immediate reasoning over complex raw visual\ncontent and enabling resource-efficient harmful meme detection with general\nlarge language models (LLMs). Building on these textual descriptions, we\nfurther incorporate targeted, interpretable human-crafted guidelines to guide\nmodels' reasoning under zero-shot CoT prompting. As such, this framework allows\nfor easy adaptation to different harmfulness detection criteria across\nplatforms, regions, and over time, offering high flexibility and\nexplainability. Extensive experiments on seven benchmark datasets validate the\neffectiveness of our framework, highlighting its potential for explainable and\nlow-resource harmful meme detection using small-scale LLMs. Codes and data are\navailable at: https://anonymous.4open.science/r/HMC-AF2B/README.md.",
      "upvotes": 2,
      "discussionId": "684fb8cb60b4a34dbe007b08",
      "ai_summary": "U-CoT+ is a novel framework for detecting harmful memes by converting them into textual descriptions and using human-crafted guidelines with zero-shot CoT prompting to achieve high flexibility and explainability with small-scale LLMs.",
      "ai_keywords": [
        "U-CoT+",
        "meme-to-text pipeline",
        "high-fidelity",
        "zero-shot CoT prompting",
        "human-crafted guidelines",
        "large language models (LLMs)",
        "harmful meme detection",
        "explainability",
        "flexibility",
        "benchmark datasets"
      ]
    },
    "publishedAt": "2025-06-10T02:10:45.000Z",
    "title": "Detecting Harmful Memes with Decoupled Understanding and Guided CoT\n  Reasoning",
    "summary": "Detecting harmful memes is essential for maintaining the integrity of online\nenvironments. However, current approaches often struggle with resource\nefficiency, flexibility, or explainability, limiting their practical deployment\nin content moderation systems. To address these challenges, we introduce\nU-CoT+, a novel framework for harmful meme detection. Instead of relying solely\non prompting or fine-tuning multimodal models, we first develop a high-fidelity\nmeme-to-text pipeline that converts visual memes into detail-preserving textual\ndescriptions. This design decouples meme interpretation from meme\nclassification, thus avoiding immediate reasoning over complex raw visual\ncontent and enabling resource-efficient harmful meme detection with general\nlarge language models (LLMs). Building on these textual descriptions, we\nfurther incorporate targeted, interpretable human-crafted guidelines to guide\nmodels' reasoning under zero-shot CoT prompting. As such, this framework allows\nfor easy adaptation to different harmfulness detection criteria across\nplatforms, regions, and over time, offering high flexibility and\nexplainability. Extensive experiments on seven benchmark datasets validate the\neffectiveness of our framework, highlighting its potential for explainable and\nlow-resource harmful meme detection using small-scale LLMs. Codes and data are\navailable at: https://anonymous.4open.science/r/HMC-AF2B/README.md.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.08477.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64cb02869e30a46f7b80b355",
      "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
      "fullname": "Xiaobao Wu",
      "name": "bobxwu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.11702",
      "authors": [
        {
          "_id": "684fae8360b4a34dbe007ac9",
          "user": {
            "_id": "5fad8602b8423e1d80b8a965",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5fad8602b8423e1d80b8a965/tRqTwcZmrGka8c1vFq2wX.jpeg",
            "isPro": false,
            "fullname": "Victor Gallego",
            "user": "vicgalle",
            "type": "user"
          },
          "name": "VÃ­ctor Gallego",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-06-16T05:42:55.745Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-13T12:17:38.000Z",
      "submittedOnDailyAt": "2025-06-16T04:12:09.638Z",
      "title": "Configurable Preference Tuning with Rubric-Guided Synthetic Data",
      "submittedOnDailyBy": {
        "_id": "5fad8602b8423e1d80b8a965",
        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5fad8602b8423e1d80b8a965/tRqTwcZmrGka8c1vFq2wX.jpeg",
        "isPro": false,
        "fullname": "Victor Gallego",
        "user": "vicgalle",
        "type": "user"
      },
      "summary": "Models of human feedback for AI alignment, such as those underpinning Direct\nPreference Optimization (DPO), often bake in a singular, static set of\npreferences, limiting adaptability. This paper challenges the assumption of\nmonolithic preferences by introducing Configurable Preference Tuning (CPT), a\nnovel framework for endowing language models with the ability to dynamically\nadjust their behavior based on explicit, human-interpretable directives. CPT\nleverages synthetically generated preference data, conditioned on system\nprompts derived from structured, fine-grained rubrics that define desired\nattributes like writing style. By fine-tuning with these rubric-guided\npreferences, the LLM learns to modulate its outputs at inference time in\nresponse to the system prompt, without retraining. This approach not only\noffers fine-grained control but also provides a mechanism for modeling more\nnuanced and context-dependent human feedback. Several experimental artifacts,\nsuch as training code, generated datasets and fine-tuned models are released at\nhttps://github.com/vicgalle/configurable-preference-tuning",
      "upvotes": 1,
      "discussionId": "684fae8460b4a34dbe007aca",
      "ai_summary": "Configurable Preference Tuning enables language models to dynamically adjust their behavior based on human-interprettable directives, using rubric-guided preference data for fine-tuning and inference-time modulation.",
      "ai_keywords": [
        "Configurable Preference Tuning",
        "Direct Preference Optimization",
        "language models",
        "fine-grained control",
        "rubric-guided preferences",
        "inference-time modulation"
      ]
    },
    "publishedAt": "2025-06-13T08:17:38.000Z",
    "title": "Configurable Preference Tuning with Rubric-Guided Synthetic Data",
    "summary": "Models of human feedback for AI alignment, such as those underpinning Direct\nPreference Optimization (DPO), often bake in a singular, static set of\npreferences, limiting adaptability. This paper challenges the assumption of\nmonolithic preferences by introducing Configurable Preference Tuning (CPT), a\nnovel framework for endowing language models with the ability to dynamically\nadjust their behavior based on explicit, human-interpretable directives. CPT\nleverages synthetically generated preference data, conditioned on system\nprompts derived from structured, fine-grained rubrics that define desired\nattributes like writing style. By fine-tuning with these rubric-guided\npreferences, the LLM learns to modulate its outputs at inference time in\nresponse to the system prompt, without retraining. This approach not only\noffers fine-grained control but also provides a mechanism for modeling more\nnuanced and context-dependent human feedback. Several experimental artifacts,\nsuch as training code, generated datasets and fine-tuned models are released at\nhttps://github.com/vicgalle/configurable-preference-tuning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.11702.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "5fad8602b8423e1d80b8a965",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5fad8602b8423e1d80b8a965/tRqTwcZmrGka8c1vFq2wX.jpeg",
      "fullname": "Victor Gallego",
      "name": "vicgalle",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 129
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2506.09600",
      "authors": [
        {
          "_id": "684fca8160b4a34dbe007b4f",
          "name": "Itay Nakash",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b50",
          "name": "George Kour",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b51",
          "name": "Koren Lazar",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b52",
          "name": "Matan Vetzler",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b53",
          "name": "Guy Uziel",
          "hidden": false
        },
        {
          "_id": "684fca8160b4a34dbe007b54",
          "name": "Ateret Anaby-Tavor",
          "hidden": false
        }
      ],
      "mediaUrls": [
        "https://cdn-uploads.huggingface.co/production/uploads/671f8106d677d3a764a6f9a5/99oCW2IrMaCeLyuyfgvbG.png"
      ],
      "publishedAt": "2025-06-11T10:59:47.000Z",
      "submittedOnDailyAt": "2025-06-16T06:16:02.507Z",
      "title": "Effective Red-Teaming of Policy-Adherent Agents",
      "submittedOnDailyBy": {
        "_id": "671f8106d677d3a764a6f9a5",
        "avatarUrl": "/avatars/90b4b00058aac30c060c5eac8debb1c7.svg",
        "isPro": false,
        "fullname": "itay nakash",
        "user": "itaynakash",
        "type": "user"
      },
      "summary": "Task-oriented LLM-based agents are increasingly used in domains with strict\npolicies, such as refund eligibility or cancellation rules. The challenge lies\nin ensuring that the agent consistently adheres to these rules and policies,\nappropriately refusing any request that would violate them, while still\nmaintaining a helpful and natural interaction. This calls for the development\nof tailored design and evaluation methodologies to ensure agent resilience\nagainst malicious user behavior. We propose a novel threat model that focuses\non adversarial users aiming to exploit policy-adherent agents for personal\nbenefit. To address this, we present CRAFT, a multi-agent red-teaming system\nthat leverages policy-aware persuasive strategies to undermine a\npolicy-adherent agent in a customer-service scenario, outperforming\nconventional jailbreak methods such as DAN prompts, emotional manipulation, and\ncoercive. Building upon the existing tau-bench benchmark, we introduce\ntau-break, a complementary benchmark designed to rigorously assess the agent's\nrobustness against manipulative user behavior. Finally, we evaluate several\nstraightforward yet effective defense strategies. While these measures provide\nsome protection, they fall short, highlighting the need for stronger,\nresearch-driven safeguards to protect policy-adherent agents from adversarial\nattacks",
      "upvotes": 1,
      "discussionId": "684fca8160b4a34dbe007b55",
      "ai_summary": "CRAFT, a multi-agent system using policy-aware persuasive strategies, challenges policy-adherent LLM-based agents in customer service to assess and improve their robustness against adversarial attacks.",
      "ai_keywords": [
        "LLM-based agents",
        "policy-adherence",
        "adversarial users",
        "CRAFT",
        "multi-agent red-teaming",
        "policy-aware persuasive strategies",
        "DAN prompts",
        "emotional manipulation",
        "coercive",
        "tau-break",
        "defense strategies",
        "adversarial attacks"
      ]
    },
    "publishedAt": "2025-06-11T06:59:47.000Z",
    "title": "Effective Red-Teaming of Policy-Adherent Agents",
    "summary": "Task-oriented LLM-based agents are increasingly used in domains with strict\npolicies, such as refund eligibility or cancellation rules. The challenge lies\nin ensuring that the agent consistently adheres to these rules and policies,\nappropriately refusing any request that would violate them, while still\nmaintaining a helpful and natural interaction. This calls for the development\nof tailored design and evaluation methodologies to ensure agent resilience\nagainst malicious user behavior. We propose a novel threat model that focuses\non adversarial users aiming to exploit policy-adherent agents for personal\nbenefit. To address this, we present CRAFT, a multi-agent red-teaming system\nthat leverages policy-aware persuasive strategies to undermine a\npolicy-adherent agent in a customer-service scenario, outperforming\nconventional jailbreak methods such as DAN prompts, emotional manipulation, and\ncoercive. Building upon the existing tau-bench benchmark, we introduce\ntau-break, a complementary benchmark designed to rigorously assess the agent's\nrobustness against manipulative user behavior. Finally, we evaluate several\nstraightforward yet effective defense strategies. While these measures provide\nsome protection, they fall short, highlighting the need for stronger,\nresearch-driven safeguards to protect policy-adherent agents from adversarial\nattacks",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/671f8106d677d3a764a6f9a5/99oCW2IrMaCeLyuyfgvbG.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09600.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "671f8106d677d3a764a6f9a5",
      "avatarUrl": "/avatars/90b4b00058aac30c060c5eac8debb1c7.svg",
      "fullname": "itay nakash",
      "name": "itaynakash",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2506.08592",
      "authors": [
        {
          "_id": "684cfefc3b733ba3336873a6",
          "name": "Liyan Xu",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873a7",
          "name": "Zhenlin Su",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873a8",
          "name": "Mo Yu",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873a9",
          "name": "Jiangnan Li",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873aa",
          "name": "Fandong Meng",
          "hidden": false
        },
        {
          "_id": "684cfefc3b733ba3336873ab",
          "name": "Jie Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-06-10T09:00:33.000Z",
      "submittedOnDailyAt": "2025-06-16T06:09:56.672Z",
      "title": "Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity\n  Dilemma of Embeddings",
      "submittedOnDailyBy": {
        "_id": "650f0fac11f3210cf7a8a849",
        "avatarUrl": "/avatars/687d56c3a6d4f5cdb34e424cdcff954d.svg",
        "isPro": false,
        "fullname": "Leon Xu",
        "user": "lxucs",
        "type": "user"
      },
      "summary": "This work focuses on an observed limitation of text encoders: embeddings may\nnot be able to recognize fine-grained entities or events within the semantics,\nresulting in failed dense retrieval on even simple cases. To examine such\nbehaviors, we first introduce a new evaluation dataset in Chinese, named\nCapRetrieval, whose passages are image captions, and queries are phrases\ninquiring entities or events in various forms. Zero-shot evaluation suggests\nthat encoders may fail on these fine-grained matching, regardless of training\nsources or model sizes. Aiming for enhancement, we proceed to finetune encoders\nwith our proposed data generation strategies, which obtains the best\nperformance on CapRetrieval. Within this process, we further identify an issue\nof granularity dilemma, a challenge for embeddings to express fine-grained\nsalience while aligning with overall semantics. Our dataset, code and models in\nthis work are publicly released at https://github.com/lxucs/CapRetrieval.",
      "upvotes": 0,
      "discussionId": "684cfefc3b733ba3336873ac",
      "ai_summary": "A new dataset named CapRetrieval is introduced to evaluate the ability of text encoders to recognize fine-grained entities and events, highlighting challenges in dense retrieval tasks.",
      "ai_keywords": [
        "text encoders",
        "embeddings",
        "fine-grained entities",
        "events",
        "dense retrieval",
        "zero-shot evaluation",
        "data generation strategies",
        "granularity dilemma"
      ]
    },
    "publishedAt": "2025-06-10T05:00:33.000Z",
    "title": "Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity\n  Dilemma of Embeddings",
    "summary": "This work focuses on an observed limitation of text encoders: embeddings may\nnot be able to recognize fine-grained entities or events within the semantics,\nresulting in failed dense retrieval on even simple cases. To examine such\nbehaviors, we first introduce a new evaluation dataset in Chinese, named\nCapRetrieval, whose passages are image captions, and queries are phrases\ninquiring entities or events in various forms. Zero-shot evaluation suggests\nthat encoders may fail on these fine-grained matching, regardless of training\nsources or model sizes. Aiming for enhancement, we proceed to finetune encoders\nwith our proposed data generation strategies, which obtains the best\nperformance on CapRetrieval. Within this process, we further identify an issue\nof granularity dilemma, a challenge for embeddings to express fine-grained\nsalience while aligning with overall semantics. Our dataset, code and models in\nthis work are publicly released at https://github.com/lxucs/CapRetrieval.",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.08592.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "650f0fac11f3210cf7a8a849",
      "avatarUrl": "/avatars/687d56c3a6d4f5cdb34e424cdcff954d.svg",
      "fullname": "Leon Xu",
      "name": "lxucs",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isHfAdmin": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  }
]