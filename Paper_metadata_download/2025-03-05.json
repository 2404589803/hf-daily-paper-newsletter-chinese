[
  {
    "paper": {
      "id": "2503.02682",
      "authors": [
        {
          "_id": "67c7c3d073299239b63f5378",
          "name": "Weimin Xiong",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f5379",
          "name": "Yifan Song",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537a",
          "name": "Qingxiu Dong",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537b",
          "name": "Bingchan Zhao",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537c",
          "name": "Feifan Song",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537d",
          "name": "Xun Wang",
          "hidden": false
        },
        {
          "_id": "67c7c3d073299239b63f537e",
          "name": "Sujian Li",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T14:54:45.000Z",
      "title": "MPO: Boosting LLM Agents with Meta Plan Optimization",
      "summary": "Recent advancements in large language models (LLMs) have enabled LLM-based\nagents to successfully tackle interactive planning tasks. However, despite\ntheir successes, existing approaches often suffer from planning hallucinations\nand require retraining for each new agent. To address these challenges, we\npropose the Meta Plan Optimization (MPO) framework, which enhances agent\nplanning capabilities by directly incorporating explicit guidance. Unlike\nprevious methods that rely on complex knowledge, which either require\nsignificant human effort or lack quality assurance, MPO leverages high-level\ngeneral guidance through meta plans to assist agent planning and enables\ncontinuous optimization of the meta plans based on feedback from the agent's\ntask execution. Our experiments conducted on two representative tasks\ndemonstrate that MPO significantly outperforms existing baselines. Moreover,\nour analysis indicates that MPO provides a plug-and-play solution that enhances\nboth task completion efficiency and generalization capabilities in previous\nunseen scenarios.",
      "upvotes": 12,
      "discussionId": "67c7c3d173299239b63f53d6",
      "githubRepo": "https://github.com/WeiminXiong/MPO"
    },
    "publishedAt": "2025-03-04T22:30:53.253Z",
    "title": "MPO: Boosting LLM Agents with Meta Plan Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02682.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6225a9983207dfc568407204",
      "avatarUrl": "/avatars/c970db6232d84ae8c0fa5f11d561d67c.svg",
      "fullname": "xwm",
      "name": "xwm",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02846",
      "authors": [
        {
          "_id": "67c7c3ce6f68759bf368533c",
          "name": "Yuzhe Gu",
          "hidden": false
        },
        {
          "_id": "67c7c3ce6f68759bf368533d",
          "name": "Wenwei Zhang",
          "hidden": false
        },
        {
          "_id": "67c7c3ce6f68759bf368533e",
          "name": "Chengqi Lyu",
          "hidden": false
        },
        {
          "_id": "67c7c3ce6f68759bf368533f",
          "name": "Dahua Lin",
          "hidden": false
        },
        {
          "_id": "67c7c3ce6f68759bf3685340",
          "name": "Kai Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T18:20:24.000Z",
      "title": "Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs",
      "summary": "Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or\nnonsensical information) when serving as AI assistants in various domains.\nSince hallucinations always come with truthful content in the LLM responses,\nprevious factuality alignment methods that conduct response-level preference\nlearning inevitably introduced noises during training. Therefore, this paper\nproposes a fine-grained factuality alignment method based on Direct Preference\nOptimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as\nmask signals, Mask-DPO only learns from factually correct sentences in the\npreferred samples and prevents the penalty on factual contents in the not\npreferred samples, which resolves the ambiguity in the preference learning.\nExtensive experimental results demonstrate that Mask-DPO can significantly\nimprove the factuality of LLMs responses to questions from both in-domain and\nout-of-domain datasets, although these questions and their corresponding topics\nare unseen during training. Only trained on the ANAH train set, the score of\nLlama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%,\neven surpassing the score of Llama3.1-70B-Instruct (53.44%), while its\nFactScore on the out-of-domain Biography dataset is also improved from 30.29%\nto 39.39%. We further study the generalization property of Mask-DPO using\ndifferent training sample scaling strategies and find that scaling the number\nof topics in the dataset is more effective than the number of questions. We\nprovide a hypothesis of what factual alignment is doing with LLMs, on the\nimplication of this phenomenon, and conduct proof-of-concept experiments to\nverify it. We hope the method and the findings pave the way for future research\non scaling factuality alignment.",
      "upvotes": 10,
      "discussionId": "67c7c3d06f68759bf3685489",
      "githubRepo": "https://github.com/open-compass/ANAH"
    },
    "publishedAt": "2025-03-04T22:25:15.163Z",
    "title": "Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02846.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6601196cc91ba4c08ad6e270",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6601196cc91ba4c08ad6e270/X2YPNzUOQXBz5Gv-xR9LW.jpeg",
      "fullname": "yuzhe gu",
      "name": "vanilla1116",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02879",
      "authors": [
        {
          "_id": "67c7c42269d99dd25c5ba0ce",
          "name": "Siming Huang",
          "hidden": false
        },
        {
          "_id": "67c7c42269d99dd25c5ba0cf",
          "name": "Yuliang Xu",
          "hidden": false
        },
        {
          "_id": "67c7c42269d99dd25c5ba0d0",
          "user": {
            "_id": "67890323f8796231c857231e",
            "avatarUrl": "/avatars/f5ccd5186968d880fee9c36324a5f713.svg",
            "isPro": false,
            "fullname": "Mingmeng Geng",
            "user": "mgeng",
            "type": "user"
          },
          "name": "Mingmeng Geng",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-03-05T03:25:23.013Z",
          "hidden": false
        },
        {
          "_id": "67c7c42269d99dd25c5ba0d1",
          "name": "Yao Wan",
          "hidden": false
        },
        {
          "_id": "67c7c42269d99dd25c5ba0d2",
          "name": "Dongping Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T18:58:13.000Z",
      "title": "Wikipedia in the Era of LLMs: Evolution and Risks",
      "summary": "In this paper, we present a thorough analysis of the impact of Large Language\nModels (LLMs) on Wikipedia, examining the evolution of Wikipedia through\nexisting data and using simulations to explore potential risks. We begin by\nanalyzing page views and article content to study Wikipedia's recent changes\nand assess the impact of LLMs. Subsequently, we evaluate how LLMs affect\nvarious Natural Language Processing (NLP) tasks related to Wikipedia, including\nmachine translation and retrieval-augmented generation (RAG). Our findings and\nsimulation results reveal that Wikipedia articles have been influenced by LLMs,\nwith an impact of approximately 1%-2% in certain categories. If the machine\ntranslation benchmark based on Wikipedia is influenced by LLMs, the scores of\nthe models may become inflated, and the comparative results among models might\nshift as well. Moreover, the effectiveness of RAG might decrease if the\nknowledge base becomes polluted by LLM-generated content. While LLMs have not\nyet fully changed Wikipedia's language and knowledge structures, we believe\nthat our empirical findings signal the need for careful consideration of\npotential future risks.",
      "upvotes": 6,
      "discussionId": "67c7c42369d99dd25c5ba103",
      "githubRepo": "https://github.com/HSM316/LLM_Wikipedia"
    },
    "publishedAt": "2025-03-04T22:25:53.653Z",
    "title": "Wikipedia in the Era of LLMs: Evolution and Risks",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02879.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "643be8879f5d314db2d9ed23",
      "avatarUrl": "/avatars/64e9bb2c4e10fbe03e2b81afedf40865.svg",
      "fullname": "Chen Dongping",
      "name": "shuaishuaicdp",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.01935",
      "authors": [
        {
          "_id": "67c7ba7f19b236e0564d1172",
          "user": {
            "_id": "66554507e6ea63012f35824c",
            "avatarUrl": "/avatars/b82de75bd60890e7bb524fc3754b131c.svg",
            "isPro": false,
            "fullname": "Kunlun_Zhu",
            "user": "Leozkl",
            "type": "user"
          },
          "name": "Kunlun Zhu",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-03-05T02:44:18.739Z",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1173",
          "name": "Hongyi Du",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1174",
          "name": "Zhaochen Hong",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1175",
          "name": "Xiaocheng Yang",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1176",
          "name": "Shuyi Guo",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1177",
          "name": "Zhe Wang",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1178",
          "name": "Zhenhailong Wang",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d1179",
          "name": "Cheng Qian",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d117a",
          "name": "Xiangru Tang",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d117b",
          "name": "Heng Ji",
          "hidden": false
        },
        {
          "_id": "67c7ba7f19b236e0564d117c",
          "name": "Jiaxuan You",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T05:18:50.000Z",
      "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM\n  agents",
      "summary": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous\nagents, yet existing benchmarks either focus on single-agent tasks or are\nconfined to narrow domains, failing to capture the dynamics of multi-agent\ncoordination and competition. In this paper, we introduce MultiAgentBench, a\ncomprehensive benchmark designed to evaluate LLM-based multi-agent systems\nacross diverse, interactive scenarios. Our framework measures not only task\ncompletion but also the quality of collaboration and competition using novel,\nmilestone-based key performance indicators. Moreover, we evaluate various\ncoordination protocols (including star, chain, tree, and graph topologies) and\ninnovative strategies such as group discussion and cognitive planning. Notably,\ngpt-4o-mini reaches the average highest task score, graph structure performs\nthe best among coordination protocols in the research scenario, and cognitive\nplanning improves milestone achievement rates by 3%. Code and datasets are\npublic available at https://github.com/MultiagentBench/MARBLE.",
      "upvotes": 6,
      "discussionId": "67c7ba8219b236e0564d124a",
      "githubRepo": "https://github.com/MultiagentBench/MARBLE"
    },
    "publishedAt": "2025-03-04T21:46:46.873Z",
    "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01935.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "64c090a9f613170e7be93d2f",
      "avatarUrl": "/avatars/ccbdf444e1f2386d2281e8e42059ebb0.svg",
      "fullname": "KunlunZhu",
      "name": "KunlunZhu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.14856",
      "authors": [
        {
          "_id": "67bee83509a4524abf899511",
          "name": "Weilin Zhao",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899512",
          "name": "Tengyu Pan",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899513",
          "name": "Xu Han",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899514",
          "name": "Yudi Zhang",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899515",
          "name": "Ao Sun",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899516",
          "name": "Yuxiang Huang",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899517",
          "name": "Kaihuo Zhang",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899518",
          "name": "Weilun Zhao",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf899519",
          "name": "Yuxuan Li",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf89951a",
          "name": "Jianyong Wang",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf89951b",
          "name": "Zhiyuan Liu",
          "hidden": false
        },
        {
          "_id": "67bee83509a4524abf89951c",
          "name": "Maosong Sun",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-20T18:58:10.000Z",
      "title": "FR-Spec: Accelerating Large-Vocabulary Language Models via\n  Frequency-Ranked Speculative Sampling",
      "summary": "Speculative sampling has emerged as an important technique for accelerating\nthe auto-regressive generation process of large language models (LLMs) by\nutilizing a draft-then-verify mechanism to produce multiple tokens per forward\npass. While state-of-the-art speculative sampling methods use only a single\nlayer and a language modeling (LM) head as the draft model to achieve\nimpressive layer compression, their efficiency gains are substantially reduced\nfor large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens.\nTo address this, we present FR-Spec, a frequency-ranked speculative sampling\nframework that optimizes draft candidate selection through vocabulary space\ncompression. By constraining the draft search to a frequency-prioritized token\nsubset, our method reduces LM Head computation overhead by 75% while ensuring\nthe equivalence of the final output distribution. Experiments across multiple\ndatasets demonstrate an average of 1.12times speedup over the\nstate-of-the-art speculative sampling method EAGLE-2.",
      "upvotes": 5,
      "discussionId": "67bee83609a4524abf899550",
      "githubRepo": "https://github.com/thunlp/FR-Spec"
    },
    "publishedAt": "2025-03-05T00:36:34.146Z",
    "title": "FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.14856.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b8ff3d95bd42c770878042",
      "avatarUrl": "/avatars/564a4dccdf9e5b813a99979b0ef58183.svg",
      "fullname": "Weilin Zhao",
      "name": "Achazwl",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.00955",
      "authors": [
        {
          "_id": "67c7dbff25d0b3348ddace44",
          "name": "Nam V. Nguyen",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace45",
          "name": "Dien X. Tran",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace46",
          "name": "Thanh T. Tran",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace47",
          "name": "Anh T. Hoang",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace48",
          "name": "Tai V. Duong",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace49",
          "name": "Di T. Le",
          "hidden": false
        },
        {
          "_id": "67c7dbff25d0b3348ddace4a",
          "name": "Phuc-Lu Le",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-02T16:22:46.000Z",
      "title": "SemViQA: A Semantic Question Answering System for Vietnamese Information\n  Fact-Checking",
      "summary": "The rise of misinformation, exacerbated by Large Language Models (LLMs) like\nGPT and Gemini, demands robust fact-checking solutions, especially for\nlow-resource languages like Vietnamese. Existing methods struggle with semantic\nambiguity, homonyms, and complex linguistic structures, often trading accuracy\nfor efficiency. We introduce SemViQA, a novel Vietnamese fact-checking\nframework integrating Semantic-based Evidence Retrieval (SER) and Two-step\nVerdict Classification (TVC). Our approach balances precision and speed,\nachieving state-of-the-art results with 78.97\\% strict accuracy on ISE-DSC01\nand 80.82\\% on ViWikiFC, securing 1st place in the UIT Data Science Challenge.\nAdditionally, SemViQA Faster improves inference speed 7x while maintaining\ncompetitive accuracy. SemViQA sets a new benchmark for Vietnamese fact\nverification, advancing the fight against misinformation. The source code is\navailable at: https://github.com/DAVID-NGUYEN-S16/SemViQA.",
      "upvotes": 5,
      "discussionId": "67c7dc0025d0b3348ddace64",
      "githubRepo": "https://github.com/DAVID-NGUYEN-S16/SemViQA"
    },
    "publishedAt": "2025-03-05T00:08:53.214Z",
    "title": "SemViQA: A Semantic Question Answering System for Vietnamese Information Fact-Checking",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00955.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64c2bea2ada7df214276913b",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64c2bea2ada7df214276913b/QFCtmCn439Afsr7uqyoMT.jpeg",
      "fullname": "Nguyen Van Nam",
      "name": "DavidNguyen",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.01328",
      "authors": [
        {
          "_id": "67c7b5900b05ab9c7e805433",
          "name": "Xinyi Wan",
          "hidden": false
        },
        {
          "_id": "67c7b5900b05ab9c7e805434",
          "name": "Penghui Qi",
          "hidden": false
        },
        {
          "_id": "67c7b5900b05ab9c7e805435",
          "name": "Guangxing Huang",
          "hidden": false
        },
        {
          "_id": "67c7b5900b05ab9c7e805436",
          "name": "Jialin Li",
          "hidden": false
        },
        {
          "_id": "67c7b5900b05ab9c7e805437",
          "name": "Min Lin",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T09:11:06.000Z",
      "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory\n  Optimization",
      "summary": "Pipeline parallelism (PP) is widely used for training large language models\n(LLMs), yet its scalability is often constrained by high activation memory\nconsumption as the number of in-flight microbatches grows with the degree of\nPP. In this paper, we focus on addressing this challenge by leveraging the\nunder-explored memory offload strategy in PP. With empirical study, we discover\nthat in the majority of standard configurations, at least half, and potentially\nall, of the activations can be offloaded with negligible overhead. In the cases\nwhere full overload is not possible, we introduce a novel selective offload\nstrategy that decreases peak activation memory in a better-than-linear manner.\nFurthermore, we integrate memory offload with other techniques to jointly\nconsider overall throughput and memory limitation. Our experiments proves that\nthe per-device activation memory effectively reduces with the total number of\nstages, making PP a stronger alternative than TP, offering up to a 19\\%\nacceleration with even lower memory consumption. The implementation is\nopen-sourced at\nhttps://github.com/sail-sg/zero-bubble-pipeline-parallelism{this url}.",
      "upvotes": 5,
      "discussionId": "67c7b5970b05ab9c7e8055a1",
      "githubRepo": "https://github.com/sail-sg/zero-bubble"
    },
    "publishedAt": "2025-03-04T21:30:49.808Z",
    "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01328.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "63510eea0b94548566dad923",
      "avatarUrl": "/avatars/629eaaf810718259bf7588dc2e6cc0d5.svg",
      "fullname": "Xinyi Wan",
      "name": "ufotalent",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 5
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02197",
      "authors": [
        {
          "_id": "67c7c183203958ca9c09171a",
          "name": "Zhixun Chen",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171b",
          "name": "Ming Li",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171c",
          "name": "Yuxuan Huang",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171d",
          "name": "Yali Du",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171e",
          "name": "Meng Fang",
          "hidden": false
        },
        {
          "_id": "67c7c183203958ca9c09171f",
          "name": "Tianyi Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T02:14:55.000Z",
      "title": "ATLaS: Agent Tuning via Learning Critical Steps",
      "summary": "Large Language Model (LLM) agents have demonstrated remarkable generalization\ncapabilities across multi-domain tasks. Existing agent tuning approaches\ntypically employ supervised finetuning on entire expert trajectories. However,\nbehavior-cloning of full trajectories can introduce expert bias and weaken\ngeneralization to states not covered by the expert data. Additionally, critical\nsteps, such as planning, complex reasoning for intermediate subtasks, and\nstrategic decision-making, are essential to success in agent tasks, so learning\nthese steps is the key to improving LLM agents. For more effective and\nefficient agent tuning, we propose ATLaS that identifies the critical steps in\nexpert trajectories and finetunes LLMs solely on these steps with reduced\ncosts. By steering the training's focus to a few critical steps, our method\nmitigates the risk of overfitting entire trajectories and promotes\ngeneralization across different environments and tasks. In extensive\nexperiments, an LLM finetuned on only 30% critical steps selected by ATLaS\noutperforms the LLM finetuned on all steps and recent open-source LLM agents.\nATLaS maintains and improves base LLM skills as generalist agents interacting\nwith diverse environments.",
      "upvotes": 4,
      "discussionId": "67c7c185203958ca9c091751"
    },
    "publishedAt": "2025-03-04T22:17:48.386Z",
    "title": "ATLaS: Agent Tuning via Learning Critical Steps",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02197.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647f5af5b0e96764589f3b2a",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/VJ4cDyjp5M3V5WmI5gPIU.jpeg",
      "fullname": "Tianyi Zhou",
      "name": "zhoutianyi",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 12
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02878",
      "authors": [
        {
          "_id": "67c7bf7c40de8b1b534d23fa",
          "user": {
            "_id": "635d76ce94e5b275ca74b967",
            "avatarUrl": "/avatars/5d9a389e5fd558c0b8f0724bf0838a3e.svg",
            "isPro": false,
            "fullname": "Ethan Mendes",
            "user": "emendes3",
            "type": "user"
          },
          "name": "Ethan Mendes",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-05T03:06:00.588Z",
          "hidden": false
        },
        {
          "_id": "67c7bf7c40de8b1b534d23fb",
          "name": "Alan Ritter",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T18:58:11.000Z",
      "title": "Language Models can Self-Improve at State-Value Estimation for Better\n  Search",
      "summary": "Collecting ground truth task completion rewards or human demonstrations for\nmulti-step reasoning tasks is often cost-prohibitive and time-consuming,\nespecially in interactive domains like web tasks. To address this bottleneck,\nwe present self-taught lookahead, a self-supervised method that leverages\nstate-transition dynamics to train a value model capable of effectively guiding\nlanguage model-controlled search. We find that moderately sized (8 billion\nparameters) open-weight value models improved with self-taught lookahead can\nmatch the performance of using a frontier LLM such as gpt-4o as the value\nmodel. Furthermore, we find that self-taught lookahead improves performance by\n20% while reducing costs 37x compared to previous LLM-based tree search,\nwithout relying on ground truth rewards.",
      "upvotes": 4,
      "discussionId": "67c7bf7e40de8b1b534d2491",
      "githubRepo": "https://github.com/ethanm88/self-taught-lookahead"
    },
    "publishedAt": "2025-03-04T22:07:18.480Z",
    "title": "Language Models can Self-Improve at State-Value Estimation for Better Search",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02878.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "635d76ce94e5b275ca74b967",
      "avatarUrl": "/avatars/5d9a389e5fd558c0b8f0724bf0838a3e.svg",
      "fullname": "Ethan Mendes",
      "name": "emendes3",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.01342",
      "authors": [
        {
          "_id": "67c6b46e8389d77f5ba87179",
          "user": {
            "_id": "6585493b53c37507639fe3ba",
            "avatarUrl": "/avatars/b7e71d4fa5ebb89a7ed6b2a8313687b5.svg",
            "isPro": false,
            "fullname": "Hao Tang",
            "user": "kanashi6",
            "type": "user"
          },
          "name": "Hao Tang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-03-04T08:34:43.034Z",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717a",
          "name": "Chenwei Xie",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717b",
          "name": "Haiyang Wang",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717c",
          "name": "Xiaoyi Bao",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717d",
          "name": "Tingyu Weng",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717e",
          "name": "Pandeng Li",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba8717f",
          "name": "Yun Zheng",
          "hidden": false
        },
        {
          "_id": "67c6b46e8389d77f5ba87180",
          "name": "Liwei Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-03T09:27:24.000Z",
      "title": "UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended\n  Language Interface",
      "summary": "Generalist models have achieved remarkable success in both language and\nvision-language tasks, showcasing the potential of unified modeling. However,\neffectively integrating fine-grained perception tasks like detection and\nsegmentation into these models remains a significant challenge. This is\nprimarily because these tasks often rely heavily on task-specific designs and\narchitectures that can complicate the modeling process. To address this\nchallenge, we present \\ours, a framework that Unifies\nFine-grained visual perception tasks through an Open-ended\nlanguage interface. By transforming all perception targets into the language\nspace, \\ours unifies object-level detection, pixel-level segmentation, and\nimage-level vision-language tasks into a single model. Additionally, we\nintroduce a novel embedding retrieval approach that relies solely on the\nlanguage interface to support segmentation tasks. Our framework bridges the gap\nbetween fine-grained perception and vision-language tasks, significantly\nsimplifying architectural design and training strategies while achieving\ncomparable or superior performance to methods with intricate task-specific\ndesigns. After multi-task training on five standard visual perception datasets,\n\\ours outperforms the previous state-of-the-art generalist models by 12.3 mAP\non COCO instance segmentation and 3.3 mIoU on ADE20K semantic segmentation.\nFurthermore, our method seamlessly integrates with existing MLLMs, effectively\ncombining fine-grained perception capabilities with their advanced language\nabilities, thereby enabling more challenging tasks such as reasoning\nsegmentation. Code and models will be publicly available.",
      "upvotes": 2,
      "discussionId": "67c6b4728389d77f5ba8724d",
      "githubRepo": "https://github.com/nnnth/UFO"
    },
    "publishedAt": "2025-03-04T23:55:08.057Z",
    "title": "UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01342.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6585493b53c37507639fe3ba",
      "avatarUrl": "/avatars/b7e71d4fa5ebb89a7ed6b2a8313687b5.svg",
      "fullname": "Hao Tang",
      "name": "kanashi6",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2503.02268",
      "authors": [
        {
          "_id": "67c7ebafdf15f5978ac987c3",
          "name": "Wenjia Jiang",
          "hidden": false
        },
        {
          "_id": "67c7ebafdf15f5978ac987c4",
          "name": "Yangyang Zhuang",
          "hidden": false
        },
        {
          "_id": "67c7ebafdf15f5978ac987c5",
          "name": "Chenxi Song",
          "hidden": false
        },
        {
          "_id": "67c7ebafdf15f5978ac987c6",
          "name": "Xu Yang",
          "hidden": false
        },
        {
          "_id": "67c7ebafdf15f5978ac987c7",
          "name": "Chi Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T04:34:09.000Z",
      "title": "AppAgentX: Evolving GUI Agents as Proficient Smartphone Users",
      "summary": "Recent advancements in Large Language Models (LLMs) have led to the\ndevelopment of intelligent LLM-based agents capable of interacting with\ngraphical user interfaces (GUIs). These agents demonstrate strong reasoning and\nadaptability, enabling them to perform complex tasks that traditionally\nrequired predefined rules. However, the reliance on step-by-step reasoning in\nLLM-based agents often results in inefficiencies, particularly for routine\ntasks. In contrast, traditional rule-based systems excel in efficiency but lack\nthe intelligence and flexibility to adapt to novel scenarios. To address this\nchallenge, we propose a novel evolutionary framework for GUI agents that\nenhances operational efficiency while retaining intelligence and flexibility.\nOur approach incorporates a memory mechanism that records the agent's task\nexecution history. By analyzing this history, the agent identifies repetitive\naction sequences and evolves high-level actions that act as shortcuts,\nreplacing these low-level operations and improving efficiency. This allows the\nagent to focus on tasks requiring more complex reasoning, while simplifying\nroutine actions. Experimental results on multiple benchmark tasks demonstrate\nthat our approach significantly outperforms existing methods in both efficiency\nand accuracy. The code will be open-sourced to support further research.",
      "upvotes": 1,
      "discussionId": "67c7ebb5df15f5978ac98975"
    },
    "publishedAt": "2025-03-05T01:15:42.467Z",
    "title": "AppAgentX: Evolving GUI Agents as Proficient Smartphone Users",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/64196320ed725fef64419c2a/dUDWK6xfRd9uVZz77V0K6.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02268.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64196320ed725fef64419c2a",
      "avatarUrl": "/avatars/96feb22fb5e8931d6c9e0ea06148266f.svg",
      "fullname": "Chi Zhang",
      "name": "DrChiZhang",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 3
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2503.02876",
      "authors": [
        {
          "_id": "67c7bd7149b52e85403758f8",
          "user": {
            "_id": "6308bae5c038bf42d56a98e5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/yrslTwUe_vy_ZJha1H83m.png",
            "isPro": false,
            "fullname": "Dmitry Nechaev",
            "user": "mgvz",
            "type": "user"
          },
          "name": "Dmitry Nechaev",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-05T03:07:52.944Z",
          "hidden": false
        },
        {
          "_id": "67c7bd7149b52e85403758f9",
          "user": {
            "_id": "6655b0b9d6c043f39719eaaf",
            "avatarUrl": "/avatars/66138e67ef3be41f29857b285b37adff.svg",
            "isPro": false,
            "fullname": "Alex Pchelnikov",
            "user": "alpchel",
            "type": "user"
          },
          "name": "Alexey Pchelnikov",
          "status": "extracted_confirmed",
          "statusLastChangedAt": "2025-03-05T03:07:35.092Z",
          "hidden": false
        },
        {
          "_id": "67c7bd7149b52e85403758fa",
          "name": "Ekaterina Ivanova",
          "hidden": false
        }
      ],
      "publishedAt": "2025-03-04T18:57:12.000Z",
      "title": "SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dataset and\n  Baseline Models",
      "summary": "Advancing AI in computational pathology requires large, high-quality, and\ndiverse datasets, yet existing public datasets are often limited in organ\ndiversity, class coverage, or annotation quality. To bridge this gap, we\nintroduce SPIDER (Supervised Pathology Image-DEscription Repository), the\nlargest publicly available patch-level dataset covering multiple organ types,\nincluding Skin, Colorectal, and Thorax, with comprehensive class coverage for\neach organ. SPIDER provides high-quality annotations verified by expert\npathologists and includes surrounding context patches, which enhance\nclassification performance by providing spatial context.\n  Alongside the dataset, we present baseline models trained on SPIDER using the\nHibou-L foundation model as a feature extractor combined with an\nattention-based classification head. The models achieve state-of-the-art\nperformance across multiple tissue categories and serve as strong benchmarks\nfor future digital pathology research. Beyond patch classification, the model\nenables rapid identification of significant areas, quantitative tissue metrics,\nand establishes a foundation for multimodal approaches.\n  Both the dataset and trained models are publicly available to advance\nresearch, reproducibility, and AI-driven pathology development. Access them at:\nhttps://github.com/HistAI/SPIDER",
      "upvotes": 1,
      "discussionId": "67c7bd7649b52e8540375a34"
    },
    "publishedAt": "2025-03-04T22:08:26.811Z",
    "title": "SPIDER: A Comprehensive Multi-Organ Supervised Pathology Dataset and Baseline Models",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02876.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6308bae5c038bf42d56a98e5",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/yrslTwUe_vy_ZJha1H83m.png",
      "fullname": "Dmitry Nechaev",
      "name": "mgvz",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  }
]