[
    {
        "paper": {
            "id": "2407.03320",
            "authors": [
                {
                    "_id": "66861e5838277890b5e3d803",
                    "name": "Pan Zhang",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d804",
                    "name": "Xiaoyi Dong",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d805",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63859cf3b2906edaf83af9f0/iUQm5FAomzqYi6fkqIn9F.jpeg",
                        "isPro": false,
                        "fullname": "Yuhang Zang",
                        "user": "yuhangzang",
                        "type": "user"
                    },
                    "name": "Yuhang Zang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-04T08:03:20.977Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d806",
                    "user": {
                        "avatarUrl": "/avatars/b320c77dfad039d9f9c54127f610d44f.svg",
                        "isPro": false,
                        "fullname": "Cao Yuhang",
                        "user": "yhcao",
                        "type": "user"
                    },
                    "name": "Yuhang Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:08:27.158Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d807",
                    "user": {
                        "avatarUrl": "/avatars/f586bd8f17ea06f11c4f9cf6fc603917.svg",
                        "isPro": false,
                        "fullname": "Rui Qian",
                        "user": "shvdi",
                        "type": "user"
                    },
                    "name": "Rui Qian",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-04T11:59:55.369Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d808",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b02ec0e5000ae8a572ced5/h5T5c14F-lHmx3X5K67A2.jpeg",
                        "isPro": true,
                        "fullname": "Lin Chen",
                        "user": "Lin-Chen",
                        "type": "user"
                    },
                    "name": "Lin Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-04T08:03:19.273Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d809",
                    "user": {
                        "avatarUrl": "/avatars/a85635d886c7f157b6723dec5c01c030.svg",
                        "isPro": false,
                        "fullname": "Qipeng Guo",
                        "user": "QipengGuo",
                        "type": "user"
                    },
                    "name": "Qipeng Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:09:24.788Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d80a",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
                        "isPro": false,
                        "fullname": "HAODONG DUAN",
                        "user": "KennyUTC",
                        "type": "user"
                    },
                    "name": "Haodong Duan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:09:30.823Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d80b",
                    "name": "Bin Wang",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d80c",
                    "name": "Linke Ouyang",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d80d",
                    "user": {
                        "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
                        "isPro": false,
                        "fullname": "Songyang Zhang",
                        "user": "zsytony",
                        "type": "user"
                    },
                    "name": "Songyang Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:09:00.282Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d80e",
                    "user": {
                        "avatarUrl": "/avatars/18958b8406d1ce492b54c1c839f18c54.svg",
                        "isPro": false,
                        "fullname": "Wenwei Zhang",
                        "user": "ZwwWayne",
                        "type": "user"
                    },
                    "name": "Wenwei Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:08:36.985Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d80f",
                    "name": "Yining Li",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d810",
                    "name": "Yang Gao",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d811",
                    "name": "Peng Sun",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d812",
                    "name": "Xinyue Zhang",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d813",
                    "name": "Wei Li",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d814",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/blOlCW3k-GR4zV9zCA94s.jpeg",
                        "isPro": false,
                        "fullname": "Jingwen Li",
                        "user": "mersso",
                        "type": "user"
                    },
                    "name": "Jingwen Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:10:43.071Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d815",
                    "user": {
                        "avatarUrl": "/avatars/f42794fe25bffcd870a1bcee69b95298.svg",
                        "isPro": false,
                        "fullname": "wenhai.wang",
                        "user": "wangwhcore",
                        "type": "user"
                    },
                    "name": "Wenhai Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:11:20.377Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d816",
                    "name": "Hang Yan",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d817",
                    "user": {
                        "avatarUrl": "/avatars/fa1f2ae7972d7cde99dab178136ccbb0.svg",
                        "isPro": false,
                        "fullname": "Conghui He",
                        "user": "conghui",
                        "type": "user"
                    },
                    "name": "Conghui He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:07:09.993Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d818",
                    "name": "Xingcheng Zhang",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d819",
                    "name": "Kai Chen",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d81a",
                    "user": {
                        "avatarUrl": "/avatars/db67dd6c4b2b41054ddcce5a18ade6f8.svg",
                        "isPro": false,
                        "fullname": "Jifeng Dai",
                        "user": "daijifeng",
                        "type": "user"
                    },
                    "name": "Jifeng Dai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:11:42.980Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d81b",
                    "name": "Yu Qiao",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d81c",
                    "user": {
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:11:55.600Z",
                    "hidden": false
                },
                {
                    "_id": "66861e5838277890b5e3d81d",
                    "name": "Jiaqi Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-03T17:59:21.000Z",
            "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model\n  Supporting Long-Contextual Input and Output",
            "summary": "We present InternLM-XComposer-2.5 (IXC-2.5), a versatile large-vision\nlanguage model that supports long-contextual input and output. IXC-2.5 excels\nin various text-image comprehension and composition applications, achieving\nGPT-4V level capabilities with merely 7B LLM backend. Trained with 24K\ninterleaved image-text contexts, it can seamlessly extend to 96K long contexts\nvia RoPE extrapolation. This long-context capability allows IXC-2.5 to excel in\ntasks requiring extensive input and output contexts. Compared to its previous\n2.0 version, InternLM-XComposer-2.5 features three major upgrades in\nvision-language comprehension: (1) Ultra-High Resolution Understanding, (2)\nFine-Grained Video Understanding, and (3) Multi-Turn Multi-Image Dialogue. In\naddition to comprehension, IXC-2.5 extends to two compelling applications using\nextra LoRA parameters for text-image composition: (1) Crafting Webpages and (2)\nComposing High-Quality Text-Image Articles. IXC-2.5 has been evaluated on 28\nbenchmarks, outperforming existing open-source state-of-the-art models on 16\nbenchmarks. It also surpasses or competes closely with GPT-4V and Gemini Pro on\n16 key tasks. The InternLM-XComposer-2.5 is publicly available at\nhttps://github.com/InternLM/InternLM-XComposer.",
            "upvotes": 48
        },
        "publishedAt": "2024-07-04T02:31:32.455Z",
        "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64b4eec4faa3181a5eab9c46/zWZvMJB5Qz5lzOHtYXews.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.03320.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
            "fullname": "Jiaqi Wang",
            "name": "myownskyW7",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.19380",
            "authors": [
                {
                    "_id": "668543ec49af4905c09ba830",
                    "user": {
                        "avatarUrl": "/avatars/ff041e7a8cbca8e7130c3102a5d31c0c.svg",
                        "isPro": false,
                        "fullname": "Ivan Rubachev",
                        "user": "puhsu",
                        "type": "user"
                    },
                    "name": "Ivan Rubachev",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T11:59:27.502Z",
                    "hidden": false
                },
                {
                    "_id": "668543ec49af4905c09ba831",
                    "name": "Nikolay Kartashev",
                    "hidden": false
                },
                {
                    "_id": "668543ec49af4905c09ba832",
                    "user": {
                        "avatarUrl": "/avatars/fbab83d3f7667e1c96954824976678f4.svg",
                        "isPro": false,
                        "fullname": "Yury Gorishniy",
                        "user": "Yura52",
                        "type": "user"
                    },
                    "name": "Yury Gorishniy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:01:02.404Z",
                    "hidden": false
                },
                {
                    "_id": "668543ec49af4905c09ba833",
                    "name": "Artem Babenko",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-27T17:55:31.000Z",
            "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
            "summary": "Benchmarks that closely reflect downstream application scenarios are\nessential for the streamlined adoption of new research in tabular machine\nlearning (ML). In this work, we examine existing tabular benchmarks and find\ntwo common characteristics of industry-grade tabular data that are\nunderrepresented in the datasets available to the academic community. First,\ntabular data often changes over time in real-world deployment scenarios. This\nimpacts model performance and requires time-based train and test splits for\ncorrect model evaluation. Yet, existing academic tabular datasets often lack\ntimestamp metadata to enable such evaluation. Second, a considerable portion of\ndatasets in production settings stem from extensive data acquisition and\nfeature engineering pipelines. For each specific dataset, this can have a\ndifferent impact on the absolute and relative number of predictive,\nuninformative, and correlated features, which in turn can affect model\nselection. To fill the aforementioned gaps in academic benchmarks, we introduce\nTabReD -- a collection of eight industry-grade tabular datasets covering a wide\nrange of domains from finance to food delivery services. We assess a large\nnumber of tabular ML models in the feature-rich, temporally-evolving data\nsetting facilitated by TabReD. We demonstrate that evaluation on time-based\ndata splits leads to different methods ranking, compared to evaluation on\nrandom splits more common in academic benchmarks. Furthermore, on the TabReD\ndatasets, MLP-like architectures and GBDT show the best results, while more\nsophisticated DL models are yet to prove their effectiveness.",
            "upvotes": 30
        },
        "publishedAt": "2024-07-04T10:03:14.535Z",
        "title": "TabReD: A Benchmark of Tabular Machine Learning in-the-Wild",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.19380.png",
        "numComments": 6,
        "submittedBy": {
            "avatarUrl": "/avatars/ff041e7a8cbca8e7130c3102a5d31c0c.svg",
            "fullname": "Ivan Rubachev",
            "name": "puhsu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02392",
            "authors": [
                {
                    "_id": "668618e247f2a33570ed316e",
                    "user": {
                        "avatarUrl": "/avatars/010655deb56266dd6483d122a0bbacd8.svg",
                        "isPro": false,
                        "fullname": "wentong li",
                        "user": "wentong2025",
                        "type": "user"
                    },
                    "name": "Wentong Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T08:47:11.356Z",
                    "hidden": false
                },
                {
                    "_id": "668618e247f2a33570ed316f",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a3fe3dde901eb01df12398/Js2bEx4rxKuEKVt5z9I2D.jpeg",
                        "isPro": false,
                        "fullname": "YuqianYuan",
                        "user": "CircleRadon",
                        "type": "user"
                    },
                    "name": "Yuqian Yuan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-04T08:03:26.166Z",
                    "hidden": false
                },
                {
                    "_id": "668618e247f2a33570ed3170",
                    "name": "Jian Liu",
                    "hidden": false
                },
                {
                    "_id": "668618e247f2a33570ed3171",
                    "user": {
                        "avatarUrl": "/avatars/901a91f8270d3363f89a26785e471586.svg",
                        "isPro": false,
                        "fullname": "Dongqi Tang",
                        "user": "coura",
                        "type": "user"
                    },
                    "name": "Dongqi Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:13:51.284Z",
                    "hidden": false
                },
                {
                    "_id": "668618e247f2a33570ed3172",
                    "name": "Song Wang",
                    "hidden": false
                },
                {
                    "_id": "668618e247f2a33570ed3173",
                    "name": "Jianke Zhu",
                    "hidden": false
                },
                {
                    "_id": "668618e247f2a33570ed3174",
                    "name": "Lei Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T16:10:55.000Z",
            "title": "TokenPacker: Efficient Visual Projector for Multimodal LLM",
            "summary": "The visual projector serves as an essential bridge between the visual encoder\nand the Large Language Model (LLM) in a Multimodal LLM (MLLM). Typically, MLLMs\nadopt a simple MLP to preserve all visual contexts via one-to-one\ntransformation. However, the visual tokens are redundant and can be\nconsiderably increased when dealing with high-resolution images, impairing the\nefficiency of MLLMs significantly. Some recent works have introduced resampler\nor abstractor to reduce the number of resulting visual tokens. Unfortunately,\nthey fail to capture finer details and undermine the visual reasoning\ncapabilities of MLLMs. In this work, we propose a novel visual projector, which\nadopts a coarse-to-fine scheme to inject the enriched characteristics to\ngenerate the condensed visual tokens. In specific, we first interpolate the\nvisual features as a low-resolution point query, providing the overall visual\nrepresentation as the foundation. Then, we introduce a region-to-point\ninjection module that utilizes high-resolution, multi-level region-based cues\nas fine-grained reference keys and values, allowing them to be fully absorbed\nwithin the corresponding local context region. This step effectively updates\nthe coarse point query, transforming it into an enriched one for the subsequent\nLLM reasoning. Extensive experiments demonstrate that our approach compresses\nthe visual tokens by 75%~89%, while achieves comparable or even better\nperformance across diverse benchmarks with significantly higher efficiency. The\nsource codes can be found at https://github.com/CircleRadon/TokenPacker.",
            "upvotes": 15
        },
        "publishedAt": "2024-07-04T02:16:29.325Z",
        "title": "TokenPacker: Efficient Visual Projector for Multimodal LLM",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02392.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64c48a78d07620bdc99777d4/NJC4Ot0a7YSdU5RC6dgga.jpeg",
            "fullname": "LI WENTONG",
            "name": "sunshine-lwt",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02687",
            "authors": [
                {
                    "_id": "6686334bb3b3b6dbf2ddce0d",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b4b02a103617b0a5b0ee2e/LasBC-pCnPJ6XuCt6qqcp.jpeg",
                        "isPro": false,
                        "fullname": "Seyedmorteza Sadat",
                        "user": "msadat97",
                        "type": "user"
                    },
                    "name": "Seyedmorteza Sadat",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-04T08:03:17.605Z",
                    "hidden": false
                },
                {
                    "_id": "6686334bb3b3b6dbf2ddce0e",
                    "user": {
                        "avatarUrl": "/avatars/3297e18e43d40e902b9554a077a34a8a.svg",
                        "isPro": false,
                        "fullname": "Manuel Kansy",
                        "user": "manuelkansy",
                        "type": "user"
                    },
                    "name": "Manuel Kansy",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-04T08:03:15.655Z",
                    "hidden": false
                },
                {
                    "_id": "6686334bb3b3b6dbf2ddce0f",
                    "name": "Otmar Hilliges",
                    "hidden": false
                },
                {
                    "_id": "6686334bb3b3b6dbf2ddce10",
                    "user": {
                        "avatarUrl": "/avatars/59bbd4ed38277b313051aac78f6808ac.svg",
                        "isPro": false,
                        "fullname": "Romann Weber",
                        "user": "RMW",
                        "type": "user"
                    },
                    "name": "Romann M. Weber",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:15:30.196Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T22:04:00.000Z",
            "title": "No Training, No Problem: Rethinking Classifier-Free Guidance for\n  Diffusion Models",
            "summary": "Classifier-free guidance (CFG) has become the standard method for enhancing\nthe quality of conditional diffusion models. However, employing CFG requires\neither training an unconditional model alongside the main diffusion model or\nmodifying the training procedure by periodically inserting a null condition.\nThere is also no clear extension of CFG to unconditional models. In this paper,\nwe revisit the core principles of CFG and introduce a new method, independent\ncondition guidance (ICG), which provides the benefits of CFG without the need\nfor any special training procedures. Our approach streamlines the training\nprocess of conditional diffusion models and can also be applied during\ninference on any pre-trained conditional model. Additionally, by leveraging the\ntime-step information encoded in all diffusion networks, we propose an\nextension of CFG, called time-step guidance (TSG), which can be applied to any\ndiffusion model, including unconditional ones. Our guidance techniques are easy\nto implement and have the same sampling cost as CFG. Through extensive\nexperiments, we demonstrate that ICG matches the performance of standard CFG\nacross various conditional diffusion models. Moreover, we show that TSG\nimproves generation quality in a manner similar to CFG, without relying on any\nconditional information.",
            "upvotes": 12
        },
        "publishedAt": "2024-07-04T04:08:43.005Z",
        "title": "No Training, No Problem: Rethinking Classifier-Free Guidance for Diffusion Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02687.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b4b02a103617b0a5b0ee2e/LasBC-pCnPJ6XuCt6qqcp.jpeg",
            "fullname": "Seyedmorteza Sadat",
            "name": "msadat97",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02869",
            "authors": [
                {
                    "_id": "668639f8b9a71fa518a628bd",
                    "name": "Zeyu Xie",
                    "hidden": false
                },
                {
                    "_id": "668639f8b9a71fa518a628be",
                    "user": {
                        "avatarUrl": "/avatars/aa6b34575220679af9cef23ecbfc781b.svg",
                        "isPro": false,
                        "fullname": "Xuenan Xu",
                        "user": "wsntxxn",
                        "type": "user"
                    },
                    "name": "Xuenan Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:17:06.950Z",
                    "hidden": false
                },
                {
                    "_id": "668639f8b9a71fa518a628bf",
                    "name": "Zhizheng Wu",
                    "hidden": false
                },
                {
                    "_id": "668639f8b9a71fa518a628c0",
                    "name": "Mengyue Wu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-03T07:33:14.000Z",
            "title": "PicoAudio: Enabling Precise Timestamp and Frequency Controllability of\n  Audio Events in Text-to-audio Generation",
            "summary": "Recently, audio generation tasks have attracted considerable research\ninterests. Precise temporal controllability is essential to integrate audio\ngeneration with real applications. In this work, we propose a temporal\ncontrolled audio generation framework, PicoAudio. PicoAudio integrates temporal\ninformation to guide audio generation through tailored model design. It\nleverages data crawling, segmentation, filtering, and simulation of\nfine-grained temporally-aligned audio-text data. Both subjective and objective\nevaluations demonstrate that PicoAudio dramantically surpasses current\nstate-of-the-art generation models in terms of timestamp and occurrence\nfrequency controllability. The generated samples are available on the demo\nwebsite https://PicoAudio.github.io.",
            "upvotes": 6
        },
        "publishedAt": "2024-07-04T04:28:26.367Z",
        "title": "PicoAudio: Enabling Precise Timestamp and Frequency Controllability of Audio Events in Text-to-audio Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02869.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.03300",
            "authors": [
                {
                    "_id": "6686497f1119f961e54211e9",
                    "user": {
                        "avatarUrl": "/avatars/4f262272e6222f879c6c0fedfa2e5861.svg",
                        "isPro": false,
                        "fullname": "Yilun Xu",
                        "user": "AaronXyl",
                        "type": "user"
                    },
                    "name": "Yilun Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:35:48.060Z",
                    "hidden": false
                },
                {
                    "_id": "6686497f1119f961e54211ea",
                    "user": {
                        "avatarUrl": "/avatars/4a1f6dd371094ada3addc10746a91616.svg",
                        "isPro": false,
                        "fullname": "Gabriele Corso",
                        "user": "gcorso",
                        "type": "user"
                    },
                    "name": "Gabriele Corso",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:46:42.221Z",
                    "hidden": false
                },
                {
                    "_id": "6686497f1119f961e54211eb",
                    "name": "Tommi Jaakkola",
                    "hidden": false
                },
                {
                    "_id": "6686497f1119f961e54211ec",
                    "user": {
                        "avatarUrl": "/avatars/b22db0823311f866c00db2efc4b9f814.svg",
                        "isPro": false,
                        "fullname": "Arash Vahdat",
                        "user": "avahdat",
                        "type": "user"
                    },
                    "name": "Arash Vahdat",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:47:07.441Z",
                    "hidden": false
                },
                {
                    "_id": "6686497f1119f961e54211ed",
                    "name": "Karsten Kreis",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-03T17:42:46.000Z",
            "title": "DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents",
            "summary": "Diffusion models (DMs) have revolutionized generative learning. They utilize\na diffusion process to encode data into a simple Gaussian distribution.\nHowever, encoding a complex, potentially multimodal data distribution into a\nsingle continuous Gaussian distribution arguably represents an unnecessarily\nchallenging learning problem. We propose Discrete-Continuous Latent Variable\nDiffusion Models (DisCo-Diff) to simplify this task by introducing\ncomplementary discrete latent variables. We augment DMs with learnable discrete\nlatents, inferred with an encoder, and train DM and encoder end-to-end.\nDisCo-Diff does not rely on pre-trained networks, making the framework\nuniversally applicable. The discrete latents significantly simplify learning\nthe DM's complex noise-to-data mapping by reducing the curvature of the DM's\ngenerative ODE. An additional autoregressive transformer models the\ndistribution of the discrete latents, a simple step because DisCo-Diff requires\nonly few discrete variables with small codebooks. We validate DisCo-Diff on toy\ndata, several image synthesis tasks as well as molecular docking, and find that\nintroducing discrete latents consistently improves model performance. For\nexample, DisCo-Diff achieves state-of-the-art FID scores on class-conditioned\nImageNet-64/128 datasets with ODE sampler.",
            "upvotes": 5
        },
        "publishedAt": "2024-07-04T05:36:40.829Z",
        "title": "DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/649c37de5ffe05267a105fe8/VipKKmOzkE00LsiGVF59A.png",
            "https://cdn-uploads.huggingface.co/production/uploads/649c37de5ffe05267a105fe8/3VmgKsFRnoh1mn1kzDunM.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.03300.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/4f262272e6222f879c6c0fedfa2e5861.svg",
            "fullname": "Yilun Xu",
            "name": "AaronXyl",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.03169",
            "authors": [
                {
                    "_id": "6685fe7fb615543f13b11a23",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5e060e7dcbfd036a99df0dbf/qJ31KnXhyP701B2vcot8Q.jpeg",
                        "isPro": false,
                        "fullname": "Chao-Wei Huang",
                        "user": "chaoweihuang",
                        "type": "user"
                    },
                    "name": "Chao-Wei Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-04T08:03:44.624Z",
                    "hidden": false
                },
                {
                    "_id": "6685fe7fb615543f13b11a24",
                    "user": {
                        "avatarUrl": "/avatars/2334eff6fec16fdc551f453f6e363df7.svg",
                        "isPro": false,
                        "fullname": "Hui Lu",
                        "user": "huilu",
                        "type": "user"
                    },
                    "name": "Hui Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:47:49.628Z",
                    "hidden": false
                },
                {
                    "_id": "6685fe7fb615543f13b11a25",
                    "user": {
                        "avatarUrl": "/avatars/1a4bb70ca3a5ed1a6d201324d0de9858.svg",
                        "isPro": false,
                        "fullname": "Hongyu Gong",
                        "user": "hygong",
                        "type": "user"
                    },
                    "name": "Hongyu Gong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:47:58.118Z",
                    "hidden": false
                },
                {
                    "_id": "6685fe7fb615543f13b11a26",
                    "name": "Hirofumi Inaguma",
                    "hidden": false
                },
                {
                    "_id": "6685fe7fb615543f13b11a27",
                    "user": {
                        "avatarUrl": "/avatars/508372876a654957650ee9429886d10c.svg",
                        "isPro": false,
                        "fullname": "ilia kulikov",
                        "user": "uralik",
                        "type": "user"
                    },
                    "name": "Ilia Kulikov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:48:11.445Z",
                    "hidden": false
                },
                {
                    "_id": "6685fe7fb615543f13b11a28",
                    "user": {
                        "avatarUrl": "/avatars/77de68494021f298bf2561b2ea9ffef8.svg",
                        "isPro": false,
                        "fullname": "Ruslan Mavlyutov",
                        "user": "mavlyutovrus",
                        "type": "user"
                    },
                    "name": "Ruslan Mavlyutov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:48:17.106Z",
                    "hidden": false
                },
                {
                    "_id": "6685fe7fb615543f13b11a29",
                    "user": {
                        "avatarUrl": "/avatars/2168f769c526362f9ed35473f4b30047.svg",
                        "isPro": false,
                        "fullname": "Sravya Popuri",
                        "user": "sravyapopuri388",
                        "type": "user"
                    },
                    "name": "Sravya Popuri",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-04T12:48:23.311Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-03T14:42:49.000Z",
            "title": "Investigating Decoder-only Large Language Models for Speech-to-text\n  Translation",
            "summary": "Large language models (LLMs), known for their exceptional reasoning\ncapabilities, generalizability, and fluency across diverse domains, present a\npromising avenue for enhancing speech-related tasks. In this paper, we focus on\nintegrating decoder-only LLMs to the task of speech-to-text translation (S2TT).\nWe propose a decoder-only architecture that enables the LLM to directly consume\nthe encoded speech representation and generate the text translation.\nAdditionally, we investigate the effects of different parameter-efficient\nfine-tuning techniques and task formulation. Our model achieves\nstate-of-the-art performance on CoVoST 2 and FLEURS among models trained\nwithout proprietary data. We also conduct analyses to validate the design\nchoices of our proposed model and bring insights to the integration of LLMs to\nS2TT.",
            "upvotes": 3
        },
        "publishedAt": "2024-07-04T06:53:59.934Z",
        "title": "Investigating Decoder-only Large Language Models for Speech-to-text Translation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.03169.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5e060e7dcbfd036a99df0dbf/qJ31KnXhyP701B2vcot8Q.jpeg",
            "fullname": "Chao-Wei Huang",
            "name": "chaoweihuang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.02551",
            "authors": [
                {
                    "_id": "6686b9c3434e14e5a1ee2182",
                    "name": "David Glukhov",
                    "hidden": false
                },
                {
                    "_id": "6686b9c3434e14e5a1ee2183",
                    "name": "Ziwen Han",
                    "hidden": false
                },
                {
                    "_id": "6686b9c3434e14e5a1ee2184",
                    "name": "Ilia Shumailov",
                    "hidden": false
                },
                {
                    "_id": "6686b9c3434e14e5a1ee2185",
                    "name": "Vardan Papyan",
                    "hidden": false
                },
                {
                    "_id": "6686b9c3434e14e5a1ee2186",
                    "name": "Nicolas Papernot",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-02T16:19:25.000Z",
            "title": "A False Sense of Safety: Unsafe Information Leakage in 'Safe' AI\n  Responses",
            "summary": "Large Language Models (LLMs) are vulnerable to\njailbreaksx2013methods to elicit harmful or generally impermissible\noutputs. Safety measures are developed and assessed on their effectiveness at\ndefending against jailbreak attacks, indicating a belief that safety is\nequivalent to robustness. We assert that current defense mechanisms, such as\noutput filters and alignment fine-tuning, are, and will remain, fundamentally\ninsufficient for ensuring model safety. These defenses fail to address risks\narising from dual-intent queries and the ability to composite innocuous outputs\nto achieve harmful goals. To address this critical gap, we introduce an\ninformation-theoretic threat model called inferential adversaries who exploit\nimpermissible information leakage from model outputs to achieve malicious\ngoals. We distinguish these from commonly studied security adversaries who only\nseek to force victim models to generate specific impermissible outputs. We\ndemonstrate the feasibility of automating inferential adversaries through\nquestion decomposition and response aggregation. To provide safety guarantees,\nwe define an information censorship criterion for censorship mechanisms,\nbounding the leakage of impermissible information. We propose a defense\nmechanism which ensures this bound and reveal an intrinsic safety-utility\ntrade-off. Our work provides the first theoretically grounded understanding of\nthe requirements for releasing safe LLMs and the utility costs involved.",
            "upvotes": 0
        },
        "publishedAt": "2024-07-04T13:35:15.560Z",
        "title": "A False Sense of Safety: Unsafe Information Leakage in 'Safe' AI Responses",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.02551.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/db428715dfd2239df2aeaaff1282323f.svg",
            "fullname": "i",
            "name": "iliashum",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]