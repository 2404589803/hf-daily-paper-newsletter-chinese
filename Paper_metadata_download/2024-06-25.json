[
    {
        "paper": {
            "id": "2406.16855",
            "authors": [
                {
                    "_id": "667a2da1d25dfd6fef20d30b",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631ee086c1a8269da39265c6/wUa1epGtTGcUv2mvrLUcD.png",
                        "isPro": false,
                        "fullname": "Yuang Peng",
                        "user": "yuangpeng",
                        "type": "user"
                    },
                    "name": "Yuang Peng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:16.296Z",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d30c",
                    "name": "Yuxin Cui",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d30d",
                    "user": {
                        "avatarUrl": "/avatars/21b1dadeaa7ee2ca2be7150c8a8c27c3.svg",
                        "isPro": false,
                        "fullname": "Haomiao Tang",
                        "user": "Me0W",
                        "type": "user"
                    },
                    "name": "Haomiao Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:48:11.274Z",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d30e",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63c3e8abc7d7f4c63a515a02/npMHnVP2hHLbvoUGe7C4O.jpeg",
                        "isPro": false,
                        "fullname": "Zekun Qi",
                        "user": "qizekun",
                        "type": "user"
                    },
                    "name": "Zekun Qi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:48:19.255Z",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d30f",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
                        "isPro": false,
                        "fullname": "Runpei Dong",
                        "user": "RunpeiDong",
                        "type": "user"
                    },
                    "name": "Runpei Dong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:18.443Z",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d310",
                    "user": {
                        "avatarUrl": "/avatars/ac873a2bf07349386f88e085f9c16ad7.svg",
                        "isPro": false,
                        "fullname": "baijing",
                        "user": "baijing163",
                        "type": "user"
                    },
                    "name": "Jing Bai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:48:34.002Z",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d311",
                    "name": "Chunrui Han",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d312",
                    "name": "Zheng Ge",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d313",
                    "name": "Xiangyu Zhang",
                    "hidden": false
                },
                {
                    "_id": "667a2da1d25dfd6fef20d314",
                    "name": "Shu-Tao Xia",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T17:58:47.000Z",
            "title": "DreamBench++: A Human-Aligned Benchmark for Personalized Image\n  Generation",
            "summary": "Personalized image generation holds great promise in assisting humans in\neveryday work and life due to its impressive function in creatively generating\npersonalized content. However, current evaluations either are automated but\nmisalign with humans or require human evaluations that are time-consuming and\nexpensive. In this work, we present DreamBench++, a human-aligned benchmark\nautomated by advanced multimodal GPT models. Specifically, we systematically\ndesign the prompts to let GPT be both human-aligned and self-aligned, empowered\nwith task reinforcement. Further, we construct a comprehensive dataset\ncomprising diverse images and prompts. By benchmarking 7 modern generative\nmodels, we demonstrate that DreamBench++ results in significantly more\nhuman-aligned evaluation, helping boost the community with innovative findings.",
            "upvotes": 35
        },
        "publishedAt": "2024-06-25T01:35:04.046Z",
        "title": "DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16855.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631ee086c1a8269da39265c6/wUa1epGtTGcUv2mvrLUcD.png",
            "fullname": "Yuang Peng",
            "name": "yuangpeng",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.15877",
            "authors": [
                {
                    "_id": "667a170251c8952e0769d84a",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b7fb545233925f253531c8/W50u2G1HK3EtUKHRU189V.jpeg",
                        "isPro": false,
                        "fullname": "Terry Yue Zhuo",
                        "user": "terryyz",
                        "type": "user"
                    },
                    "name": "Terry Yue Zhuo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:44:50.867Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d84b",
                    "name": "Minh Chien Vu",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d84c",
                    "user": {
                        "avatarUrl": "/avatars/d913dff9380e711aa4ecf368e3070f88.svg",
                        "isPro": false,
                        "fullname": "Jenny Chim",
                        "user": "j-chim",
                        "type": "user"
                    },
                    "name": "Jenny Chim",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:45:08.786Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d84d",
                    "name": "Han Hu",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d84e",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660795228685-5feab3a28a3201f8e554c969.png",
                        "isPro": false,
                        "fullname": "Wenhao Yu",
                        "user": "wyu1",
                        "type": "user"
                    },
                    "name": "Wenhao Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:45:22.045Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d84f",
                    "name": "Ratnadira Widyasari",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d850",
                    "user": {
                        "avatarUrl": "/avatars/3637ab04f9342cf15340a47c9645722a.svg",
                        "isPro": false,
                        "fullname": "Imam Nur Bani Yusuf",
                        "user": "imamnurby",
                        "type": "user"
                    },
                    "name": "Imam Nur Bani Yusuf",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:45:32.815Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d851",
                    "user": {
                        "avatarUrl": "/avatars/3ca99b55bc920cf868657ec947e86a3f.svg",
                        "isPro": false,
                        "fullname": "Haolan Zhan",
                        "user": "zhanhaolan",
                        "type": "user"
                    },
                    "name": "Haolan Zhan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:45:39.609Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d852",
                    "user": {
                        "avatarUrl": "/avatars/a9983416adf916267cdc4b179da95336.svg",
                        "isPro": false,
                        "fullname": "junda he",
                        "user": "dennishe97",
                        "type": "user"
                    },
                    "name": "Junda He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:45:45.375Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d853",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1644514433181-62054c0b522e40b4a18d8744.jpeg",
                        "isPro": true,
                        "fullname": "Indraneil Paul",
                        "user": "iNeil77",
                        "type": "user"
                    },
                    "name": "Indraneil Paul",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:45:51.159Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d854",
                    "user": {
                        "avatarUrl": "/avatars/f2ec3670bb984b9e17c2ebd4bb602e35.svg",
                        "isPro": false,
                        "fullname": "Simon Brunner",
                        "user": "SBRUNNE2",
                        "type": "user"
                    },
                    "name": "Simon Brunner",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:45:56.727Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d855",
                    "name": "Chen Gong",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d856",
                    "name": "Thong Hoang",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d857",
                    "user": {
                        "avatarUrl": "/avatars/e901c3aaa16d3a06dff09896ce8a67a2.svg",
                        "isPro": false,
                        "fullname": "Armel Randy Zebaze",
                        "user": "ArmelRandy",
                        "type": "user"
                    },
                    "name": "Armel Randy Zebaze",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:46:11.542Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d858",
                    "user": {
                        "avatarUrl": "/avatars/95be1e289f8ba8b384a47ff65b506168.svg",
                        "isPro": false,
                        "fullname": "XiaohengHong",
                        "user": "hongxh",
                        "type": "user"
                    },
                    "name": "Xiaoheng Hong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:46:18.546Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d859",
                    "user": {
                        "avatarUrl": "/avatars/06f05622e232304d3f0b8c291f3263be.svg",
                        "isPro": true,
                        "fullname": "Wen-Ding Li",
                        "user": "xu3kev",
                        "type": "user"
                    },
                    "name": "Wen-Ding Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:46:25.367Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d85a",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661339692442-6304061c0547362a22a76a17.jpeg",
                        "isPro": false,
                        "fullname": "Jean Kaddour",
                        "user": "JeanKaddour",
                        "type": "user"
                    },
                    "name": "Jean Kaddour",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T07:46:37.344Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d85b",
                    "name": "Ming Xu",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d85c",
                    "user": {
                        "avatarUrl": "/avatars/b6fca49559a61cf66628088c60d26c10.svg",
                        "isPro": false,
                        "fullname": "Zhihan Zhang",
                        "user": "zhihz0535",
                        "type": "user"
                    },
                    "name": "Zhihan Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T08:36:11.547Z",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d85d",
                    "name": "Prateek Yadav",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d85e",
                    "name": "Naman Jain",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d85f",
                    "name": "Alex Gu",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d860",
                    "name": "Zhoujun Cheng",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d861",
                    "name": "Jiawei Liu",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d862",
                    "name": "Qian Liu",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d863",
                    "name": "Zijian Wang",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d864",
                    "name": "David Lo",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d865",
                    "name": "Binyuan Hui",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d866",
                    "name": "Niklas Muennighoff",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d867",
                    "name": "Daniel Fried",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d868",
                    "name": "Xiaoning Du",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d869",
                    "name": "Harm de Vries",
                    "hidden": false
                },
                {
                    "_id": "667a170251c8952e0769d86a",
                    "name": "Leandro Von Werra",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-22T15:52:04.000Z",
            "title": "BigCodeBench: Benchmarking Code Generation with Diverse Function Calls\n  and Complex Instructions",
            "summary": "Automated software engineering has been greatly empowered by the recent\nadvances in Large Language Models (LLMs) for programming. While current\nbenchmarks have shown that LLMs can perform various software engineering tasks\nlike human developers, the majority of their evaluations are limited to short\nand self-contained algorithmic tasks. Solving challenging and practical\nprogramming tasks requires the capability of utilizing diverse function calls\nas tools to efficiently implement functionalities like data analysis and web\ndevelopment. In addition, using multiple tools to solve a task needs\ncompositional reasoning by accurately understanding complex instructions.\nFulfilling both of these characteristics can pose a great challenge for LLMs.\nTo assess how well LLMs can solve challenging and practical programming tasks,\nwe introduce Bench, a benchmark that challenges LLMs to invoke multiple\nfunction calls as tools from 139 libraries and 7 domains for 1,140 fine-grained\nprogramming tasks. To evaluate LLMs rigorously, each programming task\nencompasses 5.6 test cases with an average branch coverage of 99%. In addition,\nwe propose a natural-language-oriented variant of Bench, Benchi, that\nautomatically transforms the original docstrings into short instructions only\nwith essential information. Our extensive evaluation of 60 LLMs shows that LLMs\nare not yet capable of following complex instructions to use function calls\nprecisely, with scores up to 60%, significantly lower than the human\nperformance of 97%. The results underscore the need for further advancements in\nthis area.",
            "upvotes": 26
        },
        "publishedAt": "2024-06-25T06:22:56.645Z",
        "title": "BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15877.png",
        "numComments": 8,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b7fb545233925f253531c8/W50u2G1HK3EtUKHRU189V.jpeg",
            "fullname": "Terry Yue Zhuo",
            "name": "terryyz",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16048",
            "authors": [
                {
                    "_id": "667a6c233f20f47d49334f91",
                    "user": {
                        "avatarUrl": "/avatars/91de4eb48f51bfd6e028c08ccfa98f8c.svg",
                        "isPro": false,
                        "fullname": "Royi Rassin",
                        "user": "Royir",
                        "type": "user"
                    },
                    "name": "Royi Rassin",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-25T07:05:08.346Z",
                    "hidden": false
                },
                {
                    "_id": "667a6c233f20f47d49334f92",
                    "user": {
                        "avatarUrl": "/avatars/75cd5327713e078e5e70c8a8086f3488.svg",
                        "isPro": false,
                        "fullname": "Yaron Fairstein",
                        "user": "yyfairstein",
                        "type": "user"
                    },
                    "name": "Yaron Fairstein",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T11:17:13.015Z",
                    "hidden": false
                },
                {
                    "_id": "667a6c233f20f47d49334f93",
                    "user": {
                        "avatarUrl": "/avatars/a59f8ffec3b87d71e428425d74c74795.svg",
                        "isPro": false,
                        "fullname": "Oren Kalinsky",
                        "user": "orenk",
                        "type": "user"
                    },
                    "name": "Oren Kalinsky",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-25T07:05:08.346Z",
                    "hidden": false
                },
                {
                    "_id": "667a6c233f20f47d49334f94",
                    "name": "Guy Kushilevitz",
                    "hidden": false
                },
                {
                    "_id": "667a6c233f20f47d49334f95",
                    "user": {
                        "avatarUrl": "/avatars/0dcac15e5cc6c9cb89dd7af2818bacb9.svg",
                        "isPro": false,
                        "fullname": "Nachshon Cohen",
                        "user": "nachshonc",
                        "type": "user"
                    },
                    "name": "Nachshon Cohen",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-25T10:41:39.417Z",
                    "hidden": false
                },
                {
                    "_id": "667a6c233f20f47d49334f96",
                    "user": {
                        "avatarUrl": "/avatars/972929b6e560f328a305f99e5365b685.svg",
                        "isPro": false,
                        "fullname": "Alexander Libov",
                        "user": "alibov",
                        "type": "user"
                    },
                    "name": "Alexander Libov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T13:34:22.404Z",
                    "hidden": false
                },
                {
                    "_id": "667a6c233f20f47d49334f97",
                    "name": "Yoav Goldberg",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-23T08:24:08.000Z",
            "title": "Evaluating D-MERIT of Partial-annotation on Information Retrieval",
            "summary": "Retrieval models are often evaluated on partially-annotated datasets. Each\nquery is mapped to a few relevant texts and the remaining corpus is assumed to\nbe irrelevant. As a result, models that successfully retrieve false negatives\nare punished in evaluation. Unfortunately, completely annotating all texts for\nevery query is not resource efficient. In this work, we show that using\npartially-annotated datasets in evaluation can paint a distorted picture. We\ncurate D-MERIT, a passage retrieval evaluation set from Wikipedia, aspiring to\ncontain all relevant passages for each query. Queries describe a group (e.g.,\n``journals about linguistics'') and relevant passages are evidence that\nentities belong to the group (e.g., a passage indicating that Language is a\njournal about linguistics). We show that evaluating on a dataset containing\nannotations for only a subset of the relevant passages might result in\nmisleading ranking of the retrieval systems and that as more relevant texts are\nincluded in the evaluation set, the rankings converge. We propose our dataset\nas a resource for evaluation and our study as a recommendation for balance\nbetween resource-efficiency and reliable evaluation when annotating evaluation\nsets for text retrieval.",
            "upvotes": 24
        },
        "publishedAt": "2024-06-25T05:35:26.369Z",
        "title": "Evaluating D-MERIT of Partial-annotation on Information Retrieval",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16048.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/91de4eb48f51bfd6e028c08ccfa98f8c.svg",
            "fullname": "Royi Rassin",
            "name": "Royir",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16852",
            "authors": [
                {
                    "_id": "667a3a30b032d9a6594c8c99",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63565cc56d7fcf1bedb7d347/XGcHP4VkO_oieA1gZ4IAX.jpeg",
                        "isPro": false,
                        "fullname": "Zhang Peiyuan",
                        "user": "PY007",
                        "type": "user"
                    },
                    "name": "Peiyuan Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:11.134Z",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8c9a",
                    "user": {
                        "avatarUrl": "/avatars/4c1720db323082e644babeb827c6f5d4.svg",
                        "isPro": false,
                        "fullname": "kcz",
                        "user": "kcz358",
                        "type": "user"
                    },
                    "name": "Kaichen Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:08.902Z",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8c9b",
                    "name": "Bo Li",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8c9c",
                    "name": "Guangtao Zeng",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8c9d",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1658152070753-62b5777f593a2c49da69dc02.jpeg",
                        "isPro": false,
                        "fullname": "Jingkang Yang",
                        "user": "Jingkang",
                        "type": "user"
                    },
                    "name": "Jingkang Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:07:05.709Z",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8c9e",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png",
                        "isPro": false,
                        "fullname": "Zhang Yuanhan",
                        "user": "ZhangYuanhan",
                        "type": "user"
                    },
                    "name": "Yuanhan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:07:43.895Z",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8c9f",
                    "name": "Ziyue Wang",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8ca0",
                    "name": "Haoran Tan",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8ca1",
                    "user": {
                        "avatarUrl": "/avatars/430560ec2c2547f819225769ab432f30.svg",
                        "isPro": false,
                        "fullname": "Chunyuan Li",
                        "user": "Chunyuan24",
                        "type": "user"
                    },
                    "name": "Chunyuan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:09:27.187Z",
                    "hidden": false
                },
                {
                    "_id": "667a3a30b032d9a6594c8ca2",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
                        "isPro": false,
                        "fullname": "Ziwei Liu",
                        "user": "liuziwei7",
                        "type": "user"
                    },
                    "name": "Ziwei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:09:40.723Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T17:58:06.000Z",
            "title": "Long Context Transfer from Language to Vision",
            "summary": "Video sequences offer valuable temporal information, but existing large\nmultimodal models (LMMs) fall short in understanding extremely long videos.\nMany works address this by reducing the number of visual tokens using visual\nresamplers. Alternatively, in this paper, we approach this problem from the\nperspective of the language model. By simply extrapolating the context length\nof the language backbone, we enable LMMs to comprehend orders of magnitude more\nvisual tokens without any video training. We call this phenomenon long context\ntransfer and carefully ablate its properties. To effectively measure LMMs'\nability to generalize to long contexts in the vision modality, we develop\nV-NIAH (Visual Needle-In-A-Haystack), a purely synthetic long vision benchmark\ninspired by the language model's NIAH test. Our proposed Long Video Assistant\n(LongVA) can process 2000 frames or over 200K visual tokens without additional\ncomplexities. With its extended context length, LongVA achieves\nstate-of-the-art performance on Video-MME among 7B-scale models by densely\nsampling more input frames. Our work is open-sourced at\nhttps://github.com/EvolvingLMMs-Lab/LongVA.",
            "upvotes": 16
        },
        "publishedAt": "2024-06-25T02:19:43.401Z",
        "title": "Long Context Transfer from Language to Vision",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63565cc56d7fcf1bedb7d347/Oe1FKbY5dw1xBDEDmvvp6.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16852.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63565cc56d7fcf1bedb7d347/XGcHP4VkO_oieA1gZ4IAX.jpeg",
            "fullname": "Zhang Peiyuan",
            "name": "PY007",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16338",
            "authors": [
                {
                    "_id": "667a2f6cb2401c64d7e0169c",
                    "user": {
                        "avatarUrl": "/avatars/a711a6aa35757dfd7b78b26098a964fc.svg",
                        "isPro": false,
                        "fullname": "Yuxuan Wang",
                        "user": "ColorfulAI",
                        "type": "user"
                    },
                    "name": "Yuxuan Wang",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-06-25T05:47:11.864Z",
                    "hidden": false
                },
                {
                    "_id": "667a2f6cb2401c64d7e0169d",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643672220b2c0d86d0b0f639/8nqZku8HxsSL_zR3XJPqK.png",
                        "isPro": false,
                        "fullname": "Yueqian Wang",
                        "user": "wangyueqian",
                        "type": "user"
                    },
                    "name": "Yueqian Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:14:29.905Z",
                    "hidden": false
                },
                {
                    "_id": "667a2f6cb2401c64d7e0169e",
                    "name": "Dongyan Zhao",
                    "hidden": false
                },
                {
                    "_id": "667a2f6cb2401c64d7e0169f",
                    "user": {
                        "avatarUrl": "/avatars/9112bfeed598dfabf9e077e69e09ecc9.svg",
                        "isPro": false,
                        "fullname": "Cihang Xie",
                        "user": "cihangxie",
                        "type": "user"
                    },
                    "name": "Cihang Xie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:14:51.184Z",
                    "hidden": false
                },
                {
                    "_id": "667a2f6cb2401c64d7e016a0",
                    "user": {
                        "avatarUrl": "/avatars/d9d0420f7ddfe2f3a7e029fb05f1c89f.svg",
                        "isPro": false,
                        "fullname": "Zilong Zheng",
                        "user": "zlzheng",
                        "type": "user"
                    },
                    "name": "Zilong Zheng",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-25T02:46:08.771Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T06:21:59.000Z",
            "title": "VideoHallucer: Evaluating Intrinsic and Extrinsic Hallucinations in\n  Large Video-Language Models",
            "summary": "Recent advancements in Multimodal Large Language Models (MLLMs) have extended\ntheir capabilities to video understanding. Yet, these models are often plagued\nby \"hallucinations\", where irrelevant or nonsensical content is generated,\ndeviating from the actual video context. This work introduces VideoHallucer,\nthe first comprehensive benchmark for hallucination detection in large\nvideo-language models (LVLMs). VideoHallucer categorizes hallucinations into\ntwo main types: intrinsic and extrinsic, offering further subcategories for\ndetailed analysis, including object-relation, temporal, semantic detail,\nextrinsic factual, and extrinsic non-factual hallucinations. We adopt an\nadversarial binary VideoQA method for comprehensive evaluation, where pairs of\nbasic and hallucinated questions are crafted strategically. By evaluating\neleven LVLMs on VideoHallucer, we reveal that i) the majority of current models\nexhibit significant issues with hallucinations; ii) while scaling datasets and\nparameters improves models' ability to detect basic visual cues and\ncounterfactuals, it provides limited benefit for detecting extrinsic factual\nhallucinations; iii) existing models are more adept at detecting facts than\nidentifying hallucinations. As a byproduct, these analyses further instruct the\ndevelopment of our self-PEP framework, achieving an average of 5.38%\nimprovement in hallucination resistance across all model architectures.",
            "upvotes": 16
        },
        "publishedAt": "2024-06-25T01:19:22.379Z",
        "title": "VideoHallucer: Evaluating Intrinsic and Extrinsic Hallucinations in Large Video-Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16338.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/d9d0420f7ddfe2f3a7e029fb05f1c89f.svg",
            "fullname": "Zilong Zheng",
            "name": "zlzheng",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16860",
            "authors": [
                {
                    "_id": "667a74223463f1209e7ec98f",
                    "name": "Shengbang Tong",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec990",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626dc5105f7327906f0b2a4e/QCSzuwYqsv8ozRnusVb-F.jpeg",
                        "isPro": false,
                        "fullname": "Ellis Brown",
                        "user": "ellisbrown",
                        "type": "user"
                    },
                    "name": "Ellis Brown",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T08:17:45.589Z",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec991",
                    "user": {
                        "avatarUrl": "/avatars/557dd9d4707e3b38e0805dfb87c08004.svg",
                        "isPro": false,
                        "fullname": "Penghao Wu",
                        "user": "craigwu",
                        "type": "user"
                    },
                    "name": "Penghao Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:36:22.748Z",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec992",
                    "user": {
                        "avatarUrl": "/avatars/94483f3a1fd26ee43b32510538f1cd80.svg",
                        "isPro": false,
                        "fullname": "Sanghyun Woo",
                        "user": "shwoo93",
                        "type": "user"
                    },
                    "name": "Sanghyun Woo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:36:28.657Z",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec993",
                    "user": {
                        "avatarUrl": "/avatars/4b3655264f8119f3a9f22bd547f0100b.svg",
                        "isPro": false,
                        "fullname": "Manoj Middepogu",
                        "user": "manoj1729",
                        "type": "user"
                    },
                    "name": "Manoj Middepogu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:36:33.894Z",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec994",
                    "name": "Sai Charitha Akula",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec995",
                    "user": {
                        "avatarUrl": "/avatars/795c63f2394080eec78ca7981d4a1f78.svg",
                        "isPro": false,
                        "fullname": "Jihan Yang",
                        "user": "jihanyang",
                        "type": "user"
                    },
                    "name": "Jihan Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:37:17.179Z",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec996",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1652346592327-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Shusheng Yang",
                        "user": "ShushengYang",
                        "type": "user"
                    },
                    "name": "Shusheng Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:37:31.788Z",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec997",
                    "name": "Adithya Iyer",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec998",
                    "user": {
                        "avatarUrl": "/avatars/0f57068a138cb181e9451bfc1ed3d1c0.svg",
                        "isPro": false,
                        "fullname": "Xichen Pan",
                        "user": "xcpan",
                        "type": "user"
                    },
                    "name": "Xichen Pan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:38:09.129Z",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec999",
                    "name": "Austin Wang",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec99a",
                    "name": "Rob Fergus",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec99b",
                    "user": {
                        "avatarUrl": "/avatars/9156dc406ed3f9ee62b73657ac20f5ed.svg",
                        "isPro": false,
                        "fullname": "Yann LeCun",
                        "user": "ylecun",
                        "type": "user"
                    },
                    "name": "Yann LeCun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:39:07.946Z",
                    "hidden": false
                },
                {
                    "_id": "667a74223463f1209e7ec99c",
                    "user": {
                        "avatarUrl": "/avatars/216e12b77e45ac5f1fa20932f5745411.svg",
                        "isPro": false,
                        "fullname": "Saining Xie",
                        "user": "sainx",
                        "type": "user"
                    },
                    "name": "Saining Xie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:39:00.996Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T17:59:42.000Z",
            "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
            "summary": "We introduce Cambrian-1, a family of multimodal LLMs (MLLMs) designed with a\nvision-centric approach. While stronger language models can enhance multimodal\ncapabilities, the design choices for vision components are often insufficiently\nexplored and disconnected from visual representation learning research. This\ngap hinders accurate sensory grounding in real-world scenarios. Our study uses\nLLMs and visual instruction tuning as an interface to evaluate various visual\nrepresentations, offering new insights into different models and architectures\n-- self-supervised, strongly supervised, or combinations thereof -- based on\nexperiments with over 20 vision encoders. We critically examine existing MLLM\nbenchmarks, addressing the difficulties involved in consolidating and\ninterpreting results from various tasks, and introduce a new vision-centric\nbenchmark, CV-Bench. To further improve visual grounding, we propose the\nSpatial Vision Aggregator (SVA), a dynamic and spatially-aware connector that\nintegrates high-resolution vision features with LLMs while reducing the number\nof tokens. Additionally, we discuss the curation of high-quality visual\ninstruction-tuning data from publicly available sources, emphasizing the\nimportance of data source balancing and distribution ratio. Collectively,\nCambrian-1 not only achieves state-of-the-art performance but also serves as a\ncomprehensive, open cookbook for instruction-tuned MLLMs. We provide model\nweights, code, supporting tools, datasets, and detailed instruction-tuning and\nevaluation recipes. We hope our release will inspire and accelerate\nadvancements in multimodal systems and visual representation learning.",
            "upvotes": 13
        },
        "publishedAt": "2024-06-25T06:16:03.544Z",
        "title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/626dc5105f7327906f0b2a4e/qVHyBDnbjhDWiSJZqPLpi.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16860.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626dc5105f7327906f0b2a4e/QCSzuwYqsv8ozRnusVb-F.jpeg",
            "fullname": "Ellis Brown",
            "name": "ellisbrown",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16260",
            "authors": [
                {
                    "_id": "667a29ea42ef3dbfae30e96b",
                    "user": {
                        "avatarUrl": "/avatars/fd3f8a844b391be6c1ac2ea89b228f5a.svg",
                        "isPro": false,
                        "fullname": "Tan Zhen Xiong",
                        "user": "ZhenXiong",
                        "type": "user"
                    },
                    "name": "Zhenxiong Tan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:05:14.275Z",
                    "hidden": false
                },
                {
                    "_id": "667a29ea42ef3dbfae30e96c",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/634cfebc350bcee9bed20a4d/fN47nN5rhw-HJaFLBZWQy.png",
                        "isPro": false,
                        "fullname": "Xingyi Yang",
                        "user": "adamdad",
                        "type": "user"
                    },
                    "name": "Xingyi Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:32.043Z",
                    "hidden": false
                },
                {
                    "_id": "667a29ea42ef3dbfae30e96d",
                    "user": {
                        "avatarUrl": "/avatars/35d2c8d6615d8ed8ad6d695e5d748ab2.svg",
                        "isPro": false,
                        "fullname": "Songhua Liu",
                        "user": "flyingman",
                        "type": "user"
                    },
                    "name": "Songhua Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:05:22.109Z",
                    "hidden": false
                },
                {
                    "_id": "667a29ea42ef3dbfae30e96e",
                    "user": {
                        "avatarUrl": "/avatars/9d5b1bb2a41928e08176b703935133ab.svg",
                        "isPro": false,
                        "fullname": "Wangxinchao",
                        "user": "wxcTest",
                        "type": "user"
                    },
                    "name": "Xinchao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:05:44.065Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T01:56:12.000Z",
            "title": "Video-Infinity: Distributed Long Video Generation",
            "summary": "Diffusion models have recently achieved remarkable results for video\ngeneration. Despite the encouraging performances, the generated videos are\ntypically constrained to a small number of frames, resulting in clips lasting\nmerely a few seconds. The primary challenges in producing longer videos include\nthe substantial memory requirements and the extended processing time required\non a single GPU. A straightforward solution would be to split the workload\nacross multiple GPUs, which, however, leads to two issues: (1) ensuring all\nGPUs communicate effectively to share timing and context information, and (2)\nmodifying existing video diffusion models, which are usually trained on short\nsequences, to create longer videos without additional training. To tackle\nthese, in this paper we introduce Video-Infinity, a distributed inference\npipeline that enables parallel processing across multiple GPUs for long-form\nvideo generation. Specifically, we propose two coherent mechanisms: Clip\nparallelism and Dual-scope attention. Clip parallelism optimizes the gathering\nand sharing of context information across GPUs which minimizes communication\noverhead, while Dual-scope attention modulates the temporal self-attention to\nbalance local and global contexts efficiently across the devices. Together, the\ntwo mechanisms join forces to distribute the workload and enable the fast\ngeneration of long videos. Under an 8 x Nvidia 6000 Ada GPU (48G) setup, our\nmethod generates videos up to 2,300 frames in approximately 5 minutes, enabling\nlong video generation at a speed 100 times faster than the prior methods.",
            "upvotes": 13
        },
        "publishedAt": "2024-06-25T00:53:32.910Z",
        "title": "Video-Infinity: Distributed Long Video Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16260.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/634cfebc350bcee9bed20a4d/fN47nN5rhw-HJaFLBZWQy.png",
            "fullname": "Xingyi Yang",
            "name": "adamdad",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16768",
            "authors": [
                {
                    "_id": "667a598613c37a0fe4a8b06e",
                    "user": {
                        "avatarUrl": "/avatars/273959d87f0c67747588cf0700d64039.svg",
                        "isPro": false,
                        "fullname": "Alexandre Rame",
                        "user": "alexrame",
                        "type": "user"
                    },
                    "name": "Alexandre Ram",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:17:55.519Z",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b06f",
                    "user": {
                        "avatarUrl": "/avatars/b21069bc2d7ee4cc1508008e3c8ade64.svg",
                        "isPro": false,
                        "fullname": "Johan Ferret",
                        "user": "ferretj",
                        "type": "user"
                    },
                    "name": "Johan Ferret",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:18:03.169Z",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b070",
                    "name": "Nino Vieillard",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b071",
                    "user": {
                        "avatarUrl": "/avatars/440f88769da1113d6158fe7e0514ead3.svg",
                        "isPro": false,
                        "fullname": "Robert Dadashi",
                        "user": "ddsh",
                        "type": "user"
                    },
                    "name": "Robert Dadashi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:18:17.076Z",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b072",
                    "user": {
                        "avatarUrl": "/avatars/da2ee162f33c681e3d1c4d1e6d44dcbd.svg",
                        "isPro": false,
                        "fullname": "Lonard Hussenot",
                        "user": "leonardhussenot",
                        "type": "user"
                    },
                    "name": "Lonard Hussenot",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:18:24.900Z",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b073",
                    "user": {
                        "avatarUrl": "/avatars/7aface0db75500a2b0ede75179be35ce.svg",
                        "isPro": false,
                        "fullname": "Pierre-Louis Cedoz",
                        "user": "plcedoz",
                        "type": "user"
                    },
                    "name": "Pierre-Louis Cedoz",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:18:30.765Z",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b074",
                    "user": {
                        "avatarUrl": "/avatars/6874f0e5a7edca4145c57d7908f89840.svg",
                        "isPro": false,
                        "fullname": "Pier Giuseppe Sessa",
                        "user": "piergs",
                        "type": "user"
                    },
                    "name": "Pier Giuseppe Sessa",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:18:37.543Z",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b075",
                    "name": "Sertan Girgin",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b076",
                    "user": {
                        "avatarUrl": "/avatars/975c1cc3eb2f97cf8e848162056d5bea.svg",
                        "isPro": false,
                        "fullname": "Arthur Douillard",
                        "user": "ArthurDouillard",
                        "type": "user"
                    },
                    "name": "Arthur Douillard",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:32:35.814Z",
                    "hidden": false
                },
                {
                    "_id": "667a598613c37a0fe4a8b077",
                    "name": "Olivier Bachem",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T16:24:34.000Z",
            "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
            "summary": "Reinforcement learning from human feedback (RLHF) aligns large language\nmodels (LLMs) by encouraging their generations to have high rewards, using a\nreward model trained on human preferences. To prevent the forgetting of\npre-trained knowledge, RLHF usually incorporates a KL regularization; this\nforces the policy to remain close to its supervised fine-tuned initialization,\nthough it hinders the reward optimization. To tackle the trade-off between KL\nand reward, in this paper we introduce a novel alignment strategy named Weight\nAveraged Rewarded Policies (WARP). WARP merges policies in the weight space at\nthree distinct stages. First, it uses the exponential moving average of the\npolicy as a dynamic anchor in the KL regularization. Second, it applies\nspherical interpolation to merge independently fine-tuned policies into a new\nenhanced one. Third, it linearly interpolates between this merged model and the\ninitialization, to recover features from pre-training. This procedure is then\napplied iteratively, with each iteration's final model used as an advanced\ninitialization for the next, progressively refining the KL-reward Pareto front,\nachieving superior rewards at fixed KL. Experiments with GEMMA policies\nvalidate that WARP improves their quality and alignment, outperforming other\nopen-source LLMs.",
            "upvotes": 12
        },
        "publishedAt": "2024-06-25T04:17:41.085Z",
        "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63c94ede00104ea998de19a6/bSbC8D0TMhQT__RYpfM04.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16768.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/273959d87f0c67747588cf0700d64039.svg",
            "fullname": "Alexandre Rame",
            "name": "alexrame",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16758",
            "authors": [
                {
                    "_id": "667a2585e737163dcb22f1df",
                    "user": {
                        "avatarUrl": "/avatars/3c8b679bc72f30c547782579e9592bb1.svg",
                        "isPro": false,
                        "fullname": "Euiin Yi",
                        "user": "euiin",
                        "type": "user"
                    },
                    "name": "Euiin Yi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:15:32.506Z",
                    "hidden": false
                },
                {
                    "_id": "667a2585e737163dcb22f1e0",
                    "user": {
                        "avatarUrl": "/avatars/a797b72363e06cd2222165493bf7e39c.svg",
                        "isPro": false,
                        "fullname": "Taehyeon Kim",
                        "user": "Kthyeon",
                        "type": "user"
                    },
                    "name": "Taehyeon Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:36.931Z",
                    "hidden": false
                },
                {
                    "_id": "667a2585e737163dcb22f1e1",
                    "name": "Hongseok Jeung",
                    "hidden": false
                },
                {
                    "_id": "667a2585e737163dcb22f1e2",
                    "user": {
                        "avatarUrl": "/avatars/b16ebf9a9a2533807b747588446c45b9.svg",
                        "isPro": false,
                        "fullname": "Du-Seong Chang",
                        "user": "Du-Seong",
                        "type": "user"
                    },
                    "name": "Du-Seong Chang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:15:43.224Z",
                    "hidden": false
                },
                {
                    "_id": "667a2585e737163dcb22f1e3",
                    "name": "Se-Young Yun",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T16:06:50.000Z",
            "title": "Towards Fast Multilingual LLM Inference: Speculative Decoding and\n  Specialized Drafters",
            "summary": "Large language models (LLMs) have revolutionized natural language processing\nand broadened their applicability across diverse commercial applications.\nHowever, the deployment of these models is constrained by high inference time\nin multilingual settings. To mitigate this challenge, this paper explores a\ntraining recipe of an assistant model in speculative decoding, which are\nleveraged to draft and-then its future tokens are verified by the target LLM.\nWe show that language-specific draft models, optimized through a targeted\npretrain-and-finetune strategy, substantially brings a speedup of inference\ntime compared to the previous methods. We validate these models across various\nlanguages in inference time, out-of-domain speedup, and GPT-4o evaluation.",
            "upvotes": 12
        },
        "publishedAt": "2024-06-25T00:38:07.358Z",
        "title": "Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16758.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/a797b72363e06cd2222165493bf7e39c.svg",
            "fullname": "Taehyeon Kim",
            "name": "Kthyeon",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16690",
            "authors": [
                {
                    "_id": "667a4bbdb2401c64d7ede147",
                    "user": {
                        "avatarUrl": "/avatars/fd911e9143d1a7aedd21a7d611543fcc.svg",
                        "isPro": false,
                        "fullname": "Xuyang Shen",
                        "user": "Ryan1122",
                        "type": "user"
                    },
                    "name": "Xuyang Shen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:02.849Z",
                    "hidden": false
                },
                {
                    "_id": "667a4bbdb2401c64d7ede148",
                    "name": "Dong Li",
                    "hidden": false
                },
                {
                    "_id": "667a4bbdb2401c64d7ede149",
                    "user": {
                        "avatarUrl": "/avatars/7eaebf3438323d9e6629cb25f541ffc7.svg",
                        "isPro": false,
                        "fullname": "lengruitao",
                        "user": "lengruitao",
                        "type": "user"
                    },
                    "name": "Ruitao Leng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:16:54.446Z",
                    "hidden": false
                },
                {
                    "_id": "667a4bbdb2401c64d7ede14a",
                    "user": {
                        "avatarUrl": "/avatars/f0e0f2830c5cb7428cbbc9634d95c34b.svg",
                        "isPro": false,
                        "fullname": "Zhen Qin",
                        "user": "zhenqincn",
                        "type": "user"
                    },
                    "name": "Zhen Qin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:17:01.859Z",
                    "hidden": false
                },
                {
                    "_id": "667a4bbdb2401c64d7ede14b",
                    "user": {
                        "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
                        "isPro": false,
                        "fullname": "Weigao Sun",
                        "user": "weigao266",
                        "type": "user"
                    },
                    "name": "Weigao Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:17:08.568Z",
                    "hidden": false
                },
                {
                    "_id": "667a4bbdb2401c64d7ede14c",
                    "user": {
                        "avatarUrl": "/avatars/7b5f17b184e93f1e45b4038c877c034a.svg",
                        "isPro": false,
                        "fullname": "Yiran Zhong",
                        "user": "zhongyiran1994",
                        "type": "user"
                    },
                    "name": "Yiran Zhong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:17:28.460Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T14:51:31.000Z",
            "title": "Scaling Laws for Linear Complexity Language Models",
            "summary": "The interest in linear complexity models for large language models is on the\nrise, although their scaling capacity remains uncertain. In this study, we\npresent the scaling laws for linear complexity language models to establish a\nfoundation for their scalability. Specifically, we examine the scaling\nbehaviors of three efficient linear architectures. These include TNL, a linear\nattention model with data-independent decay; HGRN2, a linear RNN with\ndata-dependent decay; and cosFormer2, a linear attention model without decay.\nWe also include LLaMA as a baseline architecture for softmax attention for\ncomparison. These models were trained with six variants, ranging from 70M to 7B\nparameters on a 300B-token corpus, and evaluated with a total of 1,376\nintermediate checkpoints on various downstream tasks. These tasks include\nvalidation loss, commonsense reasoning, and information retrieval and\ngeneration. The study reveals that existing linear complexity language models\nexhibit similar scaling capabilities as conventional transformer-based models\nwhile also demonstrating superior linguistic proficiency and knowledge\nretention.",
            "upvotes": 9
        },
        "publishedAt": "2024-06-25T03:18:20.262Z",
        "title": "Scaling Laws for Linear Complexity Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16690.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/fd911e9143d1a7aedd21a7d611543fcc.svg",
            "fullname": "Xuyang Shen",
            "name": "Ryan1122",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.14833",
            "authors": [
                {
                    "_id": "667a35b89f78b2d01bd1b5b7",
                    "user": {
                        "avatarUrl": "/avatars/8a76c27fe6c71eb98a28b4ebfb90336d.svg",
                        "isPro": false,
                        "fullname": "Guo",
                        "user": "YiDuo1999",
                        "type": "user"
                    },
                    "name": "Yiduo Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:28:43.723Z",
                    "hidden": false
                },
                {
                    "_id": "667a35b89f78b2d01bd1b5b8",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/641a6895fb5ffff5ac79d593/dFR_ofjbqCrcqGa9R3MMq.jpeg",
                        "isPro": false,
                        "fullname": "Jie Fu",
                        "user": "bigaidream",
                        "type": "user"
                    },
                    "name": "Jie Fu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T08:58:55.208Z",
                    "hidden": false
                },
                {
                    "_id": "667a35b89f78b2d01bd1b5b9",
                    "name": "Huishuai Zhang",
                    "hidden": false
                },
                {
                    "_id": "667a35b89f78b2d01bd1b5ba",
                    "name": "Dongyan Zhao",
                    "hidden": false
                },
                {
                    "_id": "667a35b89f78b2d01bd1b5bb",
                    "user": {
                        "avatarUrl": "/avatars/11caacefc68c1259dbc8764cc4340481.svg",
                        "isPro": false,
                        "fullname": "Yikang Shen",
                        "user": "YikangS",
                        "type": "user"
                    },
                    "name": "Yikang Shen",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-06-25T03:12:57.090Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-21T02:28:37.000Z",
            "title": "Efficient Continual Pre-training by Mitigating the Stability Gap",
            "summary": "Continual pre-training has increasingly become the predominant approach for\nadapting Large Language Models (LLMs) to new domains. This process involves\nupdating the pre-trained LLM with a corpus from a new domain, resulting in a\nshift in the training distribution. To study the behavior of LLMs during this\nshift, we measured the model's performance throughout the continual\npre-training process. we observed a temporary performance drop at the\nbeginning, followed by a recovery phase, a phenomenon known as the \"stability\ngap,\" previously noted in vision models classifying new classes. To address\nthis issue and enhance LLM performance within a fixed compute budget, we\npropose three effective strategies: (1) Continually pre-training the LLM on a\nsubset with a proper size for multiple epochs, resulting in faster performance\nrecovery than pre-training the LLM on a large corpus in a single epoch; (2)\nPre-training the LLM only on high-quality sub-corpus, which rapidly boosts\ndomain performance; and (3) Using a data mixture similar to the pre-training\ndata to reduce distribution gap. We conduct various experiments on Llama-family\nmodels to validate the effectiveness of our strategies in both medical\ncontinual pre-training and instruction tuning. For example, our strategies\nimprove the average medical task performance of the OpenLlama-3B model from\n36.2% to 40.7% with only 40% of the original training budget and enhance the\naverage general task performance without causing forgetting. Furthermore, we\napply our strategies to the Llama-3-8B model. The resulting model,\nLlama-3-Physician, achieves the best medical performance among current\nopen-source models, and performs comparably to or even better than GPT-4 on\nseveral medical benchmarks. We release our models at\nhttps://huggingface.co/YiDuo1999/Llama-3-Physician-8B-Instruct.",
            "upvotes": 9
        },
        "publishedAt": "2024-06-25T01:44:48.093Z",
        "title": "Efficient Continual Pre-training by Mitigating the Stability Gap",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14833.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/8a76c27fe6c71eb98a28b4ebfb90336d.svg",
            "fullname": "Guo",
            "name": "YiDuo1999",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.15927",
            "authors": [
                {
                    "_id": "667a6283becec8fc51091263",
                    "user": {
                        "avatarUrl": "/avatars/8c9503e43f403d655b11ea5c6e23ae79.svg",
                        "isPro": false,
                        "fullname": "Jannik",
                        "user": "jlko",
                        "type": "user"
                    },
                    "name": "Jannik Kossen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T11:18:56.617Z",
                    "hidden": false
                },
                {
                    "_id": "667a6283becec8fc51091264",
                    "user": {
                        "avatarUrl": "/avatars/e90d729b9ca8e583175e8f61972cf888.svg",
                        "isPro": false,
                        "fullname": "Jiatong Han",
                        "user": "Juliushanhanhan",
                        "type": "user"
                    },
                    "name": "Jiatong Han",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:45:12.741Z",
                    "hidden": false
                },
                {
                    "_id": "667a6283becec8fc51091265",
                    "name": "Muhammed Razzak",
                    "hidden": false
                },
                {
                    "_id": "667a6283becec8fc51091266",
                    "user": {
                        "avatarUrl": "/avatars/df939fc527b4beffcf7d0001710578e1.svg",
                        "isPro": false,
                        "fullname": "Lisa Schut",
                        "user": "schutje",
                        "type": "user"
                    },
                    "name": "Lisa Schut",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:45:22.511Z",
                    "hidden": false
                },
                {
                    "_id": "667a6283becec8fc51091267",
                    "user": {
                        "avatarUrl": "/avatars/5efafc534010f3025fe3ab862a681369.svg",
                        "isPro": false,
                        "fullname": "Shreshth Malik",
                        "user": "s-a-malik",
                        "type": "user"
                    },
                    "name": "Shreshth Malik",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:45:28.044Z",
                    "hidden": false
                },
                {
                    "_id": "667a6283becec8fc51091268",
                    "name": "Yarin Gal",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-22T19:46:06.000Z",
            "title": "Semantic Entropy Probes: Robust and Cheap Hallucination Detection in\n  LLMs",
            "summary": "We propose semantic entropy probes (SEPs), a cheap and reliable method for\nuncertainty quantification in Large Language Models (LLMs). Hallucinations,\nwhich are plausible-sounding but factually incorrect and arbitrary model\ngenerations, present a major challenge to the practical adoption of LLMs.\nRecent work by Farquhar et al. (2024) proposes semantic entropy (SE), which can\ndetect hallucinations by estimating uncertainty in the space semantic meaning\nfor a set of model generations. However, the 5-to-10-fold increase in\ncomputation cost associated with SE computation hinders practical adoption. To\naddress this, we propose SEPs, which directly approximate SE from the hidden\nstates of a single generation. SEPs are simple to train and do not require\nsampling multiple model generations at test time, reducing the overhead of\nsemantic uncertainty quantification to almost zero. We show that SEPs retain\nhigh performance for hallucination detection and generalize better to\nout-of-distribution data than previous probing methods that directly predict\nmodel accuracy. Our results across models and tasks suggest that model hidden\nstates capture SE, and our ablation studies give further insights into the\ntoken positions and model layers for which this is the case.",
            "upvotes": 7
        },
        "publishedAt": "2024-06-25T05:34:04.154Z",
        "title": "Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15927.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/8c9503e43f403d655b11ea5c6e23ae79.svg",
            "fullname": "Jannik",
            "name": "jlko",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16747",
            "authors": [
                {
                    "_id": "667a851b67be4d7b18f3ff57",
                    "user": {
                        "avatarUrl": "/avatars/2476676fe910a01d96b9f42e068353ed.svg",
                        "isPro": false,
                        "fullname": "Chao Lou",
                        "user": "chaochaoL",
                        "type": "user"
                    },
                    "name": "Chao Lou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:34:33.454Z",
                    "hidden": false
                },
                {
                    "_id": "667a851b67be4d7b18f3ff58",
                    "user": {
                        "avatarUrl": "/avatars/b55dd3d6fcb3ccac2e3880d01a9bdc63.svg",
                        "isPro": false,
                        "fullname": "Zixia Jia",
                        "user": "vickyandkekey",
                        "type": "user"
                    },
                    "name": "Zixia Jia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:34:39.717Z",
                    "hidden": false
                },
                {
                    "_id": "667a851b67be4d7b18f3ff59",
                    "user": {
                        "avatarUrl": "/avatars/d9d0420f7ddfe2f3a7e029fb05f1c89f.svg",
                        "isPro": false,
                        "fullname": "Zilong Zheng",
                        "user": "zlzheng",
                        "type": "user"
                    },
                    "name": "Zilong Zheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:35:01.138Z",
                    "hidden": false
                },
                {
                    "_id": "667a851b67be4d7b18f3ff5a",
                    "name": "Kewei Tu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T15:55:59.000Z",
            "title": "Sparser is Faster and Less is More: Efficient Sparse Attention for\n  Long-Range Transformers",
            "summary": "Accommodating long sequences efficiently in autoregressive Transformers,\nespecially within an extended context window, poses significant challenges due\nto the quadratic computational complexity and substantial KV memory\nrequirements inherent in self-attention mechanisms. In this work, we introduce\nSPARSEK Attention, a novel sparse attention mechanism designed to overcome\nthese computational and memory obstacles while maintaining performance. Our\napproach integrates a scoring network and a differentiable top-k mask operator,\nSPARSEK, to select a constant number of KV pairs for each query, thereby\nenabling gradient-based optimization. As a result, SPARSEK Attention offers\nlinear time complexity and constant memory footprint during generation.\nExperimental results reveal that SPARSEK Attention outperforms previous sparse\nattention methods and provides significant speed improvements during both\ntraining and inference, particularly in language modeling and downstream tasks.\nFurthermore, our method can be seamlessly integrated into pre-trained Large\nLanguage Models (LLMs) with minimal fine-tuning, offering a practical solution\nfor effectively managing long-range dependencies in diverse applications.",
            "upvotes": 5
        },
        "publishedAt": "2024-06-25T07:35:51.247Z",
        "title": "Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63a95a6a7930fa8c7dd63d4e/N2PVSbkk9p9Yr_hXtb0m9.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16747.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/d9d0420f7ddfe2f3a7e029fb05f1c89f.svg",
            "fullname": "Zilong Zheng",
            "name": "zlzheng",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16235",
            "authors": [
                {
                    "_id": "667a3d632d6477209ea8b46c",
                    "name": "Xiaochen Li",
                    "hidden": false
                },
                {
                    "_id": "667a3d632d6477209ea8b46d",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61424bf4f0d914a5f606a823/0td8lR4elBaVvJUD9Pojh.png",
                        "isPro": false,
                        "fullname": "Yong Zheng-Xin",
                        "user": "yongzx",
                        "type": "user"
                    },
                    "name": "Zheng-Xin Yong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:04.796Z",
                    "hidden": false
                },
                {
                    "_id": "667a3d632d6477209ea8b46e",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/608849cadf398c3b285ce95b/roABeBreO9pZRPxzVoOPM.jpeg",
                        "isPro": false,
                        "fullname": "Stephen Bach",
                        "user": "SteveBach",
                        "type": "user"
                    },
                    "name": "Stephen H. Bach",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:34:27.134Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-23T22:53:47.000Z",
            "title": "Preference Tuning For Toxicity Mitigation Generalizes Across Languages",
            "summary": "Detoxifying multilingual Large Language Models (LLMs) has become crucial due\nto their increasing global use. In this work, we explore zero-shot\ncross-lingual generalization of preference tuning in detoxifying LLMs. Unlike\nprevious studies that show limited cross-lingual generalization for other\nsafety tasks, we demonstrate that Direct Preference Optimization (DPO) training\nwith only English data can significantly reduce toxicity in multilingual\nopen-ended generations. For example, the probability of mGPT-1.3B generating\ntoxic continuations drops from 46.8% to 3.9% across 17 different languages\nafter training. Our results also extend to other multilingual LLMs, such as\nBLOOM, Llama3, and Aya-23. Using mechanistic interpretability tools like causal\nintervention and activation analysis, we identified the dual multilinguality\nproperty of MLP layers in LLMs, which explains the cross-lingual generalization\nof DPO. Finally, we show that bilingual sentence retrieval can predict the\ncross-lingual transferability of DPO preference tuning.",
            "upvotes": 5
        },
        "publishedAt": "2024-06-25T02:20:47.199Z",
        "title": "Preference Tuning For Toxicity Mitigation Generalizes Across Languages",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16235.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61424bf4f0d914a5f606a823/0td8lR4elBaVvJUD9Pojh.png",
            "fullname": "Yong Zheng-Xin",
            "name": "yongzx",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.14051",
            "authors": [
                {
                    "_id": "667a77f4536de14d364d93a1",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1640016076582-60faa5d92336d38bec48b0e4.png",
                        "isPro": false,
                        "fullname": "Nidhir Bhavsar",
                        "user": "nid989",
                        "type": "user"
                    },
                    "name": "Nidhir Bhavsar",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:36:06.679Z",
                    "hidden": false
                },
                {
                    "_id": "667a77f4536de14d364d93a2",
                    "name": "Jonathan Jordan",
                    "hidden": false
                },
                {
                    "_id": "667a77f4536de14d364d93a3",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647061e39ad4008a29061769/nHm9LquGI0Nh-MutiBvah.jpeg",
                        "isPro": false,
                        "fullname": "Sherzod Hakimov",
                        "user": "sherzod-hakimov",
                        "type": "user"
                    },
                    "name": "Sherzod Hakimov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T08:17:48.382Z",
                    "hidden": false
                },
                {
                    "_id": "667a77f4536de14d364d93a4",
                    "user": {
                        "avatarUrl": "/avatars/94d1dab7d7c26f69b2f865bebd13f6ee.svg",
                        "isPro": false,
                        "fullname": "David Schlangen",
                        "user": "davids",
                        "type": "user"
                    },
                    "name": "David Schlangen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:37:52.639Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-20T07:17:09.000Z",
            "title": "How Many Parameters Does it Take to Change a Light Bulb? Evaluating\n  Performance in Self-Play of Conversational Games as a Function of Model\n  Characteristics",
            "summary": "What makes a good Large Language Model (LLM)? That it performs well on the\nrelevant benchmarks -- which hopefully measure, with some validity, the\npresence of capabilities that are also challenged in real application. But what\nmakes the model perform well? What gives a model its abilities? We take a\nrecently introduced type of benchmark that is meant to challenge capabilities\nin a goal-directed, agentive context through self-play of conversational games,\nand analyse how performance develops as a function of model characteristics\nlike number of parameters, or type of training. We find that while there is a\nclear relationship between number of parameters and performance, there is still\na wide spread of performance points within a given size bracket, which is to be\naccounted for by training parameters such as fine-tuning data quality and\nmethod. From a more practical angle, we also find a certain degree of\nunpredictability about performance across access methods, possible due to\nunexposed sampling parameters, and a, very welcome, performance stability\nagainst at least moderate weight quantisation during inference.",
            "upvotes": 4
        },
        "publishedAt": "2024-06-25T06:34:31.752Z",
        "title": "How Many Parameters Does it Take to Change a Light Bulb? Evaluating Performance in Self-Play of Conversational Games as a Function of Model Characteristics",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14051.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647061e39ad4008a29061769/nHm9LquGI0Nh-MutiBvah.jpeg",
            "fullname": "Sherzod Hakimov",
            "name": "sherzod-hakimov",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16714",
            "authors": [
                {
                    "_id": "667a39e2dfe717c193c5b3e0",
                    "user": {
                        "avatarUrl": "/avatars/805c5f909f52656345b8bde486c9fa8f.svg",
                        "isPro": false,
                        "fullname": "Jiale Cheng",
                        "user": "CCCCCC",
                        "type": "user"
                    },
                    "name": "Jiale Cheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:14.266Z",
                    "hidden": false
                },
                {
                    "_id": "667a39e2dfe717c193c5b3e1",
                    "user": {
                        "avatarUrl": "/avatars/5ab8e5fbfaa9e5b456fb94eaa7e62832.svg",
                        "isPro": false,
                        "fullname": "Yida Lu",
                        "user": "lrxl",
                        "type": "user"
                    },
                    "name": "Yida Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T08:58:44.724Z",
                    "hidden": false
                },
                {
                    "_id": "667a39e2dfe717c193c5b3e2",
                    "name": "Xiaotao Gu",
                    "hidden": false
                },
                {
                    "_id": "667a39e2dfe717c193c5b3e3",
                    "name": "Pei Ke",
                    "hidden": false
                },
                {
                    "_id": "667a39e2dfe717c193c5b3e4",
                    "name": "Xiao Liu",
                    "hidden": false
                },
                {
                    "_id": "667a39e2dfe717c193c5b3e5",
                    "user": {
                        "avatarUrl": "/avatars/cd6779e30f716002a7838ed93d5c0754.svg",
                        "isPro": false,
                        "fullname": "Yuxiao Dong",
                        "user": "yuxiaod",
                        "type": "user"
                    },
                    "name": "Yuxiao Dong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T11:20:27.284Z",
                    "hidden": false
                },
                {
                    "_id": "667a39e2dfe717c193c5b3e6",
                    "user": {
                        "avatarUrl": "/avatars/d7c567ef5f20bb3b9905cb5015d11e12.svg",
                        "isPro": false,
                        "fullname": "Hongning Wang",
                        "user": "howang",
                        "type": "user"
                    },
                    "name": "Hongning Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T09:00:02.719Z",
                    "hidden": false
                },
                {
                    "_id": "667a39e2dfe717c193c5b3e7",
                    "user": {
                        "avatarUrl": "/avatars/1b4591c7322d649c797b3125148f1915.svg",
                        "isPro": false,
                        "fullname": "Jie Tang",
                        "user": "jerytang",
                        "type": "user"
                    },
                    "name": "Jie Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T11:20:12.918Z",
                    "hidden": false
                },
                {
                    "_id": "667a39e2dfe717c193c5b3e8",
                    "name": "Minlie Huang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T15:16:45.000Z",
            "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection\n  in Large Language Models",
            "summary": "Although Large Language Models (LLMs) are becoming increasingly powerful,\nthey still exhibit significant but subtle weaknesses, such as mistakes in\ninstruction-following or coding tasks. As these unexpected errors could lead to\nsevere consequences in practical deployments, it is crucial to investigate the\nlimitations within LLMs systematically. Traditional benchmarking approaches\ncannot thoroughly pinpoint specific model deficiencies, while manual\ninspections are costly and not scalable. In this paper, we introduce a unified\nframework, AutoDetect, to automatically expose weaknesses in LLMs across\nvarious tasks. Inspired by the educational assessment process that measures\nstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:\nExaminer, Questioner, and Assessor. The collaboration among these three agents\nis designed to realize comprehensive and in-depth weakness identification. Our\nframework demonstrates significant success in uncovering flaws, with an\nidentification success rate exceeding 30% in prominent models such as ChatGPT\nand Claude. More importantly, these identified weaknesses can guide specific\nmodel improvements, proving more effective than untargeted data augmentation\nmethods like Self-Instruct. Our approach has led to substantial enhancements in\npopular LLMs, including the Llama series and Mistral-7b, boosting their\nperformance by over 10% across several benchmarks. Code and data are publicly\navailable at https://github.com/thu-coai/AutoDetect.",
            "upvotes": 4
        },
        "publishedAt": "2024-06-25T06:27:05.517Z",
        "title": "AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16714.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/805c5f909f52656345b8bde486c9fa8f.svg",
            "fullname": "Jiale Cheng",
            "name": "CCCCCC",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16815",
            "authors": [
                {
                    "_id": "667a5e85becec8fc5106baae",
                    "user": {
                        "avatarUrl": "/avatars/00bba4b73ef1399b60831ab9eb52baa1.svg",
                        "isPro": false,
                        "fullname": "Yufei Liu",
                        "user": "ggxxii",
                        "type": "user"
                    },
                    "name": "Yufei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:41:03.089Z",
                    "hidden": false
                },
                {
                    "_id": "667a5e85becec8fc5106baaf",
                    "user": {
                        "avatarUrl": "/avatars/13f7a6f66060590e0394eb888148716c.svg",
                        "isPro": false,
                        "fullname": "junshu tang",
                        "user": "tangjs",
                        "type": "user"
                    },
                    "name": "Junshu Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:41:09.739Z",
                    "hidden": false
                },
                {
                    "_id": "667a5e85becec8fc5106bab0",
                    "user": {
                        "avatarUrl": "/avatars/7c51bd7c5bcd32ba4cfaf9cbe502cef0.svg",
                        "isPro": false,
                        "fullname": "chuzheng",
                        "user": "chuzheng",
                        "type": "user"
                    },
                    "name": "Chu Zheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:41:15.302Z",
                    "hidden": false
                },
                {
                    "_id": "667a5e85becec8fc5106bab1",
                    "name": "Shijie Zhang",
                    "hidden": false
                },
                {
                    "_id": "667a5e85becec8fc5106bab2",
                    "name": "Jinkun Hao",
                    "hidden": false
                },
                {
                    "_id": "667a5e85becec8fc5106bab3",
                    "user": {
                        "avatarUrl": "/avatars/b7c48dc999bf2f94018315b546d50eeb.svg",
                        "isPro": false,
                        "fullname": "Junwei Zhu",
                        "user": "ktpt123",
                        "type": "user"
                    },
                    "name": "Junwei Zhu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:41:52.718Z",
                    "hidden": false
                },
                {
                    "_id": "667a5e85becec8fc5106bab4",
                    "name": "Dongjin Huang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T17:25:39.000Z",
            "title": "ClotheDreamer: Text-Guided Garment Generation with 3D Gaussians",
            "summary": "High-fidelity 3D garment synthesis from text is desirable yet challenging for\ndigital avatar creation. Recent diffusion-based approaches via Score\nDistillation Sampling (SDS) have enabled new possibilities but either\nintricately couple with human body or struggle to reuse. We introduce\nClotheDreamer, a 3D Gaussian-based method for generating wearable,\nproduction-ready 3D garment assets from text prompts. We propose a novel\nrepresentation Disentangled Clothe Gaussian Splatting (DCGS) to enable separate\noptimization. DCGS represents clothed avatar as one Gaussian model but freezes\nbody Gaussian splats. To enhance quality and completeness, we incorporate\nbidirectional SDS to supervise clothed avatar and garment RGBD renderings\nrespectively with pose conditions and propose a new pruning strategy for loose\nclothing. Our approach can also support custom clothing templates as input.\nBenefiting from our design, the synthetic 3D garment can be easily applied to\nvirtual try-on and support physically accurate animation. Extensive experiments\nshowcase our method's superior and competitive performance. Our project page is\nat https://ggxxii.github.io/clothedreamer.",
            "upvotes": 4
        },
        "publishedAt": "2024-06-25T04:40:05.047Z",
        "title": "ClotheDreamer: Text-Guided Garment Generation with 3D Gaussians",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16815.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/13f7a6f66060590e0394eb888148716c.svg",
            "fullname": "junshu tang",
            "name": "tangjs",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16254",
            "authors": [
                {
                    "_id": "667a74f59f501609d28e34b9",
                    "user": {
                        "avatarUrl": "/avatars/10bc3e8754e1a9815da57d3aec2f0bb3.svg",
                        "isPro": false,
                        "fullname": "Alessandro Stolfo",
                        "user": "alestolfo",
                        "type": "user"
                    },
                    "name": "Alessandro Stolfo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:38:41.156Z",
                    "hidden": false
                },
                {
                    "_id": "667a74f59f501609d28e34ba",
                    "name": "Ben Wu",
                    "hidden": false
                },
                {
                    "_id": "667a74f59f501609d28e34bb",
                    "user": {
                        "avatarUrl": "/avatars/34d7ff8bc59aac0ed77a961596c4e4b1.svg",
                        "isPro": false,
                        "fullname": "Wes Gurnee",
                        "user": "wesg",
                        "type": "user"
                    },
                    "name": "Wes Gurnee",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:39:02.040Z",
                    "hidden": false
                },
                {
                    "_id": "667a74f59f501609d28e34bc",
                    "user": {
                        "avatarUrl": "/avatars/186a9aed84681246f48ed2a012c50def.svg",
                        "isPro": false,
                        "fullname": "Yonatan Belinkov",
                        "user": "belinkov",
                        "type": "user"
                    },
                    "name": "Yonatan Belinkov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:39:07.898Z",
                    "hidden": false
                },
                {
                    "_id": "667a74f59f501609d28e34bd",
                    "user": {
                        "avatarUrl": "/avatars/2eaa80217aae2a8dbd6cc350b7f35311.svg",
                        "isPro": false,
                        "fullname": "Song",
                        "user": "Xingyi",
                        "type": "user"
                    },
                    "name": "Xingyi Song",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:39:17.590Z",
                    "hidden": false
                },
                {
                    "_id": "667a74f59f501609d28e34be",
                    "name": "Mrinmaya Sachan",
                    "hidden": false
                },
                {
                    "_id": "667a74f59f501609d28e34bf",
                    "user": {
                        "avatarUrl": "/avatars/6d5cd2261163308b82341c1ce28984d1.svg",
                        "isPro": false,
                        "fullname": "Neel Nanda",
                        "user": "NeelNanda",
                        "type": "user"
                    },
                    "name": "Neel Nanda",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:39:26.400Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T01:31:03.000Z",
            "title": "Confidence Regulation Neurons in Language Models",
            "summary": "Despite their widespread use, the mechanisms by which large language models\n(LLMs) represent and regulate uncertainty in next-token predictions remain\nlargely unexplored. This study investigates two critical components believed to\ninfluence this uncertainty: the recently discovered entropy neurons and a new\nset of components that we term token frequency neurons. Entropy neurons are\ncharacterized by an unusually high weight norm and influence the final layer\nnormalization (LayerNorm) scale to effectively scale down the logits. Our work\nshows that entropy neurons operate by writing onto an unembedding null space,\nallowing them to impact the residual stream norm with minimal direct effect on\nthe logits themselves. We observe the presence of entropy neurons across a\nrange of models, up to 7 billion parameters. On the other hand, token frequency\nneurons, which we discover and describe here for the first time, boost or\nsuppress each token's logit proportionally to its log frequency, thereby\nshifting the output distribution towards or away from the unigram distribution.\nFinally, we present a detailed case study where entropy neurons actively manage\nconfidence in the setting of induction, i.e. detecting and continuing repeated\nsubsequences.",
            "upvotes": 3
        },
        "publishedAt": "2024-06-25T08:44:18.388Z",
        "title": "Confidence Regulation Neurons in Language Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/5e7749883d77a72421292d07/wky1DxJeLezxAhcnyLOBX.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16254.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1670231290373-5e7749883d77a72421292d07.jpeg",
            "fullname": "Gabriele Sarti",
            "name": "gsarti",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.14540",
            "authors": [
                {
                    "_id": "6679a8667dc34fe17cb367f1",
                    "user": {
                        "avatarUrl": "/avatars/0cf0050b272d1c8e46e1299de2aea22a.svg",
                        "isPro": false,
                        "fullname": "zhu",
                        "user": "fangqi",
                        "type": "user"
                    },
                    "name": "Fangqi Zhu",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-06-25T06:22:06.567Z",
                    "hidden": false
                },
                {
                    "_id": "6679a8667dc34fe17cb367f2",
                    "user": {
                        "avatarUrl": "/avatars/4e645f8cff38b0b6e0d1016cd5a23d89.svg",
                        "isPro": false,
                        "fullname": "Hongtao Wu",
                        "user": "danchaoren",
                        "type": "user"
                    },
                    "name": "Hongtao Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:52:17.258Z",
                    "hidden": false
                },
                {
                    "_id": "6679a8667dc34fe17cb367f3",
                    "name": "Song Guo",
                    "hidden": false
                },
                {
                    "_id": "6679a8667dc34fe17cb367f4",
                    "name": "Yuxiao Liu",
                    "hidden": false
                },
                {
                    "_id": "6679a8667dc34fe17cb367f5",
                    "name": "Chilam Cheang",
                    "hidden": false
                },
                {
                    "_id": "6679a8667dc34fe17cb367f6",
                    "user": {
                        "avatarUrl": "/avatars/ba746df3ae4d264af6184523930fba1c.svg",
                        "isPro": false,
                        "fullname": "Kong",
                        "user": "TaoKong",
                        "type": "user"
                    },
                    "name": "Tao Kong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:52:48.429Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-20T17:50:16.000Z",
            "title": "IRASim: Learning Interactive Real-Robot Action Simulators",
            "summary": "Scalable robot learning in the real world is limited by the cost and safety\nissues of real robots. In addition, rolling out robot trajectories in the real\nworld can be time-consuming and labor-intensive. In this paper, we propose to\nlearn an interactive real-robot action simulator as an alternative. We\nintroduce a novel method, IRASim, which leverages the power of generative\nmodels to generate extremely realistic videos of a robot arm that executes a\ngiven action trajectory, starting from an initial given frame. To validate the\neffectiveness of our method, we create a new benchmark, IRASim Benchmark, based\non three real-robot datasets and perform extensive experiments on the\nbenchmark. Results show that IRASim outperforms all the baseline methods and is\nmore preferable in human evaluations. We hope that IRASim can serve as an\neffective and scalable approach to enhance robot learning in the real world. To\npromote research for generative real-robot action simulators, we open-source\ncode, benchmark, and checkpoints at https: //gen-irasim.github.io.",
            "upvotes": 3
        },
        "publishedAt": "2024-06-25T04:55:30.640Z",
        "title": "IRASim: Learning Interactive Real-Robot Action Simulators",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64d0b110d1fda042b57a3c0b/AiovbKLefOrUC1OLWoAoZ.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.14540.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/0cf0050b272d1c8e46e1299de2aea22a.svg",
            "fullname": "zhu",
            "name": "fangqi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.15718",
            "authors": [
                {
                    "_id": "667a90b03bf5064fe3367191",
                    "user": {
                        "avatarUrl": "/avatars/a08f7cbaf155d8cef3dd6197a21890a5.svg",
                        "isPro": false,
                        "fullname": "xinrongzhang",
                        "user": "xinrongzhang2022",
                        "type": "user"
                    },
                    "name": "Xinrong Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:59:38.360Z",
                    "hidden": false
                },
                {
                    "_id": "667a90b03bf5064fe3367192",
                    "user": {
                        "avatarUrl": "/avatars/c7a77d8b0aeb2a81bffac5c09edad9ca.svg",
                        "isPro": false,
                        "fullname": "Yingfa Chen",
                        "user": "blazing",
                        "type": "user"
                    },
                    "name": "Yingfa Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:59:44.450Z",
                    "hidden": false
                },
                {
                    "_id": "667a90b03bf5064fe3367193",
                    "user": {
                        "avatarUrl": "/avatars/7d09fbe771d3c3312ac7eb6ef83ce053.svg",
                        "isPro": false,
                        "fullname": "Shengding Hu",
                        "user": "ShengdingHu",
                        "type": "user"
                    },
                    "name": "Shengding Hu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:59:50.264Z",
                    "hidden": false
                },
                {
                    "_id": "667a90b03bf5064fe3367194",
                    "name": "Xu Han",
                    "hidden": false
                },
                {
                    "_id": "667a90b03bf5064fe3367195",
                    "name": "Zihang Xu",
                    "hidden": false
                },
                {
                    "_id": "667a90b03bf5064fe3367196",
                    "name": "Yuanwei Xu",
                    "hidden": false
                },
                {
                    "_id": "667a90b03bf5064fe3367197",
                    "user": {
                        "avatarUrl": "/avatars/564a4dccdf9e5b813a99979b0ef58183.svg",
                        "isPro": false,
                        "fullname": "Weilin Zhao",
                        "user": "Achazwl",
                        "type": "user"
                    },
                    "name": "Weilin Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T14:00:34.382Z",
                    "hidden": false
                },
                {
                    "_id": "667a90b03bf5064fe3367198",
                    "name": "Maosong Sun",
                    "hidden": false
                },
                {
                    "_id": "667a90b03bf5064fe3367199",
                    "user": {
                        "avatarUrl": "/avatars/79dca137583875191ea883b193b630b7.svg",
                        "isPro": false,
                        "fullname": "Zhiyuan Liu",
                        "user": "zibuyu9",
                        "type": "user"
                    },
                    "name": "Zhiyuan Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T14:01:19.677Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-22T03:20:10.000Z",
            "title": "Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex\n  Models",
            "summary": "As large language models (LLMs) increasingly permeate daily lives, there is a\ngrowing demand for real-time interactions that mirror human conversations.\nTraditional turn-based chat systems driven by LLMs prevent users from verbally\ninteracting with the system while it is generating responses. To overcome these\nlimitations, we adapt existing LLMs to duplex models so that these\nLLMs can listen for users while generating output and dynamically adjust\nthemselves to provide users with instant feedback. % such as in response to\ninterruptions. Specifically, we divide the queries and responses of\nconversations into several time slices and then adopt a\ntime-division-multiplexing (TDM) encoding-decoding strategy to\npseudo-simultaneously process these slices. Furthermore, to make LLMs\nproficient enough to handle real-time conversations, we build a fine-tuning\ndataset consisting of alternating time slices of queries and responses as well\nas covering typical feedback types in instantaneous interactions. Our\nexperiments show that although the queries and responses of conversations are\nsegmented into incomplete slices for processing, LLMs can preserve their\noriginal performance on standard benchmarks with a few fine-tuning steps on our\ndataset. Automatic and human evaluation indicate that duplex models make\nuser-AI interactions more natural and human-like, and greatly improve user\nsatisfaction compared to vanilla LLMs. Our duplex model and dataset will be\nreleased.",
            "upvotes": 2
        },
        "publishedAt": "2024-06-25T08:11:39.397Z",
        "title": "Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15718.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/7d09fbe771d3c3312ac7eb6ef83ce053.svg",
            "fullname": "Shengding Hu",
            "name": "ShengdingHu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.16772",
            "authors": [
                {
                    "_id": "667a721deb164e5584d41568",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643581a4f3b08e267d990499/KRhB-48W4IPuB0bX16Ahj.png",
                        "isPro": false,
                        "fullname": "Zhen Huang",
                        "user": "ZhenHuang",
                        "type": "user"
                    },
                    "name": "Zhen Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:44:11.851Z",
                    "hidden": false
                },
                {
                    "_id": "667a721deb164e5584d41569",
                    "user": {
                        "avatarUrl": "/avatars/86090d2d8c7dd596cf9f7e640e8e5951.svg",
                        "isPro": false,
                        "fullname": "Zengzhi Wang",
                        "user": "SinclairWang",
                        "type": "user"
                    },
                    "name": "Zengzhi Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-06-25T07:33:34.375Z",
                    "hidden": false
                },
                {
                    "_id": "667a721deb164e5584d4156a",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65900d4ff5a209eeac08b463/ssVLX2Kv_wq31pEm4DlkM.jpeg",
                        "isPro": false,
                        "fullname": "shijie xia",
                        "user": "seven-cat",
                        "type": "user"
                    },
                    "name": "Shijie Xia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:44:28.419Z",
                    "hidden": false
                },
                {
                    "_id": "667a721deb164e5584d4156b",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661715958139-6144a0c4ff1146bbd84d9865.png",
                        "isPro": true,
                        "fullname": "Pengfei Liu",
                        "user": "Pengfei",
                        "type": "user"
                    },
                    "name": "Pengfei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T13:44:40.774Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-24T16:31:12.000Z",
            "title": "OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?",
            "summary": "In this report, we pose the following question: Who is the most intelligent\nAI model to date, as measured by the OlympicArena (an Olympic-level,\nmulti-discipline, multi-modal benchmark for superintelligent AI)? We\nspecifically focus on the most recently released models: Claude-3.5-Sonnet,\nGemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympic\nmedal Table approach to rank AI models based on their comprehensive performance\nacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnet\nshows highly competitive overall performance over GPT-4o, even surpassing\nGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)\nGemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o and\nClaude-3.5-Sonnet, but with a clear performance gap between them. (3) The\nperformance of AI models from the open-source community significantly lags\nbehind these proprietary models. (4) The performance of these models on this\nbenchmark has been less than satisfactory, indicating that we still have a long\nway to go before achieving superintelligence. We remain committed to\ncontinuously tracking and evaluating the performance of the latest powerful\nmodels on this benchmark (available at\nhttps://github.com/GAIR-NLP/OlympicArena).",
            "upvotes": 2
        },
        "publishedAt": "2024-06-25T06:03:09.346Z",
        "title": "OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.16772.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/86090d2d8c7dd596cf9f7e640e8e5951.svg",
            "fullname": "Zengzhi Wang",
            "name": "SinclairWang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2406.15704",
            "authors": [
                {
                    "_id": "667a64f34af5328a70faac49",
                    "user": {
                        "avatarUrl": "/avatars/f1a9def3afbec2f8b89ef4450770d67e.svg",
                        "isPro": false,
                        "fullname": "Guangzhi Sun",
                        "user": "BrianatCambridge",
                        "type": "user"
                    },
                    "name": "Guangzhi Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T14:02:41.604Z",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac4a",
                    "name": "Wenyi Yu",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac4b",
                    "user": {
                        "avatarUrl": "/avatars/6bc7c602e79688bc42a4c79ecf5b6d2d.svg",
                        "isPro": false,
                        "fullname": "Changli Tang",
                        "user": "Changli",
                        "type": "user"
                    },
                    "name": "Changli Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T14:02:55.818Z",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac4c",
                    "user": {
                        "avatarUrl": "/avatars/a0bc08fec550ff022a1d948d3ad9d42c.svg",
                        "isPro": false,
                        "fullname": "xianzhao chen",
                        "user": "cxzcxzcxz",
                        "type": "user"
                    },
                    "name": "Xianzhao Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-06-25T14:03:01.502Z",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac4d",
                    "name": "Tian Tan",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac4e",
                    "name": "Wei Li",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac4f",
                    "name": "Lu Lu",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac50",
                    "name": "Zejun Ma",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac51",
                    "name": "Yuxuan Wang",
                    "hidden": false
                },
                {
                    "_id": "667a64f34af5328a70faac52",
                    "name": "Chao Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-06-22T01:36:11.000Z",
            "title": "video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models",
            "summary": "Speech understanding as an element of the more generic video understanding\nusing audio-visual large language models (av-LLMs) is a crucial yet\nunderstudied aspect. This paper proposes video-SALMONN, a single end-to-end\nav-LLM for video processing, which can understand not only visual frame\nsequences, audio events and music, but speech as well. To obtain fine-grained\ntemporal information required by speech understanding, while keeping efficient\nfor other video elements, this paper proposes a novel multi-resolution causal\nQ-Former (MRC Q-Former) structure to connect pre-trained audio-visual encoders\nand the backbone large language model. Moreover, dedicated training approaches\nincluding the diversity loss and the unpaired audio-visual mixed training\nscheme are proposed to avoid frames or modality dominance. On the introduced\nspeech-audio-visual evaluation benchmark, video-SALMONN achieves more than 25\\%\nabsolute accuracy improvements on the video-QA task and over 30\\% absolute\naccuracy improvements on audio-visual QA tasks with human speech. In addition,\nvideo-SALMONN demonstrates remarkable video comprehension and reasoning\nabilities on tasks that are unprecedented by other av-LLMs. Our training code\nand model checkpoints are available at\n\\url{https://github.com/bytedance/SALMONN/}.",
            "upvotes": 2
        },
        "publishedAt": "2024-06-25T05:06:35.432Z",
        "title": "video-SALMONN: Speech-Enhanced Audio-Visual Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2406.15704.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/f1a9def3afbec2f8b89ef4450770d67e.svg",
            "fullname": "Guangzhi Sun",
            "name": "BrianatCambridge",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]