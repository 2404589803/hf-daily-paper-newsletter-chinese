[
  {
    "paper": {
      "id": "2501.07301",
      "authors": [
        {
          "_id": "6785e601117627fe711f8dd8",
          "user": {
            "_id": "64704e973601bb7b06643e98",
            "avatarUrl": "/avatars/52e51f4d1be6769e4397b8be2799cf32.svg",
            "isPro": false,
            "fullname": "Zhang",
            "user": "Zhenru",
            "type": "user"
          },
          "name": "Zhenru Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:48:52.704Z",
          "hidden": false
        },
        {
          "_id": "6785e601117627fe711f8dd9",
          "user": {
            "_id": "610b70452719facd4ea85e28",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/610b70452719facd4ea85e28/S7nMy7D0Rxq0VIVblhYDG.jpeg",
            "isPro": false,
            "fullname": "Chujie Zheng",
            "user": "chujiezheng",
            "type": "user"
          },
          "name": "Chujie Zheng",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-14T08:28:43.769Z",
          "hidden": false
        },
        {
          "_id": "6785e601117627fe711f8dda",
          "user": {
            "_id": "671f2a2ab02f88b7e2385105",
            "avatarUrl": "/avatars/a97e2f983c8290b72eeb03e2bdcaf085.svg",
            "isPro": false,
            "fullname": "Yangzhen Wu",
            "user": "wuyangzhen",
            "type": "user"
          },
          "name": "Yangzhen Wu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:49:01.963Z",
          "hidden": false
        },
        {
          "_id": "6785e601117627fe711f8ddb",
          "user": {
            "_id": "64b93578ee257c3a4cfceed1",
            "avatarUrl": "/avatars/e6188562254f75a09b4048b800860016.svg",
            "isPro": false,
            "fullname": "Beichen Zhang",
            "user": "BeichenZhang",
            "type": "user"
          },
          "name": "Beichen Zhang",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:49:43.861Z",
          "hidden": false
        },
        {
          "_id": "6785e601117627fe711f8ddc",
          "user": {
            "_id": "649a52e5de0fb7f3f499e583",
            "avatarUrl": "/avatars/25f6106fa168ae57ad5cd8ef55c70d31.svg",
            "isPro": false,
            "fullname": "Runji Lin",
            "user": "RunjiLin",
            "type": "user"
          },
          "name": "Runji Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:49:56.685Z",
          "hidden": false
        },
        {
          "_id": "6785e601117627fe711f8ddd",
          "user": {
            "_id": "6438b43ab2ea24b52ebac2b9",
            "avatarUrl": "/avatars/84133cd719a4b1e2f5c1a74178425f86.svg",
            "isPro": false,
            "fullname": "Bowen Yu",
            "user": "bwy",
            "type": "user"
          },
          "name": "Bowen Yu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:50:12.316Z",
          "hidden": false
        },
        {
          "_id": "6785e601117627fe711f8dde",
          "user": {
            "_id": "6434d4989bd5a84b5dd0b0f5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6434d4989bd5a84b5dd0b0f5/0Elf9qbfG9Hkgypm9pTGm.jpeg",
            "isPro": false,
            "fullname": "Dayiheng Liu",
            "user": "Losin94",
            "type": "user"
          },
          "name": "Dayiheng Liu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:50:18.536Z",
          "hidden": false
        },
        {
          "_id": "6785e601117627fe711f8ddf",
          "user": {
            "_id": "602f88f5e8149a962412a667",
            "avatarUrl": "/avatars/b78f0e583df8e5d5e3365934fe5f4900.svg",
            "isPro": false,
            "fullname": "Zhou",
            "user": "Jingren",
            "type": "user"
          },
          "name": "Jingren Zhou",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:50:29.301Z",
          "hidden": false
        },
        {
          "_id": "6785e601117627fe711f8de0",
          "user": {
            "_id": "620760a26e3b7210c2ff1943",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg",
            "isPro": false,
            "fullname": "Junyang Lin",
            "user": "JustinLin610",
            "type": "user"
          },
          "name": "Junyang Lin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:50:35.067Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-13T13:10:16.000Z",
      "title": "The Lessons of Developing Process Reward Models in Mathematical\n  Reasoning",
      "summary": "Process Reward Models (PRMs) emerge as a promising approach for process\nsupervision in mathematical reasoning of Large Language Models (LLMs), which\naim to identify and mitigate intermediate errors in the reasoning processes.\nHowever, the development of effective PRMs faces significant challenges,\nparticularly in data annotation and evaluation methodologies. In this paper,\nthrough extensive experiments, we demonstrate that commonly used Monte Carlo\n(MC) estimation-based data synthesis for PRMs typically yields inferior\nperformance and generalization compared to LLM-as-a-judge and human annotation\nmethods. MC estimation relies on completion models to evaluate current-step\ncorrectness, leading to inaccurate step verification. Furthermore, we identify\npotential biases in conventional Best-of-N (BoN) evaluation strategies for\nPRMs: (1) The unreliable policy models generate responses with correct answers\nbut flawed processes, leading to a misalignment between the evaluation criteria\nof BoN and the PRM objectives of process verification. (2) The tolerance of\nPRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a\nsignificant proportion of minimum scores concentrated on the final answer\nsteps, revealing the shift from process to outcome-based assessment in BoN\nOptimized PRMs. To address these challenges, we develop a consensus filtering\nmechanism that effectively integrates MC estimation with LLM-as-a-judge and\nadvocates a more comprehensive evaluation framework that combines\nresponse-level and step-level metrics. Based on the mechanisms, we\nsignificantly improve both model performance and data efficiency in the BoN\nevaluation and the step-wise error identification task. Finally, we release a\nnew state-of-the-art PRM that outperforms existing open-source alternatives and\nprovides practical guidelines for future research in building process\nsupervision models.",
      "upvotes": 20,
      "discussionId": "6785e602117627fe711f8e15"
    },
    "publishedAt": "2025-01-13T23:23:11.463Z",
    "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07301.png",
    "numComments": 3,
    "submittedBy": {
      "_id": "610b70452719facd4ea85e28",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/610b70452719facd4ea85e28/S7nMy7D0Rxq0VIVblhYDG.jpeg",
      "fullname": "Chujie Zheng",
      "name": "chujiezheng",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 26
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.06425",
      "authors": [
        {
          "_id": "6785ce62cb1fc2728334a5e2",
          "user": {
            "_id": "647bf082aba7062fe5c51ca9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/p4lY9IjHiWZETKmFq1mtU.jpeg",
            "isPro": false,
            "fullname": "Yifan Zhang",
            "user": "yifAI",
            "type": "user"
          },
          "name": "Yifan Zhang",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-14T08:28:51.600Z",
          "hidden": false
        },
        {
          "_id": "6785ce62cb1fc2728334a5e3",
          "name": "Yifeng Liu",
          "hidden": false
        },
        {
          "_id": "6785ce62cb1fc2728334a5e4",
          "name": "Huizhuo Yuan",
          "hidden": false
        },
        {
          "_id": "6785ce62cb1fc2728334a5e5",
          "user": {
            "_id": "649014b91d71e55664838d2d",
            "avatarUrl": "/avatars/f0e0f2830c5cb7428cbbc9634d95c34b.svg",
            "isPro": false,
            "fullname": "Zhen Qin",
            "user": "zhenqincn",
            "type": "user"
          },
          "name": "Zhen Qin",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:51:32.418Z",
          "hidden": false
        },
        {
          "_id": "6785ce62cb1fc2728334a5e6",
          "name": "Yang Yuan",
          "hidden": false
        },
        {
          "_id": "6785ce62cb1fc2728334a5e7",
          "user": {
            "_id": "64c039128e2612254356bba5",
            "avatarUrl": "/avatars/06cc76feebba0cc80ebb8f4ff86f6d9b.svg",
            "isPro": false,
            "fullname": "Quanquan Gu",
            "user": "thughost",
            "type": "user"
          },
          "name": "Quanquan Gu",
          "status": "admin_assigned",
          "statusLastChangedAt": "2025-01-14T08:52:03.941Z",
          "hidden": false
        },
        {
          "_id": "6785ce62cb1fc2728334a5e8",
          "name": "Andrew Chi-Chih Yao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-11T03:37:10.000Z",
      "title": "Tensor Product Attention Is All You Need",
      "summary": "Scaling language models to handle longer input sequences typically\nnecessitates large key-value (KV) caches, resulting in substantial memory\noverhead during inference. In this paper, we propose Tensor Product Attention\n(TPA), a novel attention mechanism that uses tensor decompositions to represent\nqueries, keys, and values compactly, significantly shrinking KV cache size at\ninference time. By factorizing these representations into contextual low-rank\ncomponents (contextual factorization) and seamlessly integrating with RoPE, TPA\nachieves improved model quality alongside memory efficiency. Based on TPA, we\nintroduce the Tensor ProducT ATTenTion Transformer (T6), a new model\narchitecture for sequence modeling. Through extensive empirical evaluation of\nlanguage modeling tasks, we demonstrate that T6 exceeds the performance of\nstandard Transformer baselines including MHA, MQA, GQA, and MLA across various\nmetrics, including perplexity and a range of renowned evaluation benchmarks.\nNotably, TPAs memory efficiency enables the processing of significantly longer\nsequences under fixed resource constraints, addressing a critical scalability\nchallenge in modern language models. The code is available at\nhttps://github.com/tensorgi/T6.",
      "upvotes": 15,
      "discussionId": "6785ce63cb1fc2728334a639"
    },
    "publishedAt": "2025-01-13T23:22:48.009Z",
    "title": "Tensor Product Attention Is All You Need",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/647bf082aba7062fe5c51ca9/y_7bf_BI9HbuGGrP0cJfU.png"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06425.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "647bf082aba7062fe5c51ca9",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/p4lY9IjHiWZETKmFq1mtU.jpeg",
      "fullname": "Yifan Zhang",
      "name": "yifAI",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 9
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.06173",
      "authors": [
        {
          "_id": "678604c71f54791d52bebe30",
          "user": {
            "_id": "64b5ba6060274cbb296d6288",
            "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
            "isPro": false,
            "fullname": "Junfei Xiao",
            "user": "lambertxiao",
            "type": "user"
          },
          "name": "Junfei Xiao",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-14T08:28:41.422Z",
          "hidden": false
        },
        {
          "_id": "678604c71f54791d52bebe31",
          "name": "Feng Cheng",
          "hidden": false
        },
        {
          "_id": "678604c71f54791d52bebe32",
          "name": "Lu Qi",
          "hidden": false
        },
        {
          "_id": "678604c71f54791d52bebe33",
          "name": "Liangke Gui",
          "hidden": false
        },
        {
          "_id": "678604c71f54791d52bebe34",
          "name": "Jiepeng Cen",
          "hidden": false
        },
        {
          "_id": "678604c71f54791d52bebe35",
          "name": "Zhibei Ma",
          "hidden": false
        },
        {
          "_id": "678604c71f54791d52bebe36",
          "name": "Alan Yuille",
          "hidden": false
        },
        {
          "_id": "678604c71f54791d52bebe37",
          "name": "Lu Jiang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-10T18:52:11.000Z",
      "title": "VideoAuteur: Towards Long Narrative Video Generation",
      "summary": "Recent video generation models have shown promising results in producing\nhigh-quality video clips lasting several seconds. However, these models face\nchallenges in generating long sequences that convey clear and informative\nevents, limiting their ability to support coherent narrations. In this paper,\nwe present a large-scale cooking video dataset designed to advance long-form\nnarrative generation in the cooking domain. We validate the quality of our\nproposed dataset in terms of visual fidelity and textual caption accuracy using\nstate-of-the-art Vision-Language Models (VLMs) and video generation models,\nrespectively. We further introduce a Long Narrative Video Director to enhance\nboth visual and semantic coherence in generated videos and emphasize the role\nof aligning visual embeddings to achieve improved overall video quality. Our\nmethod demonstrates substantial improvements in generating visually detailed\nand semantically aligned keyframes, supported by finetuning techniques that\nintegrate text and image embeddings within the video generation process.\nProject page: https://videoauteur.github.io/",
      "upvotes": 10,
      "discussionId": "678604d01f54791d52bec130"
    },
    "publishedAt": "2025-01-14T01:33:05.846Z",
    "title": "VideoAuteur: Towards Long Narrative Video Generation",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06173.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64b5ba6060274cbb296d6288",
      "avatarUrl": "/avatars/67e0343954dda6e92ed3f6e7976f9f87.svg",
      "fullname": "Junfei Xiao",
      "name": "lambertxiao",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.06252",
      "authors": [
        {
          "_id": "6785e78b117627fe712005c9",
          "name": "Qi Sun",
          "hidden": false
        },
        {
          "_id": "6785e78b117627fe712005ca",
          "name": "Edoardo Cetin",
          "hidden": false
        },
        {
          "_id": "6785e78b117627fe712005cb",
          "name": "Yujin Tang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-09T01:19:21.000Z",
      "title": "Transformer^2: Self-adaptive LLMs",
      "summary": "Self-adaptive large language models (LLMs) aim to solve the challenges posed\nby traditional fine-tuning methods, which are often computationally intensive\nand static in their ability to handle diverse tasks. We introduce \\implname, a\nnovel self-adaptation framework that adapts LLMs for unseen tasks in real-time\nby selectively adjusting only the singular components of their weight matrices.\nDuring inference, \\implname employs a two-pass mechanism: first, a dispatch\nsystem identifies the task properties, and then task-specific \"expert\" vectors,\ntrained using reinforcement learning, are dynamically mixed to obtain targeted\nbehavior for the incoming prompt. Our method outperforms ubiquitous approaches\nsuch as LoRA, with fewer parameters and greater efficiency. \\implname\ndemonstrates versatility across different LLM architectures and modalities,\nincluding vision-language tasks. \\implname represents a significant leap\nforward, offering a scalable, efficient solution for enhancing the adaptability\nand task-specific performance of LLMs, paving the way for truly dynamic,\nself-organizing AI systems.",
      "upvotes": 9,
      "discussionId": "6785e78b117627fe71200618"
    },
    "publishedAt": "2025-01-13T23:27:12.322Z",
    "title": "$\\text{Transformer}^2$: Self-adaptive LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06252.png",
    "numComments": 4,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5641
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.07572",
      "authors": [
        {
          "_id": "6785df7a934f275b48366bdf",
          "user": {
            "_id": "644a4fbc2166258fccc664bc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg",
            "isPro": false,
            "fullname": "Jialong Wu",
            "user": "callanwu",
            "type": "user"
          },
          "name": "Jialong Wu",
          "status": "claimed_verified",
          "statusLastChangedAt": "2025-01-14T08:28:45.818Z",
          "hidden": false
        },
        {
          "_id": "6785df7a934f275b48366be0",
          "name": "Wenbiao Yin",
          "hidden": false
        },
        {
          "_id": "6785df7a934f275b48366be1",
          "name": "Yong Jiang",
          "hidden": false
        },
        {
          "_id": "6785df7a934f275b48366be2",
          "name": "Zhenglin Wang",
          "hidden": false
        },
        {
          "_id": "6785df7a934f275b48366be3",
          "name": "Zekun Xi",
          "hidden": false
        },
        {
          "_id": "6785df7a934f275b48366be4",
          "name": "Runnan Fang",
          "hidden": false
        },
        {
          "_id": "6785df7a934f275b48366be5",
          "name": "Deyu Zhou",
          "hidden": false
        },
        {
          "_id": "6785df7a934f275b48366be6",
          "name": "Pengjun Xie",
          "hidden": false
        },
        {
          "_id": "6785df7a934f275b48366be7",
          "name": "Fei Huang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-13T18:58:07.000Z",
      "title": "WebWalker: Benchmarking LLMs in Web Traversal",
      "summary": "Retrieval-augmented generation (RAG) demonstrates remarkable performance\nacross tasks in open-domain question-answering. However, traditional search\nengines may retrieve shallow content, limiting the ability of LLMs to handle\ncomplex, multi-layered information. To address it, we introduce WebWalkerQA, a\nbenchmark designed to assess the ability of LLMs to perform web traversal. It\nevaluates the capacity of LLMs to traverse a website's subpages to extract\nhigh-quality data systematically. We propose WebWalker, which is a multi-agent\nframework that mimics human-like web navigation through an explore-critic\nparadigm. Extensive experimental results show that WebWalkerQA is challenging\nand demonstrates the effectiveness of RAG combined with WebWalker, through the\nhorizontal and vertical integration in real-world scenarios.",
      "upvotes": 8,
      "discussionId": "6785df7c934f275b48366cff"
    },
    "publishedAt": "2025-01-13T23:49:04.500Z",
    "title": "WebWalker: Benchmarking LLMs in Web Traversal",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07572.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "644a4fbc2166258fccc664bc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg",
      "fullname": "Jialong Wu",
      "name": "callanwu",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 2
    },
    "isAuthorParticipating": true
  },
  {
    "paper": {
      "id": "2501.06458",
      "authors": [
        {
          "_id": "6785e65a7d58f2945af8034d",
          "name": "Zhongzhen Huang",
          "hidden": false
        },
        {
          "_id": "6785e65a7d58f2945af8034e",
          "name": "Gui Geng",
          "hidden": false
        },
        {
          "_id": "6785e65a7d58f2945af8034f",
          "name": "Shengyi Hua",
          "hidden": false
        },
        {
          "_id": "6785e65a7d58f2945af80350",
          "name": "Zhen Huang",
          "hidden": false
        },
        {
          "_id": "6785e65a7d58f2945af80351",
          "name": "Haoyang Zou",
          "hidden": false
        },
        {
          "_id": "6785e65a7d58f2945af80352",
          "name": "Shaoting Zhang",
          "hidden": false
        },
        {
          "_id": "6785e65a7d58f2945af80353",
          "name": "Pengfei Liu",
          "hidden": false
        },
        {
          "_id": "6785e65a7d58f2945af80354",
          "name": "Xiaofan Zhang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-11T07:10:23.000Z",
      "title": "O1 Replication Journey -- Part 3: Inference-time Scaling for Medical\n  Reasoning",
      "summary": "Building upon our previous investigations of O1 replication (Part 1: Journey\nLearning [Qin et al., 2024] and Part 2: Distillation [Huang et al., 2024]),\nthis work explores the potential of inference-time scaling in large language\nmodels (LLMs) for medical reasoning tasks, ranging from diagnostic\ndecision-making to treatment planning. Through extensive experiments on medical\nbenchmarks of varying complexity (MedQA, Medbullets, and JAMA Clinical\nChallenges), our investigation reveals several key insights: (1) Increasing\ninference time does lead to improved performance. With a modest training set of\n500 samples, our model yields substantial performance improvements of 6%-11%.\n(2) Task complexity directly correlates with the required length of reasoning\nchains, confirming the necessity of extended thought processes for challenging\nproblems. (3) The differential diagnoses generated by our model adhere to the\nprinciples of the hypothetico-deductive method, producing a list of potential\nconditions that may explain a patient's symptoms and systematically narrowing\nthese possibilities by evaluating the evidence. These findings demonstrate the\npromising synergy between inference-time scaling and journey learning in\nadvancing LLMs' real-world clinical reasoning capabilities.",
      "upvotes": 5,
      "discussionId": "6785e65b7d58f2945af80393"
    },
    "publishedAt": "2025-01-13T23:22:50.865Z",
    "title": "O1 Replication Journey -- Part 3: Inference-time Scaling for Medical Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06458.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5641
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.06282",
      "authors": [
        {
          "_id": "6785e88a6bc168b98ae46a55",
          "name": "Qian Chen",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a56",
          "name": "Yafeng Chen",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a57",
          "name": "Yanni Chen",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a58",
          "name": "Mengzhe Chen",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a59",
          "name": "Yingda Chen",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a5a",
          "name": "Chong Deng",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a5b",
          "name": "Zhihao Du",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a5c",
          "name": "Ruize Gao",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a5d",
          "name": "Changfeng Gao",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a5e",
          "name": "Zhifu Gao",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a5f",
          "name": "Yabin Li",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a60",
          "name": "Xiang Lv",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a61",
          "name": "Jiaqing Liu",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a62",
          "name": "Haoneng Luo",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a63",
          "name": "Bin Ma",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a64",
          "name": "Chongjia Ni",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a65",
          "name": "Xian Shi",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a66",
          "name": "Jialong Tang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a67",
          "name": "Hui Wang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a68",
          "name": "Hao Wang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a69",
          "name": "Wen Wang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a6a",
          "name": "Yuxuan Wang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a6b",
          "name": "Yunlan Xu",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a6c",
          "name": "Fan Yu",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a6d",
          "name": "Zhijie Yan",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a6e",
          "name": "Yexin Yang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a6f",
          "name": "Baosong Yang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a70",
          "name": "Xian Yang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a71",
          "name": "Guanrou Yang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a72",
          "name": "Tianyu Zhao",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a73",
          "name": "Qinglin Zhang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a74",
          "name": "Shiliang Zhang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a75",
          "name": "Nan Zhao",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a76",
          "name": "Pei Zhang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a77",
          "name": "Chong Zhang",
          "hidden": false
        },
        {
          "_id": "6785e88a6bc168b98ae46a78",
          "name": "Jinren Zhou",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-10T15:55:27.000Z",
      "title": "MinMo: A Multimodal Large Language Model for Seamless Voice Interaction",
      "summary": "Recent advancements in large language models (LLMs) and multimodal\nspeech-text models have laid the groundwork for seamless voice interactions,\nenabling real-time, natural, and human-like conversations. Previous models for\nvoice interactions are categorized as native and aligned. Native models\nintegrate speech and text processing in one framework but struggle with issues\nlike differing sequence lengths and insufficient pre-training. Aligned models\nmaintain text LLM capabilities but are often limited by small datasets and a\nnarrow focus on speech tasks. In this work, we introduce MinMo, a Multimodal\nLarge Language Model with approximately 8B parameters for seamless voice\ninteraction. We address the main limitations of prior aligned multimodal\nmodels. We train MinMo through multiple stages of speech-to-text alignment,\ntext-to-speech alignment, speech-to-speech alignment, and duplex interaction\nalignment, on 1.4 million hours of diverse speech data and a broad range of\nspeech tasks. After the multi-stage training, MinMo achieves state-of-the-art\nperformance across various benchmarks for voice comprehension and generation\nwhile maintaining the capabilities of text LLMs, and also facilitates\nfull-duplex conversation, that is, simultaneous two-way communication between\nthe user and the system. Moreover, we propose a novel and simple voice decoder\nthat outperforms prior models in voice generation. The enhanced\ninstruction-following capabilities of MinMo supports controlling speech\ngeneration based on user instructions, with various nuances including emotions,\ndialects, and speaking rates, and mimicking specific voices. For MinMo, the\nspeech-to-text latency is approximately 100ms, full-duplex latency is\napproximately 600ms in theory and 800ms in practice. The MinMo project web page\nis https://funaudiollm.github.io/minmo, and the code and models will be\nreleased soon.",
      "upvotes": 3,
      "discussionId": "6785e88c6bc168b98ae46b59"
    },
    "publishedAt": "2025-01-13T23:31:20.641Z",
    "title": "MinMo: A Multimodal Large Language Model for Seamless Voice Interaction",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06282.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5641
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.06590",
      "authors": [
        {
          "_id": "6785e9ade1226951bc8c83cb",
          "user": {
            "_id": "63357c608adfa81faf2ac180",
            "avatarUrl": "/avatars/ae0314c644f882251baf59b9134fd36f.svg",
            "isPro": false,
            "fullname": "Xiangru Tang",
            "user": "RTT1",
            "type": "user"
          },
          "name": "Xiangru Tang",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-01-14T04:35:59.001Z",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83cc",
          "name": "Tianyu Hu",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83cd",
          "name": "Muyang Ye",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83ce",
          "name": "Yanjun Shao",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83cf",
          "name": "Xunjian Yin",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83d0",
          "name": "Siru Ouyang",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83d1",
          "name": "Wangchunshu Zhou",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83d2",
          "name": "Pan Lu",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83d3",
          "name": "Zhuosheng Zhang",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83d4",
          "name": "Yilun Zhao",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83d5",
          "name": "Arman Cohan",
          "hidden": false
        },
        {
          "_id": "6785e9ade1226951bc8c83d6",
          "name": "Mark Gerstein",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-11T17:10:30.000Z",
      "title": "ChemAgent: Self-updating Library in Large Language Models Improves\n  Chemical Reasoning",
      "summary": "Chemical reasoning usually involves complex, multi-step processes that demand\nprecise calculations, where even minor errors can lead to cascading failures.\nFurthermore, large language models (LLMs) encounter difficulties handling\ndomain-specific formulas, executing reasoning steps accurately, and integrating\ncode effectively when tackling chemical reasoning tasks. To address these\nchallenges, we present ChemAgent, a novel framework designed to improve the\nperformance of LLMs through a dynamic, self-updating library. This library is\ndeveloped by decomposing chemical tasks into sub-tasks and compiling these\nsub-tasks into a structured collection that can be referenced for future\nqueries. Then, when presented with a new problem, ChemAgent retrieves and\nrefines pertinent information from the library, which we call memory,\nfacilitating effective task decomposition and the generation of solutions. Our\nmethod designs three types of memory and a library-enhanced reasoning\ncomponent, enabling LLMs to improve over time through experience. Experimental\nresults on four chemical reasoning datasets from SciBench demonstrate that\nChemAgent achieves performance gains of up to 46% (GPT-4), significantly\noutperforming existing methods. Our findings suggest substantial potential for\nfuture applications, including tasks such as drug discovery and materials\nscience. Our code can be found at https://github.com/gersteinlab/chemagent",
      "upvotes": 1,
      "discussionId": "6785e9afe1226951bc8c8468"
    },
    "publishedAt": "2025-01-13T23:36:33.019Z",
    "title": "ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06590.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5641
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2501.07574",
      "authors": [
        {
          "_id": "6785e58ffea9f9a51055f21b",
          "name": "Xingchen Liu",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f21c",
          "name": "Piyush Tayal",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f21d",
          "name": "Jianyuan Wang",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f21e",
          "name": "Jesus Zarzar",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f21f",
          "name": "Tom Monnier",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f220",
          "name": "Konstantinos Tertikas",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f221",
          "name": "Jiali Duan",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f222",
          "name": "Antoine Toisoul",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f223",
          "name": "Jason Y. Zhang",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f224",
          "name": "Natalia Neverova",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f225",
          "name": "Andrea Vedaldi",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f226",
          "name": "Roman Shapovalov",
          "hidden": false
        },
        {
          "_id": "6785e58ffea9f9a51055f227",
          "name": "David Novotny",
          "hidden": false
        }
      ],
      "publishedAt": "2025-01-13T18:59:20.000Z",
      "title": "UnCommon Objects in 3D",
      "summary": "We introduce Uncommon Objects in 3D (uCO3D), a new object-centric dataset for\n3D deep learning and 3D generative AI. uCO3D is the largest publicly-available\ncollection of high-resolution videos of objects with 3D annotations that\nensures full-360^{circ} coverage. uCO3D is significantly more diverse than\nMVImgNet and CO3Dv2, covering more than 1,000 object categories. It is also of\nhigher quality, due to extensive quality checks of both the collected videos\nand the 3D annotations. Similar to analogous datasets, uCO3D contains\nannotations for 3D camera poses, depth maps and sparse point clouds. In\naddition, each object is equipped with a caption and a 3D Gaussian Splat\nreconstruction. We train several large 3D models on MVImgNet, CO3Dv2, and uCO3D\nand obtain superior results using the latter, showing that uCO3D is better for\nlearning applications.",
      "upvotes": 1,
      "discussionId": "6785e593fea9f9a51055f3af"
    },
    "publishedAt": "2025-01-13T23:18:37.890Z",
    "title": "UnCommon Objects in 3D",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.07574.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5641
    },
    "isAuthorParticipating": false
  }
]