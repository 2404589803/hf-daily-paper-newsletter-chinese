[
    {
        "paper": {
            "id": "2409.18869",
            "authors": [
                {
                    "_id": "66fa2b34290c1dc129add7a8",
                    "user": {
                        "_id": "63ca558304c979828311c5a5",
                        "avatarUrl": "/avatars/2a439d79fba2f987cabe780d10c94d25.svg",
                        "isPro": false,
                        "fullname": "Xinlong Wang",
                        "user": "xinlongwang",
                        "type": "user"
                    },
                    "name": "Xinlong Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:14:46.256Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7a9",
                    "user": {
                        "_id": "64e473f0b78bc92221ab1883",
                        "avatarUrl": "/avatars/85dd02c2b4879d7696b552f0f9dc2680.svg",
                        "isPro": false,
                        "fullname": "Xiaosong Zhang",
                        "user": "zhangxiaosong18",
                        "type": "user"
                    },
                    "name": "Xiaosong Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:15:11.793Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7aa",
                    "name": "Zhengxiong Luo",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7ab",
                    "user": {
                        "_id": "630d7a8f81ef9b1772b67f4c",
                        "avatarUrl": "/avatars/00757abd6e548ccebb5bfb233be129a2.svg",
                        "isPro": false,
                        "fullname": "Quan Sun",
                        "user": "QuanSun",
                        "type": "user"
                    },
                    "name": "Quan Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:15:36.626Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7ac",
                    "user": {
                        "_id": "648683de623b5f050213f2be",
                        "avatarUrl": "/avatars/83ecbcf4a21f68d2893de79f0444d6e3.svg",
                        "isPro": false,
                        "fullname": "Yufeng Cui",
                        "user": "YufengCui",
                        "type": "user"
                    },
                    "name": "Yufeng Cui",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:15:42.953Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7ad",
                    "user": {
                        "_id": "6444a987af034cdfd69f6f8d",
                        "avatarUrl": "/avatars/36544a102771a80c4fc6cb39e0973b2f.svg",
                        "isPro": false,
                        "fullname": "Jinsheng Wang",
                        "user": "wolfwjs",
                        "type": "user"
                    },
                    "name": "Jinsheng Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-30T08:06:05.320Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7ae",
                    "name": "Fan Zhang",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7af",
                    "user": {
                        "_id": "6458b59c7a7e192202df8fa0",
                        "avatarUrl": "/avatars/33ee716477e5686da8723d01e199cd27.svg",
                        "isPro": false,
                        "fullname": "Yueze Wang",
                        "user": "yzwang",
                        "type": "user"
                    },
                    "name": "Yueze Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:16:08.897Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b0",
                    "user": {
                        "_id": "6285a9133ab6642179158944",
                        "avatarUrl": "/avatars/6e10fa07c94141fcdbe0cab02bb731ca.svg",
                        "isPro": false,
                        "fullname": "Zhen Li",
                        "user": "Paper99",
                        "type": "user"
                    },
                    "name": "Zhen Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-30T08:06:07.133Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b1",
                    "user": {
                        "_id": "6341375be5071b0c5cc946a3",
                        "avatarUrl": "/avatars/c26a32b54a3f7731854059d247b5c523.svg",
                        "isPro": false,
                        "fullname": "Qiying Yu",
                        "user": "qiying",
                        "type": "user"
                    },
                    "name": "Qiying Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:16:14.863Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b2",
                    "name": "Yingli Zhao",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b3",
                    "user": {
                        "_id": "64f3eb4fd41e83d74a0173ec",
                        "avatarUrl": "/avatars/461f804bb5a7c5b31f862cfa27e52de1.svg",
                        "isPro": false,
                        "fullname": "Yulong Ao",
                        "user": "aoyulong",
                        "type": "user"
                    },
                    "name": "Yulong Ao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:16:31.716Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b4",
                    "name": "Xuebin Min",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b5",
                    "name": "Tao Li",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b6",
                    "user": {
                        "_id": "64acaeccb575c5e272f5f124",
                        "avatarUrl": "/avatars/29b0f9d0ad38755a52db1e69d112caa9.svg",
                        "isPro": false,
                        "fullname": "BoyaWu",
                        "user": "BoyaWu10",
                        "type": "user"
                    },
                    "name": "Boya Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:17:07.155Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b7",
                    "user": {
                        "_id": "64acafac1aee69ece03af05a",
                        "avatarUrl": "/avatars/6380777852546dbd432fed5544d5db0b.svg",
                        "isPro": false,
                        "fullname": "Bo Zhao",
                        "user": "BoZhaoHuggingFace",
                        "type": "user"
                    },
                    "name": "Bo Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:17:27.547Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b8",
                    "name": "Bowen Zhang",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7b9",
                    "name": "Liangdong Wang",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7ba",
                    "name": "Guang Liu",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7bb",
                    "user": {
                        "_id": "65b21047f5d76208991e463e",
                        "avatarUrl": "/avatars/0fa822c22f95b9a9bfc93a3c28144837.svg",
                        "isPro": false,
                        "fullname": "Zheqi He",
                        "user": "philokey",
                        "type": "user"
                    },
                    "name": "Zheqi He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:18:32.699Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7bc",
                    "name": "Xi Yang",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7bd",
                    "user": {
                        "_id": "650bf18678d2dfbad85c0db1",
                        "avatarUrl": "/avatars/07ac9d726dc2ccf433746ee858a8044f.svg",
                        "isPro": false,
                        "fullname": "jin liu",
                        "user": "jingjingliu",
                        "type": "user"
                    },
                    "name": "Jingjing Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:19:17.332Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7be",
                    "user": {
                        "_id": "629aa3155ab4232a3fe0893e",
                        "avatarUrl": "/avatars/cf2d4a9295b5da9e2e4d2278bbb36040.svg",
                        "isPro": false,
                        "fullname": "Yonghua Lin",
                        "user": "Yonghua",
                        "type": "user"
                    },
                    "name": "Yonghua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T08:19:23.808Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7bf",
                    "name": "Tiejun Huang",
                    "hidden": false
                },
                {
                    "_id": "66fa2b34290c1dc129add7c0",
                    "name": "Zhongyuan Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-27T16:06:11.000Z",
            "title": "Emu3: Next-Token Prediction is All You Need",
            "summary": "While next-token prediction is considered a promising path towards artificial\ngeneral intelligence, it has struggled to excel in multimodal tasks, which are\nstill dominated by diffusion models (e.g., Stable Diffusion) and compositional\napproaches (e.g., CLIP combined with LLMs). In this paper, we introduce Emu3, a\nnew suite of state-of-the-art multimodal models trained solely with next-token\nprediction. By tokenizing images, text, and videos into a discrete space, we\ntrain a single transformer from scratch on a mixture of multimodal sequences.\nEmu3 outperforms several well-established task-specific models in both\ngeneration and perception tasks, surpassing flagship models such as SDXL and\nLLaVA-1.6, while eliminating the need for diffusion or compositional\narchitectures. Emu3 is also capable of generating high-fidelity video via\npredicting the next token in a video sequence. We simplify complex multimodal\nmodel designs by converging on a singular focus: tokens, unlocking great\npotential for scaling both during training and inference. Our results\ndemonstrate that next-token prediction is a promising path towards building\ngeneral multimodal intelligence beyond language. We open-source key techniques\nand models to support further research in this direction.",
            "upvotes": 44,
            "discussionId": "66fa2b38290c1dc129add8a0"
        },
        "publishedAt": "2024-09-30T03:23:21.178Z",
        "title": "Emu3: Next-Token Prediction is All You Need",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18869.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.17692",
            "authors": [
                {
                    "_id": "66fa19f693b99e4c7c8a02ce",
                    "name": "Zekun Wang",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02cf",
                    "name": "King Zhu",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d0",
                    "user": {
                        "_id": "6580333b64bab467b9bcb615",
                        "avatarUrl": "/avatars/753afae2fefc748791550c733aa2c80b.svg",
                        "isPro": false,
                        "fullname": "Chunpu Xu",
                        "user": "cpxu",
                        "type": "user"
                    },
                    "name": "Chunpu Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:26:31.334Z",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d1",
                    "user": {
                        "_id": "628c8598ef14f971b698107f",
                        "avatarUrl": "/avatars/3a4ad87e6b5f9e836a1160d869df1447.svg",
                        "isPro": false,
                        "fullname": "Zhou",
                        "user": "Wangchunshu",
                        "type": "user"
                    },
                    "name": "Wangchunshu Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:26:42.767Z",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d2",
                    "user": {
                        "_id": "65377c30e48353201e6fdda0",
                        "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
                        "isPro": false,
                        "fullname": "Jiaheng Liu",
                        "user": "CheeryLJH",
                        "type": "user"
                    },
                    "name": "Jiaheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:26:48.968Z",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d3",
                    "name": "Yibo Zhang",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d4",
                    "name": "Jiashuo Wang",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d5",
                    "user": {
                        "_id": "64e2f812bbee0c24b93fdb88",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64e2f812bbee0c24b93fdb88/UdeMJFDWjRjydJ38WjnnO.jpeg",
                        "isPro": false,
                        "fullname": "Ning Shi",
                        "user": "MrShininnnnn",
                        "type": "user"
                    },
                    "name": "Ning Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:28:12.312Z",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d6",
                    "name": "Siyu Li",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d7",
                    "name": "Yizhi Li",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d8",
                    "name": "Haoran Que",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02d9",
                    "user": {
                        "_id": "6350d59989def14ad21e11b3",
                        "avatarUrl": "/avatars/9a7ae6131e0a89f3461f267ee844b218.svg",
                        "isPro": false,
                        "fullname": "z",
                        "user": "zhaoxiang",
                        "type": "user"
                    },
                    "name": "Zhaoxiang Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:29:05.696Z",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02da",
                    "user": {
                        "_id": "60ff5c28aa025227d344b734",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1627347980032-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Yuanxing Zhang",
                        "user": "Onmyoji",
                        "type": "user"
                    },
                    "name": "Yuanxing Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:29:51.984Z",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02db",
                    "user": {
                        "_id": "638efcf4c67af472d316d424",
                        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                        "isPro": false,
                        "fullname": "Ge Zhang",
                        "user": "zhangysk",
                        "type": "user"
                    },
                    "name": "Ge Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:30:04.866Z",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02dc",
                    "name": "Ke Xu",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02dd",
                    "name": "Jie Fu",
                    "hidden": false
                },
                {
                    "_id": "66fa19f693b99e4c7c8a02de",
                    "user": {
                        "_id": "641e5bf65f274a0a92c2f6a2",
                        "avatarUrl": "/avatars/c15a54c51998c0e6367685e8e1737ec9.svg",
                        "isPro": false,
                        "fullname": "Wenhao Huang",
                        "user": "EZ-hwh",
                        "type": "user"
                    },
                    "name": "Wenhao Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:30:57.152Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-26T09:57:16.000Z",
            "title": "MIO: A Foundation Model on Multimodal Tokens",
            "summary": "In this paper, we introduce MIO, a novel foundation model built on multimodal\ntokens, capable of understanding and generating speech, text, images, and\nvideos in an end-to-end, autoregressive manner. While the emergence of large\nlanguage models (LLMs) and multimodal large language models (MM-LLMs) propels\nadvancements in artificial general intelligence through their versatile\ncapabilities, they still lack true any-to-any understanding and generation.\nRecently, the release of GPT-4o has showcased the remarkable potential of\nany-to-any LLMs for complex real-world tasks, enabling omnidirectional input\nand output across images, speech, and text. However, it is closed-source and\ndoes not support the generation of multimodal interleaved sequences. To address\nthis gap, we present MIO, which is trained on a mixture of discrete tokens\nacross four modalities using causal multimodal modeling. MIO undergoes a\nfour-stage training process: (1) alignment pre-training, (2) interleaved\npre-training, (3) speech-enhanced pre-training, and (4) comprehensive\nsupervised fine-tuning on diverse textual, visual, and speech tasks. Our\nexperimental results indicate that MIO exhibits competitive, and in some cases\nsuperior, performance compared to previous dual-modal baselines, any-to-any\nmodel baselines, and even modality-specific baselines. Moreover, MIO\ndemonstrates advanced capabilities inherent to its any-to-any feature, such as\ninterleaved video-text generation, chain-of-visual-thought reasoning, visual\nguideline generation, instructional image editing, etc.",
            "upvotes": 30,
            "discussionId": "66fa19fc93b99e4c7c8a046c"
        },
        "publishedAt": "2024-09-30T02:16:43.949Z",
        "title": "MIO: A Foundation Model on Multimodal Tokens",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17692.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6149a9e95347647e6bb68882/Jddln1FxScCeVgTSCNBpr.png",
            "fullname": "Zekun Moore Wang",
            "name": "ZenMoore",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.17066",
            "authors": [
                {
                    "_id": "66f4d188ee391e4c1f788568",
                    "name": "Yifei Liu",
                    "hidden": false
                },
                {
                    "_id": "66f4d188ee391e4c1f788569",
                    "user": {
                        "_id": "66e59c49908789cd77addc09",
                        "avatarUrl": "/avatars/9d4753f61e1d654c7fe3e78778daa8cb.svg",
                        "isPro": false,
                        "fullname": "GGG",
                        "user": "JiChengWen",
                        "type": "user"
                    },
                    "name": "Jicheng Wen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:31:55.115Z",
                    "hidden": false
                },
                {
                    "_id": "66f4d188ee391e4c1f78856a",
                    "user": {
                        "_id": "604714a0c82d59b7347b55ae",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/604714a0c82d59b7347b55ae/WZFKDDUPi8JS0BK8t7mIv.jpeg",
                        "isPro": false,
                        "fullname": "YangWang92",
                        "user": "yangwang92",
                        "type": "user"
                    },
                    "name": "Yang Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-26T08:22:52.135Z",
                    "hidden": false
                },
                {
                    "_id": "66f4d188ee391e4c1f78856b",
                    "user": {
                        "_id": "6508091067ab943749f9e869",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6508091067ab943749f9e869/TpdHfIez3rj5wQqrruA7G.jpeg",
                        "isPro": false,
                        "fullname": "Shengyu Ye",
                        "user": "Eviloder",
                        "type": "user"
                    },
                    "name": "Shengyu Ye",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:32:01.442Z",
                    "hidden": false
                },
                {
                    "_id": "66f4d188ee391e4c1f78856c",
                    "user": {
                        "_id": "62b0009c72043b05d29492b2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b0009c72043b05d29492b2/NqRkX2YLhlfOLvYysa7dD.png",
                        "isPro": false,
                        "fullname": "Li Lyna Zhang",
                        "user": "lynazhang",
                        "type": "user"
                    },
                    "name": "Li Lyna Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:32:07.360Z",
                    "hidden": false
                },
                {
                    "_id": "66f4d188ee391e4c1f78856d",
                    "user": {
                        "_id": "662852bf8bfc90408a97acdf",
                        "avatarUrl": "/avatars/008e6faf51e1be4f0c0d17008dfe2f49.svg",
                        "isPro": false,
                        "fullname": "cao",
                        "user": "tingcao",
                        "type": "user"
                    },
                    "name": "Ting Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:32:26.099Z",
                    "hidden": false
                },
                {
                    "_id": "66f4d188ee391e4c1f78856e",
                    "name": "Cheng Li",
                    "hidden": false
                },
                {
                    "_id": "66f4d188ee391e4c1f78856f",
                    "name": "Mao Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-25T16:25:45.000Z",
            "title": "VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large\n  Language Models",
            "summary": "Scaling model size significantly challenges the deployment and inference of\nLarge Language Models (LLMs). Due to the redundancy in LLM weights, recent\nresearch has focused on pushing weight-only quantization to extremely low-bit\n(even down to 2 bits). It reduces memory requirements, optimizes storage costs,\nand decreases memory bandwidth needs during inference. However, due to\nnumerical representation limitations, traditional scalar-based weight\nquantization struggles to achieve such extreme low-bit. Recent research on\nVector Quantization (VQ) for LLMs has demonstrated the potential for extremely\nlow-bit model quantization by compressing vectors into indices using lookup\ntables.\n  In this paper, we introduce Vector Post-Training Quantization (VPTQ) for\nextremely low-bit quantization of LLMs. We use Second-Order Optimization to\nformulate the LLM VQ problem and guide our quantization algorithm design by\nsolving the optimization. We further refine the weights using\nChannel-Independent Second-Order Optimization for a granular VQ. In addition,\nby decomposing the optimization problem, we propose a brief and effective\ncodebook initialization algorithm. We also extend VPTQ to support residual and\noutlier quantization, which enhances model accuracy and further compresses the\nmodel. Our experimental results show that VPTQ reduces model quantization\nperplexity by 0.01-0.34 on LLaMA-2, 0.38-0.68 on Mistral-7B,\n4.41-7.34 on LLaMA-3 over SOTA at 2-bit, with an average accuracy\nimprovement of 0.79-1.5% on LLaMA-2, 1% on Mistral-7B, 11-22% on\nLLaMA-3 on QA tasks on average. We only utilize 10.4-18.6% of the\nquantization algorithm execution time, resulting in a 1.6-1.8times\nincrease in inference throughput compared to SOTA.",
            "upvotes": 14,
            "discussionId": "66f4d189ee391e4c1f788598"
        },
        "publishedAt": "2024-09-30T01:55:09.455Z",
        "title": "VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17066.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/604714a0c82d59b7347b55ae/WZFKDDUPi8JS0BK8t7mIv.jpeg",
            "fullname": "YangWang92",
            "name": "yangwang92",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.18964",
            "authors": [
                {
                    "_id": "66fa2c8ba0802002c35431ab",
                    "user": {
                        "_id": "661381e53bb67cb4f36401bc",
                        "avatarUrl": "/avatars/33677dfd06ae50726809e5b685507cd4.svg",
                        "isPro": false,
                        "fullname": "Shaowei Liu",
                        "user": "lsw825",
                        "type": "user"
                    },
                    "name": "Shaowei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:41:44.604Z",
                    "hidden": false
                },
                {
                    "_id": "66fa2c8ba0802002c35431ac",
                    "name": "Zhongzheng Ren",
                    "hidden": false
                },
                {
                    "_id": "66fa2c8ba0802002c35431ad",
                    "name": "Saurabh Gupta",
                    "hidden": false
                },
                {
                    "_id": "66fa2c8ba0802002c35431ae",
                    "user": {
                        "_id": "62fbe0aaa80632fbd47b86f5",
                        "avatarUrl": "/avatars/8175e3ac325745714f17dbe000ea955f.svg",
                        "isPro": false,
                        "fullname": "Shenlong Wang",
                        "user": "shenlong",
                        "type": "user"
                    },
                    "name": "Shenlong Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:42:19.365Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-27T17:59:57.000Z",
            "title": "PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation",
            "summary": "We present PhysGen, a novel image-to-video generation method that converts a\nsingle image and an input condition (e.g., force and torque applied to an\nobject in the image) to produce a realistic, physically plausible, and\ntemporally consistent video. Our key insight is to integrate model-based\nphysical simulation with a data-driven video generation process, enabling\nplausible image-space dynamics. At the heart of our system are three core\ncomponents: (i) an image understanding module that effectively captures the\ngeometry, materials, and physical parameters of the image; (ii) an image-space\ndynamics simulation model that utilizes rigid-body physics and inferred\nparameters to simulate realistic behaviors; and (iii) an image-based rendering\nand refinement module that leverages generative video diffusion to produce\nrealistic video footage featuring the simulated motion. The resulting videos\nare realistic in both physics and appearance and are even precisely\ncontrollable, showcasing superior results over existing data-driven\nimage-to-video generation works through quantitative comparison and\ncomprehensive user study. PhysGen's resulting videos can be used for various\ndownstream applications, such as turning an image into a realistic animation or\nallowing users to interact with the image and create various dynamics. Project\npage: https://stevenlsw.github.io/physgen/",
            "upvotes": 11,
            "discussionId": "66fa2c8ea0802002c3543225"
        },
        "publishedAt": "2024-09-30T03:17:46.010Z",
        "title": "PhysGen: Rigid-Body Physics-Grounded Image-to-Video Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18964.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.17545",
            "authors": [
                {
                    "_id": "66fa2848f50b1d60294265e8",
                    "user": {
                        "_id": "64757d6322b4dec4524c924c",
                        "avatarUrl": "/avatars/51c1a93f44375e2604d4c23ca66600ad.svg",
                        "isPro": false,
                        "fullname": "Cheolhun Jang",
                        "user": "fetong",
                        "type": "user"
                    },
                    "name": "Cheolhun Jang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-30T08:06:09.218Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-26T05:24:14.000Z",
            "title": "Modulated Intervention Preference Optimization (MIPO): Keep the Easy,\n  Refine the Difficult",
            "summary": "Preference optimization methods typically begin training with a well-trained\nSFT model as a reference model. In RLHF and DPO, a regularization term is used\nduring the preference optimization process to prevent the policy model from\ndeviating too far from the reference model's distribution, thereby avoiding the\ngeneration of anomalous responses. When the reference model is already\nwell-aligned with the given data or only requires slight adjustments, this\napproach can produce a well-aligned model. However, if the reference model is\nnot aligned with the given data and requires significant deviation from its\ncurrent state, a regularization term may actually hinder the model alignment.\nIn this study, we propose Modulated Intervention Preference\nOptimization (MIPO) to address this issue. MIPO modulates the degree of\nintervention from the reference model based on how well the given data is\naligned with it. If the data is well-aligned, the intervention is increased to\nprevent the policy model from diverging significantly from reference model.\nConversely, if the alignment is poor, the interference is reduced to facilitate\nmore extensive training. We compare the performance of MIPO and DPO using\nMistral-7B and Llama3-8B in Alpaca Eval 2.0 and MT-Bench. The experimental\nresults demonstrate that MIPO consistently outperforms DPO across various\nevaluation scenarios.",
            "upvotes": 9,
            "discussionId": "66fa2849f50b1d6029426602"
        },
        "publishedAt": "2024-09-30T05:36:26.070Z",
        "title": "Modulated Intervention Preference Optimization (MIPO): Keep the Easy, Refine the Difficult",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.17545.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "/avatars/51c1a93f44375e2604d4c23ca66600ad.svg",
            "fullname": "Cheolhun Jang",
            "name": "fetong",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.18839",
            "authors": [
                {
                    "_id": "66fa495601ab1cdf3672e569",
                    "user": {
                        "_id": "63ae9ff5557befe297a76f90",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672388558183-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Bin Wang",
                        "user": "wanderkid",
                        "type": "user"
                    },
                    "name": "Bin Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-30T12:08:30.143Z",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e56a",
                    "name": "Chao Xu",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e56b",
                    "name": "Xiaomeng Zhao",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e56c",
                    "name": "Linke Ouyang",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e56d",
                    "name": "Fan Wu",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e56e",
                    "name": "Zhiyuan Zhao",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e56f",
                    "name": "Rui Xu",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e570",
                    "name": "Kaiwen Liu",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e571",
                    "name": "Yuan Qu",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e572",
                    "name": "Fukai Shang",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e573",
                    "name": "Bo Zhang",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e574",
                    "name": "Liqun Wei",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e575",
                    "name": "Zhihao Sui",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e576",
                    "name": "Wei Li",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e577",
                    "name": "Botian Shi",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e578",
                    "name": "Yu Qiao",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e579",
                    "name": "Dahua Lin",
                    "hidden": false
                },
                {
                    "_id": "66fa495601ab1cdf3672e57a",
                    "user": {
                        "_id": "63f9fca8d4349b157a109eec",
                        "avatarUrl": "/avatars/fa1f2ae7972d7cde99dab178136ccbb0.svg",
                        "isPro": false,
                        "fullname": "Conghui He",
                        "user": "conghui",
                        "type": "user"
                    },
                    "name": "Conghui He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:33:29.147Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-27T15:35:15.000Z",
            "title": "MinerU: An Open-Source Solution for Precise Document Content Extraction",
            "summary": "Document content analysis has been a crucial research area in computer\nvision. Despite significant advancements in methods such as OCR, layout\ndetection, and formula recognition, existing open-source solutions struggle to\nconsistently deliver high-quality content extraction due to the diversity in\ndocument types and content. To address these challenges, we present MinerU, an\nopen-source solution for high-precision document content extraction. MinerU\nleverages the sophisticated PDF-Extract-Kit models to extract content from\ndiverse documents effectively and employs finely-tuned preprocessing and\npostprocessing rules to ensure the accuracy of the final results. Experimental\nresults demonstrate that MinerU consistently achieves high performance across\nvarious document types, significantly enhancing the quality and consistency of\ncontent extraction. The MinerU open-source project is available at\nhttps://github.com/opendatalab/MinerU.",
            "upvotes": 8,
            "discussionId": "66fa495801ab1cdf3672e61f"
        },
        "publishedAt": "2024-09-30T05:17:52.656Z",
        "title": "MinerU: An Open-Source Solution for Precise Document Content Extraction",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18839.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672388558183-noauth.jpeg",
            "fullname": "Bin Wang",
            "name": "wanderkid",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.16686",
            "authors": [
                {
                    "_id": "66fa125293b99e4c7c87e2d3",
                    "user": {
                        "_id": "65572fd2bcdc315c0a1395d7",
                        "avatarUrl": "/avatars/36135ca35bbd4baca37a9092f3e2d82c.svg",
                        "isPro": false,
                        "fullname": "dayuanfu",
                        "user": "fudayuan",
                        "type": "user"
                    },
                    "name": "Dayuan Fu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:42:50.223Z",
                    "hidden": false
                },
                {
                    "_id": "66fa125293b99e4c7c87e2d4",
                    "name": "Biqing Qi",
                    "hidden": false
                },
                {
                    "_id": "66fa125293b99e4c7c87e2d5",
                    "name": "Yihuai Gao",
                    "hidden": false
                },
                {
                    "_id": "66fa125293b99e4c7c87e2d6",
                    "user": {
                        "_id": "66d8715b36aa50556908ea7d",
                        "avatarUrl": "/avatars/63a242ba6a4579c3a5299b1146c277c0.svg",
                        "isPro": false,
                        "fullname": "Che Jiang",
                        "user": "jiangche",
                        "type": "user"
                    },
                    "name": "Che Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:44:06.741Z",
                    "hidden": false
                },
                {
                    "_id": "66fa125293b99e4c7c87e2d7",
                    "user": {
                        "_id": "61cd4b833dd34ba1985e0753",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61cd4b833dd34ba1985e0753/BfHfrwotoMESpXZOHiIe4.png",
                        "isPro": false,
                        "fullname": "KABI",
                        "user": "dongguanting",
                        "type": "user"
                    },
                    "name": "Guanting Dong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-09-30T12:44:00.514Z",
                    "hidden": false
                },
                {
                    "_id": "66fa125293b99e4c7c87e2d8",
                    "name": "Bowen Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-25T07:21:51.000Z",
            "title": "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for\n  Superior Planning and Decision-Making",
            "summary": "Long-term memory is significant for agents, in which insights play a crucial\nrole. However, the emergence of irrelevant insight and the lack of general\ninsight can greatly undermine the effectiveness of insight. To solve this\nproblem, in this paper, we introduce Multi-Scale Insight Agent (MSI-Agent), an\nembodied agent designed to improve LLMs' planning and decision-making ability\nby summarizing and utilizing insight effectively across different scales. MSI\nachieves this through the experience selector, insight generator, and insight\nselector. Leveraging a three-part pipeline, MSI can generate task-specific and\nhigh-level insight, store it in a database, and then use relevant insight from\nit to aid in decision-making. Our experiments show that MSI outperforms another\ninsight strategy when planning by GPT3.5. Moreover, We delve into the\nstrategies for selecting seed experience and insight, aiming to provide LLM\nwith more useful and relevant insight for better decision-making. Our\nobservations also indicate that MSI exhibits better robustness when facing\ndomain-shifting scenarios.",
            "upvotes": 4,
            "discussionId": "66fa125593b99e4c7c87e3ab"
        },
        "publishedAt": "2024-09-30T01:22:44.248Z",
        "title": "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.16686.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61cd4b833dd34ba1985e0753/BfHfrwotoMESpXZOHiIe4.png",
            "fullname": "KABI",
            "name": "dongguanting",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.18786",
            "authors": [
                {
                    "_id": "66facd02b505f1a04c28cf29",
                    "name": "Siheng Li",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf2a",
                    "name": "Cheng Yang",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf2b",
                    "name": "Taiqiang Wu",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf2c",
                    "name": "Chufan Shi",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf2d",
                    "name": "Yuji Zhang",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf2e",
                    "name": "Xinyu Zhu",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf2f",
                    "name": "Zesen Cheng",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf30",
                    "name": "Deng Cai",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf31",
                    "name": "Mo Yu",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf32",
                    "name": "Lemao Liu",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf33",
                    "name": "Jie Zhou",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf34",
                    "name": "Yujiu Yang",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf35",
                    "name": "Ngai Wong",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf36",
                    "name": "Xixin Wu",
                    "hidden": false
                },
                {
                    "_id": "66facd02b505f1a04c28cf37",
                    "name": "Wai Lam",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-27T14:34:54.000Z",
            "title": "A Survey on the Honesty of Large Language Models",
            "summary": "Honesty is a fundamental principle for aligning large language models (LLMs)\nwith human values, requiring these models to recognize what they know and don't\nknow and be able to faithfully express their knowledge. Despite promising,\ncurrent LLMs still exhibit significant dishonest behaviors, such as confidently\npresenting wrong answers or failing to express what they know. In addition,\nresearch on the honesty of LLMs also faces challenges, including varying\ndefinitions of honesty, difficulties in distinguishing between known and\nunknown knowledge, and a lack of comprehensive understanding of related\nresearch. To address these issues, we provide a survey on the honesty of LLMs,\ncovering its clarification, evaluation approaches, and strategies for\nimprovement. Moreover, we offer insights for future research, aiming to inspire\nfurther exploration in this important area.",
            "upvotes": 2,
            "discussionId": "66facd03b505f1a04c28cfb3"
        },
        "publishedAt": "2024-09-30T14:41:55.263Z",
        "title": "A Survey on the Honesty of Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18786.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/36f36eea72a100ee56b37c6d185b47c0.svg",
            "fullname": "Shi",
            "name": "Chufan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2409.18957",
            "authors": [
                {
                    "_id": "66faa0c2c2bf89d75e844ac5",
                    "user": {
                        "_id": "66123b20ceb89d45d692fc5f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66123b20ceb89d45d692fc5f/89nz7lbvBOla-CzkHYWlp.png",
                        "isPro": false,
                        "fullname": "Praneeth",
                        "user": "prane-eth",
                        "type": "user"
                    },
                    "name": "Praneeth Vadlapati",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-09-30T15:51:27.140Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-09-27T17:58:50.000Z",
            "title": "LML: Language Model Learning a Dataset for Data-Augmented Prediction",
            "summary": "This paper introduces a new approach to using Large Language Models (LLMs)\nfor classification tasks, which are typically handled using Machine Learning\n(ML) models. Unlike ML models that rely heavily on data cleaning and feature\nengineering, this method streamlines the process using LLMs. This paper\nproposes a new concept called \"Language Model Learning (LML)\" powered by a new\nmethod called \"Data-Augmented Prediction (DAP)\". The classification is\nperformed by LLMs using a method similar to humans manually exploring and\nunderstanding the data and deciding classifications using data as a reference.\nTraining data is summarized and evaluated to determine the features that lead\nto the classification of each label the most. In the process of DAP, the system\nuses the data summary to automatically create a query, which is used to\nretrieve relevant rows from the dataset. A classification is generated by the\nLLM using data summary and relevant rows, ensuring satisfactory accuracy even\nwith complex data. Usage of data summary and similar data in DAP ensures\ncontext-aware decision-making. The proposed method uses the words \"Act as an\nExplainable Machine Learning Model\" in the prompt to enhance the\ninterpretability of the predictions by allowing users to review the logic\nbehind each prediction. In some test cases, the system scored an accuracy above\n90%, proving the effectiveness of the system and its potential to outperform\nconventional ML models in various scenarios. The code is available at\nhttps://github.com/Pro-GenAI/LML-DAP",
            "upvotes": 2,
            "discussionId": "66faa0c2c2bf89d75e844af3"
        },
        "publishedAt": "2024-09-30T13:30:27.754Z",
        "title": "LML: Language Model Learning a Dataset for Data-Augmented Prediction",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/66123b20ceb89d45d692fc5f/klpd2wWbqjvhv7rmdeh1Z.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2409.18957.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66123b20ceb89d45d692fc5f/89nz7lbvBOla-CzkHYWlp.png",
            "fullname": "Praneeth",
            "name": "prane-eth",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]