[
    "{'paper': {'id': '2412.17743', 'authors': [{'_id': '676d2c63310ca4eb397415fe', 'name': 'Yiwen Hu', 'hidden': False}, {'_id': '676d2c63310ca4eb397415ff', 'name': 'Huatong Song', 'hidden': False}, {'_id': '676d2c63310ca4eb39741600', 'name': 'Jia Deng', 'hidden': False}, {'_id': '676d2c63310ca4eb39741601', 'name': 'Jiapeng Wang', 'hidden': False}, {'_id': '676d2c63310ca4eb39741602', 'name': 'Jie Chen', 'hidden': False}, {'_id': '676d2c63310ca4eb39741603', 'name': 'Kun Zhou', 'hidden': False}, {'_id': '676d2c63310ca4eb39741604', 'name': 'Yutao Zhu', 'hidden': False}, {'_id': '676d2c63310ca4eb39741605', 'name': 'Jinhao Jiang', 'hidden': False}, {'_id': '676d2c63310ca4eb39741606', 'name': 'Zican Dong', 'hidden': False}, {'_id': '676d2c63310ca4eb39741607', 'name': 'Wayne Xin Zhao', 'hidden': False}, {'_id': '676d2c63310ca4eb39741608', 'name': 'Ji-Rong Wen', 'hidden': False}], 'publishedAt': '2024-12-23T17:47:53.000Z', 'title': 'YuLan-Mini: An Open Data-efficient Language Model', 'summary': 'Effective pre-training of large language models (LLMs) has been challenging\\ndue to the immense resource demands and the complexity of the technical\\nprocesses involved. This paper presents a detailed technical report on\\nYuLan-Mini, a highly capable base model with 2.42B parameters that achieves\\ntop-tier performance among models of similar parameter scale. Our pre-training\\napproach focuses on enhancing training efficacy through three key technical\\ncontributions: an elaborate data pipeline combines data cleaning with data\\nschedule strategies, a robust optimization method to mitigate training\\ninstability, and an effective annealing approach that incorporates targeted\\ndata selection and long context training. Remarkably, YuLan-Mini, trained on\\n1.08T tokens, achieves performance comparable to industry-leading models that\\nrequire significantly more data. To facilitate reproduction, we release the\\nfull details of the data composition for each training phase. Project details\\ncan be accessed at the following link: https://github.com/RUC-GSAI/YuLan-Mini.', 'upvotes': 26, 'discussionId': '676d2c65310ca4eb39741682'}, 'publishedAt': '2024-12-27T01:08:10.879Z', 'title': 'YuLan-Mini: An Open Data-efficient Language Model', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/6317419f3eb2544b62389a79/ruQQgcy_OzG_dx_7Z-tk-.png', 'https://cdn-uploads.huggingface.co/production/uploads/6317419f3eb2544b62389a79/DEKzbv-CqVK7cw-pc7K_t.png', 'https://cdn-uploads.huggingface.co/production/uploads/6317419f3eb2544b62389a79/e7mdk9SoId2AUjUpoH8vD.png', 'https://cdn-uploads.huggingface.co/production/uploads/6317419f3eb2544b62389a79/UulrjfVDO1p_BSy8O-A5G.png'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.17743.png', 'numComments': 1, 'submittedBy': {'_id': '6317419f3eb2544b62389a79', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6317419f3eb2544b62389a79/8oU90du902ATtBPYCcLFK.jpeg', 'fullname': 'Ivan Hu', 'name': 'IvanHU', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 2}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2412.17483', 'authors': [{'_id': '676a2a3ebce62ec5a02c4a66', 'user': {'_id': '654c99d6e82a71cb487c2ecd', 'avatarUrl': '/avatars/480c883b587ed2e41e1e9661c844a938.svg', 'isPro': False, 'fullname': 'ChenlongDeng', 'user': 'ChenlongDeng', 'type': 'user'}, 'name': 'Chenlong Deng', 'status': 'admin_assigned', 'statusLastChangedAt': '2024-12-26T18:49:33.308Z', 'hidden': False}, {'_id': '676a2a3ebce62ec5a02c4a67', 'name': 'Zhisong Zhang', 'hidden': False}, {'_id': '676a2a3ebce62ec5a02c4a68', 'name': 'Kelong Mao', 'hidden': False}, {'_id': '676a2a3ebce62ec5a02c4a69', 'name': 'Shuaiyi Li', 'hidden': False}, {'_id': '676a2a3ebce62ec5a02c4a6a', 'name': 'Xinting Huang', 'hidden': False}, {'_id': '676a2a3ebce62ec5a02c4a6b', 'name': 'Dong Yu', 'hidden': False}, {'_id': '676a2a3ebce62ec5a02c4a6c', 'name': 'Zhicheng Dou', 'hidden': False}], 'publishedAt': '2024-12-23T11:24:04.000Z', 'title': 'A Silver Bullet or a Compromise for Full Attention? A Comprehensive\\n  Study of Gist Token-based Context Compression', 'summary': 'In this work, we provide a thorough investigation of gist-based context\\ncompression methods to improve long-context processing in large language\\nmodels. We focus on two key questions: (1) How well can these methods replace\\nfull attention models? and (2) What potential failure patterns arise due to\\ncompression? Through extensive experiments, we show that while gist-based\\ncompression can achieve near-lossless performance on tasks like\\nretrieval-augmented generation and long-document QA, it faces challenges in\\ntasks like synthetic recall. Furthermore, we identify three key failure\\npatterns: lost by the boundary, lost if surprise, and lost along the way. To\\nmitigate these issues, we propose two effective strategies: fine-grained\\nautoencoding, which enhances the reconstruction of original token information,\\nand segment-wise token importance estimation, which adjusts optimization based\\non token dependencies. Our work provides valuable insights into the\\nunderstanding of gist token-based context compression and offers practical\\nstrategies for improving compression capabilities.', 'upvotes': 17, 'discussionId': '676a2a3fbce62ec5a02c4ace'}, 'publishedAt': '2024-12-27T02:39:50.862Z', 'title': 'A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.17483.png', 'numComments': 1, 'submittedBy': {'_id': '654c99d6e82a71cb487c2ecd', 'avatarUrl': '/avatars/480c883b587ed2e41e1e9661c844a938.svg', 'fullname': 'ChenlongDeng', 'name': 'ChenlongDeng', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2412.18072', 'authors': [{'_id': '676e9cfc11998b72ab00be60', 'name': 'Wan-Cyuan Fan', 'hidden': False}, {'_id': '676e9cfc11998b72ab00be61', 'name': 'Tanzila Rahman', 'hidden': False}, {'_id': '676e9cfc11998b72ab00be62', 'name': 'Leonid Sigal', 'hidden': False}], 'publishedAt': '2024-12-24T00:59:16.000Z', 'title': 'MMFactory: A Universal Solution Search Engine for Vision-Language Tasks', 'summary': 'With advances in foundational and vision-language models, and effective\\nfine-tuning techniques, a large number of both general and special-purpose\\nmodels have been developed for a variety of visual tasks. Despite the\\nflexibility and accessibility of these models, no single model is able to\\nhandle all tasks and/or applications that may be envisioned by potential users.\\nRecent approaches, such as visual programming and multimodal LLMs with\\nintegrated tools aim to tackle complex visual tasks, by way of program\\nsynthesis. However, such approaches overlook user constraints (e.g.,\\nperformance / computational needs), produce test-time sample-specific solutions\\nthat are difficult to deploy, and, sometimes, require low-level instructions\\nthat maybe beyond the abilities of a naive user. To address these limitations,\\nwe introduce MMFactory, a universal framework that includes model and metrics\\nrouting components, acting like a solution search engine across various\\navailable models. Based on a task description and few sample input-output pairs\\nand (optionally) resource and/or performance constraints, MMFactory can suggest\\na diverse pool of programmatic solutions by instantiating and combining\\nvisio-lingual tools from its model repository. In addition to synthesizing\\nthese solutions, MMFactory also proposes metrics and benchmarks performance /\\nresource characteristics, allowing users to pick a solution that meets their\\nunique design constraints. From the technical perspective, we also introduced a\\ncommittee-based solution proposer that leverages multi-agent LLM conversation\\nto generate executable, diverse, universal, and robust solutions for the user.\\nExperimental results show that MMFactory outperforms existing methods by\\ndelivering state-of-the-art solutions tailored to user problem specifications.\\nProject page is available at https://davidhalladay.github.io/mmfactory_demo.', 'upvotes': 4, 'discussionId': '676e9cfd11998b72ab00bfe8'}, 'publishedAt': '2024-12-27T07:26:55.759Z', 'title': 'MMFactory: A Universal Solution Search Engine for Vision-Language Tasks', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18072.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5470}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2412.18176', 'authors': [{'_id': '676e9d9d8126645611b73ecb', 'name': 'Yucong Luo', 'hidden': False}, {'_id': '676e9d9d8126645611b73ecc', 'name': 'Qitao Qin', 'hidden': False}, {'_id': '676e9d9d8126645611b73ecd', 'name': 'Hao Zhang', 'hidden': False}, {'_id': '676e9d9d8126645611b73ece', 'name': 'Mingyue Cheng', 'hidden': False}, {'_id': '676e9d9d8126645611b73ecf', 'name': 'Ruiran Yan', 'hidden': False}, {'_id': '676e9d9d8126645611b73ed0', 'name': 'Kefan Wang', 'hidden': False}, {'_id': '676e9d9d8126645611b73ed1', 'name': 'Jie Ouyang', 'hidden': False}], 'publishedAt': '2024-12-24T05:23:13.000Z', 'title': 'Molar: Multimodal LLMs with Collaborative Filtering Alignment for\\n  Enhanced Sequential Recommendation', 'summary': 'Sequential recommendation (SR) systems have evolved significantly over the\\npast decade, transitioning from traditional collaborative filtering to deep\\nlearning approaches and, more recently, to large language models (LLMs). While\\nthe adoption of LLMs has driven substantial advancements, these models\\ninherently lack collaborative filtering information, relying primarily on\\ntextual content data neglecting other modalities and thus failing to achieve\\noptimal recommendation performance. To address this limitation, we propose\\nMolar, a Multimodal large language sequential recommendation framework that\\nintegrates multiple content modalities with ID information to capture\\ncollaborative signals effectively. Molar employs an MLLM to generate unified\\nitem representations from both textual and non-textual data, facilitating\\ncomprehensive multimodal modeling and enriching item embeddings. Additionally,\\nit incorporates collaborative filtering signals through a post-alignment\\nmechanism, which aligns user representations from content-based and ID-based\\nmodels, ensuring precise personalization and robust performance. By seamlessly\\ncombining multimodal content with collaborative filtering insights, Molar\\ncaptures both user interests and contextual semantics, leading to superior\\nrecommendation accuracy. Extensive experiments validate that Molar\\nsignificantly outperforms traditional and LLM-based baselines, highlighting its\\nstrength in utilizing multimodal data and collaborative signals for sequential\\nrecommendation tasks. The source code is available at\\nhttps://anonymous.4open.science/r/Molar-8B06/.', 'upvotes': 2, 'discussionId': '676e9d9d8126645611b73f18'}, 'publishedAt': '2024-12-27T07:29:26.502Z', 'title': 'Molar: Multimodal LLMs with Collaborative Filtering Alignment for Enhanced Sequential Recommendation', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2412.18176.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 5470}, 'isAuthorParticipating': False}"
]