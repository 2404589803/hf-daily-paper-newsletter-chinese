[
    {
        "paper": {
            "id": "2410.17637",
            "authors": [
                {
                    "_id": "6719b2470b8f923fdda13623",
                    "user": {
                        "_id": "66fe1334ff3ee1f7569fab6d",
                        "avatarUrl": "/avatars/6868b1a545028a9b8bbded52490dc093.svg",
                        "isPro": false,
                        "fullname": "ziyuliu",
                        "user": "ziyuliu",
                        "type": "user"
                    },
                    "name": "Ziyu Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:13:22.757Z",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda13624",
                    "user": {
                        "_id": "63859cf3b2906edaf83af9f0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63859cf3b2906edaf83af9f0/iUQm5FAomzqYi6fkqIn9F.jpeg",
                        "isPro": false,
                        "fullname": "Yuhang Zang",
                        "user": "yuhangzang",
                        "type": "user"
                    },
                    "name": "Yuhang Zang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:13:12.075Z",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda13625",
                    "name": "Xiaoyi Dong",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda13626",
                    "name": "Pan Zhang",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda13627",
                    "user": {
                        "_id": "65000bef18830fabea469fdd",
                        "avatarUrl": "/avatars/b320c77dfad039d9f9c54127f610d44f.svg",
                        "isPro": false,
                        "fullname": "Cao Yuhang",
                        "user": "yhcao",
                        "type": "user"
                    },
                    "name": "Yuhang Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:13:03.746Z",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda13628",
                    "user": {
                        "_id": "63ee1379190ddd6214efd73a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
                        "isPro": false,
                        "fullname": "HAODONG DUAN",
                        "user": "KennyUTC",
                        "type": "user"
                    },
                    "name": "Haodong Duan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-24T07:15:24.930Z",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda13629",
                    "user": {
                        "_id": "63f9fca8d4349b157a109eec",
                        "avatarUrl": "/avatars/fa1f2ae7972d7cde99dab178136ccbb0.svg",
                        "isPro": false,
                        "fullname": "Conghui He",
                        "user": "conghui",
                        "type": "user"
                    },
                    "name": "Conghui He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:00:44.324Z",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda1362a",
                    "user": {
                        "_id": "66209605f44be495f123b055",
                        "avatarUrl": "/avatars/b72081a0383a709899f9ba80b4211690.svg",
                        "isPro": false,
                        "fullname": "Yuanjun Xiong",
                        "user": "TheYJ",
                        "type": "user"
                    },
                    "name": "Yuanjun Xiong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:12:24.611Z",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda1362b",
                    "user": {
                        "_id": "636317ed80c1a705a6eff396",
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:12:18.459Z",
                    "hidden": false
                },
                {
                    "_id": "6719b2470b8f923fdda1362c",
                    "name": "Jiaqi Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-23T07:56:48.000Z",
            "title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large\n  Vision-Language Models",
            "summary": "Visual preference alignment involves training Large Vision-Language Models\n(LVLMs) to predict human preferences between visual inputs. This is typically\nachieved by using labeled datasets of chosen/rejected pairs and employing\noptimization algorithms like direct preference optimization (DPO). Existing\nvisual alignment methods, primarily designed for single-image scenarios,\nstruggle to effectively handle the complexity of multi-image tasks due to the\nscarcity of diverse training data and the high cost of annotating\nchosen/rejected pairs. We present Multi-Image Augmented Direct Preference\nOptimization (MIA-DPO), a visual preference alignment approach that effectively\nhandles multi-image inputs. MIA-DPO mitigates the scarcity of diverse\nmulti-image training data by extending single-image data with unrelated images\narranged in grid collages or pic-in-pic formats, significantly reducing the\ncosts associated with multi-image data annotations. Our observation reveals\nthat attention values of LVLMs vary considerably across different images. We\nuse attention values to identify and filter out rejected responses the model\nmay have mistakenly focused on. Our attention-aware selection for constructing\nthe chosen/rejected pairs without relying on (i) human annotation, (ii) extra\ndata, and (iii) external models or APIs. MIA-DPO is compatible with various\narchitectures and outperforms existing methods on five multi-image benchmarks,\nachieving an average performance boost of 3.0% on LLaVA-v1.5 and 4.3% on the\nrecent InternLM-XC2.5. Moreover, MIA-DPO has a minimal effect on the model's\nability to understand single images.",
            "upvotes": 25,
            "discussionId": "6719b2490b8f923fdda13696"
        },
        "publishedAt": "2024-10-24T04:23:39.578Z",
        "title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.17637.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
            "fullname": "Jiaqi Wang",
            "name": "myownskyW7",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 8
        }
    },
    {
        "paper": {
            "id": "2410.18072",
            "authors": [
                {
                    "_id": "6719dd0c0a835a6043db72e5",
                    "name": "Yiran Qin",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72e6",
                    "user": {
                        "_id": "64f5d8b05619fe1fe06ed1a7",
                        "avatarUrl": "/avatars/61016a0533760dafacefe8ce6e344318.svg",
                        "isPro": false,
                        "fullname": "Zhelun Shi",
                        "user": "CoachXP",
                        "type": "user"
                    },
                    "name": "Zhelun Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:33:12.384Z",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72e7",
                    "name": "Jiwen Yu",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72e8",
                    "name": "Xijun Wang",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72e9",
                    "user": {
                        "_id": "63f08dc79cf89c9ed1bb89cd",
                        "avatarUrl": "/avatars/37290358ad00bbd752f519cfdec02f3e.svg",
                        "isPro": false,
                        "fullname": "Zhoues",
                        "user": "Zhoues",
                        "type": "user"
                    },
                    "name": "Enshen Zhou",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-24T07:15:21.418Z",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72ea",
                    "user": {
                        "_id": "64631d6cd4d34b01f45b013f",
                        "avatarUrl": "/avatars/1119ca2fa9e9893cbe856560ac67b2c6.svg",
                        "isPro": false,
                        "fullname": "JL",
                        "user": "LIJUNLI",
                        "type": "user"
                    },
                    "name": "Lijun Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:32:08.764Z",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72eb",
                    "user": {
                        "_id": "64e314ad24809d7fa0f20fbc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/bHE0w_hjDFvU-Aul0_E7g.jpeg",
                        "isPro": false,
                        "fullname": "Zhenfei Yin",
                        "user": "JeremyYin",
                        "type": "user"
                    },
                    "name": "Zhenfei Yin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:31:58.215Z",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72ec",
                    "user": {
                        "_id": "65d5ec74cd05bc1eaa125040",
                        "avatarUrl": "/avatars/2de1b1539a86452c2c89570eeb02f5ab.svg",
                        "isPro": false,
                        "fullname": "Xihui Liu",
                        "user": "XihuiLiu",
                        "type": "user"
                    },
                    "name": "Xihui Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:31:51.537Z",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72ed",
                    "name": "Lu Sheng",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72ee",
                    "name": "Jing Shao",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72ef",
                    "name": "Lei Bai",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72f0",
                    "name": "Wanli Ouyang",
                    "hidden": false
                },
                {
                    "_id": "6719dd0c0a835a6043db72f1",
                    "user": {
                        "_id": "65324848220f490dbaa3b8c9",
                        "avatarUrl": "/avatars/cec7dcadf4657bb4f61e2c9a8075521b.svg",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "Ruimao",
                        "type": "user"
                    },
                    "name": "Ruimao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:33:32.983Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-23T17:56:11.000Z",
            "title": "WorldSimBench: Towards Video Generation Models as World Simulators",
            "summary": "Recent advancements in predictive models have demonstrated exceptional\ncapabilities in predicting the future state of objects and scenes. However, the\nlack of categorization based on inherent characteristics continues to hinder\nthe progress of predictive model development. Additionally, existing benchmarks\nare unable to effectively evaluate higher-capability, highly embodied\npredictive models from an embodied perspective. In this work, we classify the\nfunctionalities of predictive models into a hierarchy and take the first step\nin evaluating World Simulators by proposing a dual evaluation framework called\nWorldSimBench. WorldSimBench includes Explicit Perceptual Evaluation and\nImplicit Manipulative Evaluation, encompassing human preference assessments\nfrom the visual perspective and action-level evaluations in embodied tasks,\ncovering three representative embodied scenarios: Open-Ended Embodied\nEnvironment, Autonomous, Driving, and Robot Manipulation. In the Explicit\nPerceptual Evaluation, we introduce the HF-Embodied Dataset, a video assessment\ndataset based on fine-grained human feedback, which we use to train a Human\nPreference Evaluator that aligns with human perception and explicitly assesses\nthe visual fidelity of World Simulators. In the Implicit Manipulative\nEvaluation, we assess the video-action consistency of World Simulators by\nevaluating whether the generated situation-aware video can be accurately\ntranslated into the correct control signals in dynamic environments. Our\ncomprehensive evaluation offers key insights that can drive further innovation\nin video generation models, positioning World Simulators as a pivotal\nadvancement toward embodied artificial intelligence.",
            "upvotes": 12,
            "discussionId": "6719dd0e0a835a6043db737e"
        },
        "publishedAt": "2024-10-24T04:15:52.036Z",
        "title": "WorldSimBench: Towards Video Generation Models as World Simulators",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.18072.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/37290358ad00bbd752f519cfdec02f3e.svg",
            "fullname": "Zhoues",
            "name": "Zhoues",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    },
    {
        "paper": {
            "id": "2410.17891",
            "authors": [
                {
                    "_id": "6719a80204e2e351e5660f16",
                    "user": {
                        "_id": "628c83d186fc004b14e1ed48",
                        "avatarUrl": "/avatars/05ff943a9b89b5f67c5bc254bf45b8f5.svg",
                        "isPro": false,
                        "fullname": "Shansan Gong",
                        "user": "Sansa",
                        "type": "user"
                    },
                    "name": "Shansan Gong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-24T07:15:33.126Z",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f17",
                    "user": {
                        "_id": "64b83a53cbb0af9bfb106384",
                        "avatarUrl": "/avatars/8fd05154d6c2c17e16f2a5b4272846fc.svg",
                        "isPro": false,
                        "fullname": "Shivam Agarwal",
                        "user": "shivamag99",
                        "type": "user"
                    },
                    "name": "Shivam Agarwal",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-24T01:50:59.734Z",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f18",
                    "name": "Yizhe Zhang",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f19",
                    "name": "Jiacheng Ye",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f1a",
                    "name": "Lin Zheng",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f1b",
                    "user": {
                        "_id": "624561c1939c9acec2103534",
                        "avatarUrl": "/avatars/3efdf797c53d153cea7415213fb5afc7.svg",
                        "isPro": false,
                        "fullname": "Mukai Li",
                        "user": "kiaia",
                        "type": "user"
                    },
                    "name": "Mukai Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-24T07:15:31.268Z",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f1c",
                    "name": "Chenxin An",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f1d",
                    "name": "Peilin Zhao",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f1e",
                    "name": "Wei Bi",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f1f",
                    "name": "Jiawei Han",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f20",
                    "name": "Hao Peng",
                    "hidden": false
                },
                {
                    "_id": "6719a80204e2e351e5660f21",
                    "name": "Lingpeng Kong",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-23T14:04:22.000Z",
            "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive\n  Models",
            "summary": "Diffusion Language Models (DLMs) have emerged as a promising new paradigm for\ntext generative modeling, potentially addressing limitations of autoregressive\n(AR) models. However, current DLMs have been studied at a smaller scale\ncompared to their AR counterparts and lack fair comparison on language modeling\nbenchmarks. Additionally, training diffusion models from scratch at scale\nremains challenging. Given the prevalence of open-source AR language models, we\npropose adapting these models to build text diffusion models. We demonstrate\nconnections between AR and diffusion modeling objectives and introduce a simple\ncontinual pre-training approach for training diffusion models. Through\nsystematic evaluation on language modeling, reasoning, and commonsense\nbenchmarks, we show that we can convert AR models ranging from 127M to 7B\nparameters (GPT2 and LLaMA) into diffusion models DiffuGPT and DiffuLLaMA,\nusing less than 200B tokens for training. Our experimental results reveal that\nthese models outperform earlier DLMs and are competitive with their AR\ncounterparts. We release a suite of DLMs (with 127M, 355M, and 7B parameters)\ncapable of generating fluent text, performing in-context learning, filling in\nthe middle without prompt re-ordering, and following instructions\nhttps://github.com/HKUNLP/DiffuLLaMA.",
            "upvotes": 8,
            "discussionId": "6719a80304e2e351e5660f65"
        },
        "publishedAt": "2024-10-24T04:21:03.707Z",
        "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.17891.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/3efdf797c53d153cea7415213fb5afc7.svg",
            "fullname": "Mukai Li",
            "name": "kiaia",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        }
    },
    {
        "paper": {
            "id": "2410.18084",
            "authors": [
                {
                    "_id": "671a297304f808324dfa8237",
                    "user": {
                        "_id": "65990b48ac728bc303537234",
                        "avatarUrl": "/avatars/717f599381ae845721c6daccb3bb1f76.svg",
                        "isPro": false,
                        "fullname": "Hengwei Bian",
                        "user": "hengwei",
                        "type": "user"
                    },
                    "name": "Hengwei Bian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:25:40.458Z",
                    "hidden": false
                },
                {
                    "_id": "671a297304f808324dfa8238",
                    "user": {
                        "_id": "62df78222d89ce551ce0f71d",
                        "avatarUrl": "/avatars/89fba294cff2d2f941d121c1923e4c76.svg",
                        "isPro": false,
                        "fullname": "Lingdong Kong",
                        "user": "ldkong",
                        "type": "user"
                    },
                    "name": "Lingdong Kong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:25:25.234Z",
                    "hidden": false
                },
                {
                    "_id": "671a297304f808324dfa8239",
                    "user": {
                        "_id": "63f47b5321eb234ab739e91a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63f47b5321eb234ab739e91a/vWfFNVtMkHl8gieha5PPd.jpeg",
                        "isPro": false,
                        "fullname": "Haozhe Xie",
                        "user": "hzxie",
                        "type": "user"
                    },
                    "name": "Haozhe Xie",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-24T12:35:00.035Z",
                    "hidden": false
                },
                {
                    "_id": "671a297304f808324dfa823a",
                    "name": "Liang Pan",
                    "hidden": false
                },
                {
                    "_id": "671a297304f808324dfa823b",
                    "name": "Yu Qiao",
                    "hidden": false
                },
                {
                    "_id": "671a297304f808324dfa823c",
                    "user": {
                        "_id": "62ab1ac1d48b4d8b048a3473",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
                        "isPro": false,
                        "fullname": "Ziwei Liu",
                        "user": "liuziwei7",
                        "type": "user"
                    },
                    "name": "Ziwei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:25:47.367Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-23T17:59:58.000Z",
            "title": "DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes",
            "summary": "LiDAR scene generation has been developing rapidly recently. However,\nexisting methods primarily focus on generating static and single-frame scenes,\noverlooking the inherently dynamic nature of real-world driving environments.\nIn this work, we introduce DynamicCity, a novel 4D LiDAR generation framework\ncapable of generating large-scale, high-quality LiDAR scenes that capture the\ntemporal evolution of dynamic environments. DynamicCity mainly consists of two\nkey models. 1) A VAE model for learning HexPlane as the compact 4D\nrepresentation. Instead of using naive averaging operations, DynamicCity\nemploys a novel Projection Module to effectively compress 4D LiDAR features\ninto six 2D feature maps for HexPlane construction, which significantly\nenhances HexPlane fitting quality (up to 12.56 mIoU gain). Furthermore, we\nutilize an Expansion & Squeeze Strategy to reconstruct 3D feature volumes in\nparallel, which improves both network training efficiency and reconstruction\naccuracy than naively querying each 3D point (up to 7.05 mIoU gain, 2.06x\ntraining speedup, and 70.84% memory reduction). 2) A DiT-based diffusion model\nfor HexPlane generation. To make HexPlane feasible for DiT generation, a Padded\nRollout Operation is proposed to reorganize all six feature planes of the\nHexPlane as a squared 2D feature map. In particular, various conditions could\nbe introduced in the diffusion or sampling process, supporting versatile 4D\ngeneration applications, such as trajectory- and command-driven generation,\ninpainting, and layout-conditioned generation. Extensive experiments on the\nCarlaSC and Waymo datasets demonstrate that DynamicCity significantly\noutperforms existing state-of-the-art 4D LiDAR generation methods across\nmultiple metrics. The code will be released to facilitate future research.",
            "upvotes": 5,
            "discussionId": "671a297504f808324dfa8330"
        },
        "publishedAt": "2024-10-24T09:34:33.328Z",
        "title": "DynamicCity: Large-Scale LiDAR Generation from Dynamic Scenes",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.18084.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63f47b5321eb234ab739e91a/vWfFNVtMkHl8gieha5PPd.jpeg",
            "fullname": "Haozhe Xie",
            "name": "hzxie",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 7
        }
    },
    {
        "paper": {
            "id": "2410.18013",
            "authors": [
                {
                    "_id": "671a01b4c673da43e82b2867",
                    "user": {
                        "_id": "6254599b6e36fe62e141c8f9",
                        "avatarUrl": "/avatars/08d6b68b92c7bfd0a8be022ba9f2f289.svg",
                        "isPro": false,
                        "fullname": "Shyamgopal Karthik",
                        "user": "shyamgopal",
                        "type": "user"
                    },
                    "name": "Shyamgopal Karthik",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-24T08:31:42.279Z",
                    "hidden": false
                },
                {
                    "_id": "671a01b4c673da43e82b2868",
                    "user": {
                        "_id": "64eaefcd5349043b2b9670a2",
                        "avatarUrl": "/avatars/9ca92fdda3f7b14586f40e9d31a746fe.svg",
                        "isPro": false,
                        "fullname": "Huseyin Coskun",
                        "user": "hcoskun",
                        "type": "user"
                    },
                    "name": "Huseyin Coskun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:35:13.318Z",
                    "hidden": false
                },
                {
                    "_id": "671a01b4c673da43e82b2869",
                    "name": "Zeynep Akata",
                    "hidden": false
                },
                {
                    "_id": "671a01b4c673da43e82b286a",
                    "name": "Sergey Tulyakov",
                    "hidden": false
                },
                {
                    "_id": "671a01b4c673da43e82b286b",
                    "name": "Jian Ren",
                    "hidden": false
                },
                {
                    "_id": "671a01b4c673da43e82b286c",
                    "user": {
                        "_id": "66b01ee8e53bbad918362856",
                        "avatarUrl": "/avatars/293529589a91dd7a95909d66727db224.svg",
                        "isPro": false,
                        "fullname": "Anil Kag",
                        "user": "anilkagak2",
                        "type": "user"
                    },
                    "name": "Anil Kag",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:35:38.040Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-23T16:42:56.000Z",
            "title": "Scalable Ranked Preference Optimization for Text-to-Image Generation",
            "summary": "Direct Preference Optimization (DPO) has emerged as a powerful approach to\nalign text-to-image (T2I) models with human feedback. Unfortunately, successful\napplication of DPO to T2I models requires a huge amount of resources to collect\nand label large-scale datasets, e.g., millions of generated paired images\nannotated with human preferences. In addition, these human preference datasets\ncan get outdated quickly as the rapid improvements of T2I models lead to higher\nquality images. In this work, we investigate a scalable approach for collecting\nlarge-scale and fully synthetic datasets for DPO training. Specifically, the\npreferences for paired images are generated using a pre-trained reward\nfunction, eliminating the need for involving humans in the annotation process,\ngreatly improving the dataset collection efficiency. Moreover, we demonstrate\nthat such datasets allow averaging predictions across multiple models and\ncollecting ranked preferences as opposed to pairwise preferences. Furthermore,\nwe introduce RankDPO to enhance DPO-based methods using the ranking feedback.\nApplying RankDPO on SDXL and SD3-Medium models with our synthetically generated\npreference dataset ``Syn-Pic'' improves both prompt-following (on benchmarks\nlike T2I-Compbench, GenEval, and DPG-Bench) and visual quality (through user\nstudies). This pipeline presents a practical and scalable solution to develop\nbetter preference datasets to enhance the performance of text-to-image models.",
            "upvotes": 5,
            "discussionId": "671a01b7c673da43e82b29f4"
        },
        "publishedAt": "2024-10-24T06:43:59.269Z",
        "title": "Scalable Ranked Preference Optimization for Text-to-Image Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.18013.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/08d6b68b92c7bfd0a8be022ba9f2f289.svg",
            "fullname": "Shyamgopal Karthik",
            "name": "shyamgopal",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.17883",
            "authors": [
                {
                    "_id": "6719e4bd2c519a08bd42b9d5",
                    "user": {
                        "_id": "64f46b681d337935d0495d4d",
                        "avatarUrl": "/avatars/cce5a4910617931fb13062b832e14ef8.svg",
                        "isPro": false,
                        "fullname": "Filippos Christianos",
                        "user": "semitable",
                        "type": "user"
                    },
                    "name": "Filippos Christianos",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:34:29.693Z",
                    "hidden": false
                },
                {
                    "_id": "6719e4bd2c519a08bd42b9d6",
                    "user": {
                        "_id": "66e451f4c3b3a128bd078bdf",
                        "avatarUrl": "/avatars/624e2520129f408874f227df04025ec7.svg",
                        "isPro": false,
                        "fullname": "Georgios Papoudakis",
                        "user": "gpap",
                        "type": "user"
                    },
                    "name": "Georgios Papoudakis",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:34:34.954Z",
                    "hidden": false
                },
                {
                    "_id": "6719e4bd2c519a08bd42b9d7",
                    "user": {
                        "_id": "64ca5357ead94891d1d53cd1",
                        "avatarUrl": "/avatars/187073352d7767f18d5fd50a6ca69fb5.svg",
                        "isPro": false,
                        "fullname": "Thomas COSTE",
                        "user": "Fahren24",
                        "type": "user"
                    },
                    "name": "Thomas Coste",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:34:41.324Z",
                    "hidden": false
                },
                {
                    "_id": "6719e4bd2c519a08bd42b9d8",
                    "name": "Jianye Hao",
                    "hidden": false
                },
                {
                    "_id": "6719e4bd2c519a08bd42b9d9",
                    "name": "Jun Wang",
                    "hidden": false
                },
                {
                    "_id": "6719e4bd2c519a08bd42b9da",
                    "user": {
                        "_id": "66840c818f6c78ebd41f86ca",
                        "avatarUrl": "/avatars/626ffa3d262c02f964f15fa420af414c.svg",
                        "isPro": false,
                        "fullname": "Kun Shao",
                        "user": "ShaoKun-HW",
                        "type": "user"
                    },
                    "name": "Kun Shao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:34:58.709Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-23T13:57:00.000Z",
            "title": "Lightweight Neural App Control",
            "summary": "This paper introduces a novel mobile phone control architecture, termed ``app\nagents\", for efficient interactions and controls across various Android apps.\nThe proposed Lightweight Multi-modal App Control (LiMAC) takes as input a\ntextual goal and a sequence of past mobile observations, such as screenshots\nand corresponding UI trees, to generate precise actions. To address the\ncomputational constraints inherent to smartphones, within LiMAC, we introduce a\nsmall Action Transformer (AcT) integrated with a fine-tuned vision-language\nmodel (VLM) for real-time decision-making and task execution. We evaluate LiMAC\non two open-source mobile control datasets, demonstrating the superior\nperformance of our small-form-factor approach against fine-tuned versions of\nopen-source VLMs, such as Florence2 and Qwen2-VL. It also significantly\noutperforms prompt engineering baselines utilising closed-source foundation\nmodels like GPT-4o. More specifically, LiMAC increases the overall action\naccuracy by up to 19% compared to fine-tuned VLMs, and up to 42% compared to\nprompt-engineering baselines.",
            "upvotes": 4,
            "discussionId": "6719e4be2c519a08bd42ba36"
        },
        "publishedAt": "2024-10-24T04:42:04.790Z",
        "title": "Lightweight Neural App Control",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.17883.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64d98ef7a4839890b25eb78b/215-CSVLl81z6CAq0ECWU.jpeg",
            "fullname": "Fangyuan Yu",
            "name": "Ksgk-fy",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 10
        }
    },
    {
        "paper": {
            "id": "2410.13924",
            "authors": [
                {
                    "_id": "6717f63e80594ffee6df3448",
                    "user": {
                        "_id": "62c7368a6a092eda1f1f8509",
                        "avatarUrl": "/avatars/b18d5fe7491e97d9eabe26051cfe61a3.svg",
                        "isPro": false,
                        "fullname": "Guangda Ji",
                        "user": "quantaji",
                        "type": "user"
                    },
                    "name": "Guangda Ji",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T12:34:35.954Z",
                    "hidden": false
                },
                {
                    "_id": "6717f63e80594ffee6df3449",
                    "name": "Silvan Weder",
                    "hidden": false
                },
                {
                    "_id": "6717f63e80594ffee6df344a",
                    "name": "Francis Engelmann",
                    "hidden": false
                },
                {
                    "_id": "6717f63e80594ffee6df344b",
                    "name": "Marc Pollefeys",
                    "hidden": false
                },
                {
                    "_id": "6717f63e80594ffee6df344c",
                    "user": {
                        "_id": "63ff8abfb09f82a81a1e545f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/e7lJKlza9ydEAXJYI9Bx6.png",
                        "isPro": false,
                        "fullname": "Hermann Blum",
                        "user": "blumh",
                        "type": "user"
                    },
                    "name": "Hermann Blum",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T12:35:12.197Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T14:44:35.000Z",
            "title": "ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding",
            "summary": "The performance of neural networks scales with both their size and the amount\nof data they have been trained on. This is shown in both language and image\ngeneration. However, this requires scaling-friendly network architectures as\nwell as large-scale datasets. Even though scaling-friendly architectures like\ntransformers have emerged for 3D vision tasks, the GPT-moment of 3D vision\nremains distant due to the lack of training data. In this paper, we introduce\nARKit LabelMaker, the first large-scale, real-world 3D dataset with dense\nsemantic annotations. Specifically, we complement ARKitScenes dataset with\ndense semantic annotations that are automatically generated at scale. To this\nend, we extend LabelMaker, a recent automatic annotation pipeline, to serve the\nneeds of large-scale pre-training. This involves extending the pipeline with\ncutting-edge segmentation models as well as making it robust to the challenges\nof large-scale processing. Further, we push forward the state-of-the-art\nperformance on ScanNet and ScanNet200 dataset with prevalent 3D semantic\nsegmentation models, demonstrating the efficacy of our generated dataset.",
            "upvotes": 3,
            "discussionId": "6717f64180594ffee6df3547"
        },
        "publishedAt": "2024-10-24T08:14:13.853Z",
        "title": "ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63ff8abfb09f82a81a1e545f/dq5SZWryLOqLHmFDEbI-E.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13924.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/e7lJKlza9ydEAXJYI9Bx6.png",
            "fullname": "Hermann Blum",
            "name": "blumh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13458",
            "authors": [
                {
                    "_id": "671a296241f8a9c7fec7defd",
                    "name": "Wenhan Han",
                    "hidden": false
                },
                {
                    "_id": "671a296241f8a9c7fec7defe",
                    "name": "Meng Fang",
                    "hidden": false
                },
                {
                    "_id": "671a296241f8a9c7fec7deff",
                    "name": "Zihan Zhang",
                    "hidden": false
                },
                {
                    "_id": "671a296241f8a9c7fec7df00",
                    "name": "Yu Yin",
                    "hidden": false
                },
                {
                    "_id": "671a296241f8a9c7fec7df01",
                    "user": {
                        "_id": "65407ba7a38390065750233f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65407ba7a38390065750233f/1_IPMZbk-S9u2t18PQgMp.jpeg",
                        "isPro": false,
                        "fullname": "Zirui Song",
                        "user": "Ziruibest",
                        "type": "user"
                    },
                    "name": "Zirui Song",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T12:39:39.556Z",
                    "hidden": false
                },
                {
                    "_id": "671a296241f8a9c7fec7df02",
                    "name": "Ling Chen",
                    "hidden": false
                },
                {
                    "_id": "671a296241f8a9c7fec7df03",
                    "name": "Mykola Pechenizkiy",
                    "hidden": false
                },
                {
                    "_id": "671a296241f8a9c7fec7df04",
                    "name": "Qingyu Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T11:38:54.000Z",
            "title": "MedINST: Meta Dataset of Biomedical Instructions",
            "summary": "The integration of large language model (LLM) techniques in the field of\nmedical analysis has brought about significant advancements, yet the scarcity\nof large, diverse, and well-annotated datasets remains a major challenge.\nMedical data and tasks, which vary in format, size, and other parameters,\nrequire extensive preprocessing and standardization for effective use in\ntraining LLMs. To address these challenges, we introduce MedINST, the Meta\nDataset of Biomedical Instructions, a novel multi-domain, multi-task\ninstructional meta-dataset. MedINST comprises 133 biomedical NLP tasks and over\n7 million training samples, making it the most comprehensive biomedical\ninstruction dataset to date. Using MedINST as the meta dataset, we curate\nMedINST32, a challenging benchmark with different task difficulties aiming to\nevaluate LLMs' generalization ability. We fine-tune several LLMs on MedINST and\nevaluate on MedINST32, showcasing enhanced cross-task generalization.",
            "upvotes": 1,
            "discussionId": "671a296341f8a9c7fec7df50"
        },
        "publishedAt": "2024-10-24T09:33:36.990Z",
        "title": "MedINST: Meta Dataset of Biomedical Instructions",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13458.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65407ba7a38390065750233f/1_IPMZbk-S9u2t18PQgMp.jpeg",
            "fullname": "Zirui Song",
            "name": "Ziruibest",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.15522",
            "authors": [
                {
                    "_id": "671917223aa9749caf1004d1",
                    "user": {
                        "_id": "625d6ed9c4086370158824eb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/625d6ed9c4086370158824eb/KG_Plv-2rcydKzVf-9AAj.jpeg",
                        "isPro": false,
                        "fullname": "Srishti Gureja",
                        "user": "srishti-hf1110",
                        "type": "user"
                    },
                    "name": "Srishti Gureja",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-10-23T16:35:20.509Z",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004d2",
                    "name": "Lester James V. Miranda",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004d3",
                    "user": {
                        "_id": "5e4b943a37cb5b49818287b5",
                        "avatarUrl": "/avatars/21edfd3792f42c88919a3f96ed39bd1b.svg",
                        "isPro": false,
                        "fullname": "Shayekh Bin Islam",
                        "user": "shayekh",
                        "type": "user"
                    },
                    "name": "Shayekh Bin Islam",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-24T07:15:41.072Z",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004d4",
                    "user": {
                        "_id": "645c26d423ed9b7788d5e24b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/cZMUluWpYUlSLcn6yoC7c.jpeg",
                        "isPro": false,
                        "fullname": "Rishabh Maheshwary",
                        "user": "rmahesh",
                        "type": "user"
                    },
                    "name": "Rishabh Maheshwary",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:24:26.868Z",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004d5",
                    "user": {
                        "_id": "618c1ad1c74578e0a4a4d074",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/618c1ad1c74578e0a4a4d074/8u_AkeHt4d6xtQ8hzaffU.jpeg",
                        "isPro": false,
                        "fullname": "Drishti Sharma",
                        "user": "DrishtiSharma",
                        "type": "user"
                    },
                    "name": "Drishti Sharma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:24:20.823Z",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004d6",
                    "name": "Gusti Winata",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004d7",
                    "user": {
                        "_id": "628e5f90a9a3c754c1f7c88f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628e5f90a9a3c754c1f7c88f/iWqMY_l6dalrgRaJZWbK3.png",
                        "isPro": false,
                        "fullname": "Nathan Lambert",
                        "user": "natolambert",
                        "type": "user"
                    },
                    "name": "Nathan Lambert",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:24:04.907Z",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004d8",
                    "user": {
                        "_id": "624575789dc26c59bae6a19e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1648719221694-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Sebastian Ruder",
                        "user": "ruder",
                        "type": "user"
                    },
                    "name": "Sebastian Ruder",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:23:31.119Z",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004d9",
                    "user": {
                        "_id": "63434eb76f59b79da07dbddf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63434eb76f59b79da07dbddf/BEwmVjqPNYlqmutXG0G6e.jpeg",
                        "isPro": false,
                        "fullname": "Sara Hooker",
                        "user": "sarahooker",
                        "type": "user"
                    },
                    "name": "Sara Hooker",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:23:23.838Z",
                    "hidden": false
                },
                {
                    "_id": "671917223aa9749caf1004da",
                    "user": {
                        "_id": "6441042d5d600fb0951a5f99",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6441042d5d600fb0951a5f99/4CbOaYcEz99BtVAQvnGTn.jpeg",
                        "isPro": false,
                        "fullname": "Marzieh Fadaee",
                        "user": "MarziehFadaee",
                        "type": "user"
                    },
                    "name": "Marzieh Fadaee",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T14:23:17.162Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-20T22:09:44.000Z",
            "title": "M-RewardBench: Evaluating Reward Models in Multilingual Settings",
            "summary": "Reward models (RMs) have driven the state-of-the-art performance of LLMs\ntoday by enabling the integration of human feedback into the language modeling\nprocess. However, RMs are primarily trained and evaluated in English, and their\ncapabilities in multilingual settings remain largely understudied. In this\nwork, we conduct a systematic evaluation of several reward models in\nmultilingual settings. We first construct the first-of-its-kind multilingual RM\nevaluation benchmark, M-RewardBench, consisting of 2.87k preference instances\nfor 23 typologically diverse languages, that tests the chat, safety, reasoning,\nand translation capabilities of RMs. We then rigorously evaluate a wide range\nof reward models on M-RewardBench, offering fresh insights into their\nperformance across diverse languages. We identify a significant gap in RMs'\nperformances between English and non-English languages and show that RM\npreferences can change substantially from one language to another. We also\npresent several findings on how different multilingual aspects impact RM\nperformance. Specifically, we show that the performance of RMs is improved with\nimproved translation quality. Similarly, we demonstrate that the models exhibit\nbetter performance for high-resource languages. We release M-RewardBench\ndataset and the codebase in this study to facilitate a better understanding of\nRM evaluation in multilingual settings.",
            "upvotes": 1,
            "discussionId": "671917243aa9749caf10057c"
        },
        "publishedAt": "2024-10-24T07:41:28.337Z",
        "title": "M-RewardBench: Evaluating Reward Models in Multilingual Settings",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.15522.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/21edfd3792f42c88919a3f96ed39bd1b.svg",
            "fullname": "Shayekh Bin Islam",
            "name": "shayekh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 10
        }
    },
    {
        "paper": {
            "id": "2410.18071",
            "authors": [
                {
                    "_id": "6719f8a4defdd700b137bd79",
                    "name": "Yuxuan Xie",
                    "hidden": false
                },
                {
                    "_id": "6719f8a4defdd700b137bd7a",
                    "name": "Tianhua Li",
                    "hidden": false
                },
                {
                    "_id": "6719f8a4defdd700b137bd7b",
                    "user": {
                        "_id": "64b3fd42eec33e27dcc4c941",
                        "avatarUrl": "/avatars/5aa1a99468fa61d4b8b0e80b592c4e55.svg",
                        "isPro": false,
                        "fullname": "Wenqi Shao",
                        "user": "wqshao126",
                        "type": "user"
                    },
                    "name": "Wenqi Shao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:36:16.397Z",
                    "hidden": false
                },
                {
                    "_id": "6719f8a4defdd700b137bd7c",
                    "user": {
                        "_id": "63527f4e7d071f23d085ad45",
                        "avatarUrl": "/avatars/99a51adef5673b3ac1a8c02eb47759c4.svg",
                        "isPro": false,
                        "fullname": "KAIPENG ZHANG",
                        "user": "kpzhang",
                        "type": "user"
                    },
                    "name": "Kaipeng Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-24T08:36:10.188Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-23T17:54:43.000Z",
            "title": "TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing\n  Prompts",
            "summary": "Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.",
            "upvotes": 1,
            "discussionId": "6719f8a5defdd700b137bddd"
        },
        "publishedAt": "2024-10-24T06:05:07.825Z",
        "title": "TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.18071.png",
        "numComments": 0,
        "submittedBy": {
            "avatarUrl": "/avatars/47ab3ada51c9b9976ac1cd0c4301c373.svg",
            "fullname": "kaipeng",
            "name": "kpzhang996",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        }
    }
]