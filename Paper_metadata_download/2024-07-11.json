[
    {
        "paper": {
            "id": "2407.07726",
            "authors": [
                {
                    "_id": "668f4967f65238b10c6b12b7",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642d334ff65714b4585f2de4/gxBynq5KyoUP0VlAQD3-w.jpeg",
                        "isPro": false,
                        "fullname": "Lucas Beyer",
                        "user": "giffmana",
                        "type": "user"
                    },
                    "name": "Lucas Beyer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:43:35.767Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12b8",
                    "name": "Andreas Steiner",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12b9",
                    "name": "André Susano Pinto",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12ba",
                    "name": "Alexander Kolesnikov",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12bb",
                    "name": "Xiao Wang",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12bc",
                    "name": "Daniel Salz",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12bd",
                    "user": {
                        "avatarUrl": "/avatars/fe274d04b2ff7d8a079cdde6a77395c4.svg",
                        "isPro": false,
                        "fullname": "Maxim Neumann",
                        "user": "maximn",
                        "type": "user"
                    },
                    "name": "Maxim Neumann",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:46:01.880Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12be",
                    "user": {
                        "avatarUrl": "/avatars/5d82be2e7412bff1af15cc5eafa60b7d.svg",
                        "isPro": false,
                        "fullname": "Ibrahim Alabdulmohsin",
                        "user": "ibomohsin",
                        "type": "user"
                    },
                    "name": "Ibrahim Alabdulmohsin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:46:09.539Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12bf",
                    "user": {
                        "avatarUrl": "/avatars/54354c1e5774cadd1d83d42054e9d96b.svg",
                        "isPro": false,
                        "fullname": "Michael Tschannen",
                        "user": "mitsch",
                        "type": "user"
                    },
                    "name": "Michael Tschannen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:46:36.803Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c0",
                    "user": {
                        "avatarUrl": "/avatars/8737662babc5d42cafba6087ab33e716.svg",
                        "isPro": false,
                        "fullname": "Emanuele Bugliarello",
                        "user": "e-bug",
                        "type": "user"
                    },
                    "name": "Emanuele Bugliarello",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:46:45.351Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c1",
                    "name": "Thomas Unterthiner",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c2",
                    "user": {
                        "avatarUrl": "/avatars/4fbfbc0621f631d8e95a2a642fa0cd27.svg",
                        "isPro": false,
                        "fullname": "Daniel Keysers",
                        "user": "dkeysers",
                        "type": "user"
                    },
                    "name": "Daniel Keysers",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:47:05.769Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c3",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/XBmF81Uyj0N7lPclU1pUG.jpeg",
                        "isPro": false,
                        "fullname": "Skanda Koppula",
                        "user": "skoppula",
                        "type": "user"
                    },
                    "name": "Skanda Koppula",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:47:12.071Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c4",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5f881856ee5616341bc51e67/9UCZCuhBTpJC9tGPyGmMb.jpeg",
                        "isPro": true,
                        "fullname": "Fangyu Liu",
                        "user": "fl399",
                        "type": "user"
                    },
                    "name": "Fangyu Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:47:30.850Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c5",
                    "name": "Adam Grycner",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c6",
                    "user": {
                        "avatarUrl": "/avatars/12ec78d34fd849bad44217b212f31e98.svg",
                        "isPro": false,
                        "fullname": "Alexey Gritsenko",
                        "user": "AlexeyG",
                        "type": "user"
                    },
                    "name": "Alexey Gritsenko",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:47:44.594Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c7",
                    "user": {
                        "avatarUrl": "/avatars/a362a236c0654b7605dcb7673e309335.svg",
                        "isPro": false,
                        "fullname": "Neil Houlsby",
                        "user": "neilhoulsby",
                        "type": "user"
                    },
                    "name": "Neil Houlsby",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:47:51.045Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c8",
                    "name": "Manoj Kumar",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12c9",
                    "name": "Keran Rong",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12ca",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640f5502a92fedb0e8511d66/3CFOBG_gm4WlQpQXXaQlr.jpeg",
                        "isPro": false,
                        "fullname": "Julian Eisenschlos",
                        "user": "eisenjulian",
                        "type": "user"
                    },
                    "name": "Julian Eisenschlos",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:48:23.777Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12cb",
                    "name": "Rishabh Kabra",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12cc",
                    "name": "Matthias Bauer",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12cd",
                    "name": "Matko Bošnjak",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12ce",
                    "name": "Xi Chen",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12cf",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/649ac6e57c36fc2dc6e6b0f4/Scd3LiYW5Y2qunDDHnPWw.jpeg",
                        "isPro": false,
                        "fullname": "Matthias Minderer",
                        "user": "mjlm",
                        "type": "user"
                    },
                    "name": "Matthias Minderer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:48:54.125Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d0",
                    "name": "Paul Voigtlaender",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d1",
                    "user": {
                        "avatarUrl": "/avatars/0538f1c8a26d1afa1be90e3082c3791c.svg",
                        "isPro": false,
                        "fullname": "Ioana Bica",
                        "user": "ioanabica",
                        "type": "user"
                    },
                    "name": "Ioana Bica",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:51:40.141Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d2",
                    "name": "Ivana Balazevic",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d3",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64afea8efd620c8a7ad4ebd7/O3e9nLirWFVZ_jMN4lFdH.jpeg",
                        "isPro": false,
                        "fullname": "Joan Puigcerver",
                        "user": "joapuipe",
                        "type": "user"
                    },
                    "name": "Joan Puigcerver",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:51:19.650Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d4",
                    "name": "Pinelopi Papalampidi",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d5",
                    "user": {
                        "avatarUrl": "/avatars/eedf65a104d099d8a60bbffe69bc2571.svg",
                        "isPro": false,
                        "fullname": "Olivier Henaff",
                        "user": "olivierhenaff",
                        "type": "user"
                    },
                    "name": "Olivier Henaff",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:50:57.596Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d6",
                    "user": {
                        "avatarUrl": "/avatars/d038fb872833c66925f77db7d4baa559.svg",
                        "isPro": false,
                        "fullname": "Xi Xiong",
                        "user": "alzmxx",
                        "type": "user"
                    },
                    "name": "Xi Xiong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T16:23:51.810Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d7",
                    "name": "Radu Soricut",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d8",
                    "user": {
                        "avatarUrl": "/avatars/1d26a7a7ffdc5ca9e67b97030f21b098.svg",
                        "isPro": false,
                        "fullname": "Jeremiah Harmsen",
                        "user": "jharmsen",
                        "type": "user"
                    },
                    "name": "Jeremiah Harmsen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:50:30.918Z",
                    "hidden": false
                },
                {
                    "_id": "668f4967f65238b10c6b12d9",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/M2bc9PyKeFs1cCXjTfGGq.jpeg",
                        "isPro": false,
                        "fullname": "Xiaohua Zhai",
                        "user": "xiaohuazhai",
                        "type": "user"
                    },
                    "name": "Xiaohua Zhai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:50:23.887Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T14:57:46.000Z",
            "title": "PaliGemma: A versatile 3B VLM for transfer",
            "summary": "PaliGemma is an open Vision-Language Model (VLM) that is based on the\nSigLIP-So400m vision encoder and the Gemma-2B language model. It is trained to\nbe a versatile and broadly knowledgeable base model that is effective to\ntransfer. It achieves strong performance on a wide variety of open-world tasks.\nWe evaluate PaliGemma on almost 40 diverse tasks including standard VLM\nbenchmarks, but also more specialized tasks such as remote-sensing and\nsegmentation.",
            "upvotes": 31
        },
        "publishedAt": "2024-07-11T01:25:32.979Z",
        "title": "PaliGemma: A versatile 3B VLM for transfer",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07726.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.07895",
            "authors": [
                {
                    "_id": "668f4cd8c0af06ce53c13a26",
                    "name": "Feng Li",
                    "hidden": false
                },
                {
                    "_id": "668f4cd8c0af06ce53c13a27",
                    "user": {
                        "avatarUrl": "/avatars/00a9db32a42dc950112bf2593bb109cb.svg",
                        "isPro": false,
                        "fullname": "Renrui",
                        "user": "ZrrSkywalker",
                        "type": "user"
                    },
                    "name": "Renrui Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-11T08:25:47.769Z",
                    "hidden": false
                },
                {
                    "_id": "668f4cd8c0af06ce53c13a28",
                    "user": {
                        "avatarUrl": "/avatars/1d0270813ba04b7bdcdc96bab05ce4d1.svg",
                        "isPro": false,
                        "fullname": "Hao Zhang",
                        "user": "Haozhangcx",
                        "type": "user"
                    },
                    "name": "Hao Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-11T13:45:41.888Z",
                    "hidden": false
                },
                {
                    "_id": "668f4cd8c0af06ce53c13a29",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png",
                        "isPro": false,
                        "fullname": "Zhang Yuanhan",
                        "user": "ZhangYuanhan",
                        "type": "user"
                    },
                    "name": "Yuanhan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:56:09.879Z",
                    "hidden": false
                },
                {
                    "_id": "668f4cd8c0af06ce53c13a2a",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62d3f7d84b0933c48f3cdd9c/IVZXUPBSzhS01hm55x854.png",
                        "isPro": false,
                        "fullname": "Bo Li",
                        "user": "luodian",
                        "type": "user"
                    },
                    "name": "Bo Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:57:01.301Z",
                    "hidden": false
                },
                {
                    "_id": "668f4cd8c0af06ce53c13a2b",
                    "name": "Wei Li",
                    "hidden": false
                },
                {
                    "_id": "668f4cd8c0af06ce53c13a2c",
                    "name": "Zejun Ma",
                    "hidden": false
                },
                {
                    "_id": "668f4cd8c0af06ce53c13a2d",
                    "user": {
                        "avatarUrl": "/avatars/430560ec2c2547f819225769ab432f30.svg",
                        "isPro": false,
                        "fullname": "Chunyuan Li",
                        "user": "Chunyuan24",
                        "type": "user"
                    },
                    "name": "Chunyuan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T08:56:18.129Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T17:59:43.000Z",
            "title": "LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large\n  Multimodal Models",
            "summary": "Visual instruction tuning has made considerable strides in enhancing the\ncapabilities of Large Multimodal Models (LMMs). However, existing open LMMs\nlargely focus on single-image tasks, their applications to multi-image\nscenarios remains less explored. Additionally, prior LMM research separately\ntackles different scenarios, leaving it impossible to generalize cross\nscenarios with new emerging capabilities. To this end, we introduce\nLLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame\n(video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. To\nenable these capabilities, we regard the interleaved data format as a general\ntemplate and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4\nprimary domains with 14 tasks and 41 datasets. We also curate the\nLLaVA-Interleave Bench to comprehensively evaluate the multi-image performance\nof LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leading\nresults in multi-image, video, and 3D benchmarks, while maintaining the\nperformance of single-image tasks. Besides, our model also exhibits several\nemerging capabilities, e.g., transferring tasks across different settings and\nmodalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT",
            "upvotes": 21
        },
        "publishedAt": "2024-07-11T01:39:20.423Z",
        "title": "LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07895.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.07860",
            "authors": [
                {
                    "_id": "668f4bdd27e286af06887a7e",
                    "name": "Daniel Watson",
                    "hidden": false
                },
                {
                    "_id": "668f4bdd27e286af06887a7f",
                    "user": {
                        "avatarUrl": "/avatars/69f1e19921ba3ecdcd40bf55a6196aca.svg",
                        "isPro": false,
                        "fullname": "Saurabh Saxena",
                        "user": "saurabhsaxena",
                        "type": "user"
                    },
                    "name": "Saurabh Saxena",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:42:35.081Z",
                    "hidden": false
                },
                {
                    "_id": "668f4bdd27e286af06887a80",
                    "name": "Lala Li",
                    "hidden": false
                },
                {
                    "_id": "668f4bdd27e286af06887a81",
                    "name": "Andrea Tagliasacchi",
                    "hidden": false
                },
                {
                    "_id": "668f4bdd27e286af06887a82",
                    "name": "David J. Fleet",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T17:23:33.000Z",
            "title": "Controlling Space and Time with Diffusion Models",
            "summary": "We present 4DiM, a cascaded diffusion model for 4D novel view synthesis\n(NVS), conditioned on one or more images of a general scene, and a set of\ncamera poses and timestamps. To overcome challenges due to limited availability\nof 4D training data, we advocate joint training on 3D (with camera pose), 4D\n(pose+time) and video (time but no pose) data and propose a new architecture\nthat enables the same. We further advocate the calibration of SfM posed data\nusing monocular metric depth estimators for metric scale camera control. For\nmodel evaluation, we introduce new metrics to enrich and overcome shortcomings\nof current evaluation schemes, demonstrating state-of-the-art results in both\nfidelity and pose control compared to existing diffusion models for 3D NVS,\nwhile at the same time adding the ability to handle temporal dynamics. 4DiM is\nalso used for improved panorama stitching, pose-conditioned video to video\ntranslation, and several other tasks. For an overview see\nhttps://4d-diffusion.github.io",
            "upvotes": 7
        },
        "publishedAt": "2024-07-11T01:35:10.324Z",
        "title": "Controlling Space and Time with Diffusion Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07860.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.07464",
            "authors": [
                {
                    "_id": "668f41aa52a697a87e3c31e3",
                    "user": {
                        "avatarUrl": "/avatars/a863f3cf791f3f525df6863f8d4c476b.svg",
                        "isPro": false,
                        "fullname": "ManjieTsu",
                        "user": "ariesssxu",
                        "type": "user"
                    },
                    "name": "Manjie Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-11T13:45:44.890Z",
                    "hidden": false
                },
                {
                    "_id": "668f41aa52a697a87e3c31e4",
                    "user": {
                        "avatarUrl": "/avatars/5dac96288fa93fa965f1b57ad8d0a9b7.svg",
                        "isPro": false,
                        "fullname": "Chenxing",
                        "user": "Chenxinglili",
                        "type": "user"
                    },
                    "name": "Chenxing Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:23:59.730Z",
                    "hidden": false
                },
                {
                    "_id": "668f41aa52a697a87e3c31e5",
                    "name": "Yong Ren",
                    "hidden": false
                },
                {
                    "_id": "668f41aa52a697a87e3c31e6",
                    "name": "Rilin Chen",
                    "hidden": false
                },
                {
                    "_id": "668f41aa52a697a87e3c31e7",
                    "name": "Yu Gu",
                    "hidden": false
                },
                {
                    "_id": "668f41aa52a697a87e3c31e8",
                    "name": "Wei Liang",
                    "hidden": false
                },
                {
                    "_id": "668f41aa52a697a87e3c31e9",
                    "name": "Dong Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T08:40:39.000Z",
            "title": "Video-to-Audio Generation with Hidden Alignment",
            "summary": "Generating semantically and temporally aligned audio content in accordance\nwith video input has become a focal point for researchers, particularly\nfollowing the remarkable breakthrough in text-to-video generation. In this\nwork, we aim to offer insights into the video-to-audio generation paradigm,\nfocusing on three crucial aspects: vision encoders, auxiliary embeddings, and\ndata augmentation techniques. Beginning with a foundational model VTA-LDM built\non a simple yet surprisingly effective intuition, we explore various vision\nencoders and auxiliary embeddings through ablation studies. Employing a\ncomprehensive evaluation pipeline that emphasizes generation quality and\nvideo-audio synchronization alignment, we demonstrate that our model exhibits\nstate-of-the-art video-to-audio generation capabilities. Furthermore, we\nprovide critical insights into the impact of different data augmentation\nmethods on enhancing the generation framework's overall capacity. We showcase\npossibilities to advance the challenge of generating synchronized audio from\nsemantic and temporal perspectives. We hope these insights will serve as a\nstepping stone toward developing more realistic and accurate audio-visual\ngeneration models.",
            "upvotes": 6
        },
        "publishedAt": "2024-07-11T00:51:46.035Z",
        "title": "Video-to-Audio Generation with Hidden Alignment",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07464.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.07304",
            "authors": [
                {
                    "_id": "668f48815156d55f729b4724",
                    "user": {
                        "avatarUrl": "/avatars/dad07355462c1a7e296af237fb55a6fc.svg",
                        "isPro": false,
                        "fullname": "pujiang",
                        "user": "pujiang",
                        "type": "user"
                    },
                    "name": "Pujiang He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T14:54:53.744Z",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b4725",
                    "name": "Shan Zhou",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b4726",
                    "user": {
                        "avatarUrl": "/avatars/50abd36372e22f9a7c91ada6d7c08eff.svg",
                        "isPro": false,
                        "fullname": "huang",
                        "user": "wenhuanh",
                        "type": "user"
                    },
                    "name": "Wenhuan Huang",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-07-11T02:55:02.327Z",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b4727",
                    "name": "Changqing Li",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b4728",
                    "user": {
                        "avatarUrl": "/avatars/94053a9296500f44f7e933d091c0bc2c.svg",
                        "isPro": false,
                        "fullname": "Duyi-Wang",
                        "user": "Duyi-Wang",
                        "type": "user"
                    },
                    "name": "Duyi Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:21:01.964Z",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b4729",
                    "name": "Bin Guo",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b472a",
                    "name": "Chen Meng",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b472b",
                    "name": "Sheng Gui",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b472c",
                    "name": "Weifei Yu",
                    "hidden": false
                },
                {
                    "_id": "668f48815156d55f729b472d",
                    "name": "Yi Xie",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T01:53:49.000Z",
            "title": "Inference Performance Optimization for Large Language Models on CPUs",
            "summary": "Large language models (LLMs) have shown exceptional performance and vast\npotential across diverse tasks. However, the deployment of LLMs with high\nperformance in low-resource environments has garnered significant attention in\nthe industry. When GPU hardware resources are limited, we can explore\nalternative options on CPUs. To mitigate the financial burden and alleviate\nconstraints imposed by hardware resources, optimizing inference performance is\nnecessary. In this paper, we introduce an easily deployable inference\nperformance optimization solution aimed at accelerating LLMs on CPUs. In this\nsolution, we implement an effective way to reduce the KV cache size while\nensuring precision. We propose a distributed inference optimization approach\nand implement it based on oneAPI Collective Communications Library.\nFurthermore, we propose optimization approaches for LLMs on CPU, and conduct\ntailored optimizations for the most commonly used models. The code is\nopen-sourced at https://github.com/intel/xFasterTransformer.",
            "upvotes": 4
        },
        "publishedAt": "2024-07-11T01:20:50.087Z",
        "title": "Inference Performance Optimization for Large Language Models on CPUs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07304.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.07667",
            "authors": [
                {
                    "_id": "668f46fdd3b02463a73bc21c",
                    "name": "Jingwen He",
                    "hidden": false
                },
                {
                    "_id": "668f46fdd3b02463a73bc21d",
                    "name": "Tianfan Xue",
                    "hidden": false
                },
                {
                    "_id": "668f46fdd3b02463a73bc21e",
                    "user": {
                        "avatarUrl": "/avatars/96681e76224a6de83ebfaa6eb8cf19ca.svg",
                        "isPro": false,
                        "fullname": "dongyang liu",
                        "user": "L728187887",
                        "type": "user"
                    },
                    "name": "Dongyang Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:34:55.210Z",
                    "hidden": false
                },
                {
                    "_id": "668f46fdd3b02463a73bc21f",
                    "user": {
                        "avatarUrl": "/avatars/34d106f0fd536cc7fbeb3abb94b5d775.svg",
                        "isPro": false,
                        "fullname": "qilin",
                        "user": "xinqilin",
                        "type": "user"
                    },
                    "name": "Xinqi Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:35:02.938Z",
                    "hidden": false
                },
                {
                    "_id": "668f46fdd3b02463a73bc220",
                    "name": "Peng Gao",
                    "hidden": false
                },
                {
                    "_id": "668f46fdd3b02463a73bc221",
                    "user": {
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:35:28.492Z",
                    "hidden": false
                },
                {
                    "_id": "668f46fdd3b02463a73bc222",
                    "name": "Yu Qiao",
                    "hidden": false
                },
                {
                    "_id": "668f46fdd3b02463a73bc223",
                    "name": "Wanli Ouyang",
                    "hidden": false
                },
                {
                    "_id": "668f46fdd3b02463a73bc224",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
                        "isPro": false,
                        "fullname": "Ziwei Liu",
                        "user": "liuziwei7",
                        "type": "user"
                    },
                    "name": "Ziwei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:34:28.342Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T13:46:08.000Z",
            "title": "VEnhancer: Generative Space-Time Enhancement for Video Generation",
            "summary": "We present VEnhancer, a generative space-time enhancement framework that\nimproves the existing text-to-video results by adding more details in spatial\ndomain and synthetic detailed motion in temporal domain. Given a generated\nlow-quality video, our approach can increase its spatial and temporal\nresolution simultaneously with arbitrary up-sampling space and time scales\nthrough a unified video diffusion model. Furthermore, VEnhancer effectively\nremoves generated spatial artifacts and temporal flickering of generated\nvideos. To achieve this, basing on a pretrained video diffusion model, we train\na video ControlNet and inject it to the diffusion model as a condition on low\nframe-rate and low-resolution videos. To effectively train this video\nControlNet, we design space-time data augmentation as well as video-aware\nconditioning. Benefiting from the above designs, VEnhancer yields to be stable\nduring training and shares an elegant end-to-end training manner. Extensive\nexperiments show that VEnhancer surpasses existing state-of-the-art video\nsuper-resolution and space-time super-resolution methods in enhancing\nAI-generated videos. Moreover, with VEnhancer, exisiting open-source\nstate-of-the-art text-to-video method, VideoCrafter-2, reaches the top one in\nvideo generation benchmark -- VBench.",
            "upvotes": 4
        },
        "publishedAt": "2024-07-11T01:14:42.663Z",
        "title": "VEnhancer: Generative Space-Time Enhancement for Video Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07667.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.07565",
            "authors": [
                {
                    "_id": "668fa3782e309249dbc5d44f",
                    "user": {
                        "avatarUrl": "/avatars/22e4deac49e0be9f7c121ba7072aeb48.svg",
                        "isPro": false,
                        "fullname": "Alexanadre Matton",
                        "user": "alexmatton",
                        "type": "user"
                    },
                    "name": "Alexandre Matton",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:40:09.380Z",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d450",
                    "user": {
                        "avatarUrl": "/avatars/1c0575701529ae0f15a6fed6834a473c.svg",
                        "isPro": false,
                        "fullname": "Tom Sherborne",
                        "user": "tomsherborne",
                        "type": "user"
                    },
                    "name": "Tom Sherborne",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:40:15.540Z",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d451",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5e844d5992fa4e3c26ddb32a/qnVLOiJchVUxDBd8F-wb_.jpeg",
                        "isPro": false,
                        "fullname": "Dennis Aumiller",
                        "user": "dennlinger",
                        "type": "user"
                    },
                    "name": "Dennis Aumiller",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:40:21.598Z",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d452",
                    "user": {
                        "avatarUrl": "/avatars/79cb62d6d68baa05cb9c86105cfafa0f.svg",
                        "isPro": false,
                        "fullname": "Elena Tommasone",
                        "user": "ElenaT123",
                        "type": "user"
                    },
                    "name": "Elena Tommasone",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:40:27.341Z",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d453",
                    "user": {
                        "avatarUrl": "/avatars/a03fd621928e0d2a9ba06e1554375c8e.svg",
                        "isPro": false,
                        "fullname": "Milad Alizadeh",
                        "user": "mil-ad",
                        "type": "user"
                    },
                    "name": "Milad Alizadeh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:40:33.351Z",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d454",
                    "user": {
                        "avatarUrl": "/avatars/afec31c33ffe3387ede96a8481908d6f.svg",
                        "isPro": false,
                        "fullname": "Jingyi He",
                        "user": "Hollysshelter",
                        "type": "user"
                    },
                    "name": "Jingyi He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:40:39.751Z",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d455",
                    "name": "Raymond Ma",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d456",
                    "name": "Maxime Voisin",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d457",
                    "name": "Ellen Gilsenan-McMahon",
                    "hidden": false
                },
                {
                    "_id": "668fa3782e309249dbc5d458",
                    "user": {
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1634907979945-607fc2824ad99100d63ce35f.png",
                        "isPro": false,
                        "fullname": "Matthias Gallé",
                        "user": "mgalle",
                        "type": "user"
                    },
                    "name": "Matthias Gallé",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:41:27.369Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T11:50:20.000Z",
            "title": "On Leakage of Code Generation Evaluation Datasets",
            "summary": "In this paper we consider contamination by code generation test sets, in\nparticular in their use in modern large language models. We discuss three\npossible sources of such contamination and show findings supporting each of\nthem: (i) direct data leakage, (ii) indirect data leakage through the use of\nsynthetic data and (iii) overfitting to evaluation sets during model selection.\n  Key to our findings is a new dataset of 161 prompts with their associated\npython solutions, dataset which is released at\nhttps://huggingface.co/datasets/CohereForAI/lbpp .",
            "upvotes": 3
        },
        "publishedAt": "2024-07-11T08:53:25.904Z",
        "title": "On Leakage of Code Generation Evaluation Datasets",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07565.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg",
            "fullname": "Daniel van Strien",
            "name": "davanstrien",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.05530",
            "authors": [
                {
                    "_id": "668d4fd76bacbfd13c62055a",
                    "user": {
                        "avatarUrl": "/avatars/9cf8af8e6f428b75827458b63d376ee3.svg",
                        "isPro": false,
                        "fullname": "Boyang Wang",
                        "user": "HikariDawn",
                        "type": "user"
                    },
                    "name": "Boyang Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-11T08:27:15.636Z",
                    "hidden": false
                },
                {
                    "_id": "668d4fd76bacbfd13c62055b",
                    "name": "Nikhil Sridhar",
                    "hidden": false
                },
                {
                    "_id": "668d4fd76bacbfd13c62055c",
                    "name": "Chao Feng",
                    "hidden": false
                },
                {
                    "_id": "668d4fd76bacbfd13c62055d",
                    "name": "Mark Van der Merwe",
                    "hidden": false
                },
                {
                    "_id": "668d4fd76bacbfd13c62055e",
                    "name": "Adam Fishman",
                    "hidden": false
                },
                {
                    "_id": "668d4fd76bacbfd13c62055f",
                    "name": "Nima Fazeli",
                    "hidden": false
                },
                {
                    "_id": "668d4fd76bacbfd13c620560",
                    "name": "Jeong Joon Park",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-08T00:28:41.000Z",
            "title": "This&That: Language-Gesture Controlled Video Generation for Robot\n  Planning",
            "summary": "We propose a robot learning method for communicating, planning, and executing\na wide range of tasks, dubbed This&That. We achieve robot planning for general\ntasks by leveraging the power of video generative models trained on\ninternet-scale data containing rich physical and semantic context. In this\nwork, we tackle three fundamental challenges in video-based planning: 1)\nunambiguous task communication with simple human instructions, 2) controllable\nvideo generation that respects user intents, and 3) translating visual planning\ninto robot actions. We propose language-gesture conditioning to generate\nvideos, which is both simpler and clearer than existing language-only methods,\nespecially in complex and uncertain environments. We then suggest a behavioral\ncloning design that seamlessly incorporates the video plans. This&That\ndemonstrates state-of-the-art effectiveness in addressing the above three\nchallenges, and justifies the use of video generation as an intermediate\nrepresentation for generalizable task planning and execution. Project website:\nhttps://cfeng16.github.io/this-and-that/.",
            "upvotes": 2
        },
        "publishedAt": "2024-07-11T14:09:26.183Z",
        "title": "This&That: Language-Gesture Controlled Video Generation for Robot Planning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.05530.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/9cf8af8e6f428b75827458b63d376ee3.svg",
            "fullname": "Boyang Wang",
            "name": "HikariDawn",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.07315",
            "authors": [
                {
                    "_id": "668fb090c9ca04b1c10d53a9",
                    "user": {
                        "avatarUrl": "/avatars/8ea99f8c6c59a7d49295aebfea026963.svg",
                        "isPro": false,
                        "fullname": "Raza Imam",
                        "user": "razaimam45",
                        "type": "user"
                    },
                    "name": "Raza Imam",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:58:12.875Z",
                    "hidden": false
                },
                {
                    "_id": "668fb090c9ca04b1c10d53aa",
                    "user": {
                        "avatarUrl": "/avatars/5c109e67f66bd47a2ea85db837e49e6e.svg",
                        "isPro": false,
                        "fullname": "Mohammed Talha Alam",
                        "user": "talha-alam",
                        "type": "user"
                    },
                    "name": "Mohammed Talha Alam",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:58:19.295Z",
                    "hidden": false
                },
                {
                    "_id": "668fb090c9ca04b1c10d53ab",
                    "name": "Umaima Rahman",
                    "hidden": false
                },
                {
                    "_id": "668fb090c9ca04b1c10d53ac",
                    "name": "Mohsen Guizani",
                    "hidden": false
                },
                {
                    "_id": "668fb090c9ca04b1c10d53ad",
                    "name": "Fakhri Karray",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T02:24:43.000Z",
            "title": "CosmoCLIP: Generalizing Large Vision-Language Models for Astronomical\n  Imaging",
            "summary": "Existing vision-text contrastive learning models enhance representation\ntransferability and support zero-shot prediction by matching paired image and\ncaption embeddings while pushing unrelated pairs apart. However, astronomical\nimage-label datasets are significantly smaller compared to general image and\nlabel datasets available from the internet. We introduce CosmoCLIP, an\nastronomical image-text contrastive learning framework precisely fine-tuned on\nthe pre-trained CLIP model using SpaceNet and BLIP-based captions. SpaceNet,\nattained via FLARE, constitutes ~13k optimally distributed images, while BLIP\nacts as a rich knowledge extractor. The rich semantics derived from this\nSpaceNet and BLIP descriptions, when learned contrastively, enable CosmoCLIP to\nachieve superior generalization across various in-domain and out-of-domain\ntasks. Our results demonstrate that CosmoCLIP is a straightforward yet powerful\nframework, significantly outperforming CLIP in zero-shot classification and\nimage-text retrieval tasks.",
            "upvotes": 2
        },
        "publishedAt": "2024-07-11T08:51:52.852Z",
        "title": "CosmoCLIP: Generalizing Large Vision-Language Models for Astronomical Imaging",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07315.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1627505688463-60107b385ac3e86b3ea4fc34.jpeg",
            "fullname": "Daniel van Strien",
            "name": "davanstrien",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.05528",
            "authors": [
                {
                    "_id": "668dda5f963fdbcecc82a151",
                    "user": {
                        "avatarUrl": "/avatars/9c72744836f86a8e355a45700b10e393.svg",
                        "isPro": false,
                        "fullname": "Paul Albert",
                        "user": "PAlbert31",
                        "type": "user"
                    },
                    "name": "Paul Albert",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-10T08:19:49.399Z",
                    "hidden": false
                },
                {
                    "_id": "668dda5f963fdbcecc82a152",
                    "user": {
                        "avatarUrl": "/avatars/156a4257f3fce1e40f89b42f1ea3522d.svg",
                        "isPro": false,
                        "fullname": "Jack Valmadre",
                        "user": "jvlmdr",
                        "type": "user"
                    },
                    "name": "Jack Valmadre",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-07-11T10:58:56.498Z",
                    "hidden": false
                },
                {
                    "_id": "668dda5f963fdbcecc82a153",
                    "name": "Eric Arazo",
                    "hidden": false
                },
                {
                    "_id": "668dda5f963fdbcecc82a154",
                    "name": "Tarun Krishna",
                    "hidden": false
                },
                {
                    "_id": "668dda5f963fdbcecc82a155",
                    "name": "Noel E. O'Connor",
                    "hidden": false
                },
                {
                    "_id": "668dda5f963fdbcecc82a156",
                    "name": "Kevin McGuinness",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-08T00:21:42.000Z",
            "title": "An accurate detection is not all you need to combat label noise in\n  web-noisy datasets",
            "summary": "Training a classifier on web-crawled data demands learning algorithms that\nare robust to annotation errors and irrelevant examples. This paper builds upon\nthe recent empirical observation that applying unsupervised contrastive\nlearning to noisy, web-crawled datasets yields a feature representation under\nwhich the in-distribution (ID) and out-of-distribution (OOD) samples are\nlinearly separable. We show that direct estimation of the separating hyperplane\ncan indeed offer an accurate detection of OOD samples, and yet, surprisingly,\nthis detection does not translate into gains in classification accuracy.\nDigging deeper into this phenomenon, we discover that the near-perfect\ndetection misses a type of clean examples that are valuable for supervised\nlearning. These examples often represent visually simple images, which are\nrelatively easy to identify as clean examples using standard loss- or\ndistance-based methods despite being poorly separated from the OOD distribution\nusing unsupervised learning. Because we further observe a low correlation with\nSOTA metrics, this urges us to propose a hybrid solution that alternates\nbetween noise detection using linear separation and a state-of-the-art (SOTA)\nsmall-loss approach. When combined with the SOTA algorithm PLS, we\nsubstantially improve SOTA results for real-world image classification in the\npresence of web noise github.com/PaulAlbert31/LSA",
            "upvotes": 2
        },
        "publishedAt": "2024-07-11T03:52:47.237Z",
        "title": "An accurate detection is not all you need to combat label noise in web-noisy datasets",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.05528.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/9c72744836f86a8e355a45700b10e393.svg",
            "fullname": "Paul Albert",
            "name": "PAlbert31",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2407.07788",
            "authors": [
                {
                    "_id": "668f4aba4a4f5339ce284751",
                    "name": "Nikita Chernyadev",
                    "hidden": false
                },
                {
                    "_id": "668f4aba4a4f5339ce284752",
                    "name": "Nicholas Backshall",
                    "hidden": false
                },
                {
                    "_id": "668f4aba4a4f5339ce284753",
                    "name": "Xiao Ma",
                    "hidden": false
                },
                {
                    "_id": "668f4aba4a4f5339ce284754",
                    "user": {
                        "avatarUrl": "/avatars/ebae53ee5330e285ac6a55155298e5d1.svg",
                        "isPro": false,
                        "fullname": "Yunfan Lu",
                        "user": "lyfkyle",
                        "type": "user"
                    },
                    "name": "Yunfan Lu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-07-11T08:25:50.146Z",
                    "hidden": false
                },
                {
                    "_id": "668f4aba4a4f5339ce284755",
                    "name": "Younggyo Seo",
                    "hidden": false
                },
                {
                    "_id": "668f4aba4a4f5339ce284756",
                    "name": "Stephen James",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-07-10T16:04:18.000Z",
            "title": "BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark",
            "summary": "We introduce BiGym, a new benchmark and learning environment for mobile\nbi-manual demo-driven robotic manipulation. BiGym features 40 diverse tasks set\nin home environments, ranging from simple target reaching to complex kitchen\ncleaning. To capture the real-world performance accurately, we provide\nhuman-collected demonstrations for each task, reflecting the diverse modalities\nfound in real-world robot trajectories. BiGym supports a variety of\nobservations, including proprioceptive data and visual inputs such as RGB, and\ndepth from 3 camera views. To validate the usability of BiGym, we thoroughly\nbenchmark the state-of-the-art imitation learning algorithms and demo-driven\nreinforcement learning algorithms within the environment and discuss the future\nopportunities.",
            "upvotes": 1
        },
        "publishedAt": "2024-07-11T01:30:21.215Z",
        "title": "BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2407.07788.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    }
]