[
  {
    "paper": {
      "id": "2502.01506",
      "authors": [
        {
          "_id": "67a4214f12b90b15dc5a648e",
          "name": "Yuzhe Yang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a648f",
          "name": "Yifei Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6490",
          "name": "Minghao Wu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6491",
          "name": "Kaidi Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6492",
          "name": "Yunmiao Zhang",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6493",
          "name": "Honghai Yu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6494",
          "name": "Yan Hu",
          "hidden": false
        },
        {
          "_id": "67a4214f12b90b15dc5a6495",
          "name": "Benyou Wang",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T16:39:48.000Z",
      "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial\n  Markets",
      "summary": "The study of social emergence has long been a central focus in social\nscience. Traditional modeling approaches, such as rule-based Agent-Based Models\n(ABMs), struggle to capture the diversity and complexity of human behavior,\nparticularly the irrational factors emphasized in behavioral economics.\nRecently, large language model (LLM) agents have gained traction as simulation\ntools for modeling human behavior in social science and role-playing\napplications. Studies suggest that LLMs can account for cognitive biases,\nemotional fluctuations, and other non-rational influences, enabling more\nrealistic simulations of socio-economic dynamics. In this work, we introduce\nTwinMarket, a novel multi-agent framework that leverages LLMs to simulate\nsocio-economic systems. Specifically, we examine how individual behaviors,\nthrough interactions and feedback mechanisms, give rise to collective dynamics\nand emergent phenomena. Through experiments in a simulated stock market\nenvironment, we demonstrate how individual actions can trigger group behaviors,\nleading to emergent outcomes such as financial bubbles and recessions. Our\napproach provides valuable insights into the complex interplay between\nindividual decision-making and collective socio-economic patterns.",
      "upvotes": 18,
      "discussionId": "67a4215212b90b15dc5a650a"
    },
    "publishedAt": "2025-02-05T21:44:36.248Z",
    "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01506.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "643c047326f177a3e41627b6",
      "avatarUrl": "/avatars/ade75cebd049daf080ba80a80d516240.svg",
      "fullname": "Yifei Zhang",
      "name": "amstrongzyf",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03373",
      "authors": [
        {
          "_id": "67a42c079a4fb11b11cc4f6f",
          "name": "Edward Yeo",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f70",
          "name": "Yuxuan Tong",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f71",
          "name": "Morry Niu",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f72",
          "name": "Graham Neubig",
          "hidden": false
        },
        {
          "_id": "67a42c079a4fb11b11cc4f73",
          "name": "Xiang Yue",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:13:32.000Z",
      "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
      "summary": "Scaling inference compute enhances reasoning in large language models (LLMs),\nwith long chains-of-thought (CoTs) enabling strategies like backtracking and\nerror correction. Reinforcement learning (RL) has emerged as a crucial method\nfor developing these capabilities, yet the conditions under which long CoTs\nemerge remain unclear, and RL training requires careful design choices. In this\nstudy, we systematically investigate the mechanics of long CoT reasoning,\nidentifying the key factors that enable models to generate long CoT\ntrajectories. Through extensive supervised fine-tuning (SFT) and RL\nexperiments, we present four main findings: (1) While SFT is not strictly\nnecessary, it simplifies training and improves efficiency; (2) Reasoning\ncapabilities tend to emerge with increased training compute, but their\ndevelopment is not guaranteed, making reward shaping crucial for stabilizing\nCoT length growth; (3) Scaling verifiable reward signals is critical for RL. We\nfind that leveraging noisy, web-extracted solutions with filtering mechanisms\nshows strong potential, particularly for out-of-distribution (OOD) tasks such\nas STEM reasoning; and (4) Core abilities like error correction are inherently\npresent in base models, but incentivizing these skills effectively for complex\ntasks via RL demands significant compute, and measuring their emergence\nrequires a nuanced approach. These insights provide practical guidance for\noptimizing training strategies to enhance long CoT reasoning in LLMs. Our code\nis available at: https://github.com/eddycmu/demystify-long-cot.",
      "upvotes": 11,
      "discussionId": "67a42c089a4fb11b11cc4fae"
    },
    "publishedAt": "2025-02-05T22:27:48.348Z",
    "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03373.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "6230d750d93e84e233882dbc",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
      "fullname": "Xiang Yue",
      "name": "yuexiang96",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 26
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02339",
      "authors": [
        {
          "_id": "67a3262873bdaf626f1e9eab",
          "name": "Jinyang Wu",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eac",
          "name": "Mingkuan Feng",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9ead",
          "name": "Shuai Zhang",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eae",
          "name": "Ruihan Jin",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eaf",
          "name": "Feihu Che",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb0",
          "name": "Zengqi Wen",
          "hidden": false
        },
        {
          "_id": "67a3262873bdaf626f1e9eb1",
          "name": "Jianhua Tao",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T14:18:29.000Z",
      "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
      "summary": "Multimodal large language models (MLLMs) exhibit impressive capabilities but\nstill face challenges in complex visual reasoning. While recent efforts attempt\nto enhance MLLMs' reasoning by incorporating OpenAI o1-like structured thinking\nthrough explicit search structures or teacher-guided distillation, they often\nstruggle to balance performance and efficiency. A critical limitation is their\nheavy reliance on extensive data and search spaces, resulting in low-efficiency\nimplicit insight extraction and data utilization. To address this, we propose\nAStar, an Automated Structured thinking paradigm for multimodal reasoning via\nMonte Carlo Tree Search (MCTS). AStar automatically derives high-level\ncognitive reasoning patterns from limited data using MCTS-powered hierarchical\nstructures. Building on these explicit patterns, we design a unified reasoning\nframework that seamlessly integrates models' internal reasoning capabilities\nand external reasoning guidelines, enabling efficient inference with minimal\ntree iterations. This novel paradigm strikes a compelling balance between\nperformance and efficiency. Extensive experiments demonstrate AStar's\neffectiveness, achieving superior accuracy (54.0%) on the MathVerse\nbenchmark with a 7B backbone, surpassing GPT-4o (50.2%) while maintaining\nsubstantial data and computational efficiency.",
      "upvotes": 7,
      "discussionId": "67a3262973bdaf626f1e9edb"
    },
    "publishedAt": "2025-02-05T21:45:32.304Z",
    "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02339.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "6747de57f8cab58c22ec94a2",
      "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
      "fullname": "Jinyang Wu",
      "name": "Jinyang23",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 4
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03387",
      "authors": [
        {
          "_id": "67a445ccbdd74b63b4e52a7d",
          "name": "Yixin Ye",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7e",
          "name": "Zhen Huang",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a7f",
          "name": "Yang Xiao",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a80",
          "name": "Ethan Chern",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a81",
          "name": "Shijie Xia",
          "hidden": false
        },
        {
          "_id": "67a445ccbdd74b63b4e52a82",
          "name": "Pengfei Liu",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T17:23:45.000Z",
      "title": "LIMO: Less is More for Reasoning",
      "summary": "We present a fundamental discovery that challenges our understanding of how\ncomplex reasoning emerges in large language models. While conventional wisdom\nsuggests that sophisticated reasoning tasks demand extensive training data\n(>100,000 examples), we demonstrate that complex mathematical reasoning\nabilities can be effectively elicited with surprisingly few examples. Through\ncomprehensive experiments, our proposed model LIMO demonstrates unprecedented\nperformance in mathematical reasoning. With merely 817 curated training\nsamples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from\nprevious SFT-based models' 6.5% and 59.2% respectively, while only using 1% of\nthe training data required by previous approaches. LIMO demonstrates\nexceptional out-of-distribution generalization, achieving 40.5% absolute\nimprovement across 10 diverse benchmarks, outperforming models trained on 100x\nmore data, challenging the notion that SFT leads to memorization rather than\ngeneralization. Based on these results, we propose the Less-Is-More Reasoning\nHypothesis (LIMO Hypothesis): In foundation models where domain knowledge has\nbeen comprehensively encoded during pre-training, sophisticated reasoning\ncapabilities can emerge through minimal but precisely orchestrated\ndemonstrations of cognitive processes. This hypothesis posits that the\nelicitation threshold for complex reasoning is determined by two key factors:\n(1) the completeness of the model's encoded knowledge foundation during\npre-training, and (2) the effectiveness of post-training examples as \"cognitive\ntemplates\" that show the model how to utilize its knowledge base to solve\ncomplex reasoning tasks. To facilitate reproducibility and future research in\ndata-efficient reasoning, we release LIMO as a comprehensive open-source suite\nat https://github.com/GAIR-NLP/LIMO.",
      "upvotes": 5,
      "discussionId": "67a445cdbdd74b63b4e52af7"
    },
    "publishedAt": "2025-02-06T00:26:02.483Z",
    "title": "LIMO: Less is More for Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03387.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.02737",
      "authors": [
        {
          "_id": "67a446a9430e358f5d5ac4c3",
          "name": "Loubna Ben Allal",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c4",
          "name": "Anton Lozhkov",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c5",
          "name": "Elie Bakouch",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c6",
          "name": "Gabriel Martín Blázquez",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c7",
          "name": "Guilherme Penedo",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c8",
          "name": "Lewis Tunstall",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4c9",
          "name": "Andrés Marafioti",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ca",
          "name": "Hynek Kydlíček",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cb",
          "name": "Agustín Piqueres Lajarín",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cc",
          "name": "Vaibhav Srivastav",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cd",
          "name": "Joshua Lochner",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4ce",
          "name": "Caleb Fahlgren",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4cf",
          "name": "Xuan-Son Nguyen",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d0",
          "name": "Clémentine Fourrier",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d1",
          "name": "Ben Burtenshaw",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d2",
          "name": "Hugo Larcher",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d3",
          "name": "Haojun Zhao",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d4",
          "name": "Cyril Zakka",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d5",
          "name": "Mathieu Morlon",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d6",
          "name": "Colin Raffel",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d7",
          "user": {
            "_id": "6284b359eac6d6ca13879514",
            "avatarUrl": "/avatars/2dcca0f0d21cbe1a54eedac759adc61c.svg",
            "isPro": false,
            "fullname": "evaluate-bot",
            "user": "evaluate-bot",
            "type": "user"
          },
          "name": "Leandro von Werra",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T05:20:41.925Z",
          "hidden": false
        },
        {
          "_id": "67a446a9430e358f5d5ac4d8",
          "name": "Thomas Wolf",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-04T21:43:16.000Z",
      "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language\n  Model",
      "summary": "While large language models have facilitated breakthroughs in many\napplications of artificial intelligence, their inherent largeness makes them\ncomputationally expensive and challenging to deploy in resource-constrained\nsettings. In this paper, we document the development of SmolLM2, a\nstate-of-the-art \"small\" (1.7 billion parameter) language model (LM). To attain\nstrong performance, we overtrain SmolLM2 on ~11 trillion tokens of data using a\nmulti-stage training process that mixes web text with specialized math, code,\nand instruction-following data. We additionally introduce new specialized\ndatasets (FineMath, Stack-Edu, and SmolTalk) at stages where we found existing\ndatasets to be problematically small or low-quality. To inform our design\ndecisions, we perform both small-scale ablations as well as a manual refinement\nprocess that updates the dataset mixing rates at each stage based on the\nperformance at the previous stage. Ultimately, we demonstrate that SmolLM2\noutperforms other recent small LMs including Qwen2.5-1.5B and Llama3.2-1B. To\nfacilitate future research on LM development as well as applications of small\nLMs, we release both SmolLM2 as well as all of the datasets we prepared in the\ncourse of this project.",
      "upvotes": 5,
      "discussionId": "67a446a9430e358f5d5ac4f8"
    },
    "publishedAt": "2025-02-06T00:20:51.704Z",
    "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.02737.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01618",
      "authors": [
        {
          "_id": "67a438d26bb8caaab06f5a5e",
          "user": {
            "_id": "64c2abe8c43875b438efef25",
            "avatarUrl": "/avatars/6efda081f52cf56db2d29a5ec05cb557.svg",
            "isPro": false,
            "fullname": "isha",
            "user": "ishapuri-mit",
            "type": "user"
          },
          "name": "Isha Puri",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T04:21:39.202Z",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a5f",
          "name": "Shivchander Sudalairaj",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a60",
          "name": "Guangxuan Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a61",
          "name": "Kai Xu",
          "hidden": false
        },
        {
          "_id": "67a438d26bb8caaab06f5a62",
          "name": "Akash Srivastava",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T18:50:50.000Z",
      "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs\n  using Particle-Based Monte Carlo Methods",
      "summary": "Large language models (LLMs) have achieved significant performance gains via\nscaling up model sizes and/or data. However, recent evidence suggests\ndiminishing returns from such approaches, motivating scaling the computation\nspent at inference time. Existing inference-time scaling methods, usually with\nreward models, cast the task as a search problem, which tends to be vulnerable\nto reward hacking as a consequence of approximation errors in reward models. In\nthis paper, we instead cast inference-time scaling as a probabilistic inference\ntask and leverage sampling-based techniques to explore the typical set of the\nstate distribution of a state-space model with an approximate likelihood,\nrather than optimize for its mode directly. We propose a novel inference-time\nscaling approach by adapting particle-based Monte Carlo methods to this task.\nOur empirical evaluation demonstrates that our methods have a 4-16x better\nscaling rate over our deterministic search counterparts on various challenging\nmathematical reasoning tasks. Using our approach, we show that\nQwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts,\nwhile Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts.\nOur work not only presents an effective method to inference-time scaling, but\nalso connects the rich literature in probabilistic inference with\ninference-time scaling of LLMs to develop more robust algorithms in future\nwork. Code and further information is available at\nhttps://probabilistic-inference-scaling.github.io.",
      "upvotes": 3,
      "discussionId": "67a438d36bb8caaab06f5a87"
    },
    "publishedAt": "2025-02-05T23:23:08.428Z",
    "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "mediaUrls": [
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/gwgJD14Bd0fdz7xpcHdHe.mp4",
      "https://cdn-uploads.huggingface.co/production/uploads/648b3f3208c4a9d807a90a99/KHcaqxZL3wiloAm7x-7nA.mp4"
    ],
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01618.png",
    "numComments": 2,
    "submittedBy": {
      "_id": "648b3f3208c4a9d807a90a99",
      "avatarUrl": "/avatars/03634b4e7f8afe9b589a2d7370e29960.svg",
      "fullname": "Akash Srivastava",
      "name": "akashsri",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 8
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01154",
      "authors": [
        {
          "_id": "67a4609af2e553c1d0da914d",
          "name": "Yu-Ling Hsu",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914e",
          "name": "Hsuan Su",
          "hidden": false
        },
        {
          "_id": "67a4609af2e553c1d0da914f",
          "name": "Shang-Tse Chen",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T08:44:24.000Z",
      "title": "Jailbreaking with Universal Multi-Prompts",
      "summary": "Large language models (LLMs) have seen rapid development in recent years,\nrevolutionizing various applications and significantly enhancing convenience\nand productivity. However, alongside their impressive capabilities, ethical\nconcerns and new types of attacks, such as jailbreaking, have emerged. While\nmost prompting techniques focus on optimizing adversarial inputs for individual\ncases, resulting in higher computational costs when dealing with large\ndatasets. Less research has addressed the more general setting of training a\nuniversal attacker that can transfer to unseen tasks. In this paper, we\nintroduce JUMP, a prompt-based method designed to jailbreak LLMs using\nuniversal multi-prompts. We also adapt our approach for defense, which we term\nDUMP. Experimental results demonstrate that our method for optimizing universal\nmulti-prompts outperforms existing techniques.",
      "upvotes": 1,
      "discussionId": "67a4609bf2e553c1d0da9181"
    },
    "publishedAt": "2025-02-06T02:11:41.374Z",
    "title": "Jailbreaking with Universal Multi-Prompts",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01154.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "608abf1272b50b02c4b02865",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1619708309549-608abf1272b50b02c4b02865.jpeg",
      "fullname": "Hsuan Su",
      "name": "jacksukk",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false,
      "followerCount": 1
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.01105",
      "authors": [
        {
          "_id": "67a45c85e73ad243c0b9529e",
          "name": "Yiren Song",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b9529f",
          "name": "Danze Chen",
          "hidden": false
        },
        {
          "_id": "67a45c85e73ad243c0b952a0",
          "user": {
            "_id": "63a55320ce5763e06f78519c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1671779060549-noauth.jpeg",
            "isPro": false,
            "fullname": "Mike Shou",
            "user": "mikeshou",
            "type": "user"
          },
          "name": "Mike Zheng Shou",
          "status": "extracted_pending",
          "statusLastChangedAt": "2025-02-06T06:54:02.195Z",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-03T06:49:58.000Z",
      "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion\n  Transformer",
      "summary": "Generating cognitive-aligned layered SVGs remains challenging due to existing\nmethods' tendencies toward either oversimplified single-layer outputs or\noptimization-induced shape redundancies. We propose LayerTracer, a diffusion\ntransformer based framework that bridges this gap by learning designers'\nlayered SVG creation processes from a novel dataset of sequential design\noperations. Our approach operates in two phases: First, a text-conditioned DiT\ngenerates multi-phase rasterized construction blueprints that simulate human\ndesign workflows. Second, layer-wise vectorization with path deduplication\nproduces clean, editable SVGs. For image vectorization, we introduce a\nconditional diffusion mechanism that encodes reference images into latent\ntokens, guiding hierarchical reconstruction while preserving structural\nintegrity. Extensive experiments demonstrate LayerTracer's superior performance\nagainst optimization-based and neural baselines in both generation quality and\neditability, effectively aligning AI-generated vectors with professional design\ncognition.",
      "upvotes": 1,
      "discussionId": "67a45c8ae73ad243c0b953ea"
    },
    "publishedAt": "2025-02-06T01:55:37.207Z",
    "title": "LayerTracer: Cognitive-Aligned Layered SVG Synthesis via Diffusion Transformer",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01105.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "64311a95034ecbefddd141ef",
      "avatarUrl": "/avatars/b6dc5ca373bedbaa368208517954c375.svg",
      "fullname": "Yiren Song",
      "name": "yiren98",
      "type": "user",
      "isPro": false,
      "isHf": false,
      "isMod": false
    },
    "isAuthorParticipating": false
  },
  {
    "paper": {
      "id": "2502.03275",
      "authors": [
        {
          "_id": "67a448b69ca42c642a723a7d",
          "name": "DiJia Su",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7e",
          "name": "Hanlin Zhu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a7f",
          "name": "Yingchen Xu",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a80",
          "name": "Jiantao Jiao",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a81",
          "name": "Yuandong Tian",
          "hidden": false
        },
        {
          "_id": "67a448b69ca42c642a723a82",
          "name": "Qinqing Zheng",
          "hidden": false
        }
      ],
      "publishedAt": "2025-02-05T15:33:00.000Z",
      "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language\n  Model Reasoning",
      "summary": "Large Language Models (LLMs) excel at reasoning and planning when trained on\nchainof-thought (CoT) data, where the step-by-step thought process is\nexplicitly outlined by text tokens. However, this results in lengthy inputs\nwhere many words support textual coherence rather than core reasoning\ninformation, and processing these inputs consumes substantial computation\nresources. In this work, we propose a hybrid representation of the reasoning\nprocess, where we partially abstract away the initial reasoning steps using\nlatent discrete tokens generated by VQ-VAE, significantly reducing the length\nof reasoning traces. We explore the use of latent trace abstractions in two\nscenarios: 1) training the model from scratch for the Keys-Finding Maze\nproblem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary\nincluding unseen latent tokens, for both logical and mathematical reasoning\nproblems. To facilitate effective learning, we introduce a simple training\nprocedure that randomly mixes latent and text tokens, which enables fast\nadaptation to new latent tokens. Our approach consistently outperforms the\nbaselines methods in various benchmarks.",
      "upvotes": 1,
      "discussionId": "67a448b89ca42c642a723ac6"
    },
    "publishedAt": "2025-02-06T00:29:44.686Z",
    "title": "Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning",
    "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.03275.png",
    "numComments": 1,
    "submittedBy": {
      "_id": "60f1abe7544c2adfd699860c",
      "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
      "fullname": "AK",
      "name": "akhaliq",
      "type": "user",
      "isPro": false,
      "isHf": true,
      "isMod": false,
      "followerCount": 5956
    },
    "isAuthorParticipating": false
  }
]