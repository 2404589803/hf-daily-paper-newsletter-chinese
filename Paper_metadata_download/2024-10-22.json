[
    {
        "paper": {
            "id": "2410.16256",
            "authors": [
                {
                    "_id": "671713d85d781c10ef4152b0",
                    "name": "Maosong Cao",
                    "hidden": false
                },
                {
                    "_id": "671713d85d781c10ef4152b1",
                    "user": {
                        "_id": "63fc0d040aab060792003a68",
                        "avatarUrl": "/avatars/d573d4c4ec49513f3b157f7691becbdd.svg",
                        "isPro": false,
                        "fullname": "Alexander Lam",
                        "user": "acylam",
                        "type": "user"
                    },
                    "name": "Alexander Lam",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:37:21.537Z",
                    "hidden": false
                },
                {
                    "_id": "671713d85d781c10ef4152b2",
                    "user": {
                        "_id": "63ee1379190ddd6214efd73a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
                        "isPro": false,
                        "fullname": "HAODONG DUAN",
                        "user": "KennyUTC",
                        "type": "user"
                    },
                    "name": "Haodong Duan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:00:54.994Z",
                    "hidden": false
                },
                {
                    "_id": "671713d85d781c10ef4152b3",
                    "name": "Hongwei Liu",
                    "hidden": false
                },
                {
                    "_id": "671713d85d781c10ef4152b4",
                    "user": {
                        "_id": "630716d11801ecc7d2595021",
                        "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
                        "isPro": false,
                        "fullname": "Songyang Zhang",
                        "user": "zsytony",
                        "type": "user"
                    },
                    "name": "Songyang Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:00:56.898Z",
                    "hidden": false
                },
                {
                    "_id": "671713d85d781c10ef4152b5",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T17:56:51.000Z",
            "title": "CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and\n  Evolution",
            "summary": "Efficient and accurate evaluation is crucial for the continuous improvement\nof large language models (LLMs). Among various assessment methods, subjective\nevaluation has garnered significant attention due to its superior alignment\nwith real-world usage scenarios and human preferences. However, human-based\nevaluations are costly and lack reproducibility, making precise automated\nevaluators (judgers) vital in this process. In this report, we introduce\nCompassJudger-1, the first open-source all-in-one judge LLM.\nCompassJudger-1 is a general-purpose LLM that demonstrates remarkable\nversatility. It is capable of: 1. Performing unitary scoring and two-model\ncomparisons as a reward model; 2. Conducting evaluations according to specified\nformats; 3. Generating critiques; 4. Executing diverse tasks like a general\nLLM. To assess the evaluation capabilities of different judge models under a\nunified setting, we have also established JudgerBench, a new benchmark\nthat encompasses various subjective evaluation tasks and covers a wide range of\ntopics. CompassJudger-1 offers a comprehensive solution for various evaluation\ntasks while maintaining the flexibility to adapt to diverse requirements. Both\nCompassJudger and JudgerBench are released and available to the research\ncommunity athttps://github.com/open-compass/CompassJudger. We believe that by\nopen-sourcing these tools, we can foster collaboration and accelerate progress\nin LLM evaluation methodologies.",
            "upvotes": 51,
            "discussionId": "671713d95d781c10ef41531a"
        },
        "publishedAt": "2024-10-22T01:25:17.829Z",
        "title": "CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.16256.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/2d36a880ce4a3cf7efc5ff3987dbeaf3.svg",
            "fullname": "Songyang Zhang",
            "name": "zsytony",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.16271",
            "authors": [
                {
                    "_id": "67172185a9bd6e5e5b5c3ec8",
                    "user": {
                        "_id": "66b9d0996f861799b80b457a",
                        "avatarUrl": "/avatars/31d4989c5e0983283a6a8e8a152b82e6.svg",
                        "isPro": false,
                        "fullname": "CY Lin",
                        "user": "chinyanglin",
                        "type": "user"
                    },
                    "name": "Chin-Yang Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:06:04.512Z",
                    "hidden": false
                },
                {
                    "_id": "67172185a9bd6e5e5b5c3ec9",
                    "user": {
                        "_id": "65d70288ca16ef9ba7f72542",
                        "avatarUrl": "/avatars/8ceec128b7e7be6d1b4c615b9eced98d.svg",
                        "isPro": false,
                        "fullname": "Chung-Ho Wu",
                        "user": "kkennethwu",
                        "type": "user"
                    },
                    "name": "Chung-Ho Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:07:01.828Z",
                    "hidden": false
                },
                {
                    "_id": "67172185a9bd6e5e5b5c3eca",
                    "name": "Chang-Han Yeh",
                    "hidden": false
                },
                {
                    "_id": "67172185a9bd6e5e5b5c3ecb",
                    "name": "Shih-Han Yen",
                    "hidden": false
                },
                {
                    "_id": "67172185a9bd6e5e5b5c3ecc",
                    "name": "Cheng Sun",
                    "hidden": false
                },
                {
                    "_id": "67172185a9bd6e5e5b5c3ecd",
                    "user": {
                        "_id": "6459d5da3b6fafd9664807ab",
                        "avatarUrl": "/avatars/57430d1bbde3a2fe5586e5fbcafb0e74.svg",
                        "isPro": false,
                        "fullname": "Yu-Lun Liu",
                        "user": "yulunliu",
                        "type": "user"
                    },
                    "name": "Yu-Lun Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:07:23.744Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T17:59:53.000Z",
            "title": "FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without\n  Learned Priors",
            "summary": "Neural Radiance Fields (NeRF) face significant challenges in few-shot\nscenarios, primarily due to overfitting and long training times for\nhigh-fidelity rendering. Existing methods, such as FreeNeRF and SparseNeRF, use\nfrequency regularization or pre-trained priors but struggle with complex\nscheduling and bias. We introduce FrugalNeRF, a novel few-shot NeRF framework\nthat leverages weight-sharing voxels across multiple scales to efficiently\nrepresent scene details. Our key contribution is a cross-scale geometric\nadaptation scheme that selects pseudo ground truth depth based on reprojection\nerrors across scales. This guides training without relying on externally\nlearned priors, enabling full utilization of the training data. It can also\nintegrate pre-trained priors, enhancing quality without slowing convergence.\nExperiments on LLFF, DTU, and RealEstate-10K show that FrugalNeRF outperforms\nother few-shot NeRF methods while significantly reducing training time, making\nit a practical solution for efficient and accurate 3D scene reconstruction.",
            "upvotes": 48,
            "discussionId": "67172188a9bd6e5e5b5c3fab"
        },
        "publishedAt": "2024-10-22T02:26:36.535Z",
        "title": "FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without Learned Priors",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6459d5da3b6fafd9664807ab/aM3ZU3F78i-eujjNSrVIw.qt"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.16271.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/57430d1bbde3a2fe5586e5fbcafb0e74.svg",
            "fullname": "Yu-Lun Liu",
            "name": "yulunliu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.16268",
            "authors": [
                {
                    "_id": "67172a0c38b3deaf184d8a5c",
                    "user": {
                        "_id": "65a7c0335e79abfa2ec30c52",
                        "avatarUrl": "/avatars/2f62f83f9c5c4cc9444571f067cd85b7.svg",
                        "isPro": false,
                        "fullname": "Shuangrui Ding",
                        "user": "Mar2Ding",
                        "type": "user"
                    },
                    "name": "Shuangrui Ding",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:21:34.470Z",
                    "hidden": false
                },
                {
                    "_id": "67172a0c38b3deaf184d8a5d",
                    "name": "Rui Qian",
                    "hidden": false
                },
                {
                    "_id": "67172a0c38b3deaf184d8a5e",
                    "name": "Xiaoyi Dong",
                    "hidden": false
                },
                {
                    "_id": "67172a0c38b3deaf184d8a5f",
                    "name": "Pan Zhang",
                    "hidden": false
                },
                {
                    "_id": "67172a0c38b3deaf184d8a60",
                    "user": {
                        "_id": "63859cf3b2906edaf83af9f0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63859cf3b2906edaf83af9f0/iUQm5FAomzqYi6fkqIn9F.jpeg",
                        "isPro": false,
                        "fullname": "Yuhang Zang",
                        "user": "yuhangzang",
                        "type": "user"
                    },
                    "name": "Yuhang Zang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T07:56:52.321Z",
                    "hidden": false
                },
                {
                    "_id": "67172a0c38b3deaf184d8a61",
                    "user": {
                        "_id": "65000bef18830fabea469fdd",
                        "avatarUrl": "/avatars/b320c77dfad039d9f9c54127f610d44f.svg",
                        "isPro": false,
                        "fullname": "Cao Yuhang",
                        "user": "yhcao",
                        "type": "user"
                    },
                    "name": "Yuhang Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:25:55.933Z",
                    "hidden": false
                },
                {
                    "_id": "67172a0c38b3deaf184d8a62",
                    "user": {
                        "_id": "6371f83d5ffa922d638ef486",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6371f83d5ffa922d638ef486/UzWl3xhVvtol3Rz1mjQ9t.jpeg",
                        "isPro": false,
                        "fullname": "Yuwei Guo",
                        "user": "guoyww",
                        "type": "user"
                    },
                    "name": "Yuwei Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:26:51.123Z",
                    "hidden": false
                },
                {
                    "_id": "67172a0c38b3deaf184d8a63",
                    "user": {
                        "_id": "636317ed80c1a705a6eff396",
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:26:05.934Z",
                    "hidden": false
                },
                {
                    "_id": "67172a0c38b3deaf184d8a64",
                    "user": {
                        "_id": "64b4eec4faa3181a5eab9c46",
                        "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
                        "isPro": true,
                        "fullname": "Jiaqi Wang",
                        "user": "myownskyW7",
                        "type": "user"
                    },
                    "name": "Jiaqi Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T07:56:54.146Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T17:59:19.000Z",
            "title": "SAM2Long: Enhancing SAM 2 for Long Video Segmentation with a\n  Training-Free Memory Tree",
            "summary": "The Segment Anything Model 2 (SAM 2) has emerged as a powerful foundation\nmodel for object segmentation in both images and videos, paving the way for\nvarious downstream video applications. The crucial design of SAM 2 for video\nsegmentation is its memory module, which prompts object-aware memories from\nprevious frames for current frame prediction. However, its greedy-selection\nmemory design suffers from the \"error accumulation\" problem, where an errored\nor missed mask will cascade and influence the segmentation of the subsequent\nframes, which limits the performance of SAM 2 toward complex long-term videos.\nTo this end, we introduce SAM2Long, an improved training-free video object\nsegmentation strategy, which considers the segmentation uncertainty within each\nframe and chooses the video-level optimal results from multiple segmentation\npathways in a constrained tree search manner. In practice, we maintain a fixed\nnumber of segmentation pathways throughout the video. For each frame, multiple\nmasks are proposed based on the existing pathways, creating various candidate\nbranches. We then select the same fixed number of branches with higher\ncumulative scores as the new pathways for the next frame. After processing the\nfinal frame, the pathway with the highest cumulative score is chosen as the\nfinal segmentation result. Benefiting from its heuristic search design,\nSAM2Long is robust toward occlusions and object reappearances, and can\neffectively segment and track objects for complex long-term videos. Notably,\nSAM2Long achieves an average improvement of 3.0 points across all 24\nhead-to-head comparisons, with gains of up to 5.3 points in J&F on long-term\nvideo object segmentation benchmarks such as SA-V and LVOS. The code is\nreleased at https://github.com/Mark12Ding/SAM2Long.",
            "upvotes": 45,
            "discussionId": "67172a0e38b3deaf184d8af7"
        },
        "publishedAt": "2024-10-22T03:38:14.996Z",
        "title": "SAM2Long: Enhancing SAM 2 for Long Video Segmentation with a Training-Free Memory Tree",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64b4eec4faa3181a5eab9c46/zTCtvqD1fHvCSgeDddZg4.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.16268.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg",
            "fullname": "Jiaqi Wang",
            "name": "myownskyW7",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13861",
            "authors": [
                {
                    "_id": "671715637892af397b9a93f3",
                    "user": {
                        "_id": "65b8724123d948d884b379b1",
                        "avatarUrl": "/avatars/ce189d1d8d688c17912f9b869035b2d0.svg",
                        "isPro": false,
                        "fullname": "Rongyao Fang",
                        "user": "LucasFang",
                        "type": "user"
                    },
                    "name": "Rongyao Fang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:00:53.368Z",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93f4",
                    "user": {
                        "_id": "64a2b496e2e19de17db7de65",
                        "avatarUrl": "/avatars/241448ca487833d6cc5d57bb1fdb6ee5.svg",
                        "isPro": false,
                        "fullname": "Duan Chengqi",
                        "user": "gogoduan",
                        "type": "user"
                    },
                    "name": "Chengqi Duan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:00:48.851Z",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93f5",
                    "name": "Kun Wang",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93f6",
                    "name": "Hao Li",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93f7",
                    "name": "Hao Tian",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93f8",
                    "user": {
                        "_id": "666d4a0fe70e5838d95aebee",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/6dkjoFA_sOjCkjvcvozZ5.jpeg",
                        "isPro": false,
                        "fullname": "zengxingyu",
                        "user": "zengxingyu",
                        "type": "user"
                    },
                    "name": "Xingyu Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:32:52.126Z",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93f9",
                    "name": "Rui Zhao",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93fa",
                    "user": {
                        "_id": "64686f7172d9180d4ac8b4e4",
                        "avatarUrl": "/avatars/db67dd6c4b2b41054ddcce5a18ade6f8.svg",
                        "isPro": false,
                        "fullname": "Jifeng Dai",
                        "user": "daijifeng",
                        "type": "user"
                    },
                    "name": "Jifeng Dai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:33:01.448Z",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93fb",
                    "user": {
                        "_id": "65c04e9c27a5fdca81abcbd9",
                        "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
                        "isPro": false,
                        "fullname": "Hongsheng LI",
                        "user": "hsli-cuhk",
                        "type": "user"
                    },
                    "name": "Hongsheng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:32:41.509Z",
                    "hidden": false
                },
                {
                    "_id": "671715637892af397b9a93fc",
                    "user": {
                        "_id": "65d5ec74cd05bc1eaa125040",
                        "avatarUrl": "/avatars/2de1b1539a86452c2c89570eeb02f5ab.svg",
                        "isPro": false,
                        "fullname": "Xihui Liu",
                        "user": "XihuiLiu",
                        "type": "user"
                    },
                    "name": "Xihui Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:00:51.171Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T17:59:57.000Z",
            "title": "PUMA: Empowering Unified MLLM with Multi-granular Visual Generation",
            "summary": "Recent advancements in multimodal foundation models have yielded significant\nprogress in vision-language understanding. Initial attempts have also explored\nthe potential of multimodal large language models (MLLMs) for visual content\ngeneration. However, existing works have insufficiently addressed the varying\ngranularity demands of different image generation tasks within a unified MLLM\nparadigm - from the diversity required in text-to-image generation to the\nprecise controllability needed in image manipulation. In this work, we propose\nPUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMA\nunifies multi-granular visual features as both inputs and outputs of MLLMs,\nelegantly addressing the different granularity requirements of various image\ngeneration tasks within a unified MLLM framework. Following multimodal\npretraining and task-specific instruction tuning, PUMA demonstrates proficiency\nin a wide range of multimodal tasks. This work represents a significant step\ntowards a truly unified MLLM capable of adapting to the granularity demands of\nvarious visual tasks. The code and model will be released in\nhttps://github.com/rongyaofang/PUMA.",
            "upvotes": 41,
            "discussionId": "671715667892af397b9a94ab"
        },
        "publishedAt": "2024-10-22T01:33:52.453Z",
        "title": "PUMA: Empowering Unified MLLM with Multi-granular Visual Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13861.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/ce189d1d8d688c17912f9b869035b2d0.svg",
            "fullname": "Rongyao Fang",
            "name": "LucasFang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.15735",
            "authors": [
                {
                    "_id": "671737e60a87ad788cd4ee9c",
                    "user": {
                        "_id": "5fa19f4ba13e063b8b2b5e11",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5fa19f4ba13e063b8b2b5e11/nGVHdTYX2udnt-K8mqY27.jpeg",
                        "isPro": false,
                        "fullname": "Abhishek Thakur",
                        "user": "abhishek",
                        "type": "user"
                    },
                    "name": "Abhishek Thakur",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-10-22T07:44:34.057Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T07:53:32.000Z",
            "title": "AutoTrain: No-code training for state-of-the-art models",
            "summary": "With the advancements in open-source models, training (or finetuning) models\non custom datasets has become a crucial part of developing solutions which are\ntailored to specific industrial or open-source applications. Yet, there is no\nsingle tool which simplifies the process of training across different types of\nmodalities or tasks. We introduce AutoTrain (aka AutoTrain Advanced) -- an\nopen-source, no code tool/library which can be used to train (or finetune)\nmodels for different kinds of tasks such as: large language model (LLM)\nfinetuning, text classification/regression, token classification,\nsequence-to-sequence task, finetuning of sentence transformers, visual language\nmodel (VLM) finetuning, image classification/regression and even classification\nand regression tasks on tabular data. AutoTrain Advanced is an open-source\nlibrary providing best practices for training models on custom datasets. The\nlibrary is available at https://github.com/huggingface/autotrain-advanced.\nAutoTrain can be used in fully local mode or on cloud machines and works with\ntens of thousands of models shared on Hugging Face Hub and their variations.",
            "upvotes": 35,
            "discussionId": "671737e60a87ad788cd4eee3"
        },
        "publishedAt": "2024-10-22T04:10:40.899Z",
        "title": "AutoTrain: No-code training for state-of-the-art models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.15735.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/638eb5f949de7ae552dd6211/mJkQJGpn9tXV37N2VLFCh.jpeg",
            "fullname": "Derek Thomas",
            "name": "derek-thomas",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.14940",
            "authors": [
                {
                    "_id": "671712096914e88ea68a0644",
                    "user": {
                        "_id": "6415947858a690df103af49f",
                        "avatarUrl": "/avatars/38aec23b869833bceb25b9250809b419.svg",
                        "isPro": false,
                        "fullname": "lma",
                        "user": "lin5547",
                        "type": "user"
                    },
                    "name": "Mingan Lin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:01:00.377Z",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0645",
                    "name": "Fan Yang",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0646",
                    "user": {
                        "_id": "64ced7c01720c7a483d0862f",
                        "avatarUrl": "/avatars/1fae685b7226a0a1c95b2d4993f2ab60.svg",
                        "isPro": false,
                        "fullname": "shenyanjun",
                        "user": "zilchshen",
                        "type": "user"
                    },
                    "name": "Yanjun Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:34:25.552Z",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0647",
                    "name": "Haoze Sun",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0648",
                    "user": {
                        "_id": "64be4c97ef8c0e42bf448469",
                        "avatarUrl": "/avatars/a2a45b5f17d3e27c59547312bcf7bb52.svg",
                        "isPro": false,
                        "fullname": "Tianpeng Li",
                        "user": "TJU-Tianpengli",
                        "type": "user"
                    },
                    "name": "Tianpeng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:33:45.235Z",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0649",
                    "name": "Tao Zhang",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a064a",
                    "name": "Chenzheng Zhu",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a064b",
                    "name": "Tao Zhang",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a064c",
                    "name": "Miao Zheng",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a064d",
                    "name": "Xu Li",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a064e",
                    "user": {
                        "_id": "65c2515544b6e2c37fd77f4d",
                        "avatarUrl": "/avatars/238d6ed99c6eeb9c8e04c60b2176424d.svg",
                        "isPro": false,
                        "fullname": "Yijie Zhou",
                        "user": "YijieZhou",
                        "type": "user"
                    },
                    "name": "Yijie Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:35:17.341Z",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a064f",
                    "name": "Mingyang Chen",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0650",
                    "name": "Yanzhao Qin",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0651",
                    "name": "Youquan Li",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0652",
                    "name": "Hao Liang",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0653",
                    "name": "Fei Li",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0654",
                    "name": "Yadong Li",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0655",
                    "name": "Mang Wang",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0656",
                    "user": {
                        "_id": "668d2ff4271bd45dab6a8e71",
                        "avatarUrl": "/avatars/4e198c35a9f09bbc6551c34148aaf560.svg",
                        "isPro": false,
                        "fullname": "guosheng dong",
                        "user": "dongguosheng",
                        "type": "user"
                    },
                    "name": "Guosheng Dong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:33:18.413Z",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0657",
                    "name": "Kun Fang",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0658",
                    "user": {
                        "_id": "66042414ded78d7454b9746e",
                        "avatarUrl": "/avatars/828feab7015b527b5ac5c9238fa3c7e0.svg",
                        "isPro": false,
                        "fullname": "jianhua Xu",
                        "user": "ArthurXu2020",
                        "type": "user"
                    },
                    "name": "Jianhua Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:33:25.164Z",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a0659",
                    "name": "Bin Cui",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a065a",
                    "name": "Wentao Zhang",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a065b",
                    "user": {
                        "_id": "668d4e50ed63008dfaa78304",
                        "avatarUrl": "/avatars/80854a3c6b4b7c70cd46694d4cf7296a.svg",
                        "isPro": false,
                        "fullname": "Zenan Zhou",
                        "user": "Zenan11",
                        "type": "user"
                    },
                    "name": "Zenan Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:35:33.015Z",
                    "hidden": false
                },
                {
                    "_id": "671712096914e88ea68a065c",
                    "user": {
                        "_id": "6501587887b370a56ad2608e",
                        "avatarUrl": "/avatars/6779baaa8ed9032de55a2f78e1f52e20.svg",
                        "isPro": false,
                        "fullname": "Wei-Peng Chen",
                        "user": "whenfra",
                        "type": "user"
                    },
                    "name": "Weipeng Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T08:35:26.687Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-19T02:07:33.000Z",
            "title": "Baichuan Alignment Technical Report",
            "summary": "We introduce Baichuan Alignment, a detailed analysis of the alignment\ntechniques employed in the Baichuan series of models. This represents the\nindustry's first comprehensive account of alignment methodologies, offering\nvaluable insights for advancing AI research. We investigate the critical\ncomponents that enhance model performance during the alignment process,\nincluding optimization methods, data strategies, capability enhancements, and\nevaluation processes. The process spans three key stages: Prompt Augmentation\nSystem (PAS), Supervised Fine-Tuning (SFT), and Preference Alignment. The\nproblems encountered, the solutions applied, and the improvements made are\nthoroughly recorded.\n  Through comparisons across well-established benchmarks, we highlight the\ntechnological advancements enabled by Baichuan Alignment. Baichuan-Instruct is\nan internal model, while Qwen2-Nova-72B and Llama3-PBM-Nova-70B are instruct\nversions of the Qwen2-72B and Llama-3-70B base models, optimized through\nBaichuan Alignment. Baichuan-Instruct demonstrates significant improvements in\ncore capabilities, with user experience gains ranging from 17% to 28%, and\nperforms exceptionally well on specialized benchmarks. In open-source benchmark\nevaluations, both Qwen2-Nova-72B and Llama3-PBM-Nova-70B consistently\noutperform their respective official instruct versions across nearly all\ndatasets. This report aims to clarify the key technologies behind the alignment\nprocess, fostering a deeper understanding within the community.\nLlama3-PBM-Nova-70B model is available at\nhttps://huggingface.co/PKU-Baichuan-MLSystemLab/Llama3-PBM-Nova-70B.",
            "upvotes": 32,
            "discussionId": "6717120a6914e88ea68a06b7"
        },
        "publishedAt": "2024-10-22T01:17:50.681Z",
        "title": "Baichuan Alignment Technical Report",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.14940.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/38aec23b869833bceb25b9250809b419.svg",
            "fullname": "lma",
            "name": "lin5547",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.16153",
            "authors": [
                {
                    "_id": "671718ed63c851e167b775c5",
                    "user": {
                        "_id": "6230d750d93e84e233882dbc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
                        "isPro": false,
                        "fullname": "Xiang Yue",
                        "user": "yuexiang96",
                        "type": "user"
                    },
                    "name": "Xiang Yue",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T07:57:23.127Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775c6",
                    "user": {
                        "_id": "63e7bf7be02ee67e8e53f78d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e7bf7be02ee67e8e53f78d/z9j1PWrurEyIA2JXzpz0i.png",
                        "isPro": false,
                        "fullname": "Yueqi Song",
                        "user": "yueqis",
                        "type": "user"
                    },
                    "name": "Yueqi Song",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:17:30.353Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775c7",
                    "user": {
                        "_id": "6266e0cb7a1f5a1562c4e86e",
                        "avatarUrl": "/avatars/05bb1120c7cda43e541572aa7f8d9eab.svg",
                        "isPro": false,
                        "fullname": "Akari Asai",
                        "user": "akariasai",
                        "type": "user"
                    },
                    "name": "Akari Asai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:17:24.248Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775c8",
                    "user": {
                        "_id": "6469949654873f0043b09c22",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6469949654873f0043b09c22/Lk7IJAR16Wa_sGJ2g81AQ.jpeg",
                        "isPro": false,
                        "fullname": "Seungone Kim",
                        "user": "seungone",
                        "type": "user"
                    },
                    "name": "Seungone Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T07:57:21.588Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775c9",
                    "user": {
                        "_id": "62989cd743e990340bead77c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654168730944-noauth.png",
                        "isPro": false,
                        "fullname": "Jean de Dieu Nyandwi",
                        "user": "Nyandwi",
                        "type": "user"
                    },
                    "name": "Jean de Dieu Nyandwi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T09:05:59.579Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775ca",
                    "user": {
                        "_id": "63a4d079658851481f7e4394",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4d079658851481f7e4394/yptj_hJiaqHvEaqxLs0jT.jpeg",
                        "isPro": false,
                        "fullname": "Simran Khanuja",
                        "user": "skhanuja",
                        "type": "user"
                    },
                    "name": "Simran Khanuja",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:17:15.486Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775cb",
                    "user": {
                        "_id": "634e6d7ea51d5df8c2da699d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1666084174110-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Anjali Kantharuban",
                        "user": "AnjaliRuban",
                        "type": "user"
                    },
                    "name": "Anjali Kantharuban",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:16:49.370Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775cc",
                    "user": {
                        "_id": "5f666a6b5e78cc6b0ed319fc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1635412047803-5f666a6b5e78cc6b0ed319fc.jpeg",
                        "isPro": false,
                        "fullname": "Lintang Sutawika",
                        "user": "lintang",
                        "type": "user"
                    },
                    "name": "Lintang Sutawika",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:17:08.786Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775cd",
                    "user": {
                        "_id": "643b87db0e5495afdeff8de5",
                        "avatarUrl": "/avatars/5c0bca81a52ab6b7beb7a52d82e53a10.svg",
                        "isPro": false,
                        "fullname": "Sathyanarayanan Ramamoorthy",
                        "user": "sathyaram",
                        "type": "user"
                    },
                    "name": "Sathyanarayanan Ramamoorthy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:17:02.898Z",
                    "hidden": false
                },
                {
                    "_id": "671718ed63c851e167b775ce",
                    "user": {
                        "_id": "60de14638bedd2315529d43f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1625166923504-noauth.png",
                        "isPro": false,
                        "fullname": "Graham Neubig",
                        "user": "gneubig",
                        "type": "user"
                    },
                    "name": "Graham Neubig",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:16:57.085Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T16:19:41.000Z",
            "title": "Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages",
            "summary": "Despite recent advances in multimodal large language models (MLLMs), their\ndevelopment has predominantly focused on English- and western-centric datasets\nand tasks, leaving most of the world's languages and diverse cultural contexts\nunderrepresented. This paper introduces Pangea, a multilingual multimodal LLM\ntrained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.\nPangeaIns features: 1) high-quality English instructions, 2) carefully\nmachine-translated instructions, and 3) culturally relevant multimodal tasks to\nensure cross-cultural coverage. To rigorously assess models' capabilities, we\nintroduce PangeaBench, a holistic evaluation suite encompassing 14 datasets\ncovering 47 languages. Results show that Pangea significantly outperforms\nexisting open-source models in multilingual settings and diverse cultural\ncontexts. Ablation studies further reveal the importance of English data\nproportions, language popularity, and the number of multimodal training samples\non overall performance. We fully open-source our data, code, and trained\ncheckpoints, to facilitate the development of inclusive and robust multilingual\nMLLMs, promoting equity and accessibility across a broader linguistic and\ncultural spectrum.",
            "upvotes": 24,
            "discussionId": "671718f363c851e167b7780a"
        },
        "publishedAt": "2024-10-22T02:07:31.615Z",
        "title": "Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.16153.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
            "fullname": "Xiang Yue",
            "name": "yuexiang96",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.16184",
            "authors": [
                {
                    "_id": "671725cc2df05eaa5c2f5020",
                    "name": "Yantao Liu",
                    "hidden": false
                },
                {
                    "_id": "671725cc2df05eaa5c2f5021",
                    "user": {
                        "_id": "648c4b46e549be47af1aafcd",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/648c4b46e549be47af1aafcd/YgOHbmUM2EDM-lb7GdqXz.jpeg",
                        "isPro": false,
                        "fullname": "Zijun",
                        "user": "TranSirius",
                        "type": "user"
                    },
                    "name": "Zijun Yao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T07:56:57.790Z",
                    "hidden": false
                },
                {
                    "_id": "671725cc2df05eaa5c2f5022",
                    "name": "Rui Min",
                    "hidden": false
                },
                {
                    "_id": "671725cc2df05eaa5c2f5023",
                    "user": {
                        "_id": "6586ec334f349f95cf8c98d2",
                        "avatarUrl": "/avatars/ff74ebb7d661ab70401d709885fb9717.svg",
                        "isPro": false,
                        "fullname": "caoyixin",
                        "user": "Nuomei",
                        "type": "user"
                    },
                    "name": "Yixin Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:08:11.051Z",
                    "hidden": false
                },
                {
                    "_id": "671725cc2df05eaa5c2f5024",
                    "name": "Lei Hou",
                    "hidden": false
                },
                {
                    "_id": "671725cc2df05eaa5c2f5025",
                    "user": {
                        "_id": "65df8cbc2705d9672f55d1aa",
                        "avatarUrl": "/avatars/63e46f15bb76bd9d4508fd0f54f39829.svg",
                        "isPro": false,
                        "fullname": "Juanzi Li",
                        "user": "juanli",
                        "type": "user"
                    },
                    "name": "Juanzi Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:07:50.457Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T16:48:26.000Z",
            "title": "RM-Bench: Benchmarking Reward Models of Language Models with Subtlety\n  and Style",
            "summary": "Reward models are critical in techniques like Reinforcement Learning from\nHuman Feedback (RLHF) and Inference Scaling Laws, where they guide language\nmodel alignment and select optimal responses. Despite their importance,\nexisting reward model benchmarks often evaluate models by asking them to\ndistinguish between responses generated by models of varying power. However,\nthis approach fails to assess reward models on subtle but critical content\nchanges and variations in style, resulting in a low correlation with policy\nmodel performance. To this end, we introduce RM-Bench, a novel benchmark\ndesigned to evaluate reward models based on their sensitivity to subtle content\ndifferences and resistance to style biases. Extensive experiments demonstrate\nthat RM-Bench strongly correlates with policy model performance, making it a\nreliable reference for selecting reward models to align language models\neffectively. We evaluate nearly 40 reward models on RM-Bench. Our results\nreveal that even state-of-the-art models achieve an average performance of only\n46.6%, which falls short of random-level accuracy (50%) when faced with style\nbias interference. These findings highlight the significant room for\nimprovement in current reward models. Related code and data are available at\nhttps://github.com/THU-KEG/RM-Bench.",
            "upvotes": 20,
            "discussionId": "671725cd2df05eaa5c2f5052"
        },
        "publishedAt": "2024-10-22T02:51:09.711Z",
        "title": "RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.16184.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/1bb32e7597a9b1c89c434cbf550b5382.svg",
            "fullname": "Yantao",
            "name": "RicardoL1u",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.14745",
            "authors": [
                {
                    "_id": "671701fe9ec0ff4d1501fa6c",
                    "user": {
                        "_id": "642da1cd99f3110ac27caca5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642da1cd99f3110ac27caca5/C1QJY3R_ZdaeANG1y8iW7.jpeg",
                        "isPro": false,
                        "fullname": "junyu",
                        "user": "luojunyu",
                        "type": "user"
                    },
                    "name": "Junyu Luo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:01:10.194Z",
                    "hidden": false
                },
                {
                    "_id": "671701fe9ec0ff4d1501fa6d",
                    "name": "Xiao Luo",
                    "hidden": false
                },
                {
                    "_id": "671701fe9ec0ff4d1501fa6e",
                    "user": {
                        "_id": "6270ff726417aed8a7340c8b",
                        "avatarUrl": "/avatars/3f14913c55cc4fc78678ac43fb603e80.svg",
                        "isPro": false,
                        "fullname": "Xiusi Chen",
                        "user": "XtremSup",
                        "type": "user"
                    },
                    "name": "Xiusi Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:36:49.362Z",
                    "hidden": false
                },
                {
                    "_id": "671701fe9ec0ff4d1501fa6f",
                    "user": {
                        "_id": "66ab566e30c55e83b02aa050",
                        "avatarUrl": "/avatars/62692be88b9ad34ad3f474fb0359ae20.svg",
                        "isPro": false,
                        "fullname": "Zhiping Xiao",
                        "user": "Shockzipper",
                        "type": "user"
                    },
                    "name": "Zhiping Xiao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:36:43.433Z",
                    "hidden": false
                },
                {
                    "_id": "671701fe9ec0ff4d1501fa70",
                    "name": "Wei Ju",
                    "hidden": false
                },
                {
                    "_id": "671701fe9ec0ff4d1501fa71",
                    "name": "Ming Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T16:59:46.000Z",
            "title": "SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation",
            "summary": "Supervised fine-tuning (SFT) is crucial in adapting large language models\n(LLMs) to a specific domain or task. However, only a limited amount of labeled\ndata is available in practical applications, which poses a severe challenge for\nSFT in yielding satisfactory results. Therefore, a data-efficient framework\nthat can fully exploit labeled and unlabeled data for LLM fine-tuning is highly\nanticipated. Towards this end, we introduce a semi-supervised fine-tuning\nframework named SemiEvol for LLM adaptation from a propagate-and-select manner.\nFor knowledge propagation, SemiEvol adopts a bi-level approach, propagating\nknowledge from labeled data to unlabeled data through both in-weight and\nin-context methods. For knowledge selection, SemiEvol incorporates a\ncollaborative learning mechanism, selecting higher-quality pseudo-response\nsamples. We conducted experiments using GPT-4o-mini and Llama-3.1 on seven\ngeneral or domain-specific datasets, demonstrating significant improvements in\nmodel performance on target data. Furthermore, we compared SemiEvol with SFT\nand self-evolution methods, highlighting its practicality in hybrid data\nscenarios.",
            "upvotes": 20,
            "discussionId": "671701ff9ec0ff4d1501fad0"
        },
        "publishedAt": "2024-10-22T00:58:50.796Z",
        "title": "SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.14745.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642da1cd99f3110ac27caca5/C1QJY3R_ZdaeANG1y8iW7.jpeg",
            "fullname": "junyu",
            "name": "luojunyu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.12788",
            "authors": [
                {
                    "_id": "6717157f69532dd147c7579e",
                    "user": {
                        "_id": "658e85bb5b7553ca5c29ba89",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/658e85bb5b7553ca5c29ba89/KK6UpS9agtrxevvBoup5N.jpeg",
                        "isPro": false,
                        "fullname": "Jihao Zhao",
                        "user": "Robot2050",
                        "type": "user"
                    },
                    "name": "Jihao Zhao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:00:47.204Z",
                    "hidden": false
                },
                {
                    "_id": "6717157f69532dd147c7579f",
                    "name": "Zhiyuan Ji",
                    "hidden": false
                },
                {
                    "_id": "6717157f69532dd147c757a0",
                    "user": {
                        "_id": "64be260cf8f28a19b0e02f35",
                        "avatarUrl": "/avatars/cc55af21b31589f87dbdf9fed65be6bc.svg",
                        "isPro": false,
                        "fullname": "pengnian qi",
                        "user": "MoCun",
                        "type": "user"
                    },
                    "name": "Pengnian Qi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:15:31.720Z",
                    "hidden": false
                },
                {
                    "_id": "6717157f69532dd147c757a1",
                    "user": {
                        "_id": "66daea8776dbaaa372eabec5",
                        "avatarUrl": "/avatars/1e5fbe4ff06bb6121c7029253b76b79f.svg",
                        "isPro": false,
                        "fullname": "siminniu",
                        "user": "siminniu",
                        "type": "user"
                    },
                    "name": "Simin Niu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:15:37.051Z",
                    "hidden": false
                },
                {
                    "_id": "6717157f69532dd147c757a2",
                    "name": "Bo Tang",
                    "hidden": false
                },
                {
                    "_id": "6717157f69532dd147c757a3",
                    "name": "Feiyu Xiong",
                    "hidden": false
                },
                {
                    "_id": "6717157f69532dd147c757a4",
                    "user": {
                        "_id": "62a155e615eeab266b2f2243",
                        "avatarUrl": "/avatars/e89ef156e73af028e3ce3664e6cb4e62.svg",
                        "isPro": false,
                        "fullname": "Zhiyu Li",
                        "user": "jimi888",
                        "type": "user"
                    },
                    "name": "Zhiyu Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:16:33.336Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-16T17:59:32.000Z",
            "title": "Meta-Chunking: Learning Efficient Text Segmentation via Logical\n  Perception",
            "summary": "Retrieval-Augmented Generation (RAG), while serving as a viable complement to\nlarge language models (LLMs), often overlooks the crucial aspect of text\nchunking within its pipeline, which impacts the quality of knowledge-intensive\ntasks. This paper introduces the concept of Meta-Chunking, which refers to a\ngranularity between sentences and paragraphs, consisting of a collection of\nsentences within a paragraph that have deep linguistic logical connections. To\nimplement Meta-Chunking, we designed two strategies based on LLMs: Margin\nSampling Chunking and Perplexity Chunking. The former employs LLMs to perform\nbinary classification on whether consecutive sentences need to be segmented,\nmaking decisions based on the probability difference obtained from margin\nsampling. The latter precisely identifies text chunk boundaries by analyzing\nthe characteristics of perplexity distribution. Additionally, considering the\ninherent complexity of different texts, we propose a strategy that combines\nMeta-Chunking with dynamic merging to achieve a balance between fine-grained\nand coarse-grained text chunking. Experiments conducted on eleven datasets\ndemonstrate that Meta-Chunking can more efficiently improve the performance of\nsingle-hop and multi-hop question answering based on RAG. For instance, on the\n2WikiMultihopQA dataset, it outperforms similarity chunking by 1.32 while only\nconsuming 45.8% of the time. Our code is available at\nhttps://github.com/IAAR-Shanghai/Meta-Chunking.",
            "upvotes": 15,
            "discussionId": "6717158269532dd147c758ba"
        },
        "publishedAt": "2024-10-22T02:24:32.367Z",
        "title": "Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.12788.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6455ff584095c967f9a847bb/A5wjtWsudC73fLVmgASBr.jpeg",
            "fullname": "Qingchen Yu",
            "name": "Duguce",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.16215",
            "authors": [
                {
                    "_id": "67173a397994589e3f441da8",
                    "user": {
                        "_id": "625a5446f1063e7085d5178a",
                        "avatarUrl": "/avatars/5e78186f13f74b14e01583e06ff6c4dc.svg",
                        "isPro": false,
                        "fullname": "Hao Peng",
                        "user": "Wesleythu",
                        "type": "user"
                    },
                    "name": "Hao Peng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T09:48:33.508Z",
                    "hidden": false
                },
                {
                    "_id": "67173a397994589e3f441da9",
                    "name": "Xin Lv",
                    "hidden": false
                },
                {
                    "_id": "67173a397994589e3f441daa",
                    "user": {
                        "_id": "64ed568ccf6118a9379a61b8",
                        "avatarUrl": "/avatars/6d040cbcb4a9b624cbe64c9d01cd5c88.svg",
                        "isPro": false,
                        "fullname": "Yushi Bai",
                        "user": "bys0318",
                        "type": "user"
                    },
                    "name": "Yushi Bai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T07:55:46.101Z",
                    "hidden": false
                },
                {
                    "_id": "67173a397994589e3f441dab",
                    "name": "Zijun Yao",
                    "hidden": false
                },
                {
                    "_id": "67173a397994589e3f441dac",
                    "user": {
                        "_id": "66cdd285c51a915bd5f2d017",
                        "avatarUrl": "/avatars/14e5794307e4672b1b51d26b31227e0f.svg",
                        "isPro": false,
                        "fullname": "Jiajie Zhang",
                        "user": "NeoZ123",
                        "type": "user"
                    },
                    "name": "Jiajie Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T09:14:57.280Z",
                    "hidden": false
                },
                {
                    "_id": "67173a397994589e3f441dad",
                    "name": "Lei Hou",
                    "hidden": false
                },
                {
                    "_id": "67173a397994589e3f441dae",
                    "user": {
                        "_id": "65df8cbc2705d9672f55d1aa",
                        "avatarUrl": "/avatars/63e46f15bb76bd9d4508fd0f54f39829.svg",
                        "isPro": false,
                        "fullname": "Juanzi Li",
                        "user": "juanli",
                        "type": "user"
                    },
                    "name": "Juanzi Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:13:58.645Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T17:16:13.000Z",
            "title": "Pre-training Distillation for Large Language Models: A Design Space\n  Exploration",
            "summary": "Knowledge distillation (KD) aims to transfer knowledge from a large teacher\nmodel to a smaller student model. Previous work applying KD in the field of\nlarge language models (LLMs) typically focused on the post-training phase,\nwhere the student LLM learns directly from instructions and corresponding\nresponses generated by the teacher model. In this paper, we extend KD to the\npre-training phase of LLMs, named pre-training distillation (PD). We first\nconduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a\n1.9B parameter student LLM, validating the effectiveness of PD. Considering the\nkey impact factors of distillation, we systematically explore the design space\nof pre-training distillation across four aspects: logits processing, loss\nselection, scaling law, and offline or online logits. We conduct extensive\nexperiments to explore the design space of pre-training distillation and find\nbetter configurations and interesting conclusions, such as larger student LLMs\ngenerally benefiting more from pre-training distillation, while a larger\nteacher LLM does not necessarily guarantee better results. We hope our\nexploration of the design space will inform future practices in pre-training\ndistillation.",
            "upvotes": 12,
            "discussionId": "67173a3c7994589e3f441ea6"
        },
        "publishedAt": "2024-10-22T04:09:39.526Z",
        "title": "Pre-training Distillation for Large Language Models: A Design Space Exploration",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.16215.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/6d040cbcb4a9b624cbe64c9d01cd5c88.svg",
            "fullname": "Yushi Bai",
            "name": "bys0318",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.15748",
            "authors": [
                {
                    "_id": "6717365cc613f45832d7cdf0",
                    "user": {
                        "_id": "653a3180863b9327f60e37b5",
                        "avatarUrl": "/avatars/cd85a88e42167af1782128559d1f3354.svg",
                        "isPro": false,
                        "fullname": "ShaonanWu",
                        "user": "EurekaWu123",
                        "type": "user"
                    },
                    "name": "Shaonan Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T07:56:50.016Z",
                    "hidden": false
                },
                {
                    "_id": "6717365cc613f45832d7cdf1",
                    "user": {
                        "_id": "617a3066f5910ea887210d91",
                        "avatarUrl": "/avatars/5193c5f523459f3d977defb257ef6f0d.svg",
                        "isPro": false,
                        "fullname": "Shuai Lu",
                        "user": "shuailu",
                        "type": "user"
                    },
                    "name": "Shuai Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:39:28.701Z",
                    "hidden": false
                },
                {
                    "_id": "6717365cc613f45832d7cdf2",
                    "user": {
                        "_id": "643f615aa16cd6d1f4c581de",
                        "avatarUrl": "/avatars/47753a3e82b44f81881600c52e1e8495.svg",
                        "isPro": false,
                        "fullname": "Yeyun Gong",
                        "user": "yegong",
                        "type": "user"
                    },
                    "name": "Yeyun Gong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:39:23.194Z",
                    "hidden": false
                },
                {
                    "_id": "6717365cc613f45832d7cdf3",
                    "user": {
                        "_id": "66422aede3e9eba09d3cb753",
                        "avatarUrl": "/avatars/52a6292fcc3a37265062bdcfbea73441.svg",
                        "isPro": false,
                        "fullname": "Nan Duan",
                        "user": "opotle",
                        "type": "user"
                    },
                    "name": "Nan Duan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:39:17.629Z",
                    "hidden": false
                },
                {
                    "_id": "6717365cc613f45832d7cdf4",
                    "name": "Ping Wei",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T08:04:21.000Z",
            "title": "Alchemy: Amplifying Theorem-Proving Capability through Symbolic Mutation",
            "summary": "Formal proofs are challenging to write even for experienced experts. Recent\nprogress in Neural Theorem Proving (NTP) shows promise in expediting this\nprocess. However, the formal corpora available on the Internet are limited\ncompared to the general text, posing a significant data scarcity challenge for\nNTP. To address this issue, this work proposes Alchemy, a general framework for\ndata synthesis that constructs formal theorems through symbolic mutation.\nSpecifically, for each candidate theorem in Mathlib, we identify all invocable\ntheorems that can be used to rewrite or apply to it. Subsequently, we mutate\nthe candidate theorem by replacing the corresponding term in the statement with\nits equivalent form or antecedent. As a result, our method increases the number\nof theorems in Mathlib by an order of magnitude, from 110k to 6M. Furthermore,\nwe perform continual pretraining and supervised finetuning on this augmented\ncorpus for large language models. Experimental results demonstrate the\neffectiveness of our approach, achieving a 5% absolute performance improvement\non Leandojo benchmark. Additionally, our synthetic data achieve a 2.5% absolute\nperformance gain on the out-of-distribution miniF2F benchmark. To provide\nfurther insights, we conduct a comprehensive analysis of synthetic data\ncomposition and the training paradigm, offering valuable guidance for\ndeveloping a strong theorem prover.",
            "upvotes": 9,
            "discussionId": "6717365dc613f45832d7ce50"
        },
        "publishedAt": "2024-10-22T06:55:29.186Z",
        "title": "Alchemy: Amplifying Theorem-Proving Capability through Symbolic Mutation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.15748.png",
        "numComments": 2,
        "submittedBy": {
            "avatarUrl": "/avatars/cd85a88e42167af1782128559d1f3354.svg",
            "fullname": "ShaonanWu",
            "name": "EurekaWu123",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.15316",
            "authors": [
                {
                    "_id": "67178d2465aee70effea04ae",
                    "user": {
                        "_id": "62d7b2339b629105a5d6888a",
                        "avatarUrl": "/avatars/c3f164fde6b8f9a671890e08ce8a3e75.svg",
                        "isPro": false,
                        "fullname": "Alan Dao",
                        "user": "alandao",
                        "type": "user"
                    },
                    "name": "Alan Dao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:29:03.628Z",
                    "hidden": false
                },
                {
                    "_id": "67178d2465aee70effea04af",
                    "name": "Dinh Bach Vu",
                    "hidden": false
                },
                {
                    "_id": "67178d2465aee70effea04b0",
                    "user": {
                        "_id": "630a5ef0e81e1dea2cedcec0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/630a5ef0e81e1dea2cedcec0/ATtyCvYoX4z7uxsm2sJU2.png",
                        "isPro": false,
                        "fullname": "H Huy Hong",
                        "user": "HoangHa",
                        "type": "user"
                    },
                    "name": "Huy Hoang Ha",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T12:43:59.290Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-20T07:03:49.000Z",
            "title": "Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant",
            "summary": "Large Language Models (LLMs) have revolutionized natural language processing,\nbut their application to speech-based tasks remains challenging due to the\ncomplexities of integrating audio and text modalities. This paper introduces\nIchigo, a mixed-modal model that seamlessly processes interleaved sequences of\nspeech and text. Utilizing a tokenized early-fusion approach, Ichigo quantizes\nspeech into discrete tokens and employs a uniform transformer-based\narchitecture for both speech and text modalities. This method enables joint\nreasoning and generation across modalities without the need for separate\nadapters. We present a comprehensive training methodology, including\npre-training on multilingual speech recognition datasets and fine-tuning on a\ncurated instruction dataset. Ichigo demonstrates state-of-the-art performance\non speech question-answering benchmarks, outperforming existing open-source\nspeech language models and achieving comparable results to cascaded systems.\nNotably, Ichigo exhibits a latency of just 111 ms to first token generation,\nsignificantly lower than current models. Our approach not only advances the\nfield of multimodal AI but also provides a framework for smaller research teams\nto contribute effectively to open-source speech-language models.",
            "upvotes": 6,
            "discussionId": "67178d2565aee70effea053c"
        },
        "publishedAt": "2024-10-22T11:40:31.687Z",
        "title": "Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.15316.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/630a5ef0e81e1dea2cedcec0/ATtyCvYoX4z7uxsm2sJU2.png",
            "fullname": "H Huy Hong",
            "name": "HoangHa",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.11711",
            "authors": [
                {
                    "_id": "67176ecfd73dbe05349195a0",
                    "user": {
                        "_id": "621d59ebd3df05d67132e8d9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/621d59ebd3df05d67132e8d9/0gPfPTRKKnz5kq0InTqm5.jpeg",
                        "isPro": false,
                        "fullname": "Abdelhakim Benechehab",
                        "user": "abenechehab",
                        "type": "user"
                    },
                    "name": "Abdelhakim Benechehab",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2024-10-22T09:22:25.229Z",
                    "hidden": false
                },
                {
                    "_id": "67176ecfd73dbe05349195a1",
                    "name": "Youssef Attia El Hili",
                    "hidden": false
                },
                {
                    "_id": "67176ecfd73dbe05349195a2",
                    "user": {
                        "_id": "6661f79ac36ae4c83f3213e4",
                        "avatarUrl": "/avatars/2e48f052fdf37b5b06d101a6a3232eea.svg",
                        "isPro": false,
                        "fullname": "Ambroise Odonnat ",
                        "user": "ambroiseodt",
                        "type": "user"
                    },
                    "name": "Ambroise Odonnat",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T11:31:52.056Z",
                    "hidden": false
                },
                {
                    "_id": "67176ecfd73dbe05349195a3",
                    "user": {
                        "_id": "651e90f4b395a05dff63fe9e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e90f4b395a05dff63fe9e/51g5erCgvJ43szg26EQ_M.png",
                        "isPro": false,
                        "fullname": "Oussama Zekri",
                        "user": "Xssama",
                        "type": "user"
                    },
                    "name": "Oussama Zekri",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T09:32:57.062Z",
                    "hidden": false
                },
                {
                    "_id": "67176ecfd73dbe05349195a4",
                    "user": {
                        "_id": "639789c20f1ac9c2f34a59f7",
                        "avatarUrl": "/avatars/fd73c93d50264d14f532ff52bc0d48f7.svg",
                        "isPro": false,
                        "fullname": "Albert Thomas",
                        "user": "albert9000",
                        "type": "user"
                    },
                    "name": "Albert Thomas",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T11:31:34.241Z",
                    "hidden": false
                },
                {
                    "_id": "67176ecfd73dbe05349195a5",
                    "user": {
                        "_id": "65e98cd8e19214e9d151f29e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65e98cd8e19214e9d151f29e/XjQzoVgKVzv8AZBWFQnHz.jpeg",
                        "isPro": false,
                        "fullname": "Giuseppe Paolo",
                        "user": "GPaolo",
                        "type": "user"
                    },
                    "name": "Giuseppe Paolo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T11:31:27.734Z",
                    "hidden": false
                },
                {
                    "_id": "67176ecfd73dbe05349195a6",
                    "name": "Maurizio Filippone",
                    "hidden": false
                },
                {
                    "_id": "67176ecfd73dbe05349195a7",
                    "user": {
                        "_id": "643d3c9c043254ce1092d195",
                        "avatarUrl": "/avatars/d44f504d62888e1e8b58f5723147ae9b.svg",
                        "isPro": false,
                        "fullname": "Ievgen R",
                        "user": "ievred",
                        "type": "user"
                    },
                    "name": "Ievgen Redko",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T11:35:17.552Z",
                    "hidden": false
                },
                {
                    "_id": "67176ecfd73dbe05349195a8",
                    "name": "Balzs Kgl",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-15T15:46:53.000Z",
            "title": "Zero-shot Model-based Reinforcement Learning using Large Language Models",
            "summary": "The emerging zero-shot capabilities of Large Language Models (LLMs) have led\nto their applications in areas extending well beyond natural language\nprocessing tasks. In reinforcement learning, while LLMs have been extensively\nused in text-based environments, their integration with continuous state spaces\nremains understudied. In this paper, we investigate how pre-trained LLMs can be\nleveraged to predict in context the dynamics of continuous Markov decision\nprocesses. We identify handling multivariate data and incorporating the control\nsignal as key challenges that limit the potential of LLMs' deployment in this\nsetup and propose Disentangled In-Context Learning (DICL) to address them. We\npresent proof-of-concept applications in two reinforcement learning settings:\nmodel-based policy evaluation and data-augmented off-policy reinforcement\nlearning, supported by theoretical analysis of the proposed methods. Our\nexperiments further demonstrate that our approach produces well-calibrated\nuncertainty estimates. We release the code at\nhttps://github.com/abenechehab/dicl.",
            "upvotes": 6,
            "discussionId": "67176ed1d73dbe0534919676"
        },
        "publishedAt": "2024-10-22T08:05:14.803Z",
        "title": "Zero-shot Model-based Reinforcement Learning using Large Language Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/621d59ebd3df05d67132e8d9/_wmShkTgoALp9g4NJfd2L.png",
            "https://cdn-uploads.huggingface.co/production/uploads/621d59ebd3df05d67132e8d9/fUfkHar6SqTk9FXUjNL0g.png",
            "https://cdn-uploads.huggingface.co/production/uploads/621d59ebd3df05d67132e8d9/34rX_-izpGZgCcpyS6xFb.png",
            "https://cdn-uploads.huggingface.co/production/uploads/621d59ebd3df05d67132e8d9/dAsQ_jnoRXN93xj1DPV0U.png",
            "https://cdn-uploads.huggingface.co/production/uploads/621d59ebd3df05d67132e8d9/q3c6unMOR4GLF9R00nZaM.png",
            "https://cdn-uploads.huggingface.co/production/uploads/621d59ebd3df05d67132e8d9/51bXb41417Lm2oqBayxGX.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.11711.png",
        "numComments": 3,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/621d59ebd3df05d67132e8d9/0gPfPTRKKnz5kq0InTqm5.jpeg",
            "fullname": "Abdelhakim Benechehab",
            "name": "abenechehab",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.15633",
            "authors": [
                {
                    "_id": "671742ab0c095b8e5d099551",
                    "user": {
                        "_id": "637c99bbfe115289cfedfb44",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637c99bbfe115289cfedfb44/J1de6aU0XBQRcYuqikkS0.jpeg",
                        "isPro": false,
                        "fullname": "ssz",
                        "user": "ssz1111",
                        "type": "user"
                    },
                    "name": "Shuzheng Si",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T15:02:35.806Z",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d099552",
                    "name": "Haozhe Zhao",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d099553",
                    "name": "Gang Chen",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d099554",
                    "user": {
                        "_id": "62e670d33651180f7d334ef3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661829952739-62e670d33651180f7d334ef3.jpeg",
                        "isPro": false,
                        "fullname": "LiYunshui",
                        "user": "Wa2erGo",
                        "type": "user"
                    },
                    "name": "Yunshui Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:29:52.787Z",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d099555",
                    "user": {
                        "_id": "66ba08d4bafd993a5428e051",
                        "avatarUrl": "/avatars/2bd7779582ee3ae2ff9688e1627d745e.svg",
                        "isPro": false,
                        "fullname": "Kangyang Luo",
                        "user": "lKangyang",
                        "type": "user"
                    },
                    "name": "Kangyang Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:29:58.585Z",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d099556",
                    "name": "Chuancheng Lv",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d099557",
                    "user": {
                        "_id": "66629d5ab8e23e099e229d41",
                        "avatarUrl": "/avatars/8e003decfaeebb9ab86736302452e22a.svg",
                        "isPro": false,
                        "fullname": "kaikai an",
                        "user": "kaikai1",
                        "type": "user"
                    },
                    "name": "Kaikai An",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:51:09.046Z",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d099558",
                    "user": {
                        "_id": "65623af21a0c459616cc4b03",
                        "avatarUrl": "/avatars/76467e8a3c46aca3687ffcfe964a2889.svg",
                        "isPro": false,
                        "fullname": "Fanchao Qi",
                        "user": "fanchao-qi",
                        "type": "user"
                    },
                    "name": "Fanchao Qi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:29:21.938Z",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d099559",
                    "name": "Baobao Chang",
                    "hidden": false
                },
                {
                    "_id": "671742ab0c095b8e5d09955a",
                    "name": "Maosong Sun",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T04:30:53.000Z",
            "title": "Selecting Influential Samples for Long Context Alignment via Homologous\n  Models' Guidance and Contextual Awareness Measurement",
            "summary": "The expansion of large language models to effectively handle instructions\nwith extremely long contexts has yet to be fully investigated. The primary\nobstacle lies in constructing a high-quality long instruction-following dataset\ndevised for long context alignment. Existing studies have attempted to scale up\nthe available data volume by synthesizing long instruction-following samples.\nHowever, indiscriminately increasing the quantity of data without a\nwell-defined strategy for ensuring data quality may introduce low-quality\nsamples and restrict the final performance. To bridge this gap, we aim to\naddress the unique challenge of long-context alignment, i.e., modeling the\nlong-range dependencies for handling instructions and lengthy input contexts.\nWe propose GATEAU, a novel framework designed to identify the influential and\nhigh-quality samples enriched with long-range dependency relations by utilizing\ncrafted Homologous Models' Guidance (HMG) and Contextual Awareness Measurement\n(CAM). Specifically, HMG attempts to measure the difficulty of generating\ncorresponding responses due to the long-range dependencies, using the\nperplexity scores of the response from two homologous models with different\ncontext windows. Also, the role of CAM is to measure the difficulty of\nunderstanding the long input contexts due to long-range dependencies by\nevaluating whether the model's attention is focused on important segments.\nBuilt upon both proposed methods, we select the most challenging samples as the\ninfluential data to effectively frame the long-range dependencies, thereby\nachieving better performance of LLMs. Comprehensive experiments indicate that\nGATEAU effectively identifies samples enriched with long-range dependency\nrelations and the model trained on these selected samples exhibits better\ninstruction-following and long-context understanding capabilities.",
            "upvotes": 6,
            "discussionId": "671742ac0c095b8e5d09958f"
        },
        "publishedAt": "2024-10-22T04:46:20.800Z",
        "title": "Selecting Influential Samples for Long Context Alignment via Homologous Models' Guidance and Contextual Awareness Measurement",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.15633.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637c99bbfe115289cfedfb44/J1de6aU0XBQRcYuqikkS0.jpeg",
            "fullname": "ssz",
            "name": "ssz1111",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13218",
            "authors": [
                {
                    "_id": "6712cece5fd735b90e62e60e",
                    "user": {
                        "_id": "650857fef3060ea840ffbbfe",
                        "avatarUrl": "/avatars/3a339936021c040f19a21838ae1382c4.svg",
                        "isPro": false,
                        "fullname": "Mian Zhang",
                        "user": "billmianz",
                        "type": "user"
                    },
                    "name": "Mian Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-21T07:48:04.871Z",
                    "hidden": false
                },
                {
                    "_id": "6712cece5fd735b90e62e60f",
                    "user": {
                        "_id": "604137e5c15e823a685f2af2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/604137e5c15e823a685f2af2/rrxZUyrbLpKqCmG6xtP8v.jpeg",
                        "isPro": false,
                        "fullname": "Xianjun Yang",
                        "user": "Xianjun",
                        "type": "user"
                    },
                    "name": "Xianjun Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:40:13.798Z",
                    "hidden": false
                },
                {
                    "_id": "6712cece5fd735b90e62e610",
                    "user": {
                        "_id": "650b78532ec41a31f31163e9",
                        "avatarUrl": "/avatars/522549da5ee5703b41396ce0b6811e89.svg",
                        "isPro": false,
                        "fullname": "xinlu zhang",
                        "user": "xz97",
                        "type": "user"
                    },
                    "name": "Xinlu Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:40:32.686Z",
                    "hidden": false
                },
                {
                    "_id": "6712cece5fd735b90e62e611",
                    "name": "Travis Labrum",
                    "hidden": false
                },
                {
                    "_id": "6712cece5fd735b90e62e612",
                    "name": "Jamie C. Chiu",
                    "hidden": false
                },
                {
                    "_id": "6712cece5fd735b90e62e613",
                    "name": "Shaun M. Eack",
                    "hidden": false
                },
                {
                    "_id": "6712cece5fd735b90e62e614",
                    "name": "Fei Fang",
                    "hidden": false
                },
                {
                    "_id": "6712cece5fd735b90e62e615",
                    "user": {
                        "_id": "6476607efb22e3b77f3f1452",
                        "avatarUrl": "/avatars/22f40c81e6b6e09bdb66a5afd978f98b.svg",
                        "isPro": false,
                        "fullname": "William Yang Wang",
                        "user": "wangwilliamyang",
                        "type": "user"
                    },
                    "name": "William Yang Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:41:04.582Z",
                    "hidden": false
                },
                {
                    "_id": "6712cece5fd735b90e62e616",
                    "name": "Zhiyu Zoey Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T04:52:57.000Z",
            "title": "CBT-Bench: Evaluating Large Language Models on Assisting Cognitive\n  Behavior Therapy",
            "summary": "There is a significant gap between patient needs and available mental health\nsupport today. In this paper, we aim to thoroughly examine the potential of\nusing Large Language Models (LLMs) to assist professional psychotherapy. To\nthis end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation\nof cognitive behavioral therapy (CBT) assistance. We include three levels of\ntasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of\nmultiple-choice questions; II: Cognitive model understanding, with the tasks of\ncognitive distortion classification, primary core belief classification, and\nfine-grained core belief classification; III: Therapeutic response generation,\nwith the task of generating responses to patient speech in CBT therapy\nsessions. These tasks encompass key aspects of CBT that could potentially be\nenhanced through AI assistance, while also outlining a hierarchy of capability\nrequirements, ranging from basic knowledge recitation to engaging in real\ntherapeutic conversations. We evaluated representative LLMs on our benchmark.\nExperimental results indicate that while LLMs perform well in reciting CBT\nknowledge, they fall short in complex real-world scenarios requiring deep\nanalysis of patients' cognitive structures and generating effective responses,\nsuggesting potential future work.",
            "upvotes": 3,
            "discussionId": "6712ced05fd735b90e62e656"
        },
        "publishedAt": "2024-10-22T00:40:03.181Z",
        "title": "CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13218.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/3a339936021c040f19a21838ae1382c4.svg",
            "fullname": "Mian Zhang",
            "name": "billmianz",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.16259",
            "authors": [
                {
                    "_id": "6717d970e1288236b57e351f",
                    "name": "Gengshan Yang",
                    "hidden": false
                },
                {
                    "_id": "6717d970e1288236b57e3520",
                    "name": "Andrea Bajcsy",
                    "hidden": false
                },
                {
                    "_id": "6717d970e1288236b57e3521",
                    "name": "Shunsuke Saito",
                    "hidden": false
                },
                {
                    "_id": "6717d970e1288236b57e3522",
                    "name": "Angjoo Kanazawa",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-21T17:57:50.000Z",
            "title": "Agent-to-Sim: Learning Interactive Behavior Models from Casual\n  Longitudinal Videos",
            "summary": "We present Agent-to-Sim (ATS), a framework for learning interactive behavior\nmodels of 3D agents from casual longitudinal video collections. Different from\nprior works that rely on marker-based tracking and multiview cameras, ATS\nlearns natural behaviors of animal and human agents non-invasively through\nvideo observations recorded over a long time-span (e.g., a month) in a single\nenvironment. Modeling 3D behavior of an agent requires persistent 3D tracking\n(e.g., knowing which point corresponds to which) over a long time period. To\nobtain such data, we develop a coarse-to-fine registration method that tracks\nthe agent and the camera over time through a canonical 3D space, resulting in a\ncomplete and persistent spacetime 4D representation. We then train a generative\nmodel of agent behaviors using paired data of perception and motion of an agent\nqueried from the 4D reconstruction. ATS enables real-to-sim transfer from video\nrecordings of an agent to an interactive behavior simulator. We demonstrate\nresults on pets (e.g., cat, dog, bunny) and human given monocular RGBD videos\ncaptured by a smartphone.",
            "upvotes": 1,
            "discussionId": "6717d975e1288236b57e36f8"
        },
        "publishedAt": "2024-10-22T15:28:31.068Z",
        "title": "Agent-to-Sim: Learning Interactive Behavior Models from Casual Longitudinal Videos",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62c0597543d4858f821bc87a/gaKzoZib0u0mwIqJ0TKpI.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.16259.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/ce9d28c08a5c9e8312a754714bae4634.svg",
            "fullname": "Gengshan Yang",
            "name": "gengshan-y",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.14086",
            "authors": [
                {
                    "_id": "6717ac81ee30e9f032308982",
                    "user": {
                        "_id": "64fd0dc89ecd05d5bf77d331",
                        "avatarUrl": "/avatars/1087b977ebbafc89dba1cfb1084df6aa.svg",
                        "isPro": false,
                        "fullname": "Eric Elmoznino",
                        "user": "EricElmoznino",
                        "type": "user"
                    },
                    "name": "Eric Elmoznino",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:54:21.298Z",
                    "hidden": false
                },
                {
                    "_id": "6717ac81ee30e9f032308983",
                    "user": {
                        "_id": "646402a6a5af935cfe7226a5",
                        "avatarUrl": "/avatars/98655f52a05259a5f6478588aa15bda6.svg",
                        "isPro": false,
                        "fullname": "Tom Marty",
                        "user": "3rdCore",
                        "type": "user"
                    },
                    "name": "Tom Marty",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T13:47:06.100Z",
                    "hidden": false
                },
                {
                    "_id": "6717ac81ee30e9f032308984",
                    "user": {
                        "_id": "65b2f64d54fa188a2f2a7132",
                        "avatarUrl": "/avatars/95f218fe0f525f56d12238330a68e593.svg",
                        "isPro": false,
                        "fullname": "Tejas Kasetty",
                        "user": "tejaskasetty",
                        "type": "user"
                    },
                    "name": "Tejas Kasetty",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:54:26.971Z",
                    "hidden": false
                },
                {
                    "_id": "6717ac81ee30e9f032308985",
                    "user": {
                        "_id": "669580c8643c258b90be7497",
                        "avatarUrl": "/avatars/19fc666b4d56f71020fa646ca2f173de.svg",
                        "isPro": false,
                        "fullname": "Lo Gagnon",
                        "user": "leogagnon",
                        "type": "user"
                    },
                    "name": "Leo Gagnon",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:54:32.102Z",
                    "hidden": false
                },
                {
                    "_id": "6717ac81ee30e9f032308986",
                    "name": "Sarthak Mittal",
                    "hidden": false
                },
                {
                    "_id": "6717ac81ee30e9f032308987",
                    "user": {
                        "_id": "64903c2d9b1aaa0738286323",
                        "avatarUrl": "/avatars/9c4d0734b6f779d0f138951998f1d7b5.svg",
                        "isPro": false,
                        "fullname": "Mahan Fathi",
                        "user": "mahanfathi",
                        "type": "user"
                    },
                    "name": "Mahan Fathi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:54:53.891Z",
                    "hidden": false
                },
                {
                    "_id": "6717ac81ee30e9f032308988",
                    "name": "Dhanya Sridhar",
                    "hidden": false
                },
                {
                    "_id": "6717ac81ee30e9f032308989",
                    "user": {
                        "_id": "64909d1d6f217a26d91c6d9b",
                        "avatarUrl": "/avatars/28eeff49dd5c2f01b576e4a050551e17.svg",
                        "isPro": false,
                        "fullname": "guillaume lajoie",
                        "user": "glajoie",
                        "type": "user"
                    },
                    "name": "Guillaume Lajoie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:55:02.206Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T23:37:34.000Z",
            "title": "In-context learning and Occam's razor",
            "summary": "The goal of machine learning is generalization. While the No Free Lunch\nTheorem states that we cannot obtain theoretical guarantees for generalization\nwithout further assumptions, in practice we observe that simple models which\nexplain the training data generalize best: a principle called Occam's razor.\nDespite the need for simple models, most current approaches in machine learning\nonly minimize the training error, and at best indirectly promote simplicity\nthrough regularization or architecture design. Here, we draw a connection\nbetween Occam's razor and in-context learning: an emergent ability of certain\nsequence models like Transformers to learn at inference time from past\nobservations in a sequence. In particular, we show that the next-token\nprediction loss used to train in-context learners is directly equivalent to a\ndata compression technique called prequential coding, and that minimizing this\nloss amounts to jointly minimizing both the training error and the complexity\nof the model that was implicitly learned from context. Our theory and the\nempirical experiments we use to support it not only provide a normative account\nof in-context learning, but also elucidate the shortcomings of current\nin-context learning methods, suggesting ways in which they can be improved. We\nmake our code available at https://github.com/3rdCore/PrequentialCode.",
            "upvotes": 1,
            "discussionId": "6717ac82ee30e9f0323089d9"
        },
        "publishedAt": "2024-10-22T12:21:20.207Z",
        "title": "In-context learning and Occam's razor",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/646402a6a5af935cfe7226a5/stme3ZSBlVSZzDNrtAKlz.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.14086.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/98655f52a05259a5f6478588aa15bda6.svg",
            "fullname": "Tom Marty",
            "name": "3rdCore",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13184",
            "authors": [
                {
                    "_id": "6717ac546136223abbfd80bf",
                    "user": {
                        "_id": "64468d7a3b28db22e7f84418",
                        "avatarUrl": "/avatars/ff05994acd7da64a2ed6e44f12cf77bc.svg",
                        "isPro": false,
                        "fullname": "Shwai He",
                        "user": "Shwai",
                        "type": "user"
                    },
                    "name": "Shwai He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:48:00.289Z",
                    "hidden": false
                },
                {
                    "_id": "6717ac546136223abbfd80c0",
                    "name": "Tao Ge",
                    "hidden": false
                },
                {
                    "_id": "6717ac546136223abbfd80c1",
                    "user": {
                        "_id": "6438f5555aa69077ffb16218",
                        "avatarUrl": "/avatars/582f736c0485252010b682e85db62e77.svg",
                        "isPro": false,
                        "fullname": "Guoheng Sun",
                        "user": "s1ghhh",
                        "type": "user"
                    },
                    "name": "Guoheng Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:48:19.181Z",
                    "hidden": false
                },
                {
                    "_id": "6717ac546136223abbfd80c2",
                    "user": {
                        "_id": "6623e96dd7b6076f66480898",
                        "avatarUrl": "/avatars/62288faa8ecc69c6b1cef4bc553941b9.svg",
                        "isPro": false,
                        "fullname": "Bowei Tian",
                        "user": "abdd68",
                        "type": "user"
                    },
                    "name": "Bowei Tian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T13:48:27.178Z",
                    "hidden": false
                },
                {
                    "_id": "6717ac546136223abbfd80c3",
                    "name": "Xiaoyang Wang",
                    "hidden": false
                },
                {
                    "_id": "6717ac546136223abbfd80c4",
                    "name": "Ang Li",
                    "hidden": false
                },
                {
                    "_id": "6717ac546136223abbfd80c5",
                    "name": "Dong Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T03:23:50.000Z",
            "title": "Router-Tuning: A Simple and Effective Approach for Enabling\n  Dynamic-Depth in Transformers",
            "summary": "Traditional transformer models often allocate a fixed amount of computational\nresources to every input token, leading to inefficient and unnecessary\ncomputation. To address this, the Mixture of Depths (MoD) was introduced to\ndynamically adjust the computational depth by skipping less important layers.\nDespite its promise, current MoD approaches remain under-explored and face two\nmain challenges: (1) high training costs due to the need to train the\nentire model along with the routers that determine which layers to skip, and\n(2) the risk of performance degradation when important layers are\nbypassed. In response to the first issue, we propose Router-Tuning, a method\nthat fine-tunes only the router on a small dataset, drastically reducing the\ncomputational overhead associated with full model training. For the second\nchallenge, we propose MindSkip, which deploys Attention with Dynamic\nDepths. This method preserves the model's performance while significantly\nenhancing computational and memory efficiency. Extensive experiments\ndemonstrate that our approach delivers competitive results while dramatically\nimproving the computation efficiency, e.g., 21\\% speedup and only a 0.2\\%\nperformance drop. The code is released at\nhttps://github.com/CASE-Lab-UMD/Router-Tuning.",
            "upvotes": 1,
            "discussionId": "6717ac556136223abbfd8119"
        },
        "publishedAt": "2024-10-22T12:16:10.342Z",
        "title": "Router-Tuning: A Simple and Effective Approach for Enabling Dynamic-Depth in Transformers",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13184.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/7f67f357c830ed6dade7ed7548ac1f05.svg",
            "fullname": "Ang Li",
            "name": "charleslipku",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.15460",
            "authors": [
                {
                    "_id": "6717a5dadcef4aa5a830ef29",
                    "user": {
                        "_id": "659d84dba74945e564da065b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/659d84dba74945e564da065b/NMavmXi1gkmtKO0GI-HKX.png",
                        "isPro": false,
                        "fullname": "MZ",
                        "user": "Shahradmz",
                        "type": "user"
                    },
                    "name": "Shahrad Mohammadzadeh",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T13:28:05.645Z",
                    "hidden": false
                },
                {
                    "_id": "6717a5dadcef4aa5a830ef2a",
                    "name": "Juan David Guerra",
                    "hidden": false
                },
                {
                    "_id": "6717a5dadcef4aa5a830ef2b",
                    "name": "Marco Bonizzato",
                    "hidden": false
                },
                {
                    "_id": "6717a5dadcef4aa5a830ef2c",
                    "name": "Reihaneh Rabbany",
                    "hidden": false
                },
                {
                    "_id": "6717a5dadcef4aa5a830ef2d",
                    "name": "Golnoosh Farnadi",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-20T18:18:23.000Z",
            "title": "Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language\n  Model Training",
            "summary": "As large language models (LLMs) become increasingly deployed across various\nindustries, concerns regarding their reliability, particularly due to\nhallucinations-outputs that are factually inaccurate or irrelevant to user\ninput-have grown. Our research investigates the relationship between the\ntraining process and the emergence of hallucinations to address a key gap in\nexisting research that focuses primarily on post hoc detection and mitigation\nstrategies. Using models from the Pythia suite (70M-12B parameters) and several\nhallucination detection metrics, we analyze hallucination trends throughout\ntraining and explore LLM internal dynamics. We introduce SEnsitive Neuron\nDropout (SeND), a novel training protocol designed to mitigate hallucinations\nby reducing variance during training. SeND achieves this by deterministically\ndropping neurons with significant variability on a dataset, referred to as\nSensitive Neurons. In addition, we develop an unsupervised hallucination\ndetection metric, Efficient EigenScore (EES), which approximates the\ntraditional EigenScore in 2x speed. This efficient metric is integrated into\nour protocol, allowing SeND to be both computationally scalable and effective\nat reducing hallucinations. Our empirical evaluation demonstrates that our\napproach improves LLM reliability at test time by up to 40% compared to normal\ntraining while also providing an efficient method to improve factual accuracy\nwhen adapting LLMs to domains such as Wikipedia and Medical datasets.",
            "upvotes": 1,
            "discussionId": "6717a5dbdcef4aa5a830ef94"
        },
        "publishedAt": "2024-10-22T11:59:59.515Z",
        "title": "Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.15460.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/659d84dba74945e564da065b/NMavmXi1gkmtKO0GI-HKX.png",
            "fullname": "MZ",
            "name": "Shahradmz",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.13394",
            "authors": [
                {
                    "_id": "67121b74e82a3853eda3b069",
                    "user": {
                        "_id": "5fbfc7a6e366524fe8e97ccf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1673518581924-5fbfc7a6e366524fe8e97ccf.png",
                        "isPro": false,
                        "fullname": "Sumanth Doddapaneni",
                        "user": "sumanthd",
                        "type": "user"
                    },
                    "name": "Sumanth Doddapaneni",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:48:58.988Z",
                    "hidden": false
                },
                {
                    "_id": "67121b74e82a3853eda3b06a",
                    "user": {
                        "_id": "63ef3cd11e695b35aa48bebc",
                        "avatarUrl": "/avatars/398beced61e1b47d9bf2f38583250bbc.svg",
                        "isPro": false,
                        "fullname": "Mohammed Safi Ur Rahman Khan",
                        "user": "safikhan",
                        "type": "user"
                    },
                    "name": "Mohammed Safi Ur Rahman Khan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-18T12:15:16.098Z",
                    "hidden": false
                },
                {
                    "_id": "67121b74e82a3853eda3b06b",
                    "user": {
                        "_id": "6408278e8dca6cec91cb7e55",
                        "avatarUrl": "/avatars/fc599425785202727b1a21b89af552bb.svg",
                        "isPro": false,
                        "fullname": "Dilip Venkatesh",
                        "user": "dipsivenkatesh",
                        "type": "user"
                    },
                    "name": "Dilip Venkatesh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:50:07.904Z",
                    "hidden": false
                },
                {
                    "_id": "67121b74e82a3853eda3b06c",
                    "user": {
                        "_id": "61cd4af60996e2a209ff7b96",
                        "avatarUrl": "/avatars/7b47bfaba15dfaf37ce38cb0216f3102.svg",
                        "isPro": false,
                        "fullname": "Raj Dabre",
                        "user": "prajdabre",
                        "type": "user"
                    },
                    "name": "Raj Dabre",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:50:02.568Z",
                    "hidden": false
                },
                {
                    "_id": "67121b74e82a3853eda3b06d",
                    "user": {
                        "_id": "5fce179fb3dbf216ad31837b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1659894079257-5fce179fb3dbf216ad31837b.jpeg",
                        "isPro": false,
                        "fullname": "Anoop Kunchukuttan",
                        "user": "anoopk",
                        "type": "user"
                    },
                    "name": "Anoop Kunchukuttan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:49:57.100Z",
                    "hidden": false
                },
                {
                    "_id": "67121b74e82a3853eda3b06e",
                    "user": {
                        "_id": "6551c181c0e106160e9d3297",
                        "avatarUrl": "/avatars/d2c498d7f361f4133d1104fde72c24b9.svg",
                        "isPro": false,
                        "fullname": "Mitesh Khapra",
                        "user": "miteshk",
                        "type": "user"
                    },
                    "name": "Mitesh M. Khapra",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:49:50.912Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-17T09:45:32.000Z",
            "title": "Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs",
            "summary": "Evaluating machine-generated text remains a significant challenge in NLP,\nespecially for non-English languages. Current methodologies, including\nautomated metrics, human assessments, and LLM-based evaluations, predominantly\nfocus on English, revealing a significant gap in multilingual evaluation\nframeworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an\nextensible framework that includes evaluator LLMs (Hercule) and a novel test\nset (Recon) specifically designed for multilingual evaluation. Our test set\nfeatures 500 human-annotated instructions spanning various task capabilities\nalong with human judgment scores across six languages. This would enable\nbenchmarking of general-purpose multilingual LLMs and facilitate\nmeta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a\ncross-lingual evaluation model that addresses the scarcity of reference answers\nin the target language by learning to assign scores to responses based on\neasily available reference answers in English. Our experiments demonstrate that\nHercule aligns more closely with human judgments compared to proprietary\nmodels, demonstrating the effectiveness of such cross-lingual evaluation in low\nresource scenarios. Further, it is also effective in zero-shot evaluation on\nunseen languages. This study is the first comprehensive examination of\ncross-lingual evaluation using LLMs, presenting a scalable and effective\napproach for multilingual assessment. All code, datasets, and models will be\npublicly available to enable further research in this important area.",
            "upvotes": 1,
            "discussionId": "67121b76e82a3853eda3b13b"
        },
        "publishedAt": "2024-10-22T01:37:42.657Z",
        "title": "Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.13394.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "/avatars/398beced61e1b47d9bf2f38583250bbc.svg",
            "fullname": "Mohammed Safi Ur Rahman Khan",
            "name": "safikhan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    },
    {
        "paper": {
            "id": "2410.15017",
            "authors": [
                {
                    "_id": "67171043c3d0f3134dc15bde",
                    "user": {
                        "_id": "6401a3d63e3d0f2745aad104",
                        "avatarUrl": "/avatars/8c458237830c814676386b023401a80d.svg",
                        "isPro": false,
                        "fullname": "Md Mubtasim Ahasan",
                        "user": "mubtasim",
                        "type": "user"
                    },
                    "name": "Md Mubtasim Ahasan",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2024-10-22T03:07:46.167Z",
                    "hidden": false
                },
                {
                    "_id": "67171043c3d0f3134dc15bdf",
                    "name": "Md Fahim",
                    "hidden": false
                },
                {
                    "_id": "67171043c3d0f3134dc15be0",
                    "user": {
                        "_id": "60d34afe0c54a218bc775297",
                        "avatarUrl": "/avatars/fd560b0f858be5ed534f85b7a6df3e14.svg",
                        "isPro": false,
                        "fullname": "Tasnim Mohiuddin",
                        "user": "tasnim",
                        "type": "user"
                    },
                    "name": "Tasnim Mohiuddin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2024-10-22T09:43:10.038Z",
                    "hidden": false
                },
                {
                    "_id": "67171043c3d0f3134dc15be1",
                    "name": "A K M Mahbubur Rahman",
                    "hidden": false
                },
                {
                    "_id": "67171043c3d0f3134dc15be2",
                    "user": {
                        "_id": "63a4754927f1f64ed7238dac",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
                        "isPro": false,
                        "fullname": "Aman Chadha",
                        "user": "amanchadha",
                        "type": "user"
                    },
                    "name": "Aman Chadha",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2024-10-22T08:01:02.592Z",
                    "hidden": false
                },
                {
                    "_id": "67171043c3d0f3134dc15be3",
                    "name": "Tariq Iqbal",
                    "hidden": false
                },
                {
                    "_id": "67171043c3d0f3134dc15be4",
                    "name": "M Ashraful Amin",
                    "hidden": false
                },
                {
                    "_id": "67171043c3d0f3134dc15be5",
                    "name": "Md Mofijul Islam",
                    "hidden": false
                },
                {
                    "_id": "67171043c3d0f3134dc15be6",
                    "name": "Amin Ahsan Ali",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-10-19T07:14:14.000Z",
            "title": "DM-Codec: Distilling Multimodal Representations for Speech Tokenization",
            "summary": "Recent advancements in speech-language models have yielded significant\nimprovements in speech tokenization and synthesis. However, effectively mapping\nthe complex, multidimensional attributes of speech into discrete tokens remains\nchallenging. This process demands acoustic, semantic, and contextual\ninformation for precise speech representations. Existing speech representations\ngenerally fall into two categories: acoustic tokens from audio codecs and\nsemantic tokens from speech self-supervised learning models. Although recent\nefforts have unified acoustic and semantic tokens for improved performance,\nthey overlook the crucial role of contextual representation in comprehensive\nspeech modeling. Our empirical investigations reveal that the absence of\ncontextual representations results in elevated Word Error Rate (WER) and Word\nInformation Lost (WIL) scores in speech transcriptions. To address these\nlimitations, we propose two novel distillation approaches: (1) a language model\n(LM)-guided distillation method that incorporates contextual information, and\n(2) a combined LM and self-supervised speech model (SM)-guided distillation\ntechnique that effectively distills multimodal representations (acoustic,\nsemantic, and contextual) into a comprehensive speech tokenizer, termed\nDM-Codec. The DM-Codec architecture adopts a streamlined encoder-decoder\nframework with a Residual Vector Quantizer (RVQ) and incorporates the LM and SM\nduring the training process. Experiments show DM-Codec significantly\noutperforms state-of-the-art speech tokenization models, reducing WER by up to\n13.46%, WIL by 9.82%, and improving speech quality by 5.84% and intelligibility\nby 1.85% on the LibriSpeech benchmark dataset. The code, samples, and model\ncheckpoints are available at https://github.com/mubtasimahasan/DM-Codec.",
            "upvotes": 1,
            "discussionId": "67171044c3d0f3134dc15c5d"
        },
        "publishedAt": "2024-10-22T01:20:41.121Z",
        "title": "DM-Codec: Distilling Multimodal Representations for Speech Tokenization",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63a4754927f1f64ed7238dac/etGkdX_-cdTGUf560dvlq.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2410.15017.png",
        "numComments": 1,
        "submittedBy": {
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63a4754927f1f64ed7238dac/aH-eJF-31g4vof9jv2gmI.jpeg",
            "fullname": "Aman Chadha",
            "name": "amanchadha",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        }
    }
]