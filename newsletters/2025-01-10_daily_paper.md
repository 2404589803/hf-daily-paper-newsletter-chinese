
# <img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.png" width="30"/> Hugging Face 2025-01-10 论文日报

## 📊 今日论文统计
- 总论文数：9
- 热门领域：Transformer, LLM, NLP

## 📝 论文详情


### 1. GAN已死；GAN永存！一个现代的GAN基线

**原文标题：** The GAN is dead; long live the GAN! A Modern GAN Baseline

**摘要：**
有一种广泛传播的说法认为GANs难以训练，并且文献中的GAN架构充斥着经验技巧。我们提供了反对这一说法的证据，并以更有原则的方式构建了一个现代的GAN基线。首先，我们推导出一个表现良好的正则化相对论GAN损失函数，解决了之前通过一系列临时技巧处理的模式丢失和不收敛问题。我们对该损失函数进行了数学分析，并证明其具有局部收敛保证，这与大多数现有的相对论损失函数不同。其次，我们的新损失函数使我们能够摒弃所有临时技巧，并用现代架构替换常见GANs中使用的过时骨干网络。以StyleGAN2为例，我们提出了一个简化和现代化的路线图，从而产生了一个新的极简基线——R3GAN。尽管方法简单，但我们的方法在FFHQ、ImageNet、CIFAR和Stacked MNIST数据集上超越了StyleGAN2，并与最先进的GANs和扩散模型相比表现优异。

**论文链接：** []()



---

### 2. 基于视频的自回归预训练实证研究

**原文标题：** An Empirical Study of Autoregressive Pre-training from Videos

**摘要：**
本文对基于视频的自回归预训练进行了实证研究。为了开展研究，我们构建了一系列自回归视频模型，称为Toto。我们将视频视为视觉标记的序列，并训练Transformer模型以自回归方式预测未来的标记。我们的模型在一个包含超过1万亿视觉标记的多样化视频和图像数据集上进行了预训练。我们探索了不同的架构、训练和推理设计选择。我们在一系列下游任务上评估了学习到的视觉表示，包括图像识别、视频分类、目标跟踪和机器人技术。我们的结果表明，尽管具有最小的归纳偏差，自回归预训练在所有基准测试中都表现出竞争力。最后，我们发现，扩展我们的视频模型会产生与语言模型相似的扩展曲线，尽管速率不同。更多详情请访问https://brjathu.github.io/toto/

**论文链接：** []()



---

### 3. 视觉语言模型是否已准备好用于自动驾驶？从可靠性、数据和指标角度的实证研究

**原文标题：** Are VLMs Ready for Autonomous Driving? An Empirical Study from the
  Reliability, Data, and Metric Perspectives

**摘要：**
视觉语言模型（VLMs）的最新进展引发了人们对其在自动驾驶中应用的兴趣，特别是在通过自然语言生成可解释的驾驶决策方面。然而，关于VLMs是否能够固有地提供视觉基础、可靠且可解释的驾驶解释的假设在很大程度上仍未得到验证。为了填补这一空白，我们引入了DriveBench，这是一个基准数据集，旨在评估VLMs在17种设置（干净、损坏和纯文本输入）下的可靠性，涵盖19,200帧图像、20,498个问答对、三种问题类型、四项主流驾驶任务以及总共12个流行的VLMs。我们的研究结果表明，VLMs通常生成基于一般知识或文本线索的看似合理的响应，而非真正的视觉基础，特别是在视觉输入退化或缺失的情况下。这种行为被数据集不平衡和评估指标不足所掩盖，在自动驾驶等安全关键场景中构成重大风险。我们进一步观察到，VLMs在多模态推理方面存在困难，并且对输入损坏表现出更高的敏感性，导致性能不一致。为了应对这些挑战，我们提出了改进的评估指标，优先考虑稳健的视觉基础和多模态理解。此外，我们强调了利用VLMs对损坏的感知来增强其可靠性的潜力，为在现实世界的自动驾驶环境中开发更可信和可解释的决策系统提供了路线图。基准工具包可公开访问。

**论文链接：** []()



---

### 4. 增强大型语言模型中的人类化响应能力

**原文标题：** Enhancing Human-Like Responses in Large Language Models

**摘要：**
本文探讨了使大型语言模型（LLMs）更加人类化的最新进展。我们重点关注增强人工智能系统中自然语言理解、对话连贯性和情感智能的技术。研究评估了多种方法，包括使用多样化数据集进行微调、融入心理学原理以及设计能更好模仿人类推理模式的模型。我们的研究结果表明，这些增强不仅改善了用户交互体验，还为跨不同领域的AI应用开辟了新的可能性。未来的工作将解决这些人类化属性带来的伦理影响和潜在偏见。

**论文链接：** []()



---

### 5. Centurio：大型视觉语言模型多语言能力的驱动因素研究

**原文标题：** Centurio: On Drivers of Multilingual Ability of Large Vision-Language
  Model

**摘要：**
迄今为止，大多数大型视觉语言模型（LVLMs）主要是在英语数据上进行训练的，这使得它们在理解非英语输入和生成目标语言输出方面表现不佳。现有的研究通过增加多语言训练数据来缓解这些问题，但大多采用临时的方式，缺乏对不同训练组合如何影响不同语言群体的深入理解。在本研究中，我们对大规模多语言LVLMs的训练策略进行了全面调查。首先，我们进行了一系列多阶段实验，涵盖13个下游视觉语言任务和43种语言，系统地考察了：（1）在不降低英语性能的情况下可以包含的训练语言数量；（2）预训练数据的最佳语言分布；（3）指令调优数据的最佳语言分布。此外，我们还（4）研究了如何提高多语言图像中文本的理解能力，并为此任务引入了一个新的基准。令人惊讶的是，我们的分析表明，可以（i）同时包含多达100种训练语言，（ii）仅使用25-50%的非英语数据，就能显著提高多语言性能，同时保持强大的英语性能。我们还发现，（iii）在预训练和指令调优中包含非英语OCR数据对于提高多语言图像中文本的理解能力至关重要。最后，我们将所有发现整合在一起，训练了Centurio，一个支持100种语言的LVLM，在涵盖14个任务和56种语言的评估中提供了最先进的性能。

**论文链接：** []()



---

### 6. 视觉自回归模型的计算极限与可证明高效性标准：细粒度复杂性分析

**原文标题：** On Computational Limits and Provably Efficient Criteria of Visual
  Autoregressive Models: A Fine-Grained Complexity Analysis

**摘要：**
最近，视觉自回归（VAR）模型在图像生成领域引入了一项突破性进展，通过从粗到细的“下一尺度预测”范式提供了一种可扩展的方法。然而，[Tian, Jiang, Yuan, Peng and Wang, NeurIPS 2024]中提出的VAR模型的最先进算法需要O(n^4)的时间，这在计算上是低效的。在本研究中，我们通过细粒度复杂性视角分析了VAR模型的计算极限和效率标准。我们的关键贡献是确定了在何种条件下VAR计算可以实现次二次时间复杂度。具体而言，我们为VAR注意力机制中使用的输入矩阵的范数建立了一个关键阈值。超过该阈值时，假设细粒度复杂性理论中的强指数时间假设（SETH），VAR模型的次四次时间算法是不可能的。为了证实我们的理论发现，我们提出了利用低秩近似的高效构造，这些构造符合我们推导的标准。本研究从理论角度开启了VAR模型计算效率的研究。我们的技术将为在VAR框架中推进可扩展且高效的图像生成提供新的见解。

**论文链接：** []()



---

### 7. 基于熵引导的注意力机制用于私有大语言模型

**原文标题：** Entropy-Guided Attention for Private LLMs

**摘要：**
专有语言模型的普及引发了严重的隐私问题，这促使私有推理（PI）技术的进步，其中计算直接在加密数据上进行，而不会泄露用户的敏感信息。尽管PI提供了一个有前景的解决方案，但其实际部署受到显著的通信和延迟开销的阻碍，这些开销主要源于非线性操作。为了解决这一问题，我们引入了一个信息论框架来表征仅解码器语言模型中非线性的作用，为优化适应PI需求的Transformer架构奠定了原则性基础。通过利用香农熵作为定量度量，我们揭示了非线性之前未被探索的双重意义：除了确保训练稳定性外，它们对于保持注意力头多样性至关重要。具体而言，我们发现移除非线性会触发两种关键故障模式：深层中的{\em熵崩溃}导致训练不稳定，以及浅层中的{\em熵过载}导致多头注意力（MHA）表示能力的未充分利用。我们提出了一种基于熵引导的注意力机制，并结合一种新颖的熵正则化技术来缓解熵过载。此外，我们探索了适用于PI的层归一化替代方案，以防止熵崩溃并稳定减少非线性的LLM训练。我们的研究弥合了信息论与架构设计之间的差距，确立了熵动力学作为开发高效PI架构的原则性指南。代码和实现可在https://github.com/Nandan91/entropy-guided-attention-llm{entropy-guided-llm}获取。

**论文链接：** []()



---

### 8. SWE-Fixer：训练开源大型语言模型以实现高效GitHub问题解决

**原文标题：** SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub
  Issue Resolution

**摘要：**
大型语言模型（LLMs）在各种复杂任务中展示了显著的熟练度。LLMs的一个重要应用是解决软件工程挑战，特别是通过修复用户报告的问题来解决GitHub上的实际任务。然而，目前许多方法依赖于专有的LLMs，这限制了可重复性、可访问性和透明度。用于解决软件工程问题的LLMs的关键组件以及如何有效增强其能力仍不明确。为了解决这些挑战，我们引入了SWE-Fixer，一种新颖的开源LLM，旨在有效且高效地解决GitHub问题。SWE-Fixer包含两个基本模块：代码文件检索模块和代码编辑模块。检索模块采用BM25结合轻量级LLM模型实现从粗到细的文件检索。随后，代码编辑模块利用另一个LLM模型为识别出的文件生成补丁。然后，为了弥补公开数据集的不足，我们编制了一个包含110K GitHub问题及其相应补丁的广泛数据集，并分别训练SWE-Fixer的两个模块。我们在SWE-Bench Lite和Verified基准上评估了我们的方法，分别在开源模型中取得了23.3%和30.2%的最先进性能。这些结果突显了我们方法的有效性。我们将在https://github.com/InternLM/SWE-Fixer上公开我们的模型、数据集和代码。

**论文链接：** []()



---

### 9. 构建历史土耳其语自然语言处理的基础：资源与模型

**原文标题：** Building Foundations for Natural Language Processing of Historical
  Turkish: Resources and Models

**摘要：**
本文介绍了用于历史土耳其语自然语言处理（NLP）的基础资源和模型，这一领域在计算语言学中尚未得到充分探索。我们提出了首个命名实体识别（NER）数据集HisTR，以及首个适用于历史土耳其语的通用依存树库OTA-BOUN，并利用这些数据集训练了基于Transformer的模型，用于命名实体识别、依存句法分析和词性标注任务。此外，我们还引入了奥斯曼文本语料库（OTC），这是一个涵盖广泛历史时期的、经过清理的转写历史土耳其语文本语料库。我们的实验结果表明，在历史土耳其语的计算分析方面取得了显著进展，在需要理解历史语言结构的任务中取得了令人鼓舞的结果。这些结果也突显了现有的挑战，如领域适应和跨时期语言变化。所有提供的资源和模型均在https://huggingface.co/bucolin上公开，作为未来历史土耳其语NLP进展的基准。

**论文链接：** []()



---


## 🔍 关键词云图
![关键词云图](images/keywords_wordcloud.png)

## 📈 近期论文趋势
![论文趋势](images/daily_papers.png)

## 🎙️ 语音播报
- [收听今日论文解读](audio/2025-01-10_daily_papers.mp3)

## 📱 订阅渠道
- GitHub: [hf-daily-paper-newsletter-chinese](https://github.com/2404589803/hf-daily-paper-newsletter-chinese)