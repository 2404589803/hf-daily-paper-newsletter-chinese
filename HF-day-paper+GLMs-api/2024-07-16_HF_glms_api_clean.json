[
    {
        "url": "https://arxiv.org/abs/2407.10671",
        "content": "很抱歉，我无法访问您提供的文章链接（https://arxiv.org/abs/2407.10671）。因此，我无法提供关于这篇文章的具体内容。您可以尝试直接访问该链接，或者提供文章的标题和作者信息，这样我可能能够通过其他方式帮助您获取相关信息。"
    },
    {
        "url": "https://arxiv.org/abs/2407.10058",
        "content": "很抱歉，我无法访问您提供的文章链接。由于这个原因，我无法提供关于这篇文章的具体内容。如果您能提供文章的标题或摘要，我会尽力帮助您。"
    },
    {
        "url": "https://arxiv.org/abs/2407.10457",
        "content": "这篇文章的标题是《The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism》，主要探讨了大型语言模型（LLMs）的评价问题。目前对LLMs的评价往往忽略了非确定性，通常只关注每个示例的单个输出。这限制了我们对LLMs在实际应用中性能变异性的理解。研究通过探索关于贪婪解码和采样之间性能差异的关键问题，识别基准测试在非确定性方面的不一致性，以及检查独特的模型行为，来解决这个问题。通过广泛的实验，作者观察到贪婪解码在大多数评估任务中通常优于采样方法。此外，还观察到不同大小的LLMs和校准方法之间的性能一致性，注意到校准可以减少采样方差。此外，作者提出的一种最佳-of-N采样方法显示，较小的LLMs可以匹配或超过较大的模型，如GPT-4-Turbo，突显了较小LLMs的未开发潜力。这项研究显示了在LLM评价中考虑非确定性的重要性，并为未来的LLM开发和评价提供了见解。\n\n搜索结果来自：\n[2407.10457] The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism - https://arxiv.org/abs/2407.10457"
    },
    {
        "url": "https://arxiv.org/abs/2407.10969",
        "content": "无法访问和检索关于文章 \"https://arxiv.org/abs/2407.10969\" 的具体内容。如果您能提供这篇文章的标题或摘要，我可以尝试根据这些信息来回答您的问题。"
    },
    {
        "url": "https://arxiv.org/abs/2407.10943",
        "content": "这篇文章的标题是《GRUtopia: Dream General Robots in a City at Scale》，发表在计算机科学和机器人学领域。文章的主要内容是探索在具身人工智能（Embodied AI）领域的扩展定律。鉴于收集现实世界数据的成本过高，作者认为模拟到现实（Sim2Real）范式是扩展具身模型学习的关键步骤。文章介绍了GRUtopia项目，这是为各种机器人设计的首个模拟交互式3D社会。项目包括几个进展：一是GRScenes场景数据集，包含10万个交互式、精细标注的场景，可以自由组合成城市规模的环境；二是GRResidents，一个由大型语言模型（LLM）驱动的非玩家角色（NPC）系统，负责社交互动、任务生成和任务分配；三是GRBench基准，支持各种机器人，但主要关注腿式机器人作为主要代理，并提出了涉及物体定位导航、社交定位导航和定位操纵的中等挑战性任务。作者希望这项工作能够缓解该领域高质量数据的稀缺问题，并为具身人工智能研究提供更全面的评估。\n\n搜索结果来自：\n[2407.10943] GRUtopia: Dream General Robots in a City at Scale - http://export.arxiv.org/abs/2407.10943"
    },
    {
        "url": "https://arxiv.org/abs/2407.10973",
        "content": "很抱歉，我无法访问和检索关于文章 \"Make-An-Agent: A Generalizable Policy Network Generator with Behavior-Prompted Diffusion\" (arXiv:2407.10973) 的详细信息。这可能是因为网站的限制或其他技术原因。如果您能提供文章的摘要或主要内容，我可以帮助解读或讨论。或者，您可以直接访问 [arXiv网站](https://arxiv.org/) 查看该文章的详细内容。"
    },
    {
        "url": "https://arxiv.org/abs/2407.10387",
        "content": "这篇文章的标题是《Masked Generative Video-to-Audio Transformers with Enhanced Synchronicity》，由Santiago Pascual等人撰写。文章主要探讨了视频到音频（Video-to-Audio, V2A）的生成技术，这项技术利用仅视觉的视频特征来渲染与场景相匹配的合理声音。重要的是，生成的声音起始点应与视觉动作相匹配，否则会出现不自然的同步瑕疵。\n\n文章提出了一种名为MaskVAT的V2A生成模型，该模型将全频带高质量通用音频编解码器与序列到序列的掩蔽生成模型相结合。这种组合允许同时建模高音频质量、语义匹配和时间同步性。研究结果表明，通过将高质量编解码器与适当的预训练音视频特征以及序列到序列的并行结构相结合，可以在保持与最新无编解码器生成音频模型竞争的同时，实现高度同步的结果。\n\n这篇文章已被ECCV 2024接受，涵盖了声音（cs.SD）、人工智能（cs.AI）、计算机视觉和模式识别（cs.CV）、音频和语音处理（eess.AS）等领域。\n\n更多细节和文章的具体内容，可以通过访问arXiv网站查看。\n\n搜索结果来自：\n[2407.10387] Masked Generative Video-to-Audio Transformers with Enhanced Synchronicity - https://arxiv.org/abs/2407.10387\n[2407.10387] Masked Generative Video-to-Audio Transformers with Enhanced Synchronicity - http://export.arxiv.org/abs/2407.10387"
    },
    {
        "url": "https://arxiv.org/abs/2407.07523",
        "content": "这篇文章标题为《SHERL: Synthesizing High Accuracy and Efficient Memory for Resource-Limited Transfer Learning》，提交于2024年7月10日，主要研究了在资源受限的情况下，如何提高参数高效迁移学习（PETL）的准确性和内存效率。PETL是近年来为了适应大型预训练模型到下游任务而兴起的一个研究领域，它在减少可训练参数的同时，也面临着微调过程中的内存挑战。\n\n文章提出了一种名为SHERL的创新内存高效策略，用于资源受限的场景。SHERL将整个适应过程分解为两个连续且互补的过程。在早期路线中，通过去冗余操作整合中间输出，增强它们与后续交互的兼容性；在晚期路线中，利用最少的晚期预训练层可以减轻内存开销的峰值，并将这些相对灵活的特征调节为对新领域更适应和强大的表示。文章在视觉-语言和纯语言任务上进行了广泛的实验，结果显示SHERL结合了参数高效和内存高效技术的优势，在多样化的架构中以更低的内存进行微调，表现与或优于传统PETL方法。\n\n这项研究由来自大连理工大学、鲁汶大学、腾讯微信和香港科技大学的研究人员共同完成，并已被ECCV2024接受。更多细节和代码可以在GitHub上找到。\n\n搜索结果来自：\n[2407.07523] SHERL: Synthesizing High Accuracy and Efficient Memory for Resource-Limited Transfer Learning - http://export.arxiv.org/abs/2407.07523\n - http://export.arxiv.org/pdf/2407.07523"
    },
    {
        "url": "https://arxiv.org/abs/2407.09533",
        "content": "这篇文章标题为《Video Occupancy Models》（视频占用模型），提交于2024年6月25日。文章介绍了一种新的视频预测模型家族，旨在支持下游控制任务。这些模型被称为视频占用模型（VOCs）。VOCs在紧凑的潜在空间中运行，因此避免了关于单个像素的预测需求。与先前的潜在空间世界模型不同，VOCs直接预测未来状态的折现分布，从而避免了多步骤展开的需求。文章指出，在构建用于下游控制的视频预测模型时，这两个特性都是有益的。相关代码可在提供的GitHub链接中找到。\n\n搜索结果来自：\n[2407.09533] Video Occupancy Models - http://export.arxiv.org/abs/2407.09533"
    },
    {
        "url": "https://arxiv.org/abs/2407.10285",
        "content": "这篇文章的标题是《Noise Calibration: Plug-and-play Content-Preserving Video Enhancement using Pre-trained Video Diffusion Models》。文章发表于2024年7月14日，属于计算机视觉和模式识别领域。文章的主要研究内容是为了提高合成视频的质量。目前，一种主要的方法涉及重新训练专家扩散模型，然后实施去噪过程以进行细化。尽管训练成本高昂，但保持原始视频和增强视频之间内容的一致性仍然是一个重大挑战。为了应对这一挑战，作者提出了一种新的公式，同时考虑了视觉质量和内容的一致性。内容的一致性通过一种新的损失函数来保证，该函数保持输入的结构，而视觉质量则通过利用预训练扩散模型的去噪过程来提高。为了解决提出的优化问题，作者开发了一种即插即用的噪声优化策略，称为噪声校准。通过几次迭代细化初始随机噪声，可以大量保留原始视频的内容，并且增强效果显示出显著的改进。文章通过广泛的实验证明了所提方法的有效性。\n\n搜索结果来自：\n[2407.10285] Noise Calibration: Plug-and-play Content-Preserving Video Enhancement using Pre-trained Video Diffusion Models - http://export.arxiv.org/abs/2407.10285"
    },
    {
        "url": "https://arxiv.org/abs/2407.10827",
        "content": "无法访问您提供的文章链接（https://arxiv.org/abs/2407.10827）。因此，我无法提供关于这篇文章的具体内容。如果您能提供文章的标题或摘要，我可以尝试通过这些信息来帮助您。"
    },
    {
        "url": "https://arxiv.org/abs/2407.10910",
        "content": "这篇文章的标题是《DataDream: Few-shot Guided Dataset Generation》，发表于2024年7月15日，主要研究内容涉及计算机视觉和模式识别（Computer Vision and Pattern Recognition）以及机器学习（Machine Learning）。文章的核心贡献是提出了一个名为DataDream的框架，用于合成分类数据集。这个框架在仅有少量真实样本的指导下，能够更真实地代表真实数据分布。\n\n具体来说，文章指出，尽管文本到图像的扩散模型在图像合成方面取得了最先进的结果，但它们在下游应用中的有效性尚未得到证明。先前的研究提出了在有限的真实数据访问情况下为图像分类器训练生成数据的方法。然而，这些方法在生成真实分布的图像或描述细粒度特征方面存在困难，从而阻碍了在合成数据集上训练的分类模型的泛化能力。\n\nDataDream通过在少量真实图像上微调LoRA权重来改进图像生成模型，然后使用调整后的模型生成训练数据。此外，该框架还通过在合成数据上微调CLIP的LoRA权重来改进下游图像分类，从而在多种数据集上超越了先前方法的分类准确性。文章通过大量实验证明了DataDream的有效性，在10个数据集中的7个上，使用少量样本数据超过了最先进的分类准确性，而在其他3个上具有竞争力。\n\n此外，文章还提供了关于各种因素（如真实样本数量、生成图像数量以及模型性能的微调计算）对模型性能影响的见解。该研究的代码可在GitHub上找到。\n\n搜索结果来自：\n[2407.10910] DataDream: Few-shot Guided Dataset Generation - http://export.arxiv.org/abs/2407.10910"
    },
    {
        "url": "https://arxiv.org/abs/2407.10953",
        "content": "这篇文章标题为“MMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models”，由Chengguang Gan等作者撰写。文章主要探讨了互强化效应（Mutual Reinforcement Effect, MRE）在信息提取和多功能研究中的应用。此前，MRE混合数据集仅限于日语，限制了全球研究社区的全面探索。为了解决这一限制，文章引入了一个涵盖英语、日语和中文的21个子数据集的多语言MRE混合数据集（MMM）。此外，文章还提出了一种利用大型语言模型（LLMs）辅助数据集翻译的方法，大幅减少了构建数据集所需的手动注释时间。文章还通过整合开放领域的命名实体识别（NER）和句子分类任务来丰富数据集。利用这个扩展的数据集，研究人员开发了一个统一的输入-输出框架，用于训练一个开放领域信息提取大型语言模型（OIELLM）。该模型显示出有效处理新MMM数据集的能力，并在性能上取得了显著提升。\n\n搜索结果来自：\n[2407.10953] MMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models - https://arxiv.org/abs/2407.10953"
    },
    {
        "url": "https://arxiv.org/abs/2407.10362",
        "content": "无法访问您提供的文章链接 \"https://arxiv.org/abs/2407.10362\"。因此，我无法提供关于这篇文章的具体内容。如果您能提供文章的标题或摘要，我可以尝试通过其他方式帮助您获取相关信息。"
    }
]