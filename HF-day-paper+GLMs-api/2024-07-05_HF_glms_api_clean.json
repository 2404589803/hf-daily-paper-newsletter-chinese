[
    {
        "url": "https://arxiv.org/abs/2407.01906",
        "content": "这篇文章的标题是《Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models》，作者是 Zihan Wang 等人。文章主要研究了针对具有 Mixture-of-Experts (MoE) 架构的大型语言模型 (LLMs) 的参数高效微调 (PEFT) 方法。研究内容包括：1) 调查在定制任务中激活的专家的分散程度，发现特定任务的路由分布倾向于高度集中，而激活的专家分布在不同任务之间有显著差异。2) 提出了专家专门微调（Expert-Specialized Fine-Tuning, ESFT），该方法只调整与下游任务最相关的专家，同时冻结其他专家和模块；实验结果表明，这种方法不仅提高了调整效率，而且性能与全参数微调相当甚至更优。3) 进一步分析了 MoE 架构对专家专门微调的影响，发现具有更细粒度专家的 MoE 模型在选择与下游任务最相关的专家组合方面更有优势，从而提高了训练效率和效果。\n\n搜索结果来自：\n[2407.01906] Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models - https://arxiv.org/abs/2407.01906"
    },
    {
        "url": "https://arxiv.org/abs/2407.01392",
        "content": "这篇文章标题为《Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion》，发表在2024年7月的arXiv上。文章介绍了一种名为“Diffusion Forcing”的新训练范式，这是一种针对扩散模型进行训练的方法，目的是去噪一组具有独立每个标记噪声水平的标记。文章将Diffusion Forcing应用于序列生成建模，通过训练因果性下一个标记预测模型来生成一个或多个未来标记，而无需完全扩散过去的标记。\n\n这种方法结合了下一个标记预测模型的优点，例如可变长度生成，以及全序列扩散模型的优点，例如能够引导采样到期望的轨迹。文章提出的方法提供了一系列额外的功能，例如（1）展开连续标记的序列，如视频，长度超过训练范围，而在这种情况下基线会偏离；（2）新的采样和引导方案，这些方案独占地从Diffusion Forcing的可变范围和因果架构中获益，这导致在决策和规划任务中性能显著提升。\n\n除了其经验上的成功，文章中的方法被证明可以优化从真实联合分布中抽取的所有标记子序列的可能性的变分下界。该项目的主页为：[boyuan.space/diffusion-forcing](https://boyuan.space/diffusion-forcing/)。\n\n搜索结果来自：\n[2407.01392] Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion - http://export.arxiv.org/abs/2407.01392\nDiffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion - NASA/ADS - https://ui.adsabs.harvard.edu/abs/2024arXiv240701392C/abstract"
    },
    {
        "url": "https://arxiv.org/abs/2407.03321",
        "content": "这篇文章标题为《Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages》，由Max Zuo和其他四位作者撰写。文章主要探讨了使用语言模型解决规划问题的方法，特别是将自然语言描述的规划任务翻译成结构化的规划语言，如规划领域定义语言（PDDL）。文章指出，尽管这种方法很有前景，但准确衡量生成的PDDL代码质量仍然是一个重大挑战。为了解决这一问题，作者们引入了一个名为“Planetarium”的基准测试，旨在评估语言模型从自然语言描述生成PDDL代码的能力。他们创建了一个PDDL等价算法，通过灵活地与真实PDDL进行比较来严格评估语言模型生成的PDDL代码的正确性。此外，他们还展示了一个包含132,037个文本到PDDL对的 dataset，覆盖了13个不同难度的任务，并评估了几个API访问和开放权重语言模型，揭示了这一任务的复杂性。\n\n搜索结果来自：\n[2407.03321] Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages - https://arxiv.org/abs/2407.03321"
    }
]