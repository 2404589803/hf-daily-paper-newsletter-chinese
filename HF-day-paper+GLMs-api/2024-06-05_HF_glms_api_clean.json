[
    {
        "url": "https://arxiv.org/abs/2406.02430",
        "content": "这篇文章介绍了一种名为Seed-TTS的高质量、多功能的语音生成模型家族。Seed-TTS是一系列大规模的自回归文本到语音（TTS）模型，能够生成几乎与人类语音无法区分的语音。这些模型在语音生成方面表现卓越，特别是在语音的上下文学习方面，无论是在说话人相似性和自然度方面，都能与真实的人类语音相媲美。通过微调，这些模型在这些指标上实现了更高的主观评分。Seed-TTS在控制各种语音属性（如情感）方面具有卓越的性能，并能生成极具表现力和多样性的语音。此外，文章还提出了一种用于语音分解的自我蒸馏方法，以及一种增强模型鲁棒性、说话人相似性和可控性的强化学习方法。文章还介绍了Seed-TTS的非自回归（NAR）变体，名为Seed-TTS_DiT，它采用完全基于扩散的架构。与以前的NAR语音合成系统不同，Seed-TTS_DiT不依赖于预先估计的音素持续时间，并通过端到端处理进行语音生成。文章展示了这种变体在语音编辑方面的有效性，并鼓励读者访问相关链接听取演示。\n\n搜索结果来自：\n[2406.02430] Seed-TTS: A Family of High-Quality Versatile Speech Generation Models - https://arxiv.org/abs/2406.02430"
    },
    {
        "url": "https://arxiv.org/abs/2406.02543",
        "content": "这篇文章的标题是《To Believe or Not to Believe Your LLM》，发表于2024年6月4日，主要探讨了大型语言模型（LLMs）中的不确定性量化问题。研究的目的是识别出模型在回答特定查询时的不确定性大小。文章同时考虑了认识论不确定性（epistemic uncertainty）和偶然不确定性（aleatoric uncertainty），前者源于对真相（如事实或语言）的无知，后者则来自不可减少的随机性（如多个可能的答案）。文章提出了一种信息论度量，可以可靠地检测何时只有认识论不确定性较大，在这种情况下，模型的输出是不可靠的。这种条件可以通过基于先前响应的特殊迭代提示来计算。例如，这允许在单答案和多答案响应中检测到幻觉（即认识论不确定性高的情况）。这与许多标准的不确定性量化策略（如对响应的对数似然进行阈值处理）形成对比，后者无法在多答案情况下检测到幻觉。文章进行了一系列实验，证明了这种量化方法的优势。此外，研究还揭示了一些关于LLM如何通过迭代提示放大给定输出的概率的信息，这可能具有独立的研究价值。\n\n搜索结果来自：\n[2406.02543] To Believe or Not to Believe Your LLM - https://web3.arxiv.org/abs/2406.02543"
    },
    {
        "url": "https://arxiv.org/abs/2406.02230",
        "content": "这篇文章标题为《I4VGen: Image as Stepping Stone for Text-to-Video Generation》，由Xiefan Guo等作者撰写。文章主要讨论了文本到视频生成的技术，提出了一种名为I4VGen的框架。这个框架通过利用稳健的图像技术来提高文本到视频生成的质量和多样性。I4VGen将文本到视频的生成过程分解为两个阶段：锚点图像合成和锚点图像引导的视频合成。该方法包括一个创新性的噪声不变视频评分蒸馏采样过程，用于将静态图像转化为动态视频，并通过视频再生过程来细化视频。这一推理策略有效减轻了非零终端信噪比的问题。广泛的评估表明，I4VGen不仅能够生成视觉上更真实、文本上更忠实的视频，而且可以无缝整合到现有的图像到视频扩散模型中，从而提高整体视频质量。\n\n搜索结果来自：\n[2406.02230] I4VGen: Image as Stepping Stone for Text-to-Video Generation - https://arxiv.org/abs/2406.02230"
    },
    {
        "url": "https://arxiv.org/abs/2406.02507",
        "content": "这篇文章的标题是《用较差版本的自己指导扩散模型》（Guiding a Diffusion Model with a Bad Version of Itself），由Tero Karras和其他五位作者撰写。文章主要研究了图像生成扩散模型中的几个关键方面：图像质量、结果多样性以及结果与给定条件（如类别标签或文本提示）的对齐程度。文章提出了一种新的指导方法，即使用一个较小、训练较少版本的模型本身来指导生成过程，而不是使用无条件模型。这种方法在保持结果多样性的同时，显著提高了图像质量，并在ImageNet生成中取得了破纪录的表现。\n\n搜索结果来自：\n[2406.02507] Guiding a Diffusion Model with a Bad Version of Itself - https://web3.arxiv.org/abs/2406.02507"
    },
    {
        "url": "https://arxiv.org/abs/2406.01660",
        "content": "这篇文章标题为《Self-Improving Robust Preference Optimization》，由Eugene Choi和其他四位作者撰写，提交于2024年6月3日。文章主要讨论了在线和离线强化学习从人类偏好（RLHF）方法，例如PPO和DPO，在使AI与人类偏好一致方面的成功。尽管这些方法取得了成功，但它们存在一个根本问题：它们的最佳解决方案高度依赖于特定任务（即对于非分布内（OOD）任务不够鲁棒）。文章针对这一挑战提出了“Self-Improving Robust Preference Optimization (SRPO)”，这是一种实用的、具有数学原理的离线RLHF框架，对任务变化完全鲁棒。SRPO的关键思想是将学习人类偏好的问题视为一个自我改进过程，这可以数学上表达为一个最小-最大目标，旨在以对抗性方式联合优化自我改进策略和生成策略。这个优化问题的解决方案与训练任务无关，因此对任务变化具有鲁棒性。文章进一步展示了这个目标可以重新表达为非对抗性的离线损失形式，可以使用标准监督优化技术大规模优化，而无需奖励模型和在线推理。文章通过AI胜率（WR）对抗人类（GOLD）完成度来展示SRPO的有效性。特别是在OOD XSUM数据集上评估SRPO时，它在5次自我修订后，胜率比著名的DPO高出15%，达到90%。\n\n搜索结果来自：\n[2406.01660] Self-Improving Robust Preference Optimization - https://arxiv.org/abs/2406.01660"
    },
    {
        "url": "https://arxiv.org/abs/2406.02511",
        "content": "这篇文章标题为“V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation”，主要研究了肖像视频生成领域的一个新方法。文章提出了一种名为V-Express的技术，通过渐进式训练和条件性丢弃操作来平衡不同的控制信号。这种方法能够逐渐使弱条件变得有效，从而实现同时考虑面部姿势、参考图像和音频等多种因素的视频生成能力。该研究特别指出，音频信号通常较弱，经常被更强的信号（如面部姿势和参考图像）所掩盖，而V-Express方法能够有效地解决这个问题，提升音频信号在视频生成中的影响力。\n\n搜索结果来自：\n[2406.02511] V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation - https://arxiv.org/abs/2406.02511"
    },
    {
        "url": "https://arxiv.org/abs/2406.02523",
        "content": "文章《RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots》是一篇关于人工智能和机器人学的研究论文。这篇论文提交于2024年6月4日，主要探讨了如何利用真实的物理模拟来扩展机器人学习环境、任务和数据集。论文提出了一个名为RoboCasa的大规模模拟框架，用于在日常生活环境中训练通用型机器人。这个框架特别关注厨房环境，提供了跨越150多个对象类别的数千个3D资产，以及许多可互动的家具和电器。\n\n为了增强模拟的真实性和多样性，研究团队使用了生成性AI工具，例如从文本到3D模型的物体资产和从文本到图像模型的环境纹理。他们还设计了一套100个任务进行系统评估，包括由大型语言模型指导生成的复合任务。为了促进学习，研究团队提供了高质量的人类演示，并整合了自动轨迹生成方法，以最小化人力负担，大幅扩大数据集。实验显示，使用合成生成的机器人数据用于大规模模仿学习呈现出明显的扩展趋势，并且在利用模拟数据执行实际任务方面显示出巨大的潜力。相关的视频和开源代码可以在RoboCasa网站上找到。\n\n搜索结果来自：\n[2406.02523] RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots - https://arxiv.org/abs/2406.02523\n[2406.02523] RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots - http://export.arxiv.org/abs/2406.02523"
    },
    {
        "url": "https://arxiv.org/abs/2406.02509",
        "content": "这篇文章标题为“CamCo: Camera-Controllable 3D-Consistent Image-to-Video Generation”，主要研究了一种名为CamCo的技术。这项技术允许在图像到视频生成过程中进行细粒度的摄像机姿态控制。通过使用普吕克坐标，研究团队为预训练的图像到视频生成器装备了精确参数化的摄像机姿态输入。为了增强生成视频的3D一致性，他们在每个注意力块中整合了一种称为极线注意力模块的组件，强制特征图遵守极线约束。此外，研究团队还使用通过运动结构算法估计的摄像机姿态对真实世界视频上的CamCo进行了微调，以更好地合成物体运动。实验结果表明，CamCo在提高3D一致性和摄像机控制能力方面显著优于先前模型，同时有效生成合理的物体运动。\n\n搜索结果来自：\n[2406.02509] CamCo: Camera-Controllable 3D-Consistent Image-to-Video Generation - https://arxiv.org/abs/2406.02509"
    }
]