[
    {
        "url": "https://arxiv.org/abs/2406.11230",
        "content": "这篇文章的标题是《Multimodal Needle in a Haystack: Benchmarking Long-Context Capability of Multimodal Large Language Models》。文章主要探讨了多模态大型语言模型（MLLMs）在处理长文本上下文方面的能力。虽然MLLMs在各种应用中显示出巨大的潜力，但它们在处理长文本上下文方面的能力还没有得到全面的评估。\n\n为了填补这一研究空白，作者引入了一个名为MultiModal Needle-in-a-haystack（MMNeedle）的新基准，专门用于评估MLLMs处理长文本上下文的能力。这个基准测试不仅使用多图像输入，还通过图像拼接来进一步增加输入上下文的长度，并开发了一个协议来自动生成子图像级别的检索标签。MMNeedle的核心评估方式是测试MLLMs根据文本指令和图像内容描述，在一组图像（haystack）中定位目标子图像（needle）的能力。这种设置需要MLLMs具有对广泛视觉上下文的深入理解以及在长文本上下文图像输入中有效信息检索的能力。\n\n通过这个基准，作者评估了包括API-based和开源模型在内的最先进的MLLMs。研究发现，GPT-4o在长文本上下文场景中一致性地超越了其他模型，但在负样本中存在幻觉问题，即当haystack中不存在needle时。这项对MLLMs的全面长文本上下文评估还揭示了API-based和开源模型之间的性能差距。\n\n文章的代码、数据和重现主要结果的说明都可以在GitHub上找到。\n\n搜索结果来自：\nMultimodal Needle in a Haystack: Benchmarking Long-Context Capability of Multimodal Large Language Models - NASA/ADS - https://ui.adsabs.harvard.edu/abs/2024arXiv240611230W/abstract\n[2406.11230] Multimodal Needle in a Haystack: Benchmarking Long-Context Capability of Multimodal Large Language Models - http://export.arxiv.org/abs/2406.11230"
    },
    {
        "url": "https://arxiv.org/abs/2406.11612",
        "content": "这篇文章的标题是《Long Code Arena: a Set of Benchmarks for Long-Context Code Models》，由Egor Bogomolov和其他10位作者共同撰写，于2024年6月17日提交至arXiv。文章的主要内容集中在机器学习和自然语言处理领域的快速发展，特别是在处理长上下文窗口方面模型的进步。近年来，支持上下文的大小已经增加了几个数量级。\n\n文章指出，目前缺乏超越单个文件上下文的代码处理基准，而最流行的基准通常仅限于单个方法。为了填补这一空白，作者们引入了“Long Code Arena”，这是一套包含六个基准的代码处理任务，这些任务需要项目范围的上下文。这些任务涵盖了代码处理的各个方面，包括基于库的代码生成、CI构建修复、项目级代码完成、提交消息生成、错误定位和模块摘要。\n\n对于每个任务，作者们提供了一个手动验证的测试数据集、一个评估套件，以及基于流行LLMs的开源基线解决方案，以展示数据集的使用方法，并简化其他研究人员的使用。这些基准的页面已发布在HuggingFace Spaces上，包括排行榜、所有数据集的HuggingFace Hub链接，以及包含基线的GitHub仓库链接。\n\n总的来说，这篇文章旨在为代码处理领域提供更全面、更贴近实际项目需求的基准测试，以促进该领域的进一步发展和研究。\n\n搜索结果来自：\n[2406.11612] Long Code Arena: a Set of Benchmarks for Long-Context Code Models - https://arxiv.org/abs/2406.11612\n[2406.11612] Long Code Arena: a Set of Benchmarks for Long-Context Code Models - http://export.arxiv.org/abs/2406.11612"
    },
    {
        "url": "https://arxiv.org/abs/2406.11139",
        "content": "这篇文章的标题是《Breaking Boundaries: Investigating the Effects of Model Editing on Cross-linguistic Performance》，由Somnath Banerjee和其他六位作者撰写，提交于2024年6月17日。文章的主要内容集中在探讨预训练语言模型（PLMs），如BERT和GPT，在自然语言处理（NLP）领域的影响，特别是在英语中的应用。这些模型虽然极大地推动了NLP的发展，但同时也造成了语言上的不平衡。\n\n文章着重于实现语言公平性的需求，通过在多语言环境中检查多种知识编辑技术来达到这一目标。研究评估了包括Mistral、TowerInstruct、OpenHathi、Tamil-Llama和Kan-Llama在内的多种模型在英语、德语、法语、意大利语、西班牙语、印地语、泰米尔语和卡纳达语等语言中的表现。研究发现了正常模型和合并模型在跨语言一致性方面的显著差异。文章还采用了“每种语言为自己”（ELFI）和“每种语言为其他语言”（ELFO）等策略来对这些模型进行压力测试。\n\n研究发现，大型语言模型（LLMs）有望克服语言障碍，为未来在AI技术中实现语言包容性奠定了基础。这篇文章目前处于审稿阶段，归类于计算与语言（cs.CL）领域。\n\n搜索结果来自：\n[2406.11139] Breaking Boundaries: Investigating the Effects of Model Editing on Cross-linguistic Performance - https://arxiv.org/abs/2406.11139\n[2406.11139] Breaking Boundaries: Investigating the Effects of Model Editing on Cross-linguistic Performance - http://export.arxiv.org/abs/2406.11139"
    },
    {
        "url": "https://arxiv.org/abs/2406.12649",
        "content": "这篇文章标题为《Probabilistic Conceptual Explainers: Trustworthy Conceptual Explanations for Vision Foundation Models》，主要探讨了视觉变换器（Vision Transformers, ViTs）在作为强大的视觉基础模型方面的重点，尤其是在与大型语言模型联合训练的能力。文章指出，目前对于ViTs的可信解释方法发展滞后，特别是在ViT预测的后验解释方面。现有的子图像选择方法，如特征归因和概念模型，在这方面存在不足。文章提出了五个用于解释ViTs的理想标准：忠实性、稳定性、稀疏性、多层次结构和简洁性，并展示了当前方法在全面满足这些标准方面的不足。作者引入了一个变分贝叶斯解释框架，称为概率概念解释器（PACE），该框架通过模拟路径嵌入的分布来提供可信的后验概念解释。通过在合成和真实世界数据集上的广泛实验，文章证明了PACE在定义的理想标准方面超越了最先进的方法。\n\n搜索结果来自：\n[2406.12649] Probabilistic Conceptual Explainers: Trustworthy Conceptual Explanations for Vision Foundation Models - https://arxiv.org/abs/2406.12649"
    },
    {
        "url": "https://arxiv.org/abs/2406.12034",
        "content": "这篇文章标题为《Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts》，由Junmo Kang等作者撰写。文章介绍了一种名为Self-MoE的方法，它将单一的大型语言模型（LLM）转变为一个组合式的、模块化的系统，该系统由自我专业化的专家模块组成，称为MiXSE（MiXture of Self-specialized Experts）。这种方法利用自我专业化，通过自我生成的合成数据构建专家模块，每个模块都配备了一个共享的基础LLM，并融入了自我优化的路由。这使得能够动态且针对特定能力地处理各种目标任务，增强了整体能力，而无需大量的人力标注数据和额外的参数。实证结果显示，专业化的LLM可能在非专业任务上表现出潜在的权衡。然而，Self-MoE在知识、推理、数学和编程等多样化基准上显著优于基础LLM。它还一致地胜过其他方法，包括实例合并和权重合并，同时通过设计和语义专家及路由提供了更好的灵活性和可解释性。这些发现强调了模块化的重要性以及自我改进在实现高效、可扩展和适应性强的系统中的潜力。\n\n搜索结果来自：\n[2406.12034] Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts - https://arxiv.org/abs/2406.12034"
    },
    {
        "url": "https://arxiv.org/abs/2406.12209",
        "content": "这篇文章的标题是《Interface Design for Self-Supervised Speech Models》，作者是Yi-Jen Shih和David Harwath。文章主要研究了自监督语音（Self-supervised speech, SSL）模型的接口设计。SSL模型最近被广泛应用于许多下游语音处理任务。通常的使用模式是利用SSL模型作为特征提取器，然后训练一个下游预测头来解决特定任务。然而，SSL模型的不同层已被证明捕获不同类型的信息，且组合这些层的方法尚未得到充分研究。为此，文章通过提出连接上游和下游的接口，扩展了SSL模型利用的一般框架。在这种观点下，通过逐层加权求和来组合特征的技术可以被视为一个特定的接口。文章提出了几种替代的接口设计，并展示了加权求和接口对许多任务来说并不是最优的。特别是，文章显示，一个深度与上游模型深度成对数增长的卷积接口，一致地优于许多其他接口设计。\n\n搜索结果来自：\n[2406.12209] Interface Design for Self-Supervised Speech Models - https://arxiv.org/abs/2406.12209"
    }
]