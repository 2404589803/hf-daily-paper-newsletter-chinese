[
  {
    "title": "Inference-Time Scaling for Diffusion Models beyond Scaling Denoising\n  Steps",
    "summary": "Generative models have made significant impacts across various domains,\nlargely due to their ability to scale during training by increasing data,\ncomputational resources, and model size, a phenomenon characterized by the\nscaling laws. Recent research has begun to explore inference-time scaling\nbehavior in Large Language Models (LLMs), revealing how performance can further\nimprove with additional computation during inference. Unlike LLMs, diffusion\nmodels inherently possess the flexibility to adjust inference-time computation\nvia the number of denoising steps, although the performance gains typically\nflatten after a few dozen. In this work, we explore the inference-time scaling\nbehavior of diffusion models beyond increasing denoising steps and investigate\nhow the generation performance can further improve with increased computation.\nSpecifically, we consider a search problem aimed at identifying better noises\nfor the diffusion sampling process. We structure the design space along two\naxes: the verifiers used to provide feedback, and the algorithms used to find\nbetter noise candidates. Through extensive experiments on class-conditioned and\ntext-conditioned image generation benchmarks, our findings reveal that\nincreasing inference-time compute leads to substantial improvements in the\nquality of samples generated by diffusion models, and with the complicated\nnature of images, combinations of the components in the framework can be\nspecifically chosen to conform with different application scenario.",
    "translation": "标题：超越去噪步长扩展的扩散模型推理时扩展\n\n摘要：生成模型在各个领域产生了重大影响，这主要归功于它们通过增加数据、计算资源和模型规模在训练过程中扩展的能力，这一现象由扩展定律所表征。最近的研究开始探索大型语言模型（LLMs）在推理时的扩展行为，揭示了在推理过程中通过增加计算量如何进一步提升性能。与LLMs不同，扩散模型天生具备通过调整去噪步数来灵活调整推理时计算的能力，尽管性能提升通常在几十步后趋于平缓。在本研究中，我们探索了扩散模型在增加去噪步数之外的推理时扩展行为，并研究了如何通过增加计算量进一步提升生成性能。具体而言，我们考虑了一个旨在为扩散采样过程识别更好噪声的搜索问题。我们沿着两个轴构建设计空间：用于提供反馈的验证器，以及用于寻找更好噪声候选的算法。通过在类条件和文本条件图像生成基准上的广泛实验，我们的研究结果表明，增加推理时计算量显著提高了扩散模型生成样本的质量，并且由于图像的复杂性，可以特别选择框架中的组件组合以适应不同的应用场景。",
    "url": "https://huggingface.co/papers/2501.09732",
    "arxiv_url": "https://arxiv.org/abs/2501.09732"
  },
  {
    "title": "OmniThink: Expanding Knowledge Boundaries in Machine Writing through\n  Thinking",
    "summary": "Machine writing with large language models often relies on\nretrieval-augmented generation. However, these approaches remain confined\nwithin the boundaries of the model's predefined scope, limiting the generation\nof content with rich information. Specifically, vanilla-retrieved information\ntends to lack depth, utility, and suffers from redundancy, which negatively\nimpacts the quality of generated articles, leading to shallow, repetitive, and\nunoriginal outputs. To address these issues, we propose OmniThink, a machine\nwriting framework that emulates the human-like process of iterative expansion\nand reflection. The core idea behind OmniThink is to simulate the cognitive\nbehavior of learners as they progressively deepen their knowledge of the\ntopics. Experimental results demonstrate that OmniThink improves the knowledge\ndensity of generated articles without compromising metrics such as coherence\nand depth. Human evaluations and expert feedback further highlight the\npotential of OmniThink to address real-world challenges in the generation of\nlong-form articles.",
    "translation": "标题：OmniThink：通过思维扩展机器写作的知识边界\n\n摘要：使用大型语言模型进行机器写作通常依赖于检索增强生成。然而，这些方法仍然局限于模型预定义的范围之内，限制了生成内容丰富的信息。具体而言，传统的检索信息往往缺乏深度和实用性，并且存在冗余问题，这对生成文章的质量产生了负面影响，导致文章内容浅显、重复且缺乏原创性。为了解决这些问题，我们提出了OmniThink，一种模拟人类迭代扩展和反思过程的机器写作框架。OmniThink的核心思想是模拟学习者在逐步加深对主题理解过程中的认知行为。实验结果表明，OmniThink在不损害连贯性和深度等指标的情况下，提高了生成文章的知识密度。人类评估和专家反馈进一步凸显了OmniThink在解决生成长篇文章实际挑战中的潜力。",
    "url": "https://huggingface.co/papers/2501.09751",
    "arxiv_url": "https://arxiv.org/abs/2501.09751"
  },
  {
    "title": "Exploring the Inquiry-Diagnosis Relationship with Advanced Patient\n  Simulators",
    "summary": "Online medical consultation (OMC) restricts doctors to gathering patient\ninformation solely through inquiries, making the already complex sequential\ndecision-making process of diagnosis even more challenging. Recently, the rapid\nadvancement of large language models has demonstrated a significant potential\nto transform OMC. However, most studies have primarily focused on improving\ndiagnostic accuracy under conditions of relatively sufficient information,\nwhile paying limited attention to the \"inquiry\" phase of the consultation\nprocess. This lack of focus has left the relationship between \"inquiry\" and\n\"diagnosis\" insufficiently explored. In this paper, we first extract real\npatient interaction strategies from authentic doctor-patient conversations and\nuse these strategies to guide the training of a patient simulator that closely\nmirrors real-world behavior. By inputting medical records into our patient\nsimulator to simulate patient responses, we conduct extensive experiments to\nexplore the relationship between \"inquiry\" and \"diagnosis\" in the consultation\nprocess. Experimental results demonstrate that inquiry and diagnosis adhere to\nthe Liebig's law: poor inquiry quality limits the effectiveness of diagnosis,\nregardless of diagnostic capability, and vice versa. Furthermore, the\nexperiments reveal significant differences in the inquiry performance of\nvarious models. To investigate this phenomenon, we categorize the inquiry\nprocess into four types: (1) chief complaint inquiry; (2) specification of\nknown symptoms; (3) inquiry about accompanying symptoms; and (4) gathering\nfamily or medical history. We analyze the distribution of inquiries across the\nfour types for different models to explore the reasons behind their significant\nperformance differences. We plan to open-source the weights and related code of\nour patient simulator at https://github.com/LIO-H-ZEN/PatientSimulator.",
    "translation": "标题：探索高级患者模拟器中的问诊-诊断关系\n\n摘要：在线医疗咨询（OMC）限制医生仅通过问诊收集患者信息，这使得原本复杂的诊断顺序决策过程更加具有挑战性。近年来，大型语言模型的快速发展显示出改变OMC的巨大潜力。然而，大多数研究主要集中在相对充足信息条件下提高诊断准确性，而对咨询过程中的“问诊”阶段关注有限。这种关注不足导致“问诊”与“诊断”之间的关系未能得到充分探索。在本文中，我们首先从真实的医患对话中提取患者互动策略，并使用这些策略指导训练一个高度模拟现实行为的患者模拟器。通过将病历输入我们的患者模拟器以模拟患者反应，我们进行了大量实验来探索咨询过程中“问诊”与“诊断”之间的关系。实验结果表明，问诊和诊断遵循李比希定律：无论诊断能力如何，问诊质量差都会限制诊断效果，反之亦然。此外，实验揭示了各种模型在问诊表现上的显著差异。为了探究这一现象，我们将问诊过程分为四种类型：（1）主诉问诊；（2）已知症状的详细说明；（3）伴随症状的问诊；（4）收集家族或病史。我们分析了不同模型在这四种类型中的问诊分布，以探讨其表现显著差异的原因。我们计划在https://github.com/LIO-H-ZEN/PatientSimulator上开源我们的患者模拟器的权重和相关代码。",
    "url": "https://huggingface.co/papers/2501.09484",
    "arxiv_url": "https://arxiv.org/abs/2501.09484"
  },
  {
    "title": "Learnings from Scaling Visual Tokenizers for Reconstruction and\n  Generation",
    "summary": "Visual tokenization via auto-encoding empowers state-of-the-art image and\nvideo generative models by compressing pixels into a latent space. Although\nscaling Transformer-based generators has been central to recent advances, the\ntokenizer component itself is rarely scaled, leaving open questions about how\nauto-encoder design choices influence both its objective of reconstruction and\ndownstream generative performance. Our work aims to conduct an exploration of\nscaling in auto-encoders to fill in this blank. To facilitate this exploration,\nwe replace the typical convolutional backbone with an enhanced Vision\nTransformer architecture for Tokenization (ViTok). We train ViTok on\nlarge-scale image and video datasets far exceeding ImageNet-1K, removing data\nconstraints on tokenizer scaling. We first study how scaling the auto-encoder\nbottleneck affects both reconstruction and generation -- and find that while it\nis highly correlated with reconstruction, its relationship with generation is\nmore complex. We next explored the effect of separately scaling the\nauto-encoders' encoder and decoder on reconstruction and generation\nperformance. Crucially, we find that scaling the encoder yields minimal gains\nfor either reconstruction or generation, while scaling the decoder boosts\nreconstruction but the benefits for generation are mixed. Building on our\nexploration, we design ViTok as a lightweight auto-encoder that achieves\ncompetitive performance with state-of-the-art auto-encoders on ImageNet-1K and\nCOCO reconstruction tasks (256p and 512p) while outperforming existing\nauto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5x\nfewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstrates\ncompetitive performance on image generation for ImageNet-1K and sets new\nstate-of-the-art benchmarks for class-conditional video generation on UCF-101.",
    "translation": "标题：视觉分词器在重建与生成任务中的规模化探索\n\n摘要：通过自编码实现的视觉分词技术，通过将像素压缩至潜在空间，为当前最先进的图像和视频生成模型提供了强大支持。尽管基于Transformer的生成器的规模化是近期进展的核心，但分词器组件本身却很少被规模化，这留下了关于自编码器设计选择如何影响其重建目标及下游生成性能的开放性问题。我们的工作旨在探索自编码器的规模化，以填补这一空白。为了促进这一探索，我们用增强的视觉Transformer架构（ViTok）替代了典型的卷积骨干网络。我们在远超ImageNet-1K的大规模图像和视频数据集上训练ViTok，消除了分词器规模化的数据限制。我们首先研究了自编码器瓶颈的规模化如何影响重建和生成，发现虽然它与重建高度相关，但其与生成的关系更为复杂。接着，我们探讨了分别规模化自编码器的编码器和解码器对重建和生成性能的影响。关键的是，我们发现规模化编码器对重建或生成的增益微乎其微，而规模化解码器则提升了重建性能，但对生成的好处则参差不齐。基于我们的探索，我们设计了ViTok作为一个轻量级自编码器，在ImageNet-1K和COCO重建任务（256p和512p）上实现了与最先进自编码器相竞争的性能，同时在UCF-101的16帧128p视频重建上超越了现有自编码器，所有这些都使用了2-5倍更少的FLOPs。当与扩散Transformer结合时，ViTok在ImageNet-1K的图像生成上展示了竞争力，并在UCF-101的类条件视频生成上设定了新的最先进基准。",
    "url": "https://huggingface.co/papers/2501.09755",
    "arxiv_url": "https://arxiv.org/abs/2501.09755"
  },
  {
    "title": "RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation",
    "summary": "Generative AI systems like foundation models (FMs) must align well with human\nvalues to ensure their behavior is helpful and trustworthy. While Reinforcement\nLearning from Human Feedback (RLHF) has shown promise for optimizing model\nperformance using human judgments, existing RLHF pipelines predominantly rely\non immediate feedback, which can fail to accurately reflect the downstream\nimpact of an interaction on users' utility. We demonstrate that feedback based\non evaluators' foresight estimates of downstream consequences systematically\ninduces Goodhart's Law dynamics, incentivizing misaligned behaviors like\nsycophancy and deception and ultimately degrading user outcomes. To alleviate\nthis, we propose decoupling evaluation from prediction by refocusing RLHF on\nhindsight feedback. Our theoretical analysis reveals that conditioning\nevaluator feedback on downstream observations mitigates misalignment and\nimproves expected human utility, even when these observations are simulated by\nthe AI system itself. To leverage this insight in a practical alignment\nalgorithm, we introduce Reinforcement Learning from Hindsight Simulation\n(RLHS), which first simulates plausible consequences and then elicits feedback\nto assess what behaviors were genuinely beneficial in hindsight. We apply RLHS\nto two widely-employed online and offline preference optimization methods --\nProximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) --\nand show empirically that misalignment is significantly reduced with both\nmethods. Through an online human user study, we show that RLHS consistently\noutperforms RLHF in helping users achieve their goals and earns higher\nsatisfaction ratings, despite being trained solely with simulated hindsight\nfeedback. These results underscore the importance of focusing on long-term\nconsequences, even simulated ones, to mitigate misalignment in RLHF.",
    "translation": "标题：RLHS：通过事后模拟缓解RLHF中的错位问题\n\n摘要：生成式人工智能系统（如基础模型，FMs）必须与人类价值观良好对齐，以确保其行为是有帮助且可信的。尽管基于人类反馈的强化学习（RLHF）在利用人类判断优化模型性能方面显示出潜力，但现有的RLHF流程主要依赖于即时反馈，这可能无法准确反映交互对用户效用的下游影响。我们证明，基于评估者对下游后果的预见性估计的反馈会系统地引发古德哈特定律动态，激励诸如谄媚和欺骗等错位行为，并最终降低用户结果。为了缓解这一问题，我们提出通过将RLHF重新聚焦于事后反馈来解耦评估与预测。我们的理论分析表明，将评估者反馈条件化于下游观察可以缓解错位并提高预期的人类效用，即使这些观察是由AI系统本身模拟的。为了在实际的对齐算法中利用这一见解，我们引入了基于事后模拟的强化学习（RLHS），该方法首先模拟可能的下游后果，然后引出反馈以评估哪些行为在事后看来是真正有益的。我们将RLHS应用于两种广泛使用的在线和离线偏好优化方法——近端策略优化（PPO）和直接偏好优化（DPO）——并通过实验证明，这两种方法中的错位问题均显著减少。通过一项在线人类用户研究，我们表明，尽管RLHS仅使用模拟的事后反馈进行训练，但在帮助用户实现目标和获得更高满意度评分方面，RLHS始终优于RLHF。这些结果强调了关注长期后果（即使是模拟的）对于缓解RLHF中的错位问题的重要性。",
    "url": "https://huggingface.co/papers/2501.08617",
    "arxiv_url": "https://arxiv.org/abs/2501.08617"
  },
  {
    "title": "SynthLight: Portrait Relighting with Diffusion Model by Learning to\n  Re-render Synthetic Faces",
    "summary": "We introduce SynthLight, a diffusion model for portrait relighting. Our\napproach frames image relighting as a re-rendering problem, where pixels are\ntransformed in response to changes in environmental lighting conditions. Using\na physically-based rendering engine, we synthesize a dataset to simulate this\nlighting-conditioned transformation with 3D head assets under varying lighting.\nWe propose two training and inference strategies to bridge the gap between the\nsynthetic and real image domains: (1) multi-task training that takes advantage\nof real human portraits without lighting labels; (2) an inference time\ndiffusion sampling procedure based on classifier-free guidance that leverages\nthe input portrait to better preserve details. Our method generalizes to\ndiverse real photographs and produces realistic illumination effects, including\nspecular highlights and cast shadows, while preserving the subject's identity.\nOur quantitative experiments on Light Stage data demonstrate results comparable\nto state-of-the-art relighting methods. Our qualitative results on in-the-wild\nimages showcase rich and unprecedented illumination effects. Project Page:\nhttps://vrroom.github.io/synthlight/",
    "translation": "标题：SynthLight：通过重新渲染合成人脸学习的扩散模型肖像重光照\n\n摘要：我们介绍了SynthLight，一种用于肖像重光照的扩散模型。我们的方法将图像重光照视为重新渲染问题，其中像素会根据环境光照条件的变化进行转换。使用基于物理的渲染引擎，我们合成了一个数据集，以模拟在不同光照条件下使用3D头部资产进行的光照条件转换。我们提出了两种训练和推理策略，以弥合合成图像和真实图像领域之间的差距：（1）利用无光照标签的真实人像进行多任务训练；（2）基于无分类器引导的推理时间扩散采样过程，利用输入肖像更好地保留细节。我们的方法能够推广到各种真实照片，并产生逼真的光照效果，包括镜面高光和投射阴影，同时保留主体的身份。我们在光舞台数据上的定量实验展示了与最先进的重光照方法相当的结果。我们在野外图像上的定性结果展示了丰富且前所未有的光照效果。项目页面：https://vrroom.github.io/synthlight/",
    "url": "https://huggingface.co/papers/2501.09756",
    "arxiv_url": "https://arxiv.org/abs/2501.09756"
  },
  {
    "title": "FAST: Efficient Action Tokenization for Vision-Language-Action Models",
    "summary": "Autoregressive sequence models, such as Transformer-based vision-language\naction (VLA) policies, can be tremendously effective for capturing complex and\ngeneralizable robotic behaviors. However, such models require us to choose a\ntokenization of our continuous action signals, which determines how the\ndiscrete symbols predicted by the model map to continuous robot actions. We\nfind that current approaches for robot action tokenization, based on simple\nper-dimension, per-timestep binning schemes, typically perform poorly when\nlearning dexterous skills from high-frequency robot data. To address this\nchallenge, we propose a new compression-based tokenization scheme for robot\nactions, based on the discrete cosine transform. Our tokenization approach,\nFrequency-space Action Sequence Tokenization (FAST), enables us to train\nautoregressive VLAs for highly dexterous and high-frequency tasks where\nstandard discretization methods fail completely. Based on FAST, we release\nFAST+, a universal robot action tokenizer, trained on 1M real robot action\ntrajectories. It can be used as a black-box tokenizer for a wide range of robot\naction sequences, with diverse action spaces and control frequencies. Finally,\nwe show that, when combined with the pi0 VLA, our method can scale to training\non 10k hours of robot data and match the performance of diffusion VLAs, while\nreducing training time by up to 5x.",
    "translation": "标题：FAST：面向视觉-语言-动作模型的高效动作标记化方法\n\n摘要：自回归序列模型，如基于Transformer的视觉-语言-动作（VLA）策略，在捕捉复杂且可泛化的机器人行为方面非常有效。然而，这类模型要求我们对连续动作信号进行标记化选择，这决定了模型预测的离散符号如何映射到连续的机器人动作。我们发现，当前基于简单的每维度、每时间步分箱方案的机器人动作标记化方法，在处理高频机器人数据以学习灵巧技能时通常表现不佳。为了解决这一挑战，我们提出了一种基于离散余弦变换的压缩式机器人动作标记化方案。我们的标记化方法，即频域动作序列标记化（FAST），使我们能够训练自回归VLA模型，以应对标准离散化方法完全失效的高灵巧性和高频率任务。基于FAST，我们发布了FAST+，一个在100万条真实机器人动作轨迹上训练的通用机器人动作标记器。它可以作为黑箱标记器，适用于各种机器人动作序列，涵盖不同的动作空间和控制频率。最后，我们展示了当与pi0 VLA结合时，我们的方法能够扩展到在1万小时机器人数据上进行训练，并与扩散VLA的性能相匹配，同时将训练时间减少多达5倍。",
    "url": "https://huggingface.co/papers/2501.09747",
    "arxiv_url": "https://arxiv.org/abs/2501.09747"
  },
  {
    "title": "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with\n  Large Language Models",
    "summary": "Language has long been conceived as an essential tool for human reasoning.\nThe breakthrough of Large Language Models (LLMs) has sparked significant\nresearch interest in leveraging these models to tackle complex reasoning tasks.\nResearchers have moved beyond simple autoregressive token generation by\nintroducing the concept of \"thought\" -- a sequence of tokens representing\nintermediate steps in the reasoning process. This innovative paradigm enables\nLLMs' to mimic complex human reasoning processes, such as tree search and\nreflective thinking. Recently, an emerging trend of learning to reason has\napplied reinforcement learning (RL) to train LLMs to master reasoning\nprocesses. This approach enables the automatic generation of high-quality\nreasoning trajectories through trial-and-error search algorithms, significantly\nexpanding LLMs' reasoning capacity by providing substantially more training\ndata. Furthermore, recent studies demonstrate that encouraging LLMs to \"think\"\nwith more tokens during test-time inference can further significantly boost\nreasoning accuracy. Therefore, the train-time and test-time scaling combined to\nshow a new research frontier -- a path toward Large Reasoning Model. The\nintroduction of OpenAI's o1 series marks a significant milestone in this\nresearch direction. In this survey, we present a comprehensive review of recent\nprogress in LLM reasoning. We begin by introducing the foundational background\nof LLMs and then explore the key technical components driving the development\nof large reasoning models, with a focus on automated data construction,\nlearning-to-reason techniques, and test-time scaling. We also analyze popular\nopen-source projects at building large reasoning models, and conclude with open\nchallenges and future research directions.",
    "translation": "标题：迈向大规模推理模型：基于大语言模型的强化推理研究综述\n\n摘要：语言长期以来被视为人类推理的重要工具。大语言模型（LLMs）的突破引发了利用这些模型解决复杂推理任务的广泛研究兴趣。研究者们已超越了简单的自回归标记生成，引入了“思维”概念——即代表推理过程中间步骤的标记序列。这一创新范式使LLMs能够模拟复杂的人类推理过程，如树搜索和反思性思维。最近，一种新兴的“学习推理”趋势应用强化学习（RL）来训练LLMs掌握推理过程。该方法通过试错搜索算法自动生成高质量的推理轨迹，显著扩展了LLMs的推理能力，并提供了更多的训练数据。此外，最近的研究表明，在测试时推理过程中鼓励LLMs使用更多标记进行“思考”可以进一步提高推理准确性。因此，训练时和测试时的扩展相结合，展示了一个新的研究前沿——通向大规模推理模型的路径。OpenAI的o1系列的引入标志着这一研究方向的重要里程碑。在本综述中，我们全面回顾了LLM推理的最新进展。我们首先介绍了LLMs的基础背景，然后探讨了推动大规模推理模型发展的关键技术组件，重点关注自动数据构建、学习推理技术和测试时扩展。我们还分析了构建大规模推理模型的流行开源项目，并总结了开放挑战和未来研究方向。",
    "url": "https://huggingface.co/papers/2501.09686",
    "arxiv_url": "https://arxiv.org/abs/2501.09686"
  },
  {
    "title": "AnyStory: Towards Unified Single and Multiple Subject Personalization in\n  Text-to-Image Generation",
    "summary": "Recently, large-scale generative models have demonstrated outstanding\ntext-to-image generation capabilities. However, generating high-fidelity\npersonalized images with specific subjects still presents challenges,\nespecially in cases involving multiple subjects. In this paper, we propose\nAnyStory, a unified approach for personalized subject generation. AnyStory not\nonly achieves high-fidelity personalization for single subjects, but also for\nmultiple subjects, without sacrificing subject fidelity. Specifically, AnyStory\nmodels the subject personalization problem in an \"encode-then-route\" manner. In\nthe encoding step, AnyStory utilizes a universal and powerful image encoder,\ni.e., ReferenceNet, in conjunction with CLIP vision encoder to achieve\nhigh-fidelity encoding of subject features. In the routing step, AnyStory\nutilizes a decoupled instance-aware subject router to accurately perceive and\npredict the potential location of the corresponding subject in the latent\nspace, and guide the injection of subject conditions. Detailed experimental\nresults demonstrate the excellent performance of our method in retaining\nsubject details, aligning text descriptions, and personalizing for multiple\nsubjects. The project page is at https://aigcdesigngroup.github.io/AnyStory/ .",
    "translation": "标题：AnyStory：面向文本到图像生成中统一单主体与多主体个性化的研究\n\n摘要：近年来，大规模生成模型在文本到图像生成方面展现了卓越的能力。然而，生成具有特定主体的高保真个性化图像仍面临挑战，尤其是在涉及多个主体的情况下。本文提出AnyStory，一种统一的主体个性化生成方法。AnyStory不仅实现了单主体的高保真个性化，还实现了多主体的高保真个性化，且不牺牲主体保真度。具体而言，AnyStory以“编码-路由”的方式对主体个性化问题进行建模。在编码步骤中，AnyStory利用一个通用且强大的图像编码器，即ReferenceNet，结合CLIP视觉编码器，实现主体特征的高保真编码。在路由步骤中，AnyStory利用解耦的实例感知主体路由器，准确感知并预测潜在空间中对应主体的可能位置，并指导主体条件的注入。详细的实验结果展示了我们的方法在保留主体细节、对齐文本描述以及多主体个性化方面的优异性能。项目页面位于https://aigcdesigngroup.github.io/AnyStory/。",
    "url": "https://huggingface.co/papers/2501.09503",
    "arxiv_url": "https://arxiv.org/abs/2501.09503"
  },
  {
    "title": "CaPa: Carve-n-Paint Synthesis for Efficient 4K Textured Mesh Generation",
    "summary": "The synthesis of high-quality 3D assets from textual or visual inputs has\nbecome a central objective in modern generative modeling. Despite the\nproliferation of 3D generation algorithms, they frequently grapple with\nchallenges such as multi-view inconsistency, slow generation times, low\nfidelity, and surface reconstruction problems. While some studies have\naddressed some of these issues, a comprehensive solution remains elusive. In\nthis paper, we introduce CaPa, a carve-and-paint framework that\ngenerates high-fidelity 3D assets efficiently. CaPa employs a two-stage\nprocess, decoupling geometry generation from texture synthesis. Initially, a 3D\nlatent diffusion model generates geometry guided by multi-view inputs, ensuring\nstructural consistency across perspectives. Subsequently, leveraging a novel,\nmodel-agnostic Spatially Decoupled Attention, the framework synthesizes\nhigh-resolution textures (up to 4K) for a given geometry. Furthermore, we\npropose a 3D-aware occlusion inpainting algorithm that fills untextured\nregions, resulting in cohesive results across the entire model. This pipeline\ngenerates high-quality 3D assets in less than 30 seconds, providing\nready-to-use outputs for commercial applications. Experimental results\ndemonstrate that CaPa excels in both texture fidelity and geometric stability,\nestablishing a new standard for practical, scalable 3D asset generation.",
    "translation": "标题：CaPa：用于高效4K纹理网格生成的雕刻与绘制合成方法\n\n摘要：从文本或视觉输入合成高质量的3D资产已成为现代生成建模的核心目标。尽管3D生成算法层出不穷，但它们经常面临多视角不一致、生成速度慢、保真度低以及表面重建问题等挑战。虽然一些研究已经解决了部分问题，但全面的解决方案仍然难以实现。本文介绍了CaPa，一种雕刻与绘制框架，能够高效生成高保真度的3D资产。CaPa采用两阶段过程，将几何生成与纹理合成解耦。首先，一个3D潜在扩散模型在多视角输入的指导下生成几何，确保跨视角的结构一致性。随后，利用一种新颖的、模型无关的空间解耦注意力机制，该框架为给定几何合成了高分辨率纹理（最高可达4K）。此外，我们提出了一种3D感知的遮挡修复算法，用于填充未纹理化的区域，从而在整个模型中实现一致的结果。该流程在不到30秒的时间内生成高质量的3D资产，为商业应用提供即用型输出。实验结果表明，CaPa在纹理保真度和几何稳定性方面均表现出色，为实用、可扩展的3D资产生成树立了新标准。",
    "url": "https://huggingface.co/papers/2501.09433",
    "arxiv_url": "https://arxiv.org/abs/2501.09433"
  }
]