{
  "title": "OmniManip: Towards General Robotic Manipulation via Object-Centric\n  Interaction Primitives as Spatial Constraints",
  "summary": "The development of general robotic systems capable of manipulating in\nunstructured environments is a significant challenge. While Vision-Language\nModels(VLM) excel in high-level commonsense reasoning, they lack the\nfine-grained 3D spatial understanding required for precise manipulation tasks.\nFine-tuning VLM on robotic datasets to create Vision-Language-Action\nModels(VLA) is a potential solution, but it is hindered by high data collection\ncosts and generalization issues. To address these challenges, we propose a\nnovel object-centric representation that bridges the gap between VLM's\nhigh-level reasoning and the low-level precision required for manipulation. Our\nkey insight is that an object's canonical space, defined by its functional\naffordances, provides a structured and semantically meaningful way to describe\ninteraction primitives, such as points and directions. These primitives act as\na bridge, translating VLM's commonsense reasoning into actionable 3D spatial\nconstraints. In this context, we introduce a dual closed-loop, open-vocabulary\nrobotic manipulation system: one loop for high-level planning through primitive\nresampling, interaction rendering and VLM checking, and another for low-level\nexecution via 6D pose tracking. This design ensures robust, real-time control\nwithout requiring VLM fine-tuning. Extensive experiments demonstrate strong\nzero-shot generalization across diverse robotic manipulation tasks,\nhighlighting the potential of this approach for automating large-scale\nsimulation data generation.",
  "translation": "标题：OmniManip：通过以对象为中心的交互原语作为空间约束实现通用机器人操作\n\n摘要：开发能够在非结构化环境中进行操作的通用机器人系统是一个重大挑战。尽管视觉语言模型（VLM）在高层常识推理方面表现出色，但它们缺乏精确操作任务所需的细粒度三维空间理解能力。通过在机器人数据集上微调VLM以创建视觉语言动作模型（VLA）是一种潜在的解决方案，但这种方法受到高数据收集成本和泛化问题的阻碍。为了应对这些挑战，我们提出了一种新颖的以对象为中心的表示方法，该方法弥合了VLM的高层推理与操作所需的低层精度之间的差距。我们的关键见解是，由对象的功能可供性定义的规范空间提供了一种结构化和语义上有意义的方式来描述交互原语，例如点和方向。这些原语充当桥梁，将VLM的常识推理转化为可操作的三维空间约束。在此背景下，我们引入了一种双闭环、开放词汇的机器人操作系统：一个环路通过原语重采样、交互渲染和VLM检查进行高层规划，另一个环路通过6D姿态跟踪进行低层执行。这种设计确保了无需VLM微调的鲁棒实时控制。大量实验展示了在各种机器人操作任务中的强零样本泛化能力，突显了该方法在自动化大规模仿真数据生成方面的潜力。",
  "url": "https://huggingface.co/papers/2501.03841"
}